<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>SICP</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="./src/styles/docco.min.css">
        <link rel="stylesheet" href="./run_button_style.css">
        <link rel="stylesheet" href="./custom.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">SICP</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<p><a href="book-Z-H-4.html#%_toc_%_chap_Temp_2">Foreword</a></p>
<p>Educators, generals, dieticians, psychologists, and parents program.
Armies, students, and some societies are programmed. An assault on large
problems employs a succession of programs, most of which spring into
existence en route. These programs are rife with issues that appear to
be particular to the problem at hand. To appreciate programming as an
intellectual activity in its own right you must turn to computer
programming; you must read and write computer programs -- many of them.
It doesn't matter much what the programs are about or what applications
they serve. What does matter is how well they perform and how smoothly
they fit with other programs in the creation of still greater programs.
The programmer must seek both perfection of part and adequacy of
collection. In this book the use of ``program'' is focused on the
creation, execution, and study of programs written in a dialect of Lisp
for execution on a digital computer. Using Lisp we restrict or limit not
what we may program, but only the notation for our program descriptions.</p>
<p>Our traffic with the subject matter of this book involves us with three
foci of phenomena: the human mind, collections of computer programs, and
the computer. Every computer program is a model, hatched in the mind, of
a real or mental process. These processes, arising from human experience
and thought, are huge in number, intricate in detail, and at any time
only partially understood. They are modeled to our permanent
satisfaction rarely by our computer programs. Thus even though our
programs are carefully handcrafted discrete collections of symbols,
mosaics of interlocking functions, they continually evolve: we change
them as our perception of the model deepens, enlarges, generalizes until
the model ultimately attains a metastable place within still another
model with which we struggle. The source of the exhilaration associated
with computer programming is the continual unfolding within the mind and
on the computer of mechanisms expressed as programs and the explosion of
perception they generate. If art interprets our dreams, the computer
executes them in the guise of programs!</p>
<p>For all its power, the computer is a harsh taskmaster. Its programs must
be correct, and what we wish to say must be said accurately in every
detail. As in every other symbolic activity, we become convinced of
program truth through argument. Lisp itself can be assigned a semantics
(another model, by the way), and if a program's function can be
specified, say, in the predicate calculus, the proof methods of logic
can be used to make an acceptable correctness argument. Unfortunately,
as programs get large and complicated, as they almost always do, the
adequacy, consistency, and correctness of the specifications themselves
become open to doubt, so that complete formal arguments of correctness
seldom accompany large programs. Since large programs grow from small
ones, it is crucial that we develop an arsenal of standard program
structures of whose correctness we have become sure -- we call them
idioms -- and learn to combine them into larger structures using
organizational techniques of proven value. These techniques are treated
at length in this book, and understanding them is essential to
participation in the Promethean enterprise called programming. More than
anything else, the uncovering and mastery of powerful organizational
techniques accelerates our ability to create large, significant
programs. Conversely, since writing large programs is very taxing, we
are stimulated to invent new methods of reducing the mass of function
and detail to be fitted into large programs.</p>
<p>Unlike programs, computers must obey the laws of physics. If they wish
to perform rapidly -- a few nanoseconds per state change -- they must
transmit electrons only small distances (at most 1
[^1^/[2]{.small}]{.small} feet). The heat generated by the huge number
of devices so concentrated in space has to be removed. An exquisite
engineering art has been developed balancing between multiplicity of
function and density of devices. In any event, hardware always operates
at a level more primitive than that at which we care to program. The
processes that transform our Lisp programs to ``machine'' programs
are themselves abstract models which we program. Their study and
creation give a great deal of insight into the organizational programs
associated with programming arbitrary models. Of course the computer
itself can be so modeled. Think of it: the behavior of the smallest
physical switching element is modeled by quantum mechanics described by
differential equations whose detailed behavior is captured by numerical
approximations represented in computer programs executing on computers
composed of <code>...</code>!</p>
<p>It is not merely a matter of tactical convenience to separately identify
the three foci. Even though, as they say, it's all in the head, this
logical separation induces an acceleration of symbolic traffic between
these foci whose richness, vitality, and potential is exceeded in human
experience only by the evolution of life itself. At best, relationships
between the foci are metastable. The computers are never large enough or
fast enough. Each breakthrough in hardware technology leads to more
massive programming enterprises, new organizational principles, and an
enrichment of abstract models. Every reader should ask himself
periodically ``Toward what end, toward what end?'' -- but do not
ask it too often lest you pass up the fun of programming for the
constipation of bittersweet philosophy.</p>
<p>Among the programs we write, some (but never enough) perform a precise
mathematical function such as sorting or finding the maximum of a
sequence of numbers, determining primality, or finding the square root.
We call such programs algorithms, and a great deal is known of their
optimal behavior, particularly with respect to the two important
parameters of execution time and data storage requirements. A programmer
should acquire good algorithms and idioms. Even though some programs
resist precise specifications, it is the responsibility of the
programmer to estimate, and always to attempt to improve, their
performance.</p>
<p>Lisp is a survivor, having been in use for about a quarter of a century.
Among the active programming languages only Fortran has had a longer
life. Both languages have supported the programming needs of important
areas of application, Fortran for scientific and engineering computation
and Lisp for artificial intelligence. These two areas continue to be
important, and their programmers are so devoted to these two languages
that Lisp and Fortran may well continue in active use for at least
another quarter-century.</p>
<p>Lisp changes. The Scheme dialect used in this text has evolved from the
original Lisp and differs from the latter in several important ways,
including static scoping for variable binding and permitting functions
to yield functions as values. In its semantic structure Scheme is as
closely akin to Algol 60 as to early Lisps. Algol 60, never to be an
active language again, lives on in the genes of Scheme and Pascal. It
would be difficult to find two languages that are the communicating coin
of two more different cultures than those gathered around these two
languages. Pascal is for building pyramids -- imposing, breathtaking,
static structures built by armies pushing heavy blocks into place. Lisp
is for building organisms -- imposing, breathtaking, dynamic structures
built by squads fitting fluctuating myriads of simpler organisms into
place. The organizing principles used are the same in both cases, except
for one extraordinarily important difference: The discretionary
exportable functionality entrusted to the individual Lisp programmer is
more than an order of magnitude greater than that to be found within
Pascal enterprises. Lisp programs inflate libraries with functions whose
utility transcends the application that produced them. The list, Lisp's
native data structure, is largely responsible for such growth of
utility. The simple structure and natural applicability of lists are
reflected in functions that are amazingly nonidiosyncratic. In Pascal
the plethora of declarable data structures induces a specialization
within functions that inhibits and penalizes casual cooperation. It is
better to have 100 functions operate on one data structure than to have
10 functions operate on 10 data structures. As a result the pyramid must
stand unchanged for a millennium; the organism must evolve or perish.</p>
<p>To illustrate this difference, compare the treatment of material and
exercises within this book with that in any first-course text using
Pascal. Do not labor under the illusion that this is a text digestible
at MIT only, peculiar to the breed found there. It is precisely what a
serious book on programming Lisp must be, no matter who the student is
or where it is used.</p>
<p>Note that this is a text about programming, unlike most Lisp books,
which are used as a preparation for work in artificial intelligence.
After all, the critical programming concerns of software engineering and
artificial intelligence tend to coalesce as the systems under
investigation become larger. This explains why there is such growing
interest in Lisp outside of artificial intelligence.</p>
<p>As one would expect from its goals, artificial intelligence research
generates many significant programming problems. In other programming
cultures this spate of problems spawns new languages. Indeed, in any
very large programming task a useful organizing principle is to control
and isolate traffic within the task modules via the invention of
language. These languages tend to become less primitive as one
approaches the boundaries of the system where we humans interact most
often. As a result, such systems contain complex language-processing
functions replicated many times. Lisp has such a simple syntax and
semantics that parsing can be treated as an elementary task. Thus
parsing technology plays almost no role in Lisp programs, and the
construction of language processors is rarely an impediment to the rate
of growth and change of large Lisp systems. Finally, it is this very
simplicity of syntax and semantics that is responsible for the burden
and freedom borne by all Lisp programmers. No Lisp program of any size
beyond a few lines can be written without being saturated with
discretionary functions. Invent and fit; have fits and reinvent! We
toast the Lisp programmer who pens his thoughts within nests of
parentheses.</p>
<p>Alan J. Perlis<br />
New Haven, Connecticut</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="preface-to-the-second-edition"><a class="header" href="#preface-to-the-second-edition">Preface to the Second Edition</a></h1>
<div class="info">
Is it possible that software is not like anything else, that it is meant to be discarded: that the whole point is to always see it as a soap bubble?
<p>Alan J. Perlis</p>
</div>
The material in this book has been the basis of MIT's entry-level computer science subject since 1980. We had been teaching this material for four years when the first edition was published, and twelve more years have elapsed until the appearance of this second edition. We are pleased that our work has been widely adopted and incorporated into other texts. We have seen our students take the ideas and programs in this book and build them in as the core of new computer systems and languages. In literal realization of an ancient Talmudic pun, our students have become our builders. We are lucky to have such capable students and such accomplished builders.
<p>In preparing this edition, we have incorporated hundreds of clarifications suggested by our own teaching experience and the comments of colleagues at MIT and elsewhere. We have redesigned most of the major programming systems in the book, including the generic-arithmetic system, the interpreters, the register-machine simulator, and the compiler; and we have rewritten all the program examples to ensure that any Scheme implementation conforming to the IEEE Scheme standard (IEEE 1990) will be able to run the code.</p>
<p>This edition emphasizes several new themes. The most important of these is the central role played by different approaches to dealing with time in computational models: objects with state, concurrent programming, functional programming, lazy evaluation, and nondeterministic programming. We have included new sections on concurrency and nondeterminism, and we have tried to integrate this theme throughout the book.</p>
<p>The first edition of the book closely followed the syllabus of our MIT one-semester subject. With all the new material in the second edition, it will not be possible to cover everything in a single semester, so the instructor will have to pick and choose. In our own teaching, we sometimes skip the section on logic programming (section 4.4), we have students use the register-machine simulator but we do not cover its implementation (section 5.2), and we give only a cursory overview of the compiler (section 5.5). Even so, this is still an intense course. Some instructors may wish to cover only the first three or four chapters, leaving the other material for subsequent courses.</p>
<p>The World-Wide-Web site mitpress.mit.edu/sicp provides support for users of this book. This includes programs from the book, sample programming assignments, supplementary materials, and downloadable implementations of the Scheme dialect of Lisp.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="preface-to-the-first-edition"><a class="header" href="#preface-to-the-first-edition">Preface to the First Edition</a></h1>
<p>A computer is like a violin. You can imagine a novice trying first a phonograph and then a violin. The latter, he says, sounds terrible. That is the argument we have heard from our humanists and most of our computer scientists. Computer programs are good, they say, for particular purposes, but they aren't flexible. Neither is a violin, or a typewriter, until you learn how to use it.</p>
<p>Marvin Minsky, ``Why Programming Is a Good
Medium for Expressing Poorly-Understood and Sloppily-Formulated Ideas''</p>
<p>The Structure and Interpretation of Computer Programs'' is the entry-level subject in computer science at the Massachusetts Institute of Technology. It is required of all students at MIT who major in electrical engineering or in computer science, as one-fourth of the
common core curriculum,'' which also includes two subjects on circuits and linear systems and a subject on the design of digital systems. We have been involved in the development of this subject since 1978, and we have taught this material in its present form since the fall of 1980 to between 600 and 700 students each year. Most of these students have had little or no prior formal training in computation, although many have played with computers a bit and a few have had extensive programming or hardware-design experience.</p>
<p>Our design of this introductory computer-science subject reflects two major concerns. First, we want to establish the idea that a computer language is not just a way of getting a computer to perform operations but rather that it is a novel formal medium for expressing ideas about methodology. Thus, programs must be written for people to read, and only incidentally for machines to execute. Second, we believe that the essential material to be addressed by a subject at this level is not the syntax of particular programming-language constructs, nor clever algorithms for computing particular functions efficiently, nor even the mathematical analysis of algorithms and the foundations of computing, but rather the techniques used to control the intellectual complexity of large software systems.</p>
<p>Our goal is that students who complete this subject should have a good feel for the elements of style and the aesthetics of programming. They should have command of the major techniques for controlling complexity in a large system. They should be capable of reading a 50-page-long program, if it is written in an exemplary style. They should know what not to read, and what they need not understand at any moment. They should feel secure about modifying a program, retaining the spirit and style of the original author.</p>
<p>These skills are by no means unique to computer programming. The techniques we teach and draw upon are common to all of engineering design. We control complexity by building abstractions that hide details when appropriate. We control complexity by establishing conventional interfaces that enable us to construct systems by combining standard, well-understood pieces in a ``mix and match'' way. We control complexity by establishing new languages for describing a design, each of which emphasizes particular aspects of the design and deemphasizes others.</p>
<p>Underlying our approach to this subject is our conviction that
computer science'' is not a science and that its significance has little to do with computers. The computer revolution is a revolution in the way we think and in the way we express what we think. The essence of this change is the emergence of what might best be called procedural epistemology -- the study of the structure of knowledge from an imperative point of view, as opposed to the more declarative point of view taken by classical mathematical subjects. Mathematics provides a framework for dealing precisely with notions of ``what is.'' Computation provides a framework for dealing precisely with notions of
how to.''</p>
<p>In teaching our material we use a dialect of the programming language Lisp. We never formally teach the language, because we don't have to. We just use it, and students pick it up in a few days. This is one great advantage of Lisp-like languages: They have very few ways of forming compound expressions, and almost no syntactic structure. All of the formal properties can be covered in an hour, like the rules of chess. After a short time we forget about syntactic details of the language (because there are none) and get on with the real issues -- figuring out what we want to compute, how we will decompose problems into manageable parts, and how we will work on the parts. Another advantage of Lisp is that it supports (but does not enforce) more of the large-scale strategies for modular decomposition of programs than any other language we know. We can make procedural and data abstractions, we can use higher-order functions to capture common patterns of usage, we can model local state using assignment and data mutation, we can link parts of a program with streams and delayed evaluation, and we can easily implement embedded languages. All of this is embedded in an interactive environment with excellent support for incremental program design, construction, testing, and debugging. We thank all the generations of Lisp wizards, starting with John McCarthy, who have fashioned a fine tool of unprecedented power and elegance.</p>
<p>Scheme, the dialect of Lisp that we use, is an attempt to bring together the power and elegance of Lisp and Algol. From Lisp we take the metalinguistic power that derives from the simple syntax, the uniform representation of programs as data objects, and the garbage-collected heap-allocated data. From Algol we take lexical scoping and block structure, which are gifts from the pioneers of programming-language design who were on the Algol committee. We wish to cite John Reynolds and Peter Landin for their insights into the relationship of Church's lambda calculus to the structure of programming languages. We also recognize our debt to the mathematicians who scouted out this territory decades before computers appeared on the scene. These pioneers include Alonzo Church, Barkley Rosser, Stephen Kleene, and Haskell Curry.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h1>
<p>We would like to thank the many people who have helped us develop this book and this curriculum.</p>
<p>Our subject is a clear intellectual descendant of ``6.231,'' a wonderful subject on programming linguistics and the lambda calculus taught at MIT in the late 1960s by Jack Wozencraft and Arthur Evans, Jr.</p>
<p>We owe a great debt to Robert Fano, who reorganized MIT's introductory curriculum in electrical engineering and computer science to emphasize the principles of engineering design. He led us in starting out on this enterprise and wrote the first set of subject notes from which this book evolved.</p>
<p>Much of the style and aesthetics of programming that we try to teach were developed in conjunction with Guy Lewis Steele Jr., who collaborated with Gerald Jay Sussman in the initial development of the Scheme language. In addition, David Turner, Peter Henderson, Dan Friedman, David Wise, and Will Clinger have taught us many of the techniques of the functional programming community that appear in this book.</p>
<p>Joel Moses taught us about structuring large systems. His experience with the Macsyma system for symbolic computation provided the insight that one should avoid complexities of control and concentrate on organizing the data to reflect the real structure of the world being modeled.</p>
<p>Marvin Minsky and Seymour Papert formed many of our attitudes about programming and its place in our intellectual lives. To them we owe the understanding that computation provides a means of expression for exploring ideas that would otherwise be too complex to deal with precisely. They emphasize that a student's ability to write and modify programs provides a powerful medium in which exploring becomes a natural activity.</p>
<p>We also strongly agree with Alan Perlis that programming is lots of fun and we had better be careful to support the joy of programming. Part of this joy derives from observing great masters at work. We are fortunate to have been apprentice programmers at the feet of Bill Gosper and Richard Greenblatt.</p>
<p>It is difficult to identify all the people who have contributed to the development of our curriculum. We thank all the lecturers, recitation instructors, and tutors who have worked with us over the past fifteen years and put in many extra hours on our subject, especially Bill Siebert, Albert Meyer, Joe Stoy, Randy Davis, Louis Braida, Eric Grimson, Rod Brooks, Lynn Stein, and Peter Szolovits. We would like to specially acknowledge the outstanding teaching contributions of Franklyn Turbak, now at Wellesley; his work in undergraduate instruction set a standard that we can all aspire to. We are grateful to Jerry Saltzer and Jim Miller for helping us grapple with the mysteries of concurrency, and to Peter Szolovits and David McAllester for their contributions to the exposition of nondeterministic evaluation in chapter 4.</p>
<p>Many people have put in significant effort presenting this material at other universities. Some of the people we have worked closely with are Jacob Katzenelson at the Technion, Hardy Mayer at the University of California at Irvine, Joe Stoy at Oxford, Elisha Sacks at Purdue, and Jan Komorowski at the Norwegian University of Science and Technology. We are exceptionally proud of our colleagues who have received major teaching awards for their adaptations of this subject at other universities, including Kenneth Yip at Yale, Brian Harvey at the University of California at Berkeley, and Dan Huttenlocher at Cornell.</p>
<p>Al Moyé arranged for us to teach this material to engineers at Hewlett-Packard, and for the production of videotapes of these lectures. We would like to thank the talented instructors -- in particular Jim Miller, Bill Siebert, and Mike Eisenberg -- who have designed continuing education courses incorporating these tapes and taught them at universities and industry all over the world.</p>
<p>Many educators in other countries have put in significant work translating the first edition. Michel Briand, Pierre Chamard, and André Pic produced a French edition; Susanne Daniels-Herold produced a German edition; and Fumio Motoyoshi produced a Japanese edition. We do not know who produced the Chinese edition, but we consider it an honor to have been selected as the subject of an ``unauthorized'' translation.</p>
<p>It is hard to enumerate all the people who have made technical contributions to the development of the Scheme systems we use for instructional purposes. In addition to Guy Steele, principal wizards have included Chris Hanson, Joe Bowbeer, Jim Miller, Guillermo Rozas, and Stephen Adams. Others who have put in significant time are Richard Stallman, Alan Bawden, Kent Pitman, Jon Taft, Neil Mayle, John Lamping, Gwyn Osnos, Tracy Larrabee, George Carrette, Soma Chaudhuri, Bill Chiarchiaro, Steven Kirsch, Leigh Klotz, Wayne Noss, Todd Cass, Patrick O'Donnell, Kevin Theobald, Daniel Weise, Kenneth Sinclair, Anthony Courtemanche, Henry M. Wu, Andrew Berlin, and Ruth Shyu.</p>
<p>Beyond the MIT implementation, we would like to thank the many people who worked on the IEEE Scheme standard, including William Clinger and Jonathan Rees, who edited the R4RS, and Chris Haynes, David Bartley, Chris Hanson, and Jim Miller, who prepared the IEEE standard.</p>
<p>Dan Friedman has been a long-time leader of the Scheme community. The community's broader work goes beyond issues of language design to encompass significant educational innovations, such as the high-school curriculum based on EdScheme by Schemer's Inc., and the wonderful books by Mike Eisenberg and by Brian Harvey and Matthew Wright.</p>
<p>We appreciate the work of those who contributed to making this a real book, especially Terry Ehling, Larry Cohen, and Paul Bethge at the MIT Press. Ella Mazel found the wonderful cover image. For the second edition we are particularly grateful to Bernard and Ella Mazel for help with the book design, and to David Jones, TEX wizard extraordinaire. We also are indebted to those readers who made penetrating comments on the new draft: Jacob Katzenelson, Hardy Mayer, Jim Miller, and especially Brian Harvey, who did unto this book as Julie did unto his book Simply Scheme.</p>
<p>Finally, we would like to acknowledge the support of the organizations that have encouraged this work over the years, including support from Hewlett-Packard, made possible by Ira Goldstein and Joel Birnbaum, and support from DARPA, made possible by Bob Kahn.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<p><a href="book-Z-H-4.html#%_toc_%_chap_Temp_849">References</a></p>
<p>Abelson, Harold, Andrew Berlin, Jacob Katzenelson, William McAllister,
Guillermo Rozas, Gerald Jay Sussman, and Jack Wisdom. 1992. The
Supercomputer Toolkit: A general framework for special-purpose
computing. <em>International Journal of High-Speed Electronics</em>
3(3):337-361.</p>
<p>Allen, John. 1978. <em>Anatomy of Lisp.</em> New York: McGraw-Hill.</p>
<p>ANSI X3.226-1994. <em>American National Standard for Information Systems
-- Programming Language -- Common Lisp.</em></p>
<p>Appel, Andrew W. 1987. Garbage collection can be faster than stack
allocation. <em>Information Processing Letters</em> 25(4):275-279.</p>
<p>Backus, John. 1978. Can programming be liberated from the von Neumann
style? <em>Communications of the ACM</em> 21(8):613-641.</p>
<p>Baker, Henry G., Jr. 1978. List processing in real time on a serial
computer. <em>Communications of the ACM</em> 21(4):280-293.</p>
<p>Batali, John, Neil Mayle, Howard Shrobe, Gerald Jay Sussman, and Daniel
Weise. 1982. The Scheme-81 architecture -- System and chip. In
<em>Proceedings of the MIT Conference on Advanced Research in VLSI,</em> edited
by Paul Penfield, Jr. Dedham, MA: Artech House.</p>
<p>Borning, Alan. 1977. ThingLab -- An object-oriented system for building
simulations using constraints. In <em>Proceedings of the 5th International
Joint Conference on Artificial Intelligence.</em></p>
<p>Borodin, Alan, and Ian Munro. 1975. <em>The Computational Complexity of
Algebraic and Numeric Problems.</em> New York: American Elsevier.</p>
<p>Chaitin, Gregory J. 1975. Randomness and mathematical proof. <em>Scientific
American</em> 232(5):47-52.</p>
<p>Church, Alonzo. 1941. <em>The Calculi of Lambda-Conversion.</em> Princeton,
N.J.: Princeton University Press.</p>
<p>Clark, Keith L. 1978. Negation as failure. In <em>Logic and Data Bases.</em>
New York: Plenum Press, pp. 293-322.</p>
<p>Clinger, William. 1982. Nondeterministic call by need is neither lazy
nor by name. In <em>Proceedings of the ACM Symposium on Lisp and Functional
Programming,</em> pp. 226-234.</p>
<p>Clinger, William, and Jonathan Rees. 1991. Macros that work. In
<em>Proceedings of the 1991 ACM Conference on Principles of Programming
Languages,</em> pp. 155-162.</p>
<p>Colmerauer A., H. Kanoui, R. Pasero, and P. Roussel. 1973. Un système de
communication homme-machine en français. Technical report, Groupe
Intelligence Artificielle, Université d'Aix Marseille, Luminy.</p>
<p>Cormen, Thomas, Charles Leiserson, and Ronald Rivest. 1990.
<em>Introduction to Algorithms.</em> Cambridge, MA: MIT Press.</p>
<p>Darlington, John, Peter Henderson, and David Turner. 1982. <em>Functional
Programming and Its Applications.</em> New York: Cambridge University Press.</p>
<p>Dijkstra, Edsger W. 1968a. The structure of the ``THE''
multiprogramming system. <em>Communications of the ACM</em> 11(5):341-346.</p>
<p>Dijkstra, Edsger W. 1968b. Cooperating sequential processes. In
<em>Programming Languages</em>, edited by F. Genuys. New York: Academic Press,
pp. 43-112.</p>
<p>Dinesman, Howard P. 1968. <em>Superior Mathematical Puzzles</em>. New York:
Simon and Schuster.</p>
<p>deKleer, Johan, Jon Doyle, Guy Steele, and Gerald J. Sussman. 1977.
AMORD: Explicit control of reasoning. In <em>Proceedings of the ACM
Symposium on Artificial Intelligence and Programming Languages,</em> pp.
116-125.</p>
<p>Doyle, Jon. 1979. A truth maintenance system. <em>Artificial Intelligence</em>
12:231-272.</p>
<p>Feigenbaum, Edward, and Howard Shrobe. 1993. The Japanese National Fifth
Generation Project: Introduction, survey, and evaluation. In <em>Future
Generation Computer Systems,</em> vol. 9, pp. 105-117.</p>
<p>Feeley, Marc. 1986. Deux approches à l'implantation du language Scheme.
Masters thesis, Université de Montréal.</p>
<p>Feeley, Marc and Guy Lapalme. 1987. Using closures for code generation.
<em>Journal of Computer Languages</em> 12(1):47-66.</p>
<p>Feller, William. 1957. <em>An Introduction to Probability Theory and Its
Applications,</em> volume 1. New York: John Wiley &amp; Sons.</p>
<p>Fenichel, R., and J. Yochelson. 1969. A Lisp garbage collector for
virtual memory computer systems. <em>Communications of the ACM</em>
12(11):611-612.</p>
<p>Floyd, Robert. 1967. Nondeterministic algorithms. <em>JACM,</em> 14(4):636-644.</p>
<p>Forbus, Kenneth D., and Johan deKleer. 1993. <em>Building Problem Solvers.</em>
Cambridge, MA: MIT Press.</p>
<p>Friedman, Daniel P., and David S. Wise. 1976. CONS should not evaluate
its arguments. In <em>Automata, Languages, and Programming: Third
International Colloquium,</em> edited by S. Michaelson and R. Milner, pp.
257-284.</p>
<p>Friedman, Daniel P., Mitchell Wand, and Christopher T. Haynes. 1992.
<em>Essentials of Programming Languages.</em> Cambridge, MA: MIT
Press/McGraw-Hill.</p>
<p>Gabriel, Richard P. 1988. The Why of <em>Y</em>. <em>Lisp Pointers</em> 2(2):15-25.</p>
<p>Goldberg, Adele, and David Robson. 1983. <em>Smalltalk-80: The Language and
Its Implementation.</em> Reading, MA: Addison-Wesley.</p>
<p>Gordon, Michael, Robin Milner, and Christopher Wadsworth. 1979.
<em>Edinburgh LCF.</em> Lecture Notes in Computer Science, volume 78. New York:
Springer-Verlag.</p>
<p>Gray, Jim, and Andreas Reuter. 1993. <em>Transaction Processing: Concepts
and Models.</em> San Mateo, CA: Morgan-Kaufman.</p>
<p>Green, Cordell. 1969. Application of theorem proving to problem solving.
In <em>Proceedings of the International Joint Conference on Artificial
Intelligence,</em> pp. 219-240.</p>
<p>Green, Cordell, and Bertram Raphael. 1968. The use of theorem-proving
techniques in question-answering systems. In <em>Proceedings of the ACM
National Conference,</em> pp. 169-181.</p>
<p>Griss, Martin L. 1981. Portable Standard Lisp, a brief overview. Utah
Symbolic Computation Group Operating Note 58, University of Utah.</p>
<p>Guttag, John V. 1977. Abstract data types and the development of data
structures. <em>Communications of the ACM</em> 20(6):397-404.</p>
<p>Hamming, Richard W. 1980. <em>Coding and Information Theory.</em> Englewood
Cliffs, N.J.: Prentice-Hall.</p>
<p>Hanson, Christopher P. 1990. Efficient stack allocation for
tail-recursive languages. In <em>Proceedings of ACM Conference on Lisp and
Functional Programming,</em> pp. 106-118.</p>
<p>Hanson, Christopher P. 1991. A syntactic closures macro facility. <em>Lisp
Pointers,</em> 4(3).</p>
<p>Hardy, Godfrey H. 1921. Srinivasa Ramanujan. <em>Proceedings of the London
Mathematical Society</em> XIX(2).</p>
<p>Hardy, Godfrey H., and E. M. Wright. 1960. <em>An Introduction to the
Theory of Numbers.</em> 4th edition. New York: Oxford University Press.</p>
<p>Havender, J. 1968. Avoiding deadlocks in multi-tasking systems. <em>IBM
Systems Journal</em> 7(2):74-84.</p>
<p>Hearn, Anthony C. 1969. Standard Lisp. Technical report AIM-90,
Artificial Intelligence Project, Stanford University.</p>
<p>Henderson, Peter. 1980. <em>Functional Programming: Application and
Implementation.</em> Englewood Cliffs, N.J.: Prentice-Hall.</p>
<p>Henderson. Peter. 1982. Functional Geometry. In <em>Conference Record of
the 1982 ACM Symposium on Lisp and Functional Programming,</em> pp. 179-187.</p>
<p>Hewitt, Carl E. 1969. PLANNER: A language for proving theorems in
robots. In <em>Proceedings of the International Joint Conference on
Artificial Intelligence,</em> pp. 295-301.</p>
<p>Hewitt, Carl E. 1977. Viewing control structures as patterns of passing
messages. <em>Journal of Artificial Intelligence</em> 8(3):323-364.</p>
<p>Hoare, C. A. R. 1972. Proof of correctness of data representations.
<em>Acta Informatica</em> 1(1).</p>
<p>Hodges, Andrew. 1983. <em>Alan Turing: The Enigma.</em> New York: Simon and
Schuster.</p>
<p>Hofstadter, Douglas R. 1979. <em>Gödel, Escher, Bach: An Eternal Golden
Braid.</em> New York: Basic Books.</p>
<p>Hughes, R. J. M. 1990. Why functional programming matters. In <em>Research
Topics in Functional Programming</em>, edited by David Turner. Reading, MA:
Addison-Wesley, pp. 17-42.</p>
<p>IEEE Std 1178-1990. 1990. <em>IEEE Standard for the Scheme Programming
Language.</em></p>
<p>Ingerman, Peter, Edgar Irons, Kirk Sattley, and Wallace Feurzeig;
assisted by M. Lind, Herbert Kanner, and Robert Floyd. 1960. THUNKS: A
way of compiling procedure statements, with some comments on procedure
declarations. Unpublished manuscript. (Also, private communication from
Wallace Feurzeig.)</p>
<p>Kaldewaij, Anne. 1990. <em>Programming: The Derivation of Algorithms.</em> New
York: Prentice-Hall.</p>
<p>Kohlbecker, Eugene Edmund, Jr. 1986. Syntactic extensions in the
programming language Lisp. Ph.D. thesis, Indiana University.</p>
<p>Konopasek, Milos, and Sundaresan Jayaraman. 1984. <em>The TK!Solver Book: A
Guide to Problem-Solving in Science, Engineering, Business, and
Education.</em> Berkeley, CA: Osborne/McGraw-Hill.</p>
<p>Knuth, Donald E. 1973. <em>Fundamental Algorithms.</em> Volume 1 of <em>The Art of
Computer Programming.</em> 2nd edition. Reading, MA: Addison-Wesley.</p>
<p>Knuth, Donald E. 1981. <em>Seminumerical Algorithms.</em> Volume 2 of <em>The Art
of Computer Programming.</em> 2nd edition. Reading, MA: Addison-Wesley.</p>
<p>Kowalski, Robert. 1973. Predicate logic as a programming language.
Technical report 70, Department of Computational Logic, School of
Artificial Intelligence, University of Edinburgh.</p>
<p>Kowalski, Robert. 1979. <em>Logic for Problem Solving.</em> New York:
North-Holland.</p>
<p>Lamport, Leslie. 1978. Time, clocks, and the ordering of events in a
distributed system. <em>Communications of the ACM</em> 21(7):558-565.</p>
<p>Lampson, Butler, J. J. Horning, R. London, J. G. Mitchell, and G. K.
Popek. 1981. Report on the programming language Euclid. Technical
report, Computer Systems Research Group, University of Toronto.</p>
<p>Landin, Peter. 1965. A correspondence between Algol 60 and Church's
lambda notation: Part I. <em>Communications of the ACM</em> 8(2):89-101.</p>
<p>Lieberman, Henry, and Carl E. Hewitt. 1983. A real-time garbage
collector based on the lifetimes of objects. <em>Communications of the ACM</em>
26(6):419-429.</p>
<p>Liskov, Barbara H., and Stephen N. Zilles. 1975. Specification
techniques for data abstractions. <em>IEEE Transactions on Software
Engineering</em> 1(1):7-19.</p>
<p>McAllester, David Allen. 1978. A three-valued truth-maintenance system.
Memo 473, MIT Artificial Intelligence Laboratory.</p>
<p>McAllester, David Allen. 1980. An outlook on truth maintenance. Memo
551, MIT Artificial Intelligence Laboratory.</p>
<p>McCarthy, John. 1960. Recursive functions of symbolic expressions and
their computation by machine. <em>Communications of the ACM</em> 3(4):184-195.</p>
<p>McCarthy, John. 1967. A basis for a mathematical theory of computation.
In <em>Computer Programing and Formal Systems</em>, edited by P. Braffort and
D. Hirschberg. North-Holland.</p>
<p>McCarthy, John. 1978. The history of Lisp. In <em>Proceedings of the ACM
SIGPLAN Conference on the History of Programming Languages.</em></p>
<p>McCarthy, John, P. W. Abrahams, D. J. Edwards, T. P. Hart, and M. I.
Levin. 1965. <em>Lisp 1.5 Programmer's Manual.</em> 2nd edition. Cambridge,
MA: MIT Press.</p>
<p>McDermott, Drew, and Gerald Jay Sussman. 1972. Conniver reference
manual. Memo 259, MIT Artificial Intelligence Laboratory.</p>
<p>Miller, Gary L. 1976. Riemann's Hypothesis and tests for primality.
<em>Journal of Computer and System Sciences</em> 13(3):300-317.</p>
<p>Miller, James S., and Guillermo J. Rozas. 1994. Garbage collection is
fast, but a stack is faster. Memo 1462, MIT Artificial Intelligence
Laboratory.</p>
<p>Moon, David. 1978. MacLisp reference manual, Version 0. Technical
report, MIT Laboratory for Computer Science.</p>
<p>Moon, David, and Daniel Weinreb. 1981. Lisp machine manual. Technical
report, MIT Artificial Intelligence Laboratory.</p>
<p>Morris, J. H., Eric Schmidt, and Philip Wadler. 1980. Experience with an
applicative string processing language. In <em>Proceedings of the 7th
Annual ACM SIGACT/SIGPLAN Symposium on the Principles of Programming
Languages.</em></p>
<p>Phillips, Hubert. 1934. <em>The Sphinx Problem Book</em>. London: Faber and
Faber.</p>
<p>Pitman, Kent. 1983. The revised MacLisp Manual (Saturday evening
edition). Technical report 295, MIT Laboratory for Computer Science.</p>
<p>Rabin, Michael O. 1980. Probabilistic algorithm for testing primality.
<em>Journal of Number Theory</em> 12:128-138.</p>
<p>Raymond, Eric. 1993. <em>The New Hacker's Dictionary.</em> 2nd edition.
Cambridge, MA: MIT Press.</p>
<p>Raynal, Michel. 1986. <em>Algorithms for Mutual Exclusion.</em> Cambridge, MA:
MIT Press.</p>
<p>Rees, Jonathan A., and Norman I. Adams IV. 1982. T: A dialect of Lisp
or, lambda: The ultimate software tool. In <em>Conference Record of the
1982 ACM Symposium on Lisp and Functional Programming,</em> pp. 114-122.</p>
<p>Rees, Jonathan, and William Clinger (eds). 1991. The revised^4^ report
on the algorithmic language Scheme. <em>Lisp Pointers,</em> 4(3).</p>
<p>Rivest, Ronald, Adi Shamir, and Leonard Adleman. 1977. A method for
obtaining digital signatures and public-key cryptosystems. Technical
memo LCS/TM82, MIT Laboratory for Computer Science.</p>
<p>Robinson, J. A. 1965. A machine-oriented logic based on the resolution
principle. <em>Journal of the ACM</em> 12(1):23.</p>
<p>Robinson, J. A. 1983. Logic programming -- Past, present, and future.
<em>New Generation Computing</em> 1:107-124.</p>
<p>Spafford, Eugene H. 1989. The Internet Worm: Crisis and aftermath.
<em>Communications of the ACM</em> 32(6):678-688.</p>
<p>Steele, Guy Lewis, Jr. 1977. Debunking the ``expensive procedure
call'' myth. In <em>Proceedings of the National Conference of the ACM,</em>
pp. 153-62.</p>
<p>Steele, Guy Lewis, Jr. 1982. An overview of Common Lisp. In <em>Proceedings
of the ACM Symposium on Lisp and Functional Programming,</em> pp. 98-107.</p>
<p>Steele, Guy Lewis, Jr. 1990. <em>Common Lisp: The Language.</em> 2nd edition.
Digital Press.</p>
<p>Steele, Guy Lewis, Jr., and Gerald Jay Sussman. 1975. Scheme: An
interpreter for the extended lambda calculus. Memo 349, MIT Artificial
Intelligence Laboratory.</p>
<p>Steele, Guy Lewis, Jr., Donald R. Woods, Raphael A. Finkel, Mark R.
Crispin, Richard M. Stallman, and Geoffrey S. Goodfellow. 1983. <em>The
Hacker's Dictionary.</em> New York: Harper &amp; Row.</p>
<p>Stoy, Joseph E. 1977. <em>Denotational Semantics.</em> Cambridge, MA: MIT
Press.</p>
<p>Sussman, Gerald Jay, and Richard M. Stallman. 1975. Heuristic techniques
in computer-aided circuit analysis. <em>IEEE Transactions on Circuits and
Systems</em> CAS-22(11):857-865.</p>
<p>Sussman, Gerald Jay, and Guy Lewis Steele Jr. 1980. Constraints -- A
language for expressing almost-hierachical descriptions. <em>AI Journal</em>
14:1-39.</p>
<p>Sussman, Gerald Jay, and Jack Wisdom. 1992. Chaotic evolution of the
solar system. <em>Science</em> 257:256-262.</p>
<p>Sussman, Gerald Jay, Terry Winograd, and Eugene Charniak. 1971.
Microplanner reference manual. Memo 203A, MIT Artificial Intelligence
Laboratory.</p>
<p>Sutherland, Ivan E. 1963. SKETCHPAD: A man-machine graphical
communication system. Technical report 296, MIT Lincoln Laboratory.</p>
<p>Teitelman, Warren. 1974. Interlisp reference manual. Technical report,
Xerox Palo Alto Research Center.</p>
<p>Thatcher, James W., Eric G. Wagner, and Jesse B. Wright. 1978. Data type
specification: Parameterization and the power of specification
techniques. In <em>Conference Record of the Tenth Annual ACM Symposium on
Theory of Computing</em>, pp. 119-132. Turner, David. 1981. The future of
applicative languages. In <em>Proceedings of the 3rd European Conference on
Informatics,</em> Lecture Notes in Computer Science, volume 123. New York:
Springer-Verlag, pp. 334-348.</p>
<p>Wand, Mitchell. 1980. Continuation-based program transformation
strategies. <em>Journal of the ACM</em> 27(1):164-180.</p>
<p>Waters, Richard C. 1979. A method for analyzing loop programs. <em>IEEE
Transactions on Software Engineering</em> 5(3):237-247.</p>
<p>Winograd, Terry. 1971. Procedures as a representation for data in a
computer program for understanding natural language. Technical report AI
TR-17, MIT Artificial Intelligence Laboratory.</p>
<p>Winston, Patrick. 1992. <em>Artificial Intelligence</em>. 3rd edition. Reading,
MA: Addison-Wesley.</p>
<p>Zabih, Ramin, David McAllester, and David Chapman. 1987.
Non-deterministic Lisp with dependency-directed backtracking. <em>AAAI-87</em>,
pp. 59-64.</p>
<p>Zippel, Richard. 1979. Probabilistic algorithms for sparse polynomials.
Ph.D. dissertation, Department of Electrical Engineering and Computer
Science, MIT.</p>
<p>Zippel, Richard. 1993. <em>Effective Polynomial Computation.</em> Boston, MA:
Kluwer Academic Publishers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<p><a href="book-Z-H-4.html#%_toc_%_chap_Temp_850">List of Exercises</a></p>
<p><a href="book-Z-H-10.html#%_thm_1.1">1.1</a><br />
<a href="book-Z-H-10.html#%_thm_1.2">1.2</a><br />
<a href="book-Z-H-10.html#%_thm_1.3">1.3</a><br />
<a href="book-Z-H-10.html#%_thm_1.4">1.4</a><br />
<a href="book-Z-H-10.html#%_thm_1.5">1.5</a><br />
<a href="book-Z-H-10.html#%_thm_1.6">1.6</a><br />
<a href="book-Z-H-10.html#%_thm_1.7">1.7</a><br />
<a href="book-Z-H-10.html#%_thm_1.8">1.8</a><br />
<a href="book-Z-H-11.html#%_thm_1.9">1.9</a><br />
<a href="book-Z-H-11.html#%_thm_1.10">1.10</a><br />
<a href="book-Z-H-11.html#%_thm_1.11">1.11</a><br />
<a href="book-Z-H-11.html#%_thm_1.12">1.12</a><br />
<a href="book-Z-H-11.html#%_thm_1.13">1.13</a><br />
<a href="book-Z-H-11.html#%_thm_1.14">1.14</a><br />
<a href="book-Z-H-11.html#%_thm_1.15">1.15</a><br />
<a href="book-Z-H-11.html#%_thm_1.16">1.16</a><br />
<a href="book-Z-H-11.html#%_thm_1.17">1.17</a><br />
<a href="book-Z-H-11.html#%_thm_1.18">1.18</a><br />
<a href="book-Z-H-11.html#%_thm_1.19">1.19</a><br />
<a href="book-Z-H-11.html#%_thm_1.20">1.20</a><br />
<a href="book-Z-H-11.html#%_thm_1.21">1.21</a><br />
<a href="book-Z-H-11.html#%_thm_1.22">1.22</a><br />
<a href="book-Z-H-11.html#%_thm_1.23">1.23</a><br />
<a href="book-Z-H-11.html#%_thm_1.24">1.24</a><br />
<a href="book-Z-H-11.html#%_thm_1.25">1.25</a><br />
<a href="book-Z-H-11.html#%_thm_1.26">1.26</a><br />
<a href="book-Z-H-11.html#%_thm_1.27">1.27</a><br />
<a href="book-Z-H-11.html#%_thm_1.28">1.28</a><br />
<a href="book-Z-H-12.html#%_thm_1.29">1.29</a><br />
<a href="book-Z-H-12.html#%_thm_1.30">1.30</a><br />
<a href="book-Z-H-12.html#%_thm_1.31">1.31</a><br />
<a href="book-Z-H-12.html#%_thm_1.32">1.32</a><br />
<a href="book-Z-H-12.html#%_thm_1.33">1.33</a><br />
<a href="book-Z-H-12.html#%_thm_1.34">1.34</a><br />
<a href="book-Z-H-12.html#%_thm_1.35">1.35</a><br />
<a href="book-Z-H-12.html#%_thm_1.36">1.36</a><br />
<a href="book-Z-H-12.html#%_thm_1.37">1.37</a><br />
<a href="book-Z-H-12.html#%_thm_1.38">1.38</a><br />
<a href="book-Z-H-12.html#%_thm_1.39">1.39</a><br />
<a href="book-Z-H-12.html#%_thm_1.40">1.40</a><br />
<a href="book-Z-H-12.html#%_thm_1.41">1.41</a><br />
<a href="book-Z-H-12.html#%_thm_1.42">1.42</a><br />
<a href="book-Z-H-12.html#%_thm_1.43">1.43</a><br />
<a href="book-Z-H-12.html#%_thm_1.44">1.44</a><br />
<a href="book-Z-H-12.html#%_thm_1.45">1.45</a><br />
<a href="book-Z-H-12.html#%_thm_1.46">1.46</a><br />
<a href="book-Z-H-14.html#%_thm_2.1">2.1</a><br />
<a href="book-Z-H-14.html#%_thm_2.2">2.2</a><br />
<a href="book-Z-H-14.html#%_thm_2.3">2.3</a><br />
<a href="book-Z-H-14.html#%_thm_2.4">2.4</a><br />
<a href="book-Z-H-14.html#%_thm_2.5">2.5</a><br />
<a href="book-Z-H-14.html#%_thm_2.6">2.6</a><br />
<a href="book-Z-H-14.html#%_thm_2.7">2.7</a><br />
<a href="book-Z-H-14.html#%_thm_2.8">2.8</a><br />
<a href="book-Z-H-14.html#%_thm_2.9">2.9</a><br />
<a href="book-Z-H-14.html#%_thm_2.10">2.10</a><br />
<a href="book-Z-H-14.html#%_thm_2.11">2.11</a><br />
<a href="book-Z-H-14.html#%_thm_2.12">2.12</a><br />
<a href="book-Z-H-14.html#%_thm_2.13">2.13</a><br />
<a href="book-Z-H-14.html#%_thm_2.14">2.14</a><br />
<a href="book-Z-H-14.html#%_thm_2.15">2.15</a><br />
<a href="book-Z-H-14.html#%_thm_2.16">2.16</a><br />
<a href="book-Z-H-15.html#%_thm_2.17">2.17</a><br />
<a href="book-Z-H-15.html#%_thm_2.18">2.18</a><br />
<a href="book-Z-H-15.html#%_thm_2.19">2.19</a><br />
<a href="book-Z-H-15.html#%_thm_2.20">2.20</a><br />
<a href="book-Z-H-15.html#%_thm_2.21">2.21</a><br />
<a href="book-Z-H-15.html#%_thm_2.22">2.22</a><br />
<a href="book-Z-H-15.html#%_thm_2.23">2.23</a><br />
<a href="book-Z-H-15.html#%_thm_2.24">2.24</a><br />
<a href="book-Z-H-15.html#%_thm_2.25">2.25</a><br />
<a href="book-Z-H-15.html#%_thm_2.26">2.26</a><br />
<a href="book-Z-H-15.html#%_thm_2.27">2.27</a><br />
<a href="book-Z-H-15.html#%_thm_2.28">2.28</a><br />
<a href="book-Z-H-15.html#%_thm_2.29">2.29</a><br />
<a href="book-Z-H-15.html#%_thm_2.30">2.30</a><br />
<a href="book-Z-H-15.html#%_thm_2.31">2.31</a><br />
<a href="book-Z-H-15.html#%_thm_2.32">2.32</a><br />
<a href="book-Z-H-15.html#%_thm_2.33">2.33</a><br />
<a href="book-Z-H-15.html#%_thm_2.34">2.34</a><br />
<a href="book-Z-H-15.html#%_thm_2.35">2.35</a><br />
<a href="book-Z-H-15.html#%_thm_2.36">2.36</a><br />
<a href="book-Z-H-15.html#%_thm_2.37">2.37</a><br />
<a href="book-Z-H-15.html#%_thm_2.38">2.38</a><br />
<a href="book-Z-H-15.html#%_thm_2.39">2.39</a><br />
<a href="book-Z-H-15.html#%_thm_2.40">2.40</a><br />
<a href="book-Z-H-15.html#%_thm_2.41">2.41</a><br />
<a href="book-Z-H-15.html#%_thm_2.42">2.42</a><br />
<a href="book-Z-H-15.html#%_thm_2.43">2.43</a><br />
<a href="book-Z-H-15.html#%_thm_2.44">2.44</a><br />
<a href="book-Z-H-15.html#%_thm_2.45">2.45</a><br />
<a href="book-Z-H-15.html#%_thm_2.46">2.46</a><br />
<a href="book-Z-H-15.html#%_thm_2.47">2.47</a><br />
<a href="book-Z-H-15.html#%_thm_2.48">2.48</a><br />
<a href="book-Z-H-15.html#%_thm_2.49">2.49</a><br />
<a href="book-Z-H-15.html#%_thm_2.50">2.50</a><br />
<a href="book-Z-H-15.html#%_thm_2.51">2.51</a><br />
<a href="book-Z-H-15.html#%_thm_2.52">2.52</a><br />
<a href="book-Z-H-16.html#%_thm_2.53">2.53</a><br />
<a href="book-Z-H-16.html#%_thm_2.54">2.54</a><br />
<a href="book-Z-H-16.html#%_thm_2.55">2.55</a><br />
<a href="book-Z-H-16.html#%_thm_2.56">2.56</a><br />
<a href="book-Z-H-16.html#%_thm_2.57">2.57</a><br />
<a href="book-Z-H-16.html#%_thm_2.58">2.58</a><br />
<a href="book-Z-H-16.html#%_thm_2.59">2.59</a><br />
<a href="book-Z-H-16.html#%_thm_2.60">2.60</a><br />
<a href="book-Z-H-16.html#%_thm_2.61">2.61</a><br />
<a href="book-Z-H-16.html#%_thm_2.62">2.62</a><br />
<a href="book-Z-H-16.html#%_thm_2.63">2.63</a><br />
<a href="book-Z-H-16.html#%_thm_2.64">2.64</a><br />
<a href="book-Z-H-16.html#%_thm_2.65">2.65</a><br />
<a href="book-Z-H-16.html#%_thm_2.66">2.66</a><br />
<a href="book-Z-H-16.html#%_thm_2.67">2.67</a><br />
<a href="book-Z-H-16.html#%_thm_2.68">2.68</a><br />
<a href="book-Z-H-16.html#%_thm_2.69">2.69</a><br />
<a href="book-Z-H-16.html#%_thm_2.70">2.70</a><br />
<a href="book-Z-H-16.html#%_thm_2.71">2.71</a><br />
<a href="book-Z-H-16.html#%_thm_2.72">2.72</a><br />
<a href="book-Z-H-17.html#%_thm_2.73">2.73</a><br />
<a href="book-Z-H-17.html#%_thm_2.74">2.74</a><br />
<a href="book-Z-H-17.html#%_thm_2.75">2.75</a><br />
<a href="book-Z-H-17.html#%_thm_2.76">2.76</a><br />
<a href="book-Z-H-18.html#%_thm_2.77">2.77</a><br />
<a href="book-Z-H-18.html#%_thm_2.78">2.78</a><br />
<a href="book-Z-H-18.html#%_thm_2.79">2.79</a><br />
<a href="book-Z-H-18.html#%_thm_2.80">2.80</a><br />
<a href="book-Z-H-18.html#%_thm_2.81">2.81</a><br />
<a href="book-Z-H-18.html#%_thm_2.82">2.82</a><br />
<a href="book-Z-H-18.html#%_thm_2.83">2.83</a><br />
<a href="book-Z-H-18.html#%_thm_2.84">2.84</a><br />
<a href="book-Z-H-18.html#%_thm_2.85">2.85</a><br />
<a href="book-Z-H-18.html#%_thm_2.86">2.86</a><br />
<a href="book-Z-H-18.html#%_thm_2.87">2.87</a><br />
<a href="book-Z-H-18.html#%_thm_2.88">2.88</a><br />
<a href="book-Z-H-18.html#%_thm_2.89">2.89</a><br />
<a href="book-Z-H-18.html#%_thm_2.90">2.90</a><br />
<a href="book-Z-H-18.html#%_thm_2.91">2.91</a><br />
<a href="book-Z-H-18.html#%_thm_2.92">2.92</a><br />
<a href="book-Z-H-18.html#%_thm_2.93">2.93</a><br />
<a href="book-Z-H-18.html#%_thm_2.94">2.94</a><br />
<a href="book-Z-H-18.html#%_thm_2.95">2.95</a><br />
<a href="book-Z-H-18.html#%_thm_2.96">2.96</a><br />
<a href="book-Z-H-18.html#%_thm_2.97">2.97</a><br />
<a href="book-Z-H-20.html#%_thm_3.1">3.1</a><br />
<a href="book-Z-H-20.html#%_thm_3.2">3.2</a><br />
<a href="book-Z-H-20.html#%_thm_3.3">3.3</a><br />
<a href="book-Z-H-20.html#%_thm_3.4">3.4</a><br />
<a href="book-Z-H-20.html#%_thm_3.5">3.5</a><br />
<a href="book-Z-H-20.html#%_thm_3.6">3.6</a><br />
<a href="book-Z-H-20.html#%_thm_3.7">3.7</a><br />
<a href="book-Z-H-20.html#%_thm_3.8">3.8</a><br />
<a href="book-Z-H-21.html#%_thm_3.9">3.9</a><br />
<a href="book-Z-H-21.html#%_thm_3.10">3.10</a><br />
<a href="book-Z-H-21.html#%_thm_3.11">3.11</a><br />
<a href="book-Z-H-22.html#%_thm_3.12">3.12</a><br />
<a href="book-Z-H-22.html#%_thm_3.13">3.13</a><br />
<a href="book-Z-H-22.html#%_thm_3.14">3.14</a><br />
<a href="book-Z-H-22.html#%_thm_3.15">3.15</a><br />
<a href="book-Z-H-22.html#%_thm_3.16">3.16</a><br />
<a href="book-Z-H-22.html#%_thm_3.17">3.17</a><br />
<a href="book-Z-H-22.html#%_thm_3.18">3.18</a><br />
<a href="book-Z-H-22.html#%_thm_3.19">3.19</a><br />
<a href="book-Z-H-22.html#%_thm_3.20">3.20</a><br />
<a href="book-Z-H-22.html#%_thm_3.21">3.21</a><br />
<a href="book-Z-H-22.html#%_thm_3.22">3.22</a><br />
<a href="book-Z-H-22.html#%_thm_3.23">3.23</a><br />
<a href="book-Z-H-22.html#%_thm_3.24">3.24</a><br />
<a href="book-Z-H-22.html#%_thm_3.25">3.25</a><br />
<a href="book-Z-H-22.html#%_thm_3.26">3.26</a><br />
<a href="book-Z-H-22.html#%_thm_3.27">3.27</a><br />
<a href="book-Z-H-22.html#%_thm_3.28">3.28</a><br />
<a href="book-Z-H-22.html#%_thm_3.29">3.29</a><br />
<a href="book-Z-H-22.html#%_thm_3.30">3.30</a><br />
<a href="book-Z-H-22.html#%_thm_3.31">3.31</a><br />
<a href="book-Z-H-22.html#%_thm_3.32">3.32</a><br />
<a href="book-Z-H-22.html#%_thm_3.33">3.33</a><br />
<a href="book-Z-H-22.html#%_thm_3.34">3.34</a><br />
<a href="book-Z-H-22.html#%_thm_3.35">3.35</a><br />
<a href="book-Z-H-22.html#%_thm_3.36">3.36</a><br />
<a href="book-Z-H-22.html#%_thm_3.37">3.37</a><br />
<a href="book-Z-H-23.html#%_thm_3.38">3.38</a><br />
<a href="book-Z-H-23.html#%_thm_3.39">3.39</a><br />
<a href="book-Z-H-23.html#%_thm_3.40">3.40</a><br />
<a href="book-Z-H-23.html#%_thm_3.41">3.41</a><br />
<a href="book-Z-H-23.html#%_thm_3.42">3.42</a><br />
<a href="book-Z-H-23.html#%_thm_3.43">3.43</a><br />
<a href="book-Z-H-23.html#%_thm_3.44">3.44</a><br />
<a href="book-Z-H-23.html#%_thm_3.45">3.45</a><br />
<a href="book-Z-H-23.html#%_thm_3.46">3.46</a><br />
<a href="book-Z-H-23.html#%_thm_3.47">3.47</a><br />
<a href="book-Z-H-23.html#%_thm_3.48">3.48</a><br />
<a href="book-Z-H-23.html#%_thm_3.49">3.49</a><br />
<a href="book-Z-H-24.html#%_thm_3.50">3.50</a><br />
<a href="book-Z-H-24.html#%_thm_3.51">3.51</a><br />
<a href="book-Z-H-24.html#%_thm_3.52">3.52</a><br />
<a href="book-Z-H-24.html#%_thm_3.53">3.53</a><br />
<a href="book-Z-H-24.html#%_thm_3.54">3.54</a><br />
<a href="book-Z-H-24.html#%_thm_3.55">3.55</a><br />
<a href="book-Z-H-24.html#%_thm_3.56">3.56</a><br />
<a href="book-Z-H-24.html#%_thm_3.57">3.57</a><br />
<a href="book-Z-H-24.html#%_thm_3.58">3.58</a><br />
<a href="book-Z-H-24.html#%_thm_3.59">3.59</a><br />
<a href="book-Z-H-24.html#%_thm_3.60">3.60</a><br />
<a href="book-Z-H-24.html#%_thm_3.61">3.61</a><br />
<a href="book-Z-H-24.html#%_thm_3.62">3.62</a><br />
<a href="book-Z-H-24.html#%_thm_3.63">3.63</a><br />
<a href="book-Z-H-24.html#%_thm_3.64">3.64</a><br />
<a href="book-Z-H-24.html#%_thm_3.65">3.65</a><br />
<a href="book-Z-H-24.html#%_thm_3.66">3.66</a><br />
<a href="book-Z-H-24.html#%_thm_3.67">3.67</a><br />
<a href="book-Z-H-24.html#%_thm_3.68">3.68</a><br />
<a href="book-Z-H-24.html#%_thm_3.69">3.69</a><br />
<a href="book-Z-H-24.html#%_thm_3.70">3.70</a><br />
<a href="book-Z-H-24.html#%_thm_3.71">3.71</a><br />
<a href="book-Z-H-24.html#%_thm_3.72">3.72</a><br />
<a href="book-Z-H-24.html#%_thm_3.73">3.73</a><br />
<a href="book-Z-H-24.html#%_thm_3.74">3.74</a><br />
<a href="book-Z-H-24.html#%_thm_3.75">3.75</a><br />
<a href="book-Z-H-24.html#%_thm_3.76">3.76</a><br />
<a href="book-Z-H-24.html#%_thm_3.77">3.77</a><br />
<a href="book-Z-H-24.html#%_thm_3.78">3.78</a><br />
<a href="book-Z-H-24.html#%_thm_3.79">3.79</a><br />
<a href="book-Z-H-24.html#%_thm_3.80">3.80</a><br />
<a href="book-Z-H-24.html#%_thm_3.81">3.81</a><br />
<a href="book-Z-H-24.html#%_thm_3.82">3.82</a><br />
<a href="book-Z-H-26.html#%_thm_4.1">4.1</a><br />
<a href="book-Z-H-26.html#%_thm_4.2">4.2</a><br />
<a href="book-Z-H-26.html#%_thm_4.3">4.3</a><br />
<a href="book-Z-H-26.html#%_thm_4.4">4.4</a><br />
<a href="book-Z-H-26.html#%_thm_4.5">4.5</a><br />
<a href="book-Z-H-26.html#%_thm_4.6">4.6</a><br />
<a href="book-Z-H-26.html#%_thm_4.7">4.7</a><br />
<a href="book-Z-H-26.html#%_thm_4.8">4.8</a><br />
<a href="book-Z-H-26.html#%_thm_4.9">4.9</a><br />
<a href="book-Z-H-26.html#%_thm_4.10">4.10</a><br />
<a href="book-Z-H-26.html#%_thm_4.11">4.11</a><br />
<a href="book-Z-H-26.html#%_thm_4.12">4.12</a><br />
<a href="book-Z-H-26.html#%_thm_4.13">4.13</a><br />
<a href="book-Z-H-26.html#%_thm_4.14">4.14</a><br />
<a href="book-Z-H-26.html#%_thm_4.15">4.15</a><br />
<a href="book-Z-H-26.html#%_thm_4.16">4.16</a><br />
<a href="book-Z-H-26.html#%_thm_4.17">4.17</a><br />
<a href="book-Z-H-26.html#%_thm_4.18">4.18</a><br />
<a href="book-Z-H-26.html#%_thm_4.19">4.19</a><br />
<a href="book-Z-H-26.html#%_thm_4.20">4.20</a><br />
<a href="book-Z-H-26.html#%_thm_4.21">4.21</a><br />
<a href="book-Z-H-26.html#%_thm_4.22">4.22</a><br />
<a href="book-Z-H-26.html#%_thm_4.23">4.23</a><br />
<a href="book-Z-H-26.html#%_thm_4.24">4.24</a><br />
<a href="book-Z-H-27.html#%_thm_4.25">4.25</a><br />
<a href="book-Z-H-27.html#%_thm_4.26">4.26</a><br />
<a href="book-Z-H-27.html#%_thm_4.27">4.27</a><br />
<a href="book-Z-H-27.html#%_thm_4.28">4.28</a><br />
<a href="book-Z-H-27.html#%_thm_4.29">4.29</a><br />
<a href="book-Z-H-27.html#%_thm_4.30">4.30</a><br />
<a href="book-Z-H-27.html#%_thm_4.31">4.31</a><br />
<a href="book-Z-H-27.html#%_thm_4.32">4.32</a><br />
<a href="book-Z-H-27.html#%_thm_4.33">4.33</a><br />
<a href="book-Z-H-27.html#%_thm_4.34">4.34</a><br />
<a href="book-Z-H-28.html#%_thm_4.35">4.35</a><br />
<a href="book-Z-H-28.html#%_thm_4.36">4.36</a><br />
<a href="book-Z-H-28.html#%_thm_4.37">4.37</a><br />
<a href="book-Z-H-28.html#%_thm_4.38">4.38</a><br />
<a href="book-Z-H-28.html#%_thm_4.39">4.39</a><br />
<a href="book-Z-H-28.html#%_thm_4.40">4.40</a><br />
<a href="book-Z-H-28.html#%_thm_4.41">4.41</a><br />
<a href="book-Z-H-28.html#%_thm_4.42">4.42</a><br />
<a href="book-Z-H-28.html#%_thm_4.43">4.43</a><br />
<a href="book-Z-H-28.html#%_thm_4.44">4.44</a><br />
<a href="book-Z-H-28.html#%_thm_4.45">4.45</a><br />
<a href="book-Z-H-28.html#%_thm_4.46">4.46</a><br />
<a href="book-Z-H-28.html#%_thm_4.47">4.47</a><br />
<a href="book-Z-H-28.html#%_thm_4.48">4.48</a><br />
<a href="book-Z-H-28.html#%_thm_4.49">4.49</a><br />
<a href="book-Z-H-28.html#%_thm_4.50">4.50</a><br />
<a href="book-Z-H-28.html#%_thm_4.51">4.51</a><br />
<a href="book-Z-H-28.html#%_thm_4.52">4.52</a><br />
<a href="book-Z-H-28.html#%_thm_4.53">4.53</a><br />
<a href="book-Z-H-28.html#%_thm_4.54">4.54</a><br />
<a href="book-Z-H-29.html#%_thm_4.55">4.55</a><br />
<a href="book-Z-H-29.html#%_thm_4.56">4.56</a><br />
<a href="book-Z-H-29.html#%_thm_4.57">4.57</a><br />
<a href="book-Z-H-29.html#%_thm_4.58">4.58</a><br />
<a href="book-Z-H-29.html#%_thm_4.59">4.59</a><br />
<a href="book-Z-H-29.html#%_thm_4.60">4.60</a><br />
<a href="book-Z-H-29.html#%_thm_4.61">4.61</a><br />
<a href="book-Z-H-29.html#%_thm_4.62">4.62</a><br />
<a href="book-Z-H-29.html#%_thm_4.63">4.63</a><br />
<a href="book-Z-H-29.html#%_thm_4.64">4.64</a><br />
<a href="book-Z-H-29.html#%_thm_4.65">4.65</a><br />
<a href="book-Z-H-29.html#%_thm_4.66">4.66</a><br />
<a href="book-Z-H-29.html#%_thm_4.67">4.67</a><br />
<a href="book-Z-H-29.html#%_thm_4.68">4.68</a><br />
<a href="book-Z-H-29.html#%_thm_4.69">4.69</a><br />
<a href="book-Z-H-29.html#%_thm_4.70">4.70</a><br />
<a href="book-Z-H-29.html#%_thm_4.71">4.71</a><br />
<a href="book-Z-H-29.html#%_thm_4.72">4.72</a><br />
<a href="book-Z-H-29.html#%_thm_4.73">4.73</a><br />
<a href="book-Z-H-29.html#%_thm_4.74">4.74</a><br />
<a href="book-Z-H-29.html#%_thm_4.75">4.75</a><br />
<a href="book-Z-H-29.html#%_thm_4.76">4.76</a><br />
<a href="book-Z-H-29.html#%_thm_4.77">4.77</a><br />
<a href="book-Z-H-29.html#%_thm_4.78">4.78</a><br />
<a href="book-Z-H-29.html#%_thm_4.79">4.79</a><br />
<a href="book-Z-H-31.html#%_thm_5.1">5.1</a><br />
<a href="book-Z-H-31.html#%_thm_5.2">5.2</a><br />
<a href="book-Z-H-31.html#%_thm_5.3">5.3</a><br />
<a href="book-Z-H-31.html#%_thm_5.4">5.4</a><br />
<a href="book-Z-H-31.html#%_thm_5.5">5.5</a><br />
<a href="book-Z-H-31.html#%_thm_5.6">5.6</a><br />
<a href="book-Z-H-32.html#%_thm_5.7">5.7</a><br />
<a href="book-Z-H-32.html#%_thm_5.8">5.8</a><br />
<a href="book-Z-H-32.html#%_thm_5.9">5.9</a><br />
<a href="book-Z-H-32.html#%_thm_5.10">5.10</a><br />
<a href="book-Z-H-32.html#%_thm_5.11">5.11</a><br />
<a href="book-Z-H-32.html#%_thm_5.12">5.12</a><br />
<a href="book-Z-H-32.html#%_thm_5.13">5.13</a><br />
<a href="book-Z-H-32.html#%_thm_5.14">5.14</a><br />
<a href="book-Z-H-32.html#%_thm_5.15">5.15</a><br />
<a href="book-Z-H-32.html#%_thm_5.16">5.16</a><br />
<a href="book-Z-H-32.html#%_thm_5.17">5.17</a><br />
<a href="book-Z-H-32.html#%_thm_5.18">5.18</a><br />
<a href="book-Z-H-32.html#%_thm_5.19">5.19</a><br />
<a href="book-Z-H-33.html#%_thm_5.20">5.20</a><br />
<a href="book-Z-H-33.html#%_thm_5.21">5.21</a><br />
<a href="book-Z-H-33.html#%_thm_5.22">5.22</a><br />
<a href="book-Z-H-34.html#%_thm_5.23">5.23</a><br />
<a href="book-Z-H-34.html#%_thm_5.24">5.24</a><br />
<a href="book-Z-H-34.html#%_thm_5.25">5.25</a><br />
<a href="book-Z-H-34.html#%_thm_5.26">5.26</a><br />
<a href="book-Z-H-34.html#%_thm_5.27">5.27</a><br />
<a href="book-Z-H-34.html#%_thm_5.28">5.28</a><br />
<a href="book-Z-H-34.html#%_thm_5.29">5.29</a><br />
<a href="book-Z-H-34.html#%_thm_5.30">5.30</a><br />
<a href="book-Z-H-35.html#%_thm_5.31">5.31</a><br />
<a href="book-Z-H-35.html#%_thm_5.32">5.32</a><br />
<a href="book-Z-H-35.html#%_thm_5.33">5.33</a><br />
<a href="book-Z-H-35.html#%_thm_5.34">5.34</a><br />
<a href="book-Z-H-35.html#%_thm_5.35">5.35</a><br />
<a href="book-Z-H-35.html#%_thm_5.36">5.36</a><br />
<a href="book-Z-H-35.html#%_thm_5.37">5.37</a><br />
<a href="book-Z-H-35.html#%_thm_5.38">5.38</a><br />
<a href="book-Z-H-35.html#%_thm_5.39">5.39</a><br />
<a href="book-Z-H-35.html#%_thm_5.40">5.40</a><br />
<a href="book-Z-H-35.html#%_thm_5.41">5.41</a><br />
<a href="book-Z-H-35.html#%_thm_5.42">5.42</a><br />
<a href="book-Z-H-35.html#%_thm_5.43">5.43</a><br />
<a href="book-Z-H-35.html#%_thm_5.44">5.44</a><br />
<a href="book-Z-H-35.html#%_thm_5.45">5.45</a><br />
<a href="book-Z-H-35.html#%_thm_5.46">5.46</a><br />
<a href="book-Z-H-35.html#%_thm_5.47">5.47</a><br />
<a href="book-Z-H-35.html#%_thm_5.48">5.48</a><br />
<a href="book-Z-H-35.html#%_thm_5.49">5.49</a><br />
<a href="book-Z-H-35.html#%_thm_5.50">5.50</a><br />
<a href="book-Z-H-35.html#%_thm_5.51">5.51</a><br />
<a href="book-Z-H-35.html#%_thm_5.52">5.52</a><br />
[]{#%_idx_6526} []{#%_idx_6528} []{#%_idx_6530} []{#%_idx_6532}</p>
<p>[]{#%_idx_6534} []{#%_idx_6536} []{#%_idx_6538}</p>
<p>[]{#%_idx_6540} []{#%_idx_6542}</p>
<p>[]{#%_idx_6544} []{#%_idx_6546}</p>
<p>[]{#%_idx_6548} []{#%_idx_6550}</p>
<p>[]{#%_idx_6552} []{#%_idx_6554}</p>
<p>[]{#%_idx_6556} []{#%_idx_6558}</p>
<p>[]{#%_idx_6560}</p>
<p>[]{#%_idx_6562} []{#%_idx_6564} []{#%_idx_6566}</p>
<p>[]{#%_idx_6568}</p>
<p>[]{#%_idx_6570}</p>
<p>[]{#%_idx_6572}</p>
<p>[]{#%_idx_6574}</p>
<p>[]{#%_idx_6576} []{#%_idx_6578}</p>
<p>[]{#%_idx_6580} []{#%_idx_6582}</p>
<p>[]{#%_idx_6584} []{#%_idx_6586} []{#%_idx_6588}</p>
<p>[]{#%_idx_6590} []{#%_idx_6592} []{#%_idx_6594} []{#%_idx_6596}
[]{#%_idx_6598} []{#%_idx_6600} []{#%_idx_6602}</p>
<p>[]{#%_idx_6604}</p>
<p>[]{#%_idx_6606}</p>
<p>[]{#%_idx_6608}</p>
<p>[]{#%_idx_6610}</p>
<p>[]{#%_idx_6612}</p>
<p>[]{#%_idx_6614}</p>
<p>[]{#%_idx_6616} []{#%_idx_6618} []{#%_idx_6620}</p>
<p>[]{#%_idx_6622}</p>
<p>[]{#%_idx_6624} []{#%_idx_6626}</p>
<p>[]{#%_idx_6628} []{#%_idx_6630} []{#%_idx_6632}</p>
<p>[]{#%_idx_6634}</p>
<p>[]{#%_idx_6636} []{#%_idx_6638}</p>
<p>[]{#%_idx_6640} []{#%_idx_6642}</p>
<p>[]{#%_idx_6644}</p>
<p>[]{#%_idx_6646}</p>
<p>[]{#%_idx_6648} []{#%_idx_6650}</p>
<p>[]{#%_idx_6652} []{#%_idx_6654} []{#%_idx_6656}</p>
<p>[]{#%_idx_6658}[]{#%_idx_6660}</p>
<p>[]{#%_idx_6662} []{#%_idx_6664} []{#%_idx_6666}</p>
<p>[]{#%_idx_6668} []{#%_idx_6670} []{#%_idx_6672} []{#%_idx_6674}
[]{#%_idx_6676} []{#%_idx_6678}</p>
<p>[]{#%_idx_6680} []{#%_idx_6682} []{#%_idx_6684} []{#%_idx_6686}
[]{#%_idx_6688} []{#%_idx_6690} []{#%_idx_6692}</p>
<p>[]{#%_idx_6694} []{#%_idx_6696} []{#%_idx_6698}</p>
<p>[]{#%_idx_6700} []{#%_idx_6702} []{#%_idx_6704}</p>
<p>[]{#%_idx_6706} []{#%_idx_6708} []{#%_idx_6710} []{#%_idx_6712}</p>
<p>[]{#%_idx_6714} []{#%_idx_6716} []{#%_idx_6718}</p>
<p>[]{#%_idx_6720} []{#%_idx_6722} []{#%_idx_6724} []{#%_idx_6726}</p>
<p>[]{#%_idx_6728}</p>
<p>[]{#%_idx_6730}</p>
<p>[]{#%_idx_6732} []{#%_idx_6734}</p>
<p>[]{#%_idx_6736}</p>
<p>[]{#%_idx_6738}</p>
<p>[]{#%_idx_6740}</p>
<p>[]{#%_idx_6742}</p>
<p>[]{#%_idx_6744} []{#%_idx_6746}</p>
<p>[]{#%_idx_6748} []{#%_idx_6750} []{#%_idx_6752} []{#%_idx_6754}
[]{#%_idx_6756} []{#%_idx_6758} []{#%_idx_6760} []{#%_idx_6762}
[]{#%_idx_6764}</p>
<p>[]{#%_idx_6766} []{#%_idx_6768} []{#%_idx_6770} []{#%_idx_6772}
[]{#%_idx_6774}</p>
<p>[]{#%_idx_6776}</p>
<p>[]{#%_idx_6778}</p>
<p>[]{#%_idx_6780}</p>
<p>[]{#%_idx_6782}</p>
<p>[]{#%_idx_6784}</p>
<p>[]{#%_idx_6786} []{#%_idx_6788} []{#%_idx_6790} []{#%_idx_6792}</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<p>Contents</p>
<p>**    <a href="book-Z-H-5.html#%_chap_Temp_2">Foreword</a>  **</p>
<p>**    <a href="book-Z-H-6.html#%_chap_Temp_3">Preface to the Second Edition</a>  **</p>
<p>**    <a href="book-Z-H-7.html#%_chap_Temp_4">Preface to the First Edition</a>  **</p>
<p>**   
<a href="book-Z-H-8.html#%_chap_Temp_5">Acknowledgments</a>  **</p>
<p>**    <a href="book-Z-H-9.html#%_chap_1">1  Building Abstractions with Procedures</a>  ** <br />
        <a href="book-Z-H-10.html#%_sec_1.1">1.1  The Elements of Programming</a> <br />
           
<a href="book-Z-H-10.html#%_sec_1.1.1">1.1.1  Expressions</a> <br />
            <a href="book-Z-H-10.html#%_sec_1.1.2">1.1.2  Naming and the Environment</a> <br />
            <a href="book-Z-H-10.html#%_sec_1.1.3">1.1.3  Evaluating Combinations</a> <br />
            <a href="book-Z-H-10.html#%_sec_1.1.4">1.1.4  Compound Procedures</a> <br />
            <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5  The Substitution Model for Procedure Application</a> <br />
            <a href="book-Z-H-10.html#%_sec_1.1.6">1.1.6  Conditional Expressions and Predicates</a> <br />
            <a href="book-Z-H-10.html#%_sec_1.1.7">1.1.7  Example: Square Roots by Newton's Method</a> <br />
            <a href="book-Z-H-10.html#%_sec_1.1.8">1.1.8  Procedures as Black-Box Abstractions</a> <br />
        <a href="book-Z-H-11.html#%_sec_1.2">1.2  Procedures and the Processes They Generate</a> <br />
            <a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1  Linear Recursion and Iteration</a> <br />
            <a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2  Tree Recursion</a> <br />
            <a href="book-Z-H-11.html#%_sec_1.2.3">1.2.3  Orders of Growth</a> <br />
           
<a href="book-Z-H-11.html#%_sec_1.2.4">1.2.4  Exponentiation</a> <br />
            <a href="book-Z-H-11.html#%_sec_1.2.5">1.2.5  Greatest Common Divisors</a> <br />
            <a href="book-Z-H-11.html#%_sec_1.2.6">1.2.6  Example: Testing for Primality</a> <br />
        <a href="book-Z-H-12.html#%_sec_1.3">1.3  Formulating Abstractions with Higher-Order Procedures</a> <br />
            <a href="book-Z-H-12.html#%_sec_1.3.1">1.3.1  Procedures as Arguments</a> <br />
            <a href="book-Z-H-12.html#%_sec_1.3.2">1.3.2  Constructing Procedures Using <code>Lambda</code></a> <br />
            <a href="book-Z-H-12.html#%_sec_1.3.3">1.3.3  Procedures as General Methods</a> <br />
            <a href="book-Z-H-12.html#%_sec_1.3.4">1.3.4  Procedures as Returned Values</a></p>
<p>**    <a href="book-Z-H-13.html#%_chap_2">2  Building Abstractions with Data</a>  ** <br />
        <a href="book-Z-H-14.html#%_sec_2.1">2.1  Introduction to Data Abstraction</a> <br />
            <a href="book-Z-H-14.html#%_sec_2.1.1">2.1.1  Example: Arithmetic Operations for Rational Numbers</a> <br />
            <a href="book-Z-H-14.html#%_sec_2.1.2">2.1.2  Abstraction Barriers</a> <br />
            <a href="book-Z-H-14.html#%_sec_2.1.3">2.1.3  What Is Meant by Data?</a> <br />
            <a href="book-Z-H-14.html#%_sec_2.1.4">2.1.4  Extended Exercise: Interval Arithmetic</a> <br />
        <a href="book-Z-H-15.html#%_sec_2.2">2.2  Hierarchical Data and the Closure Property</a> <br />
            <a href="book-Z-H-15.html#%_sec_2.2.1">2.2.1  Representing Sequences</a> <br />
            <a href="book-Z-H-15.html#%_sec_2.2.2">2.2.2  Hierarchical Structures</a> <br />
            <a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3  Sequences as Conventional Interfaces</a> <br />
            <a href="book-Z-H-15.html#%_sec_2.2.4">2.2.4  Example: A Picture Language</a> <br />
        <a href="book-Z-H-16.html#%_sec_2.3">2.3  Symbolic Data</a> <br />
           
<a href="book-Z-H-16.html#%_sec_2.3.1">2.3.1  Quotation</a> <br />
            <a href="book-Z-H-16.html#%_sec_2.3.2">2.3.2  Example: Symbolic Differentiation</a> <br />
            <a href="book-Z-H-16.html#%_sec_2.3.3">2.3.3  Example: Representing Sets</a> <br />
            <a href="book-Z-H-16.html#%_sec_2.3.4">2.3.4  Example: Huffman Encoding Trees</a> <br />
        <a href="book-Z-H-17.html#%_sec_2.4">2.4  Multiple Representations for Abstract Data</a> <br />
            <a href="book-Z-H-17.html#%_sec_2.4.1">2.4.1  Representations for Complex Numbers</a> <br />
            <a href="book-Z-H-17.html#%_sec_2.4.2">2.4.2  Tagged data</a> <br />
            <a href="book-Z-H-17.html#%_sec_2.4.3">2.4.3  Data-Directed Programming and Additivity</a> <br />
        <a href="book-Z-H-18.html#%_sec_2.5">2.5  Systems with Generic Operations</a> <br />
            <a href="book-Z-H-18.html#%_sec_2.5.1">2.5.1  Generic Arithmetic Operations</a> <br />
            <a href="book-Z-H-18.html#%_sec_2.5.2">2.5.2  Combining Data of Different Types</a> <br />
            <a href="book-Z-H-18.html#%_sec_2.5.3">2.5.3  Example: Symbolic Algebra</a></p>
<p>**    <a href="book-Z-H-19.html#%_chap_3">3  Modularity, Objects, and State</a>  ** <br />
        <a href="book-Z-H-20.html#%_sec_3.1">3.1  Assignment and Local State</a> <br />
            <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1  Local State Variables</a> <br />
            <a href="book-Z-H-20.html#%_sec_3.1.2">3.1.2  The Benefits of Introducing Assignment</a> <br />
            <a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3  The Costs of Introducing Assignment</a> <br />
        <a href="book-Z-H-21.html#%_sec_3.2">3.2  The Environment Model of Evaluation</a> <br />
            <a href="book-Z-H-21.html#%_sec_3.2.1">3.2.1  The Rules for Evaluation</a> <br />
            <a href="book-Z-H-21.html#%_sec_3.2.2">3.2.2  Applying Simple Procedures</a> <br />
            <a href="book-Z-H-21.html#%_sec_3.2.3">3.2.3  Frames as the Repository of Local State</a> <br />
            <a href="book-Z-H-21.html#%_sec_3.2.4">3.2.4  Internal Definitions</a> <br />
        <a href="book-Z-H-22.html#%_sec_3.3">3.3  Modeling with Mutable Data</a> <br />
            <a href="book-Z-H-22.html#%_sec_3.3.1">3.3.1  Mutable List Structure</a> <br />
            <a href="book-Z-H-22.html#%_sec_3.3.2">3.3.2  Representing Queues</a> <br />
            <a href="book-Z-H-22.html#%_sec_3.3.3">3.3.3  Representing Tables</a> <br />
            <a href="book-Z-H-22.html#%_sec_3.3.4">3.3.4  A Simulator for Digital Circuits</a> <br />
            <a href="book-Z-H-22.html#%_sec_3.3.5">3.3.5  Propagation of Constraints</a> <br />
        <a href="book-Z-H-23.html#%_sec_3.4">3.4  Concurrency: Time Is of the Essence</a> <br />
            <a href="book-Z-H-23.html#%_sec_3.4.1">3.4.1  The Nature of Time in Concurrent Systems</a> <br />
            <a href="book-Z-H-23.html#%_sec_3.4.2">3.4.2  Mechanisms for Controlling Concurrency</a> <br />
        <a href="book-Z-H-24.html#%_sec_3.5">3.5  Streams</a> <br />
            <a href="book-Z-H-24.html#%_sec_3.5.1">3.5.1  Streams Are Delayed Lists</a> <br />
            <a href="book-Z-H-24.html#%_sec_3.5.2">3.5.2  Infinite Streams</a> <br />
            <a href="book-Z-H-24.html#%_sec_3.5.3">3.5.3  Exploiting the Stream Paradigm</a> <br />
            <a href="book-Z-H-24.html#%_sec_3.5.4">3.5.4  Streams and Delayed Evaluation</a> <br />
            <a href="book-Z-H-24.html#%_sec_3.5.5">3.5.5  Modularity of Functional Programs and Modularity of Objects</a> <br />
**    <a href="book-Z-H-25.html#%_chap_4">4  Metalinguistic Abstraction</a>  ** <br />
        <a href="book-Z-H-26.html#%_sec_4.1">4.1  The Metacircular Evaluator</a> <br />
            <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1  The Core of the Evaluator</a> <br />
            <a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2  Representing Expressions</a> <br />
            <a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3  Evaluator Data Structures</a> <br />
            <a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4  Running the Evaluator as a Program</a> <br />
            <a href="book-Z-H-26.html#%_sec_4.1.5">4.1.5  Data as Programs</a> <br />
            <a href="book-Z-H-26.html#%_sec_4.1.6">4.1.6  Internal Definitions</a> <br />
            <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7  Separating Syntactic Analysis from Execution</a> <br />
        <a href="book-Z-H-27.html#%_sec_4.2">4.2  Variations on a Scheme -- Lazy Evaluation</a> <br />
            <a href="book-Z-H-27.html#%_sec_4.2.1">4.2.1  Normal Order and Applicative Order</a> <br />
            <a href="book-Z-H-27.html#%_sec_4.2.2">4.2.2  An Interpreter with Lazy Evaluation</a> <br />
            <a href="book-Z-H-27.html#%_sec_4.2.3">4.2.3  Streams as Lazy Lists</a> <br />
        <a href="book-Z-H-28.html#%_sec_4.3">4.3  Variations on a Scheme -- Nondeterministic Computing</a> <br />
            <a href="book-Z-H-28.html#%_sec_4.3.1">4.3.1  Amb and Search</a> <br />
            <a href="book-Z-H-28.html#%_sec_4.3.2">4.3.2  Examples of Nondeterministic Programs</a> <br />
            <a href="book-Z-H-28.html#%_sec_4.3.3">4.3.3  Implementing the <code>Amb</code> Evaluator</a> <br />
        <a href="book-Z-H-29.html#%_sec_4.4">4.4  Logic Programming</a> <br />
            <a href="book-Z-H-29.html#%_sec_4.4.1">4.4.1  Deductive Information Retrieval</a> <br />
            <a href="book-Z-H-29.html#%_sec_4.4.2">4.4.2  How the Query System Works</a> <br />
            <a href="book-Z-H-29.html#%_sec_4.4.3">4.4.3  Is Logic Programming Mathematical Logic?</a> <br />
            <a href="book-Z-H-29.html#%_sec_4.4.4">4.4.4  Implementing the Query System</a> <br />
**    <a href="book-Z-H-30.html#%_chap_5">5  Computing with Register Machines</a>  ** <br />
        <a href="book-Z-H-31.html#%_sec_5.1">5.1  Designing Register Machines</a> <br />
            <a href="book-Z-H-31.html#%_sec_5.1.1">5.1.1  A Language for Describing Register Machines</a> <br />
            <a href="book-Z-H-31.html#%_sec_5.1.2">5.1.2  Abstraction in Machine Design</a> <br />
           
<a href="book-Z-H-31.html#%_sec_5.1.3">5.1.3  Subroutines</a> <br />
            <a href="book-Z-H-31.html#%_sec_5.1.4">5.1.4  Using a Stack to Implement Recursion</a> <br />
            <a href="book-Z-H-31.html#%_sec_5.1.5">5.1.5  Instruction Summary</a> <br />
        <a href="book-Z-H-32.html#%_sec_5.2">5.2  A Register-Machine Simulator</a> <br />
            <a href="book-Z-H-32.html#%_sec_5.2.1">5.2.1  The Machine Model</a> <br />
            <a href="book-Z-H-32.html#%_sec_5.2.2">5.2.2  The Assembler</a> <br />
            <a href="book-Z-H-32.html#%_sec_5.2.3">5.2.3  Generating Execution Procedures for Instructions</a> <br />
            <a href="book-Z-H-32.html#%_sec_5.2.4">5.2.4  Monitoring Machine Performance</a> <br />
        <a href="book-Z-H-33.html#%_sec_5.3">5.3  Storage Allocation and Garbage Collection</a> <br />
            <a href="book-Z-H-33.html#%_sec_5.3.1">5.3.1  Memory as Vectors</a> <br />
            <a href="book-Z-H-33.html#%_sec_5.3.2">5.3.2  Maintaining the Illusion of Infinite Memory</a> <br />
        <a href="book-Z-H-34.html#%_sec_5.4">5.4  The Explicit-Control Evaluator</a> <br />
            <a href="book-Z-H-34.html#%_sec_5.4.1">5.4.1  The Core of the Explicit-Control Evaluator</a> <br />
            <a href="book-Z-H-34.html#%_sec_5.4.2">5.4.2  Sequence Evaluation and Tail Recursion</a> <br />
            <a href="book-Z-H-34.html#%_sec_5.4.3">5.4.3  Conditionals, Assignments, and Definitions</a> <br />
            <a href="book-Z-H-34.html#%_sec_5.4.4">5.4.4  Running the Evaluator</a> <br />
       
<a href="book-Z-H-35.html#%_sec_5.5">5.5  Compilation</a> <br />
            <a href="book-Z-H-35.html#%_sec_5.5.1">5.5.1  Structure of the Compiler</a> <br />
            <a href="book-Z-H-35.html#%_sec_5.5.2">5.5.2  Compiling Expressions</a> <br />
            <a href="book-Z-H-35.html#%_sec_5.5.3">5.5.3  Compiling Combinations</a> <br />
            <a href="book-Z-H-35.html#%_sec_5.5.4">5.5.4  Combining Instruction Sequences</a> <br />
            <a href="book-Z-H-35.html#%_sec_5.5.5">5.5.5  An Example of Compiled Code</a> <br />
            <a href="book-Z-H-35.html#%_sec_5.5.6">5.5.6  Lexical Addressing</a> <br />
            <a href="book-Z-H-35.html#%_sec_5.5.7">5.5.7  Interfacing Compiled Code to the Evaluator</a></p>
<p>**   
<a href="book-Z-H-36.html#%_chap_Temp_849">References</a>  **</p>
<p>**    <a href="book-Z-H-37.html#%_chap_Temp_850">List of
Exercises</a>  **</p>
<p>**   
<a href="book-Z-H-38.html#%_chap_Temp_851">Index</a>  **</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="1--building-abstractions-with-procedures"><a class="header" href="#1--building-abstractions-with-procedures">1  Building Abstractions with Procedures</a></h1>
<div class="info">
The acts of the mind, wherein it exerts its power over simple ideas, are chiefly these three: 1. Combining several simple ideas into one compound one, and thus all complex ideas are made. 2. The second is bringing two ideas, whether simple or complex, together, and setting them by one another so as to take a view of them at once, without uniting them into one, by which it gets all its ideas of relations. 3. The third is separating them from all other ideas that accompany them in their real existence: this is called abstraction, and thus all its general ideas are made.
<p>John Locke, An Essay Concerning Human Understanding (1690)</p>
</div>
<p>We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.</p>
<p>A computational process is indeed much like a sorcerer's idea of a spirit. It cannot be seen or touched. It is not composed of matter at all. However, it is very real. It can perform intellectual work. It can answer questions. It can affect the world by disbursing money at a bank or by controlling a robot arm in a factory. The programs we use to conjure processes are like a sorcerer's spells. They are carefully composed from symbolic expressions in arcane and esoteric programming languages that prescribe the tasks we want our processes to perform.</p>
<p>A computational process, in a correctly working computer, executes programs precisely and accurately. Thus, like the sorcerer's apprentice, novice programmers must learn to understand and to anticipate the consequences of their conjuring. Even small errors (usually called bugs or glitches) in programs can have complex and unanticipated consequences.</p>
<p>Fortunately, learning to program is considerably less dangerous than learning sorcery, because the spirits we deal with are conveniently contained in a secure way. Real-world programming, however, requires care, expertise, and wisdom. A small bug in a computer-aided design program, for example, can lead to the catastrophic collapse of an airplane or a dam or the self-destruction of an industrial robot.</p>
<p>Master software engineers have the ability to organize programs so that they can be reasonably sure that the resulting processes will perform the tasks intended. They can visualize the behavior of their systems in advance. They know how to structure programs so that unanticipated problems do not lead to catastrophic consequences, and when problems do arise, they can debug their programs. Well-designed computational systems, like well-designed automobiles or nuclear reactors, are designed in a modular manner, so that the parts can be constructed, replaced, and debugged separately.</p>
<p>Programming in Lisp
We need an appropriate language for describing processes, and we will use for this purpose the programming language Lisp. Just as our everyday thoughts are usually expressed in our natural language (such as English, French, or Japanese), and descriptions of quantitative phenomena are expressed with mathematical notations, our procedural thoughts will be expressed in Lisp. Lisp was invented in the late 1950s as a formalism for reasoning about the use of certain kinds of logical expressions, called recursion equations, as a model for computation. The language was conceived by John McCarthy and is based on his paper ``Recursive Functions of Symbolic Expressions and Their Computation by Machine'' (McCarthy 1960).</p>
<p>Despite its inception as a mathematical formalism, Lisp is a practical programming language. A Lisp interpreter is a machine that carries out processes described in the Lisp language. The first Lisp interpreter was implemented by McCarthy with the help of colleagues and students in the Artificial Intelligence Group of the MIT Research Laboratory of Electronics and in the MIT Computation Center.1 Lisp, whose name is an acronym for LISt Processing, was designed to provide symbol-manipulating capabilities for attacking programming problems such as the symbolic differentiation and integration of algebraic expressions. It included for this purpose new data objects known as atoms and lists, which most strikingly set it apart from all other languages of the period.</p>
<p>Lisp was not the product of a concerted design effort. Instead, it evolved informally in an experimental manner in response to users' needs and to pragmatic implementation considerations. Lisp's informal evolution has continued through the years, and the community of Lisp users has traditionally resisted attempts to promulgate any ``official'' definition of the language. This evolution, together with the flexibility and elegance of the initial conception, has enabled Lisp, which is the second oldest language in widespread use today (only Fortran is older), to continually adapt to encompass the most modern ideas about program design. Thus, Lisp is by now a family of dialects, which, while sharing most of the original features, may differ from one another in significant ways. The dialect of Lisp used in this book is called Scheme.2</p>
<p>Because of its experimental character and its emphasis on symbol manipulation, Lisp was at first very inefficient for numerical computations, at least in comparison with Fortran. Over the years, however, Lisp compilers have been developed that translate programs into machine code that can perform numerical computations reasonably efficiently. And for special applications, Lisp has been used with great effectiveness.3 Although Lisp has not yet overcome its old reputation as hopelessly inefficient, Lisp is now used in many applications where efficiency is not the central concern. For example, Lisp has become a language of choice for operating-system shell languages and for extension languages for editors and computer-aided design systems.</p>
<p>If Lisp is not a mainstream language, why are we using it as the framework for our discussion of programming? Because the language possesses unique features that make it an excellent medium for studying important programming constructs and data structures and for relating them to the linguistic features that support them. The most significant of these features is the fact that Lisp descriptions of processes, called procedures, can themselves be represented and manipulated as Lisp data. The importance of this is that there are powerful program-design techniques that rely on the ability to blur the traditional distinction between <code>passive'' data and </code>active'' processes. As we shall discover, Lisp's flexibility in handling procedures as data makes it one of the most convenient languages in existence for exploring these techniques. The ability to represent procedures as data also makes Lisp an excellent language for writing programs that must manipulate other programs as data, such as the interpreters and compilers that support computer languages. Above and beyond these considerations, programming in Lisp is great fun.</p>
<p>1 The Lisp 1 Programmer's Manual appeared in 1960, and the Lisp 1.5 Programmer's Manual (McCarthy 1965) was published in 1962. The early history of Lisp is described in McCarthy 1978.</p>
<p>2 The two dialects in which most major Lisp programs of the 1970s were written are MacLisp (Moon 1978; Pitman 1983), developed at the MIT Project MAC, and Interlisp (Teitelman 1974), developed at Bolt Beranek and Newman Inc. and the Xerox Palo Alto Research Center. Portable Standard Lisp (Hearn 1969; Griss 1981) was a Lisp dialect designed to be easily portable between different machines. MacLisp spawned a number of subdialects, such as Franz Lisp, which was developed at the University of California at Berkeley, and Zetalisp (Moon 1981), which was based on a special-purpose processor designed at the MIT Artificial Intelligence Laboratory to run Lisp very efficiently. The Lisp dialect used in this book, called Scheme (Steele 1975), was invented in 1975 by Guy Lewis Steele Jr. and Gerald Jay Sussman of the MIT Artificial Intelligence Laboratory and later reimplemented for instructional use at MIT. Scheme became an IEEE standard in 1990 (IEEE 1990). The Common Lisp dialect (Steele 1982, Steele 1990) was developed by the Lisp community to combine features from the earlier Lisp dialects to make an industrial standard for Lisp. Common Lisp became an ANSI standard in 1994 (ANSI 1994).</p>
<p>3 One such special application was a breakthrough computation of scientific importance -- an integration of the motion of the Solar System that extended previous results by nearly two orders of magnitude, and demonstrated that the dynamics of the Solar System is chaotic. This computation was made possible by new integration algorithms, a special-purpose compiler, and a special-purpose computer all implemented with the aid of software tools written in Lisp (Abelson et al. 1992; Sussman and Wisdom 1992).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="11--the-elements-of-programming"><a class="header" href="#11--the-elements-of-programming"><a href="book-Z-H-4.html#%_toc_%_sec_1.1">1.1  The Elements of Programming</a></a></h2>
<p>A powerful programming language is more than just a means
for instructing a computer to perform tasks. The language also serves as
a framework within which we organize our ideas about processes. Thus,
when we describe a language, we should pay particular attention to the
means that the language provides for combining simple ideas to form more
complex ideas. Every powerful language has three mechanisms for
accomplishing this:</p>
<ul>
<li>
<p><strong>primitive expressions</strong>, which represent the simplest entities the
language is concerned with,</p>
</li>
<li>
<p><strong>means of combination</strong>, by which compound elements are built from
simpler ones, and</p>
</li>
<li>
<p><strong>means of abstraction</strong>, by which compound elements can be named and
manipulated as units.</p>
</li>
</ul>
<p>In programming, we deal with two kinds of elements:
procedures and data. (Later we will discover
that they are really not so distinct.) Informally, data is ``stuff''
that we want to manipulate, and procedures are descriptions of the rules
for manipulating the data. Thus, any powerful programming language
should be able to describe primitive data and primitive procedures and
should have methods for combining and abstracting procedures and data.</p>
<p>In this chapter we will deal only with simple
numerical data so that we can focus on the
rules for building
procedures.<a href="book-Z-H-10.html#footnote_Temp_10">^[4]{.small}^</a>
In later chapters we will see that these same rules allow us to build
procedures to manipulate compound data as well.</p>
<h3 id="111--expressions"><a class="header" href="#111--expressions"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.1">1.1.1  Expressions</a></a></h3>
<h2 id="section1"><a class="header" href="#section1"><a id=section1></a>section1</a></h2>
<p>One easy way to get started at programming is to examine some typical
interactions with an interpreter for the Scheme dialect of Lisp. Imagine
that you are sitting at a computer terminal. You type an <em>expression</em>,
and the interpreter responds by displaying the result of its
<em>evaluating</em> that expression.</p>
<p>One kind of primitive expression you might
type is a number. (More precisely, the expression that you type consists
of the numerals that represent the number in base 10.) If you present
Lisp with a number</p>
<p><code>486</code>\</p>
<p>the interpreter will respond by printing <a href="book-Z-H-10.html#footnote_Temp_11">^[5]{.small}^</a></p>
<p><em><code>486</code></em>\</p>
<p>Expressions representing numbers may be
combined with an expression representing a
primitive
procedure (such as <code>+</code> or <code>*</code>) to form a compound expression that
represents the application of the procedure to those numbers. For
example:</p>
<pre><code class="language-scheme editable">(+ 137 349)
</code></pre>
<p>486</p>
<pre><code class="language-scheme editable">(- 1000 334)
</code></pre>
<p>666</p>
<pre><code class="language-scheme editable">(* 5 99)
</code></pre>
<p>495</p>
<pre><code class="language-scheme editable">(/ 10 5)
</code></pre>
<p>2</p>
<pre><code class="language-scheme editable">(+ 2.7 10)
</code></pre>
<p>12.7</p>
<p>Expressions such as these, formed by delimiting a list of
expressions within parentheses in order to denote
procedure application, are called <em>combinations</em>. The
leftmost element in the list is called the <em>operator</em>, and
the other elements are called <em>operands</em>. The
value of a combination is obtained by applying the
procedure specified by the operator to the <em>arguments</em>
that are the values of the operands.</p>
<p>The convention of placing the operator to the left of the operands is
known as <em>prefix notation</em>, and it may be somewhat
confusing at first because it departs significantly from the customary
mathematical convention. Prefix notation has several advantages,
however. One of them is that it can accommodate
procedures that may take an arbitrary number
of arguments, as in the following examples:</p>
<pre><code class="language-scheme editable">(+ 21 35 12 7)
</code></pre>
<p>75</p>
<pre><code class="language-scheme editable">(* 25 4 12)
</code></pre>
<p>1200</p>
<p>No ambiguity can arise, because the operator is always the leftmost
element and the entire combination is delimited by the parentheses.</p>
<p>A second advantage of prefix notation is that it extends
in a straightforward way to allow combinations to be <em>nested</em>, that is,
to have combinations whose elements are themselves combinations:</p>
<pre><code class="language-scheme editable">(+ (* 3 5) (- 10 6))
</code></pre>
<p>19</p>
<p>There is no limit (in principle) to the depth of such nesting and to the
overall complexity of the expressions that the Lisp interpreter can
evaluate. It is we humans who get confused by still relatively simple
expressions such as</p>
<pre><code class="language-scheme editable"></code></pre>
<p>which the interpreter would readily evaluate to be 57. We can help
ourselves by writing such an expression in the form</p>
<pre><code class="language-scheme editable">(+ (* 3
      (+ (* 2 4)
         (+ 3 5)))
   (+ (- 10 7)
      6))
</code></pre>
<p>following a formatting convention known as
<em>pretty-printing</em>, in which each long combination is
written so that the operands are aligned vertically. The resulting
indentations display clearly the structure of the
expression.<a href="book-Z-H-10.html#footnote_Temp_12">^[6]{.small}^</a></p>
<p>Even with complex expressions, the interpreter always operates in the
same basic cycle: It reads an expression from the terminal, evaluates
the expression, and prints the result. This mode of operation is often
expressed by saying that the interpreter runs in a
<em>read-eval-print loop</em>. Observe in
particular that it is not necessary to explicitly instruct the
interpreter to print the value of the
expression.<a href="book-Z-H-10.html#footnote_Temp_13">^[7]{.small}^</a></p>
<h3 id="112--naming-and-the-environment"><a class="header" href="#112--naming-and-the-environment"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.2">1.1.2  Naming and the Environment</a></a></h3>
<p>A critical aspect of a programming language is the means it provides for
using names to refer to computational objects. We say that
the name identifies a <em>variable</em> whose
<em>value</em> is the object.</p>
<p>In the Scheme dialect of Lisp, we name things with
<code>define</code>. Typing</p>
<pre><code class="language-scheme editable">(define size 2)
</code></pre>
<p>causes the interpreter to associate the value 2 with the name
<code>size</code>.<a href="book-Z-H-10.html#footnote_Temp_14">^[8]{.small}^</a>
Once the name <code>size</code> has been associated with the number 2, we can refer
to the value 2 by name:</p>
<pre><code class="language-scheme editable">size
</code></pre>
<p>2</p>
<pre><code class="language-scheme editable">(* 5 size)
</code></pre>
<p>10</p>
<p>Here are further examples of the use of <code>define</code>:</p>
<pre><code class="language-scheme editable">(define pi 3.14159)
</code></pre>
<pre><code class="language-scheme editable">(define radius 10)
</code></pre>
<pre><code class="language-scheme editable">(* pi (* radius radius))
</code></pre>
<p>314.159</p>
<pre><code class="language-scheme editable">(define circumference (* 2 pi radius))
</code></pre>
<pre><code class="language-scheme editable">circumference
</code></pre>
<p>62.8318</p>
<p><code>Define</code> is our language's simplest means of abstraction,
for it allows us to use simple names to refer to the results of compound
operations, such as the <code>circumference</code> computed above. In general,
computational objects may have very complex structures, and it would be
extremely inconvenient to have to remember and repeat their details each
time we want to use them. Indeed, complex programs are constructed by
building, step by step, computational objects of increasing complexity.
The interpreter makes this step-by-step program construction
particularly convenient because name-object associations can be created
incrementally in successive interactions. This feature encourages the
incremental development and testing of
programs and is largely responsible for the fact that a
Lisp program usually consists of a large number of relatively simple
procedures.</p>
<p>It should be clear that the possibility of associating values with
symbols and later retrieving them means that the interpreter must
maintain some sort of memory that keeps track of the name-object pairs.
This memory is called the <em>environment</em> (more precisely
the <em>global environment</em>, since we will see later that a
computation may involve a number of different
environments).<a href="book-Z-H-10.html#footnote_Temp_15">^[9]{.small}^</a></p>
<h3 id="113-evaluating-combinations"><a class="header" href="#113-evaluating-combinations"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.3">1.1.3	Evaluating Combinations</a></a></h3>
<p>One of our goals in this chapter is to
isolate issues about thinking procedurally. As a case in point, let us
consider that, in evaluating combinations, the interpreter is itself
following a procedure.</p>
<ul>
<li>To evaluate a combination, do the following:</li>
</ul>
<blockquote>
<ol>
<li>
<p>Evaluate the subexpressions of the combination.</p>
</li>
<li>
<p>Apply the procedure that is the value of the leftmost
subexpression (the operator) to the arguments that are the values of
the other subexpressions (the operands).</p>
</li>
</ol>
</blockquote>
<p>Even this simple rule illustrates some important points about processes
in general. First, observe that the first step dictates that in order to
accomplish the evaluation process for a combination we must first
perform the evaluation process on each element of the combination. Thus,
the evaluation rule is <em>recursive</em> in nature; that is, it
includes, as one of its steps, the need to invoke the rule
itself.<a href="book-Z-H-10.html#footnote_Temp_16">^[10]{.small}^</a></p>
<p>Notice how succinctly the idea of recursion can be used to
express what, in the case of a deeply nested combination, would
otherwise be viewed as a rather complicated process. For example,
evaluating</p>
<pre><code class="language-scheme editable">(* (+ 2 (* 4 6))
   (+ 3 5 7))
</code></pre>
<p>requires that the evaluation rule be applied to four different
combinations. We can obtain a picture of this process by
representing the combination in the form of a
tree, as shown in
figure	<a href="book-Z-H-10.html#%_fig_1.1">1.1</a>. Each combination is
represented by a node with branches
corresponding to the operator and the operands of the combination
stemming from it. The terminal nodes (that is, nodes with
no branches stemming from them) represent either operators or numbers.
Viewing evaluation in terms of the tree, we can imagine that the values
of the operands percolate upward, starting from the terminal nodes and
then combining at higher and higher levels. In general, we shall see
that recursion is a very powerful technique for dealing with
hierarchical, treelike objects. In fact, the ``percolate values
upward'' form of the evaluation rule is an example of a general kind
of process known as <em>tree accumulation</em>.</p>
<p><img src="ch1-Z-G-1.gif" alt="" /></p>
<p><strong>Figure 1.1:</strong>	Tree representation, showing the value of each
subcombination.</p>
<p>Next, observe that the repeated application of the first step brings us
to the point where we need to evaluate, not combinations, but primitive
expressions such as numerals, built-in operators, or other names. We
take care of the primitive cases by stipulating that</p>
<ul>
<li>the values of numerals are the numbers that they name,</li>
<li>the values of built-in operators are the machine instruction sequences
that carry out the corresponding operations, and</li>
<li>the values of other names are the objects associated with those names
in the environment.</li>
</ul>
<p>We may regard the second rule as a special case of the third one by
stipulating that symbols such as <code>+</code> and <code>*</code> are also included in the
global environment, and are associated with the sequences of machine
instructions that are their ``values.'' The key point to notice is
the role of the environment in determining the meaning of
the symbols in expressions. In an interactive language such as Lisp, it
is meaningless to speak of the value of an expression such as <code>(+ x 1)</code>
without specifying any information about the environment that would
provide a meaning for the symbol	<code>x</code> (or even for the symbol <code>+</code>). As we
shall see in chapter	3, the general notion of the environment as
providing a context in which evaluation takes place will play an
important role in our understanding of program execution.</p>
<p>Notice that the evaluation rule given above does not
handle definitions. For instance, evaluating <code>(define x 3)</code> does not
apply <code>define</code> to two arguments, one of which is the value of the symbol
<code>x</code> and the other of which is 3, since the purpose of the <code>define</code> is
precisely to associate <code>x</code> with a value. (That is, <code>(define x 3)</code> is not
a combination.)</p>
<p>Such exceptions to the general evaluation rule are called
<em>special forms</em>. <code>Define</code> is the only example of a special form that we
have seen so far, but we will meet others shortly. Each
special form has its own evaluation rule. The various kinds of
expressions (each with its associated evaluation rule) constitute the
syntax of the programming language. In comparison with
most other programming languages, Lisp has a very simple syntax; that
is, the evaluation rule for expressions can be described by a simple
general rule together with specialized rules for a small number of
special
forms.<a href="book-Z-H-10.html#footnote_Temp_17">^[11]{.small}^</a></p>
<h3 id="114--compound-procedures"><a class="header" href="#114--compound-procedures"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.4">1.1.4  Compound Procedures</a></a></h3>
<p>We have identified in Lisp some of the elements that must appear in any
powerful programming language:</p>
<ul>
<li>Numbers and arithmetic operations are primitive data and procedures.</li>
<li>Nesting of combinations provides a means of combining operations.</li>
<li>Definitions that associate names with values provide a limited means
of abstraction.</li>
</ul>
<p>Now we will learn about <em>procedure definitions</em>, a much
more powerful abstraction technique by which a compound operation can be
given a name and then referred to as a unit.</p>
<p>We begin by examining how to express the idea of ``squaring.'' We
might say, ``To square something, multiply it by itself.'' This is
expressed in our language as</p>
<pre><code class="language-scheme editable">(define (square x) (* x x))
</code></pre>
<p>We can understand this in the following way:</p>
<p><code>(define (square  x)        (*         x     x))</code>\</p>
<p>To square something, multiply it by itself.</p>
<p>We have here a <em>compound procedure</em>, which
has been given the name <code>square</code>. The procedure represents the operation
of multiplying something by itself. The thing to be multiplied is given
a local name, <code>x</code>, which plays the same role that a pronoun plays in
natural language. Evaluating
the definition creates this compound procedure and associates it with
the name
<code>square</code>.<a href="book-Z-H-10.html#footnote_Temp_18">^[12]{.small}^</a></p>
<p>The general form of a procedure definition
is</p>
<pre><code class="language-scheme editable">(define (&lt;`*`name`*`&gt; &lt;`*`formal parameters`*`&gt;) &lt;`*`body`*`&gt;)
</code></pre>
<p>The &lt;<em>name</em>&gt; is a symbol to be associated
with the procedure definition in the
environment.<a href="book-Z-H-10.html#footnote_Temp_19">^[13]{.small}^</a>
The &lt;<em>formal parameters</em>&gt; are the names
used within the body of the procedure to refer to the corresponding
arguments of the procedure. The &lt;<em>body</em>&gt;
is an expression that will yield the value of the procedure application
when the formal parameters are replaced by the actual arguments to which
the procedure is
applied.<a href="book-Z-H-10.html#footnote_Temp_20">^[14]{.small}^</a>
The &lt;<em>name</em>&gt; and the &lt;<em>formal parameters</em>&gt; are grouped within
parentheses, just as they would be in an actual call to
the procedure being defined.</p>
<p>Having defined <code>square</code>, we can now use it:</p>
<pre><code class="language-scheme editable">(square 21)
</code></pre>
<p><em><code>441</code></em><br />
\</p>
<pre><code class="language-scheme editable">(square (+ 2 5))
</code></pre>
<p><em><code>49</code></em><br />
\</p>
<pre><code class="language-scheme editable">(square (square 3))
</code></pre>
<p><em><code>81</code></em>\</p>
<p>We can also use <code>square</code> as a building block in defining other
procedures. For example, <em>x</em>^2^ + <em>y</em>^2^ can be expressed as</p>
<pre><code class="language-scheme editable">(+ (square x) (square y))
</code></pre>
<p>We can easily define a procedure <code>sum-of-squares</code> that, given any two
numbers as arguments, produces the sum of their squares:</p>
<pre><code class="language-scheme editable">(define (sum-of-squares x y)
  (+ (square x) (square y)))
</code></pre>
<p>\</p>
<pre><code class="language-scheme editable">(sum-of-squares 3 4)
</code></pre>
<p><em><code>25</code></em>\</p>
<p>Now we can use <code>sum-of-squares</code> as a building block in constructing
further procedures:</p>
<pre><code class="language-scheme editable">(define (f a)
  (sum-of-squares (+ a 1) (* a 2)))
</code></pre>
<p>\</p>
<pre><code class="language-scheme editable">(f 5)
</code></pre>
<p><em><code>136</code></em></p>
<p>Compound procedures are used in exactly the same way as
primitive procedures. Indeed, one could not tell by looking at the
definition of <code>sum-of-squares</code> given above whether <code>square</code> was built
into the interpreter, like <code>+</code> and <code>*</code>, or defined as a compound
procedure.</p>
<h3 id="115--the-substitution-model-for-procedure-application"><a class="header" href="#115--the-substitution-model-for-procedure-application"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.5">1.1.5  The Substitution Model for Procedure Application</a></a></h3>
<p>To evaluate a combination whose operator names a compound
procedure, the interpreter follows much the same process as for
combinations whose operators name primitive procedures, which we
described in section <a href="book-Z-H-10.html#%_sec_1.1.3">1.1.3</a>. That is, the
interpreter evaluates the elements of the combination and applies the
procedure (which is the value of the operator of the combination) to the
arguments (which are the values of the operands of the combination).</p>
<p>We can assume that the mechanism for applying primitive procedures to
arguments is built into the interpreter. For compound procedures, the
application process is as follows:</p>
<ul>
<li>To apply a compound procedure to arguments, evaluate the body of the
procedure with each formal parameter replaced by the corresponding
argument.</li>
</ul>
<p>To illustrate this process, let's evaluate the combination</p>
<pre><code class="language-scheme editable">(f 5)
</code></pre>
<p>where <code>f</code> is the procedure defined in
section <a href="book-Z-H-10.html#%_sec_1.1.4">1.1.4</a>. We begin by retrieving
the body of <code>f</code>:</p>
<pre><code class="language-scheme editable">(sum-of-squares (+ a 1) (* a 2))
</code></pre>
<p>Then we replace the formal parameter <code>a</code> by the argument 5:</p>
<pre><code class="language-scheme editable">(sum-of-squares (+ 5 1) (* 5 2))
</code></pre>
<p>Thus the problem reduces to the evaluation of a combination with two
operands and an operator <code>sum-of-squares</code>. Evaluating this combination
involves three subproblems. We must evaluate the operator to get the
procedure to be applied, and we must evaluate the operands to get the
arguments. Now <code>(+ 5 1)</code> produces 6 and <code>(* 5 2)</code> produces 10, so we
must apply the <code>sum-of-squares</code> procedure to 6 and 10. These values are
substituted for the formal parameters <code>x</code> and <code>y</code> in the body of
<code>sum-of-squares</code>, reducing the expression to</p>
<pre><code class="language-scheme editable">(+ (square 6) (square 10))
</code></pre>
<p>If we use the definition of <code>square</code>, this reduces to</p>
<pre><code class="language-scheme editable">(+ (* 6 6) (* 10 10))
</code></pre>
<p>which reduces by multiplication to</p>
<pre><code class="language-scheme editable">(+ 36 100)
</code></pre>
<p>and finally to</p>
<pre><code class="language-scheme editable">136
</code></pre>
<p>The process we have just described is called the <em>substitution model</em>
for procedure application. It can be taken as a model that determines
the ``meaning'' of procedure application, insofar as the procedures
in this chapter are concerned. However, there are two points that should
be stressed:</p>
<ul>
<li>The purpose of the substitution is to help us think about procedure
application, not to provide a description of how the interpreter
really works. Typical interpreters do not evaluate procedure
applications by manipulating the text of a procedure to substitute
values for the formal parameters. In practice, the
``substitution'' is accomplished by using a local environment for
the formal parameters. We will discuss this more fully in chapters 3
and 4 when we examine the implementation of an interpreter in detail.</li>
<li>Over the course of this book, we will present a sequence of
increasingly elaborate models of how interpreters work, culminating
with a complete implementation of an interpreter and compiler in
chapter 5. The substitution model is only the first of these models
-- a way to get started thinking formally about the evaluation
process. In general, when modeling phenomena in science
and engineering, we begin with simplified, incomplete models. As we
examine things in greater detail, these simple models become
inadequate and must be replaced by more refined models. The
substitution model is no exception. In particular, when we address in
chapter 3 the use of procedures with ``mutable data,'' we will see
that the substitution model breaks down and must be replaced by a more
complicated model of procedure
application.<a href="book-Z-H-10.html#footnote_Temp_21">^[15]{.small}^</a></li>
</ul>
<h4 id="applicative-order-versus-normal-order"><a class="header" href="#applicative-order-versus-normal-order"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_22">Applicative order versus normal order</a></a></h4>
<p>According to the description of evaluation given in
section <a href="book-Z-H-10.html#%_sec_1.1.3">1.1.3</a>, the interpreter first
evaluates the operator and operands and then applies the resulting
procedure to the resulting arguments. This is not the only way to
perform evaluation. An alternative evaluation model would not evaluate
the operands until their values were needed. Instead it would first
substitute operand expressions for parameters until it obtained an
expression involving only primitive operators, and would then perform
the evaluation. If we used this method, the evaluation of</p>
<pre><code class="language-scheme editable">(f 5)
</code></pre>
<p>would proceed according to the sequence of expansions</p>
<pre><code class="language-scheme editable">(sum-of-squares (+ 5 1) (* 5 2))
</code></pre>
<pre><code class="language-scheme editable">(+    (square (+ 5 1))      (square (* 5 2))  )
</code></pre>
<pre><code class="language-scheme editable">(+    (* (+ 5 1) (+ 5 1))   (* (* 5 2) (* 5 2)))
</code></pre>
<p>followed by the reductions</p>
<pre><code class="language-scheme editable">(+         (* 6 6)             (* 10 10))
</code></pre>
<pre><code class="language-scheme editable">(+           36                   100)
</code></pre>
<pre><code class="language-scheme editable">                    136
</code></pre>
<p>This gives the same answer as our previous evaluation model, but the
process is different. In particular, the evaluations of <code>(+ 5 1)</code> and
<code>(* 5 2)</code> are each performed twice here, corresponding to the reduction
of the expression</p>
<pre><code class="language-scheme editable">(* x x)
</code></pre>
<p>with <code>x</code> replaced respectively by <code>(+ 5 1)</code> and <code>(* 5 2)</code>.</p>
<p>This alternative ``fully expand and then reduce'' evaluation method
is known as <em>normal-order evaluation</em>, in contrast to the
``evaluate the arguments and then apply'' method that the
interpreter actually uses, which is called
<em>applicative-order evaluation</em>. It can be shown that, for
procedure applications that can be modeled using substitution (including
all the procedures in the first two chapters of this book) and that
yield legitimate values, normal-order and applicative-order evaluation
produce the same value. (See exercise <a href="book-Z-H-10.html#%_thm_1.5">1.5</a>
for an instance of an ``illegitimate'' value where normal-order and
applicative-order evaluation do not give the same result.)</p>
<p>Lisp uses applicative-order evaluation,
partly because of the additional efficiency obtained from avoiding
multiple evaluations of expressions such as those illustrated with
<code>(+ 5 1)</code> and <code>(* 5 2)</code> above and, more significantly, because
normal-order evaluation becomes much more complicated to deal with when
we leave the realm of procedures that can be modeled by substitution. On
the other hand, normal-order evaluation can be an extremely valuable
tool, and we will investigate some of its implications in chapters 3 and
4.<a href="book-Z-H-10.html#footnote_Temp_23">^[16]{.small}^</a></p>
<h3 id="116--conditional-expressions-and-predicates"><a class="header" href="#116--conditional-expressions-and-predicates"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.6">1.1.6  Conditional Expressions and Predicates</a></a></h3>
<p>The expressive power of the class of procedures that we can define at
this point is very limited, because we have no way to make tests and to
perform different operations depending on the result of a test. For
instance, we cannot define a procedure that computes the
absolute value of a number by testing whether the number
is positive, negative, or zero and taking different actions in the
different cases according to the rule</p>
<p><img src="ch1-Z-G-2.gif" alt="" /></p>
<p>This construct is called a <em>case analysis</em>, and there is a
special form in Lisp for notating such a case analysis. It is called
<code>cond</code> (which stands for
``conditional''), and it is used as follows:</p>
<pre><code class="language-scheme editable">(define (abs x)
  (cond ((&gt; x 0) x)
        ((= x 0) 0)
        ((&lt; x 0) (- x))))
</code></pre>
<p>The general form of a conditional expression is</p>
<p><code>(cond (&lt;</code><em><code>p</code><del><code>1</code></del></em><code>&gt; &lt;</code><em><code>e</code><del><code>1</code></del></em><code>&gt;)</code><br />
<code>      (&lt;</code><em><code>p</code><del><code>2</code></del></em><code>&gt; &lt;</code><em><code>e</code><del><code>2</code></del></em><code>&gt;)</code><br />
<code>      </code><img src="book-Z-G-D-18.gif" alt="" /><br />
<code>      (&lt;</code><em><code>p</code>~</em><code>n</code><em>~</em><code>&gt; &lt;</code><em><code>e</code>~</em><code>n</code><em>~</em><code>&gt;))</code>\</p>
<p>consisting of the symbol <code>cond</code> followed by parenthesized
pairs of expressions <code>(&lt;</code><em><code>p</code></em><code>&gt; &lt;</code><em><code>e</code></em><code>&gt;)</code> called
<em>clauses</em>. The first expression in each pair
is a <em>predicate</em> -- that is, an expression whose value is
interpreted as either true or
false.<a href="book-Z-H-10.html#footnote_Temp_24">^[17]{.small}^</a></p>
<p>Conditional expressions are evaluated as
follows. The predicate &lt;<em>p~1~</em>&gt; is evaluated first. If its value is
false, then &lt;<em>p~2~</em>&gt; is evaluated. If &lt;<em>p~2~</em>&gt;'s value is also
false, then &lt;<em>p~3~</em>&gt; is evaluated. This process continues until a
predicate is found whose value is true, in which case the interpreter
returns the value of the corresponding <em>consequent
expression</em> &lt;<em>e</em>&gt; of the clause as the value of the conditional
expression. If none of the &lt;<em>p</em>&gt;'s is found to be true, the value of
the <code>cond</code> is undefined.</p>
<p>The word <em>predicate</em> is used for procedures that return
true or false, as well as for expressions that evaluate to true or
false. The absolute-value procedure <code>abs</code> makes use of the
primitive
predicates <code>&gt;</code>, <code>&lt;</code>, and
<code>=</code>.<a href="book-Z-H-10.html#footnote_Temp_25">^[18]{.small}^</a>
These take two numbers as arguments and test whether the first number
is, respectively, greater than, less than, or equal to the second
number, returning true or false accordingly.</p>
<p>Another way to write the absolute-value procedure is</p>
<pre><code class="language-scheme editable">(define (abs x)
  (cond ((&lt; x 0) (- x))
        (else x)))
</code></pre>
<p>which could be expressed in English as ``If <em>x</em> is less than zero
return - <em>x</em>; otherwise return <em>x</em>.'' <code>Else</code> is a
special symbol that can be used in place of the &lt;<em>p</em>&gt; in the final
clause of a <code>cond</code>. This causes the <code>cond</code> to return as its value the
value of the corresponding &lt;<em>e</em>&gt; whenever all previous clauses have
been bypassed. In fact, any expression that always evaluates to a true
value could be used as the &lt;<em>p</em>&gt; here.</p>
<p>Here is yet another way to write the absolute-value procedure:</p>
<pre><code class="language-scheme editable">(define (abs x)
  (if (&lt; x 0)
      (- x)
      x))
</code></pre>
<p>This uses the special form
<code>if</code>, a restricted type of conditional that can be used when there are
precisely two cases in the case analysis. The general form
of an <code>if</code> expression is</p>
<pre><code class="language-scheme editable">(if &lt;`*`predicate`*`&gt; &lt;`*`consequent`*`&gt; &lt;`*`alternative`*`&gt;)
</code></pre>
<p>To evaluate an <code>if</code>
expression, the interpreter starts by evaluating the
&lt;<em>predicate</em>&gt; part of the expression. If the
&lt;<em>predicate</em>&gt; evaluates to a true value, the interpreter then
evaluates the &lt;<em>consequent</em>&gt; and returns its value.
Otherwise it evaluates the &lt;<em>alternative</em>&gt; and returns
its
value.<a href="book-Z-H-10.html#footnote_Temp_26">^[19]{.small}^</a></p>
<p>In addition to primitive predicates such as <code>&lt;</code>, <code>=</code>, and <code>&gt;</code>, there are
logical composition operations, which enable us to construct compound
predicates. The three most frequently used are these:</p>
<ul>
<li></li>
<li>
<p><code>(and &lt;</code><em><code>e</code><del><code>1</code></del></em><code>&gt; ``...`` &lt;</code><em><code>e</code>~</em><code>n</code><em>~</em><code>&gt;)</code></p>
<p>The interpreter evaluates the expressions &lt;<em>e</em>&gt; one at a time, in
left-to-right order. If any &lt;<em>e</em>&gt; evaluates to false, the value of
the <code>and</code> expression is false, and the rest of the &lt;<em>e</em>&gt;'s are not
evaluated. If all &lt;<em>e</em>&gt;'s evaluate to true values, the value of the
<code>and</code> expression is the value of the last one.</p>
</li>
<li>
<p><code>(or &lt;</code><em><code>e</code><del><code>1</code></del></em><code>&gt; ``...`` &lt;</code><em><code>e</code>~</em><code>n</code><em>~</em><code>&gt;)</code></p>
<p>The interpreter evaluates the expressions &lt;<em>e</em>&gt; one at a time, in
left-to-right order. If any &lt;<em>e</em>&gt; evaluates to a true value, that
value is returned as the value of the <code>or</code> expression, and the rest of
the &lt;<em>e</em>&gt;'s are not evaluated. If all &lt;<em>e</em>&gt;'s evaluate to false,
the value of the <code>or</code> expression is false.</p>
</li>
<li>
<p><code>(not &lt;</code><em><code>e</code></em><code>&gt;)</code></p>
<p>The value of a <code>not</code> expression is true when the expression &lt;<em>e</em>&gt;
evaluates to false, and false otherwise.</p>
</li>
</ul>
<p>Notice that <code>and</code> and <code>or</code> are special
forms, not procedures, because the subexpressions are not necessarily
all evaluated. <code>Not</code> is an ordinary procedure.</p>
<p>As an example of how these are used, the condition that a number <em>x</em> be
in the range 5 &lt; <em>x</em> &lt; 10 may be expressed as</p>
<pre><code class="language-scheme editable">(and (&gt; x 5) (&lt; x 10))
</code></pre>
<p>As another example, we can define a predicate to test whether one number
is greater than or equal to another as</p>
<p><code>(define (&gt;= x y)</code><br />
<code>  (or (&gt; x y) (= x y)))</code>\</p>
<p>or alternatively as</p>
<pre><code class="language-scheme editable">(define (&gt;= x y)
  (not (&lt; x y)))
</code></pre>
<p><strong>Exercise 1.1.</strong>  Below is a sequence of expressions.
What is the result printed by the interpreter in response to each
expression? Assume that the sequence is to be evaluated in the order in
which it is presented.</p>
<pre><code class="language-scheme editable">10
(+ 5 3 4)
(- 9 1)
(/ 6 2)
(+ (* 2 4) (- 4 6))
(define a 3)
(define b (+ a 1))
(+ a b (* a b))
(= a b)
(if (and (&gt; b a) (&lt; b (* a b)))
    b
    a)
(cond ((= a 4) 6)
      ((= b 4) (+ 6 7 a))
      (else 25))
(+ 2 (if (&gt; b a) b a))
(* (cond ((&gt; a b) a)
         ((&lt; a b) b)
         (else -1))
   (+ a 1))
</code></pre>
<p><strong>Exercise 1.2.</strong>  Translate the following expression
into prefix form</p>
<p><img src="ch1-Z-G-3.gif" alt="" /></p>
<p><strong>Exercise 1.3.</strong>  Define a procedure that takes three
numbers as arguments and returns the sum of the squares of the two
larger numbers.</p>
<p><strong>Exercise
1.4.</strong>  Observe that our model
of evaluation allows for combinations whose operators are compound
expressions. Use this observation to describe the behavior of the
following procedure:</p>
<pre><code class="language-scheme editable">(define (a-plus-abs-b a b)
  ((if (&gt; b 0) + -) a b))
</code></pre>
<p><strong>Exercise 1.5.</strong>  Ben
Bitdiddle has invented a test to determine whether the interpreter he is
faced with is using applicative-order evaluation or normal-order
evaluation. He defines the following two procedures:</p>
<pre><code class="language-scheme editable">(define (p) (p))
</code></pre>
<pre><code class="language-scheme editable">(define (test x y)
  (if (= x 0)
      0
      y))
</code></pre>
<p>Then he evaluates the expression</p>
<pre><code class="language-scheme editable">(test 0 (p))
</code></pre>
<p>What behavior will Ben observe with an interpreter that uses
applicative-order evaluation? What behavior will he observe with an
interpreter that uses normal-order evaluation? Explain your answer.
(Assume that the evaluation rule for the
special form <code>if</code> is the same whether the interpreter is using normal or
applicative order: The predicate expression is evaluated first, and the
result determines whether to evaluate the consequent or the alternative
expression.)</p>
<h3 id="117--example-square-roots-by-newtons-method"><a class="header" href="#117--example-square-roots-by-newtons-method"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.7">1.1.7  Example: Square Roots by Newton's Method</a></a></h3>
<p>Procedures, as introduced above, are much
like ordinary mathematical functions. They specify a value that is
determined by one or more parameters. But there is an important
difference between mathematical functions and computer procedures.
Procedures must be effective.</p>
<p>As a case in point, consider the problem of computing square roots. We
can define the square-root function as</p>
<p><img src="ch1-Z-G-4.gif" alt="" /></p>
<p>This describes a perfectly legitimate mathematical function. We could
use it to recognize whether one number is the square root of another, or
to derive facts about square roots in general. On the other hand, the
definition does not describe a procedure. Indeed, it tells us almost
nothing about how to actually find the square root of a given number. It
will not help matters to rephrase this definition in pseudo-Lisp:</p>
<pre><code class="language-scheme editable">(define (sqrt x)
  (the y (and (&gt;= y 0)
              (= (square y) x))))
</code></pre>
<p>This only begs the question.</p>
<p>The contrast between function and procedure is a reflection of the
general distinction between describing properties of things and
describing how to do things, or, as it is sometimes referred to, the
distinction between declarative knowledge
and imperative knowledge. In mathematics we
are usually concerned with declarative (what is) descriptions, whereas
in computer science we are usually concerned with imperative (how to)
descriptions.<a href="book-Z-H-10.html#footnote_Temp_32">^[20]{.small}^</a></p>
<p>How does one compute square roots? The most
common way is to use Newton's method of successive approximations,
which says that whenever we have a guess <em>y</em> for the value of the square
root of a number <em>x</em>, we can perform a simple manipulation to get a
better guess (one closer to the actual square root) by averaging <em>y</em>
with
<em>x</em>/<em>y</em>.<a href="book-Z-H-10.html#footnote_Temp_33">^[21]{.small}^</a>
For example, we can compute the square root of 2 as follows. Suppose our
initial guess is 1:</p>
<hr />
<p>Guess    Quotient              Average</p>
<p>1        (2/1) = 2             ((2 + 1)/2) = 1.5</p>
<p>1.5      (2/1.5) = 1.3333      ((1.3333 + 1.5)/2) = 1.4167</p>
<p>1.4167   (2/1.4167) = 1.4118   ((1.4167 + 1.4118)/2) = 1.4142</p>
<p>1.4142   <code>...</code>                 <code>...</code></p>
<hr />
<p>Continuing this process, we obtain better and better approximations to
the square root.</p>
<p>Now let's formalize the process in terms of procedures. We start with a
value for the radicand (the number whose square root we
are trying to compute) and a value for the guess. If the guess is good
enough for our purposes, we are done; if not, we must repeat the process
with an improved guess. We write this basic strategy as a procedure:</p>
<pre><code class="language-scheme editable">(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x)
                 x)))
</code></pre>
<p>A guess is improved by averaging it with the quotient of the radicand
and the old guess:</p>
<pre><code class="language-scheme editable">(define (improve guess x)
  (average guess (/ x guess)))
</code></pre>
<p>where</p>
<pre><code class="language-scheme editable">(define (average x y)
  (/ (+ x y) 2))
</code></pre>
<p>We also have to say what we mean by ``good enough.'' The following
will do for illustration, but it is not really a very good test. (See
exercise
<a href="book-Z-H-10.html#%_thm_1.7">1.7</a>.) The idea is to improve the
answer until it is close enough so that its square differs from the
radicand by less than a predetermined tolerance (here
0.001):<a href="book-Z-H-10.html#footnote_Temp_34">^[22]{.small}^</a></p>
<pre><code class="language-scheme editable">(define
(good-enough?
guess
x)

(&lt; (abs (- (square guess) x)) 0.001))
</code></pre>
<p>Finally, we need a way to get started. For instance, we can always guess
that the square root of any number is
1:<a href="book-Z-H-10.html#footnote_Temp_35">^[23]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (sqrt x)
  (sqrt-iter 1.0 x))
</code></pre>
<p>If we type these definitions to the interpreter, we can use <code>sqrt</code> just
as we can use any procedure:</p>
<pre><code class="language-scheme editable">(sqrt	9)
</code></pre>
<p><em><code>3.00009155413138</code></em></p>
<pre><code class="language-scheme editable">(sqrt	(+ 100	37))
</code></pre>
<p><em><code>11.704699917758145</code></em></p>
<pre><code class="language-scheme editable">(sqrt	(+ (sqrt	2)	(sqrt	3)))
</code></pre>
<p><em><code>1.7739279023207892</code></em></p>
<pre><code class="language-scheme editable">(square	(sqrt	1000))
</code></pre>
<p><em><code>1000.000369924366</code></em></p>
<p>The <code>sqrt</code> program also illustrates that the simple
procedural language we have introduced so far is sufficient for writing
any purely numerical program that one could write in, say, C or Pascal.
This might seem surprising, since we have not included in our language
any iterative (looping) constructs that direct the
computer to do something over and over again. <code>Sqrt-iter</code>, on the other
hand, demonstrates how iteration can be accomplished using no special
construct other than the ordinary ability to call a
procedure.<a href="book-Z-H-10.html#footnote_Temp_36">^[24]{.small}^</a></p>
<p><strong>Exercise 1.6.</strong>  Alyssa P.
Hacker doesn't see why <code>if</code> needs to be provided as a special form.
``Why can't I just define it as an ordinary procedure in terms of
<code>cond</code>?'' she asks. Alyssa's friend Eva Lu Ator claims this can
indeed be done, and she defines a new version of <code>if</code>:</p>
<pre><code class="language-scheme editable">(define (new-if predicate then-clause else-clause)
  (cond (predicate then-clause)
        (else else-clause)))
</code></pre>
<p>Eva demonstrates the program for Alyssa:</p>
<pre><code class="language-scheme editable">(new-if (= 2 3) 0 5)
</code></pre>
<p><em><code>5</code></em></p>
<pre><code class="language-scheme editable">(new-if (= 1 1) 0 5)
</code></pre>
<p><em><code>0</code></em></p>
<p>Delighted, Alyssa uses <code>new-if</code> to rewrite the square-root program:</p>
<pre><code class="language-scheme editable">(define (sqrt-iter guess x)
  (new-if (good-enough? guess x)
          guess
          (sqrt-iter (improve guess x)
                     x)))
</code></pre>
<p>What happens when Alyssa attempts to use this to compute square roots?
Explain.</p>
<p><strong>Exercise 1.7.</strong>  The <code>good-enough?</code> test used in
computing square roots will not be very effective for finding the square
roots of very small numbers. Also, in real computers, arithmetic
operations are almost always performed with limited precision. This
makes our test inadequate for very large numbers. Explain these
statements, with examples showing how the test fails for small and large
numbers. An alternative strategy for implementing <code>good-enough?</code> is to
watch how <code>guess</code> changes from one iteration to the next and to stop
when the change is a very small fraction of the guess. Design a
square-root procedure that uses this kind of end test. Does this work
better for small and large numbers?</p>
<p><strong>Exercise 1.8.</strong>  Newton's
method for cube roots is based on the fact that if <em>y</em> is an
approximation to the cube root of <em>x</em>, then a better approximation is
given by the value</p>
<p><img src="ch1-Z-G-5.gif" alt="" /></p>
<p>Use this formula to implement a cube-root procedure analogous to the
square-root procedure. (In section <a href="book-Z-H-12.html#%_sec_1.3.4">1.3.4</a>
we will see how to implement Newton's method in general as an
abstraction of these square-root and cube-root procedures.)</p>
<h3 id="118--procedures-as-black-box-abstractions"><a class="header" href="#118--procedures-as-black-box-abstractions"><a href="book-Z-H-4.html#%_toc_%_sec_1.1.8">1.1.8  Procedures as Black-Box Abstractions</a></a></h3>
<p><code>Sqrt</code> is our first example of a process defined by a set of mutually
defined procedures. Notice that the definition of <code>sqrt-iter</code> is
<em>recursive</em>; that is, the procedure is defined in terms of
itself. The idea of being able to define a procedure in terms of itself
may be disturbing; it may seem unclear how such a ``circular''
definition could make sense at all, much less specify a well-defined
process to be carried out by a computer. This will be addressed more
carefully in section <a href="book-Z-H-11.html#%_sec_1.2">1.2</a>. But first let's
consider some other important points illustrated by the <code>sqrt</code> example.</p>
<p>Observe that the problem of computing square roots breaks
up naturally into a number of subproblems: how to tell whether a guess
is good enough, how to improve a guess, and so on. Each of these tasks
is accomplished by a separate procedure. The entire <code>sqrt</code> program can
be viewed as a cluster of procedures (shown in
figure <a href="book-Z-H-10.html#%_fig_1.2">1.2</a>) that mirrors the decomposition
of the problem into subproblems.</p>
<p><img src="ch1-Z-G-6.gif" alt="" /></p>
<p><strong>Figure 1.2:</strong>  Procedural decomposition of the <code>sqrt</code> program.</p>
<p>The importance of this decomposition strategy is not
simply that one is dividing the program into parts. After all, we could
take any large program and divide it into parts -- the first ten lines,
the next ten lines, the next ten lines, and so on. Rather, it is crucial
that each procedure accomplishes an identifiable task that can be used
as a module in defining other procedures. For example,
when we define the <code>good-enough?</code> procedure in terms of <code>square</code>, we are
able to regard the <code>square</code> procedure as a ``black
box.'' We are not at that moment concerned with <em>how</em> the procedure
computes its result, only with the fact that it computes the square. The
details of how the square is computed can be suppressed, to be
considered at a later time. Indeed, as far as the <code>good-enough?</code>
procedure is concerned, <code>square</code> is not quite a procedure but rather an
abstraction of a procedure, a so-called
<em>procedural abstraction</em>. At this level of
abstraction, any procedure that computes the square is equally good.</p>
<p>Thus, considering only the values they return, the following two
procedures for squaring a number should be indistinguishable. Each takes
a numerical argument and produces the square of that number as the
value.<a href="book-Z-H-10.html#footnote_Temp_40">^[25]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (square x) (* x x))
</code></pre>
<pre><code class="language-scheme editable">(define (square x)
  (exp (double (log x))))
</code></pre>
<pre><code class="language-scheme editable">(define (double x) (+ x x))
</code></pre>
<p>So a procedure definition should be able to suppress detail. The users
of the procedure may not have written the procedure themselves, but may
have obtained it from another programmer as a black box. A user should
not need to know how the procedure is implemented in order to use it.</p>
<h4 id="local-names"><a class="header" href="#local-names"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_41">Local names</a></a></h4>
<p>One detail of a procedure's implementation that should
not matter to the user of the procedure is the implementer's choice of
names for the procedure's formal parameters. Thus, the following
procedures should not be distinguishable:</p>
<pre><code class="language-scheme editable">(define (square x) (* x x))
</code></pre>
<pre><code class="language-scheme editable">(define (square y) (* y y))
</code></pre>
<p>This principle -- that the meaning of a procedure should be independent
of the parameter names used by its author -- seems on the surface to be
self-evident, but its consequences are profound. The simplest
consequence is that the parameter names of a procedure must be local to
the body of the procedure. For example, we used <code>square</code> in the
definition of <code>good-enough?</code> in our square-root procedure:</p>
<pre><code class="language-scheme editable">(define (good-enough? guess x)
  (&lt; (abs (- (square guess) x)) 0.001))
</code></pre>
<p>The intention of the author of <code>good-enough?</code> is to determine if the
square of the first argument is within a given tolerance of the second
argument. We see that the author of <code>good-enough?</code> used the name <code>guess</code>
to refer to the first argument and <code>x</code> to refer to the second argument.
The argument of <code>square</code> is <code>guess</code>. If the author of <code>square</code> used <code>x</code>
(as above) to refer to that argument, we see that the <code>x</code> in
<code>good-enough?</code> must be a different <code>x</code> than the one in <code>square</code>. Running
the procedure <code>square</code> must not affect the value of <code>x</code> that is used by
<code>good-enough?</code>, because that value of <code>x</code> may be needed by
<code>good-enough?</code> after <code>square</code> is done computing.</p>
<p>If the parameters were not local to the bodies of their respective
procedures, then the parameter <code>x</code> in <code>square</code> could be confused with
the parameter <code>x</code> in <code>good-enough?</code>, and the behavior of <code>good-enough?</code>
would depend upon which version of <code>square</code> we used. Thus, <code>square</code>
would not be the black box we desired.</p>
<p>A formal parameter of a procedure has a very
special role in the procedure definition, in that it doesn't matter
what name the formal parameter has. Such a name is called a
<em>bound variable</em>, and we say that the
procedure definition <em>binds</em> its formal parameters. The
meaning of a procedure definition is unchanged if a bound variable is
consistently renamed throughout the
definition.<a href="book-Z-H-10.html#footnote_Temp_42">^[26]{.small}^</a>
If a variable is not bound, we say that it is
<em>free</em>. The set of expressions for which a
binding defines a name is called the <em>scope</em>
of that name. In a procedure definition, the bound variables declared as
the formal parameters of the
procedure have the body of the procedure as their scope.</p>
<p>In the definition of <code>good-enough?</code> above, <code>guess</code> and <code>x</code> are bound
variables but <code>&lt;</code>, <code>-</code>, <code>abs</code>, and <code>square</code> are free. The meaning of
<code>good-enough?</code> should be independent of the names we choose for <code>guess</code>
and <code>x</code> so long as they are distinct and different from <code>&lt;</code>, <code>-</code>, <code>abs</code>,
and <code>square</code>. (If we renamed <code>guess</code> to <code>abs</code> we would have introduced a
bug by <em>capturing</em> the
variable <code>abs</code>. It would have changed from free to bound.) The meaning
of <code>good-enough?</code> is not independent of the names of its free variables,
however. It surely depends upon the fact (external to this definition)
that the symbol <code>abs</code> names a procedure for computing the absolute value
of a number. <code>Good-enough?</code> will compute a different function if we
substitute <code>cos</code> for <code>abs</code> in its definition.</p>
<h4 id="internal-definitions-and-block-structure"><a class="header" href="#internal-definitions-and-block-structure"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_43">Internal definitions and block structure</a></a></h4>
<p>We have one kind of name isolation available to us so far: The formal
parameters of a procedure are local to the body of the procedure. The
square-root program illustrates another way in which we would like to
control the use of names. The existing program consists of
separate procedures:</p>
<pre><code class="language-scheme editable">(define (sqrt x)
  (sqrt-iter 1.0 x))
</code></pre>
<pre><code class="language-scheme editable">(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))
</code></pre>
<pre><code class="language-scheme editable">(define (good-enough? guess x)
  (&lt; (abs (- (square guess) x)) 0.001))
</code></pre>
<pre><code class="language-scheme editable">(define (improve guess x)
  (average guess (/ x guess)))
</code></pre>
<p>The problem with this program is that the only procedure that is
important to users of <code>sqrt</code> is <code>sqrt</code>. The other procedures
(<code>sqrt-iter</code>, <code>good-enough?</code>, and <code>improve</code>) only clutter up their
minds. They may not define any other procedure called <code>good-enough?</code> as
part of another program to work together with the square-root program,
because <code>sqrt</code> needs it. The problem is especially severe in the
construction of large systems by many separate programmers. For example,
in the construction of a large library of numerical procedures, many
numerical functions are computed as successive approximations and thus
might have procedures named <code>good-enough?</code> and <code>improve</code> as auxiliary
procedures. We would like to localize the subprocedures, hiding them
inside <code>sqrt</code> so that <code>sqrt</code> could coexist with other successive
approximations, each having its own private <code>good-enough?</code> procedure. To
make this possible, we allow a procedure to have
internal definitions that are local to that
procedure. For example, in the square-root problem we can write</p>
<pre><code class="language-scheme editable">(define (sqrt x)
  (define (good-enough? guess x)
    (&lt; (abs (- (square guess) x)) 0.001))
  (define (improve guess x)
    (average guess (/ x guess)))
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
        guess
        (sqrt-iter (improve guess x) x)))
  (sqrt-iter 1.0 x))
</code></pre>
<p>Such nesting of definitions, called <em>block structure</em>, is basically the
right solution to the simplest name-packaging problem. But there is a
better idea lurking here. In addition to internalizing the definitions
of the auxiliary procedures, we can simplify them. Since <code>x</code> is bound in
the definition of <code>sqrt</code>, the procedures <code>good-enough?</code>, <code>improve</code>, and
<code>sqrt-iter</code>, which are defined internally to <code>sqrt</code>, are in the scope of
<code>x</code>. Thus, it is not necessary to pass <code>x</code> explicitly to each of these
procedures. Instead, we allow <code>x</code> to be a
free variable in the internal definitions,
as shown below. Then <code>x</code> gets its value from the argument with which the
enclosing procedure <code>sqrt</code> is called. This discipline is called
<em>lexical
scoping</em>.<a href="book-Z-H-10.html#footnote_Temp_44">^[27]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (sqrt x)
  (define (good-enough? guess)
    (&lt; (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
        guess
        (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))
</code></pre>
<p>We will use block structure extensively to help us break up large
programs into tractable
pieces.<a href="book-Z-H-10.html#footnote_Temp_45">^[28]{.small}^</a>
The idea of block structure originated with the programming language
Algol 60. It appears in most advanced programming
languages and is an important tool for helping to organize the
construction of large programs.</p>
<hr />
<p><a href="book-Z-H-10.html#call_footnote_Temp_10">^[4]{.small}^</a>
The characterization of numbers as ``simple data'' is a barefaced
bluff. In fact, the treatment of numbers is one of the trickiest and
most confusing aspects of any programming language. Some typical issues
involved are these: Some
computer systems distinguish <em>integers</em>, such as 2, from <em>real numbers</em>,
such as 2.71. Is the real number 2.00 different from the integer 2? Are
the arithmetic operations used for integers the same as the operations
used for real numbers? Does 6 divided by 2 produce 3, or 3.0? How large
a number can we represent? How many decimal places of accuracy can we
represent? Is the range of integers the same as the range of real
numbers? Above and beyond
these questions, of course, lies a collection of issues concerning
roundoff and truncation errors -- the entire science of numerical
analysis. Since our focus in this book is on large-scale program design
rather than on numerical techniques, we are going to ignore these
problems. The numerical examples in this chapter will exhibit the usual
roundoff behavior that one observes when using arithmetic operations
that preserve a limited number of decimal places of accuracy in
noninteger operations.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_11">^[5]{.small}^</a>
Throughout this book, when we wish to emphasize the
distinction between the input typed by the user and the response printed
by the interpreter, we will show the latter in slanted characters.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_12">^[6]{.small}^</a>
Lisp systems typically provide features to
aid the user in formatting expressions. Two especially useful features
are one that automatically indents to the proper pretty-print position
whenever a new line is started and one that highlights the matching left
parenthesis whenever a right parenthesis is typed.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_13">^[7]{.small}^</a>
Lisp obeys the
convention that every expression has a value. This convention, together
with the old reputation of Lisp as an inefficient language, is the
source of the quip by Alan Perlis (paraphrasing Oscar Wilde) that
``Lisp programmers know the value of everything but the cost of
nothing.''</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_14">^[8]{.small}^</a>
In this book, we do not show the
interpreter's response to evaluating definitions, since this is highly
implementation-dependent.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_15">^[9]{.small}^</a>
Chapter 3 will show that this notion of environment is crucial, both for
understanding how the interpreter works and for implementing
interpreters.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_16">^[10]{.small}^</a>
It may seem strange that the evaluation rule says, as part of the first
step, that we should evaluate the leftmost element of a combination,
since at this point that can only be an operator such as <code>+</code> or <code>*</code>
representing a built-in primitive procedure such as addition or
multiplication. We will see later that it is useful to be able to work
with combinations whose operators are themselves compound expressions.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_17">^[11]{.small}^</a>
Special
syntactic forms that are simply convenient alternative surface
structures for things that can be written in more uniform ways are
sometimes called <em>syntactic sugar</em>, to use a phrase coined by Peter
Landin. In comparison with users of other languages, Lisp programmers,
as a rule, are less concerned with matters of syntax. (By contrast,
examine any Pascal manual and notice how much of it is devoted to
descriptions of syntax.) This disdain for syntax is due partly to the
flexibility of Lisp, which makes it easy to change surface syntax, and
partly to the observation that many ``convenient'' syntactic
constructs, which make the language less uniform, end up causing more
trouble than they are worth when programs become large and complex. In
the words of Alan Perlis, ``Syntactic sugar causes cancer of the
semicolon.''</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_18">^[12]{.small}^</a>
Observe that there are two different operations being combined here: we
are creating the procedure, and we are giving it the name <code>square</code>. It
is possible, indeed important, to be able to separate these two notions
-- to create procedures without naming them, and to give names to
procedures that have already been created. We will see how to do this in
section <a href="book-Z-H-12.html#%_sec_1.3.2">1.3.2</a>.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_19">^[13]{.small}^</a>
Throughout this book, we will describe the
general syntax of expressions by using italic symbols delimited by angle
brackets -- e.g., &lt;<em>name</em>&gt; -- to denote the ``slots'' in the
expression to be filled in when such an expression is actually used.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_20">^[14]{.small}^</a>
More generally, the body of the procedure can be a
sequence of expressions. In this case, the interpreter evaluates each
expression in the sequence in turn and returns the value of the final
expression as the value of the procedure application.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_21">^[15]{.small}^</a>
Despite the simplicity of the substitution idea, it turns out to be
surprisingly complicated to give a rigorous mathematical definition of
the substitution process. The problem arises from the possibility of
confusion between the names used for the formal parameters of a
procedure and the (possibly identical) names used in the expressions to
which the procedure may be applied. Indeed, there is a long history of
erroneous definitions of <em>substitution</em> in the literature of logic and
programming semantics. See Stoy 1977 for a careful
discussion of substitution.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_23">^[16]{.small}^</a>
In chapter 3 we will introduce <em>stream processing</em>, which is a way of
handling apparently ``infinite'' data structures by incorporating a
limited form of normal-order evaluation. In
section <a href="book-Z-H-27.html#%_sec_4.2">4.2</a> we will modify the Scheme
interpreter to produce a normal-order variant of Scheme.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_24">^[17]{.small}^</a>
``Interpreted
as either true or false'' means this: In Scheme, there are two
distinguished values that are denoted by the constants <code>#t</code> and <code>#f</code>.
When the interpreter checks a predicate's value, it interprets <code>#f</code> as
false. Any other value is treated as true. (Thus, providing <code>#t</code> is
logically unnecessary, but it is convenient.) In this book we will use
names <code>true</code> and <code>false</code>, which are associated with the values <code>#t</code> and
<code>#f</code> respectively.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_25">^[18]{.small}^</a>
<code>Abs</code> also uses the ``minus'' operator
<code>-</code>, which, when used with a single operand, as in <code>(- x)</code>, indicates
negation.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_26">^[19]{.small}^</a>
A minor difference between
<code>if</code> and <code>cond</code> is that the &lt;<em>e</em>&gt; part of each <code>cond</code> clause may be a
sequence of expressions. If the corresponding &lt;<em>p</em>&gt; is found to be
true, the expressions &lt;<em>e</em>&gt; are evaluated in sequence and the value of
the final expression in the sequence is returned as the value of the
<code>cond</code>. In an <code>if</code> expression, however, the &lt;<em>consequent</em>&gt; and
&lt;<em>alternative</em>&gt; must be single expressions.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_32">^[20]{.small}^</a>
Declarative and imperative descriptions are intimately related, as
indeed are mathematics and computer science. For instance, to say that
the answer produced by a program is ``correct'' is to
make a declarative statement about the program. There is a large amount
of research aimed at establishing techniques for proving
that programs are correct, and much of the technical difficulty of this
subject has to do with negotiating the transition between imperative
statements (from which programs are constructed) and declarative
statements (which can be used to deduce things). In a related vein, an
important current area in programming-language design is the exploration
of so-called very high-level languages, in
which one actually programs in terms of declarative statements. The idea
is to make interpreters sophisticated enough so that, given ``what
is'' knowledge specified by the programmer, they can generate ``how
to'' knowledge automatically. This cannot be done in general, but
there are important areas where progress has been made. We shall revisit
this idea in chapter 4.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_33">^[21]{.small}^</a>
This square-root algorithm is actually a special case of Newton's
method, which is a general technique for finding roots of equations. The
square-root algorithm itself was developed by Heron of
Alexandria in the first century A.D. We will see how to
express the general Newton's method as a Lisp procedure in
section <a href="book-Z-H-12.html#%_sec_1.3.4">1.3.4</a>.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_34">^[22]{.small}^</a>
We will usually give
predicates names
ending with question marks, to help us remember that they are
predicates. This is just a stylistic convention. As far as the
interpreter is concerned, the question mark is just an ordinary
character.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_35">^[23]{.small}^</a>
Observe that we express our initial guess as 1.0 rather than 1. This
would not make any difference in many Lisp implementations.
MIT
Scheme, however, distinguishes between exact integers and decimal
values, and dividing two integers produces a rational number rather than
a decimal. For example, dividing 10 by 6 yields 5/3, while dividing 10.0
by 6.0 yields 1.6666666666666667. (We will learn how to implement
arithmetic on rational numbers in
section <a href="book-Z-H-14.html#%_sec_2.1.1">2.1.1</a>.) If we start with an
initial guess of 1 in our square-root program, and <em>x</em> is an exact
integer, all subsequent values produced in the square-root computation
will be rational numbers rather than decimals. Mixed operations on
rational numbers and decimals always yield decimals, so starting with an
initial guess of 1.0 forces all subsequent values to be decimals.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_36">^[24]{.small}^</a>
Readers who are worried about the efficiency issues involved in using
procedure calls to implement iteration should note the remarks on
``tail recursion'' in section <a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a>.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_40">^[25]{.small}^</a>
It is not even clear which of these procedures is a more efficient
implementation. This depends upon the hardware available. There are
machines for which the ``obvious'' implementation is the less
efficient one. Consider a machine that has extensive tables of
logarithms and antilogarithms stored in a very efficient manner.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_42">^[26]{.small}^</a>
The concept of consistent renaming is actually subtle and difficult to
define formally. Famous logicians have made embarrassing errors here.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_44">^[27]{.small}^</a>
Lexical scoping dictates that free variables in a procedure are taken to
refer to bindings made by enclosing procedure definitions; that is, they
are looked up in the environment in which the procedure
was defined. We will see how this works in detail in chapter 3 when we
study environments and the detailed behavior of the interpreter.</p>
<p><a href="book-Z-H-10.html#call_footnote_Temp_45">^[28]{.small}^</a>
Embedded definitions must come first in a procedure body.
The management is not responsible for the consequences of running
programs that intertwine definition and use.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="12--procedures-and-the-processes-they-generate"><a class="header" href="#12--procedures-and-the-processes-they-generate"><a href="book-Z-H-4.html#%_toc_%_sec_1.2">1.2  Procedures and the Processes They Generate</a></a></h2>
<p>We have now considered the elements of programming: We have used
primitive arithmetic operations, we have combined these operations, and
we have abstracted these composite operations by defining them as
compound procedures. But that is not enough to enable us to say that we
know how to program. Our situation is analogous to that of someone who
has learned the rules for how the pieces move in chess but knows nothing
of typical openings, tactics, or strategy. Like the novice chess player,
we don't yet know the common patterns of usage in the domain. We lack
the knowledge of which moves are worth making (which procedures are
worth defining). We lack the experience to predict the consequences of
making a move (executing a procedure).</p>
<p>The ability to visualize the consequences of the actions under
consideration is crucial to becoming an expert programmer, just as it is
in any synthetic, creative activity. In becoming an expert photographer,
for example, one must learn how to look at a scene and know how dark
each region will appear on a print for each possible choice of exposure
and development conditions. Only then can one reason backward, planning
framing, lighting, exposure, and development to obtain the desired
effects. So it is with programming, where we are planning the course of
action to be taken by a process and where we control the process by
means of a program. To become experts, we must learn to visualize the
processes generated by various types of procedures. Only after we have
developed such a skill can we learn to reliably construct programs that
exhibit the desired behavior.</p>
<p>A procedure is a pattern for
the <em>local evolution</em> of a computational process. It specifies how each
stage of the process is built upon the previous stage. We would like to
be able to make statements about the overall, or <em>global</em>, behavior of a
process whose local evolution has been specified by a procedure. This is
very difficult to do in general, but we can at least try to describe
some typical patterns of process evolution.</p>
<p>In this section we will examine some common ``shapes'' for processes
generated by simple procedures. We will also investigate the rates at
which these processes consume the important computational resources of
time and space. The procedures we will consider are very simple. Their
role is like that played by test patterns in photography: as
oversimplified prototypical patterns, rather than practical examples in
their own right.</p>
<h3 id="121--linear-recursion-and-iteration"><a class="header" href="#121--linear-recursion-and-iteration"><a href="book-Z-H-4.html#%_toc_%_sec_1.2.1">1.2.1  Linear Recursion and Iteration</a></a></h3>
<p><img src="ch1-Z-G-7.gif" alt="" /></p>
<p><strong>Figure 1.3:</strong>  A linear recursive process for computing 6!.</p>
<p>We begin by considering the factorial function, defined by</p>
<p><img src="ch1-Z-G-8.gif" alt="" /></p>
<p>There are many ways to compute factorials. One way is to make use of the
observation that <em>n</em>! is equal to <em>n</em> times (<em>n</em> - 1)! for any positive
integer <em>n</em>:</p>
<p><img src="ch1-Z-G-9.gif" alt="" /></p>
<p>Thus, we can compute <em>n</em>! by computing (<em>n</em> - 1)! and multiplying the
result by <em>n</em>. If we add the stipulation that 1! is equal to 1, this
observation translates directly into a procedure:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
</code></pre>
<p>We can use the substitution model of
section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a> to watch this procedure in
action computing 6!, as shown in
figure <a href="book-Z-H-11.html#%_fig_1.3">1.3</a>.</p>
<p>Now let's take a different perspective on computing factorials. We
could describe a rule for computing <em>n</em>! by specifying that we first
multiply 1 by 2, then multiply the result by 3, then by 4, and so on
until we reach <em>n</em>. More formally, we maintain a running product,
together with a counter that counts from 1 up to <em>n</em>. We can describe
the computation by saying that the counter and the product
simultaneously change from one step to the next according to the rule</p>
<p>product <img src="book-Z-G-D-14.gif" alt="" /> counter · product</p>
<p>counter <img src="book-Z-G-D-14.gif" alt="" /> counter + 1</p>
<p>and stipulating that <em>n</em>! is the value of the product when the counter
exceeds <em>n</em>.</p>
<p><img src="ch1-Z-G-10.gif" alt="" /></p>
<p><strong>Figure 1.4:</strong>  A linear iterative process for computing 6!.</p>
<p>Once again, we can recast our description as a procedure for computing
factorials:<a href="book-Z-H-11.html#footnote_Temp_46">^[29]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (&gt; counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
</code></pre>
<p>As before, we can use the substitution model to visualize the process of
computing 6!, as shown in figure <a href="book-Z-H-11.html#%_fig_1.4">1.4</a>.</p>
<p>Compare the two processes. From one point of view, they seem hardly
different at all. Both compute the same mathematical function on the
same domain, and each requires a number of steps proportional to <em>n</em> to
compute <em>n</em>!. Indeed, both processes even carry out the same sequence of
multiplications, obtaining the same sequence of partial products. On the
other hand, when we consider the
``shapes'' of the two processes, we find
that they evolve quite differently.</p>
<p>Consider the first process. The substitution model reveals a shape of
expansion followed by contraction, indicated by the arrow in
figure <a href="book-Z-H-11.html#%_fig_1.3">1.3</a>. The expansion occurs as the
process builds up a chain of <em>deferred operations</em> (in
this case, a chain of multiplications). The contraction occurs as the
operations are actually performed. This type of process, characterized
by a chain of deferred operations, is called a
<em>recursive process</em>. Carrying out this
process requires that the interpreter keep track of the operations to be
performed later on. In the computation of <em>n</em>!, the length of the chain
of deferred multiplications, and hence the amount of information needed
to keep track of it, grows linearly with <em>n</em> (is
proportional to <em>n</em>), just like the number of steps.
Such a process is called a
<em>linear recursive process</em>.</p>
<p>By contrast, the second process does not grow and shrink. At each step,
all we need to keep track of, for any <em>n</em>, are the current values of the
variables <code>product</code>, <code>counter</code>, and <code>max-count</code>. We call this an
<em>iterative process</em>. In general, an
iterative process is one whose state can be summarized by a fixed number
of <em>state variables</em>, together with a fixed rule that
describes how the state variables should be updated as the process moves
from state to state and an (optional) end test that specifies conditions
under which the process should terminate. In computing <em>n</em>!, the number
of steps required grows linearly with <em>n</em>. Such a process is called a
<em>linear iterative process</em>.</p>
<p>The contrast between the two processes can be seen in another way. In
the iterative case, the program variables provide a complete description
of the state of the process at any point. If we stopped the computation
between steps, all we would need to do to resume the computation is to
supply the interpreter with the values of the three program variables.
Not so with the recursive process. In this case there is some additional
``hidden'' information, maintained by the interpreter and not
contained in the program variables, which indicates ``where the
process is'' in negotiating the chain of deferred operations. The
longer the chain, the more information must be
maintained.<a href="book-Z-H-11.html#footnote_Temp_47">^[30]{.small}^</a></p>
<p>In contrasting iteration and recursion, we must be careful not to
confuse the notion of a recursive <em>process</em>
with the notion of a recursive <em>procedure</em>. When we describe a procedure
as recursive, we are referring to the syntactic fact that the procedure
definition refers (either directly or indirectly) to the procedure
itself. But when we describe a process as following a pattern that is,
say, linearly recursive, we are speaking about how the process evolves,
not about the syntax of how a procedure is written. It may seem
disturbing that we refer to a recursive procedure such as <code>fact-iter</code> as
generating an iterative process. However, the process really is
iterative: Its state is captured completely by its three state
variables, and an interpreter need keep track of only three variables in
order to execute the process.</p>
<p>One reason that the distinction between process and procedure may be
confusing is that most implementations of common languages (including
Ada, Pascal, and C) are
designed in such a way that the interpretation of any recursive
procedure consumes an amount of memory that grows with the number of
procedure calls, even when the process described is, in principle,
iterative. As a consequence, these languages can describe iterative
processes only by resorting to special-purpose ``looping
constructs'' such as <code>do</code>, <code>repeat</code>, <code>until</code>, <code>for</code>, and <code>while</code>. The
implementation of Scheme we shall consider in chapter 5 does not share
this defect. It will execute an iterative process in constant space,
even if the iterative process is described by a recursive procedure. An
implementation with this property is called
<em>tail-recursive</em>. With a tail-recursive implementation,
iteration can be expressed using the ordinary procedure
call mechanism, so that special iteration constructs are useful only as
syntactic
sugar.<a href="book-Z-H-11.html#footnote_Temp_48">^[31]{.small}^</a></p>
<p><strong>Exercise 1.9.</strong>  Each of the following two procedures
defines a method for adding two positive integers in terms of the
procedures <code>inc</code>, which increments its argument by 1, and <code>dec</code>, which
decrements its argument by 1.</p>
<pre><code class="language-scheme editable">(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))
</code></pre>
<pre><code class="language-scheme editable">(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
</code></pre>
<p>Using the substitution model, illustrate the process generated by each
procedure in evaluating <code>(+ 4 5)</code>. Are these processes iterative or
recursive?</p>
<p><strong>Exercise 1.10.</strong>  The
following procedure computes a mathematical function called Ackermann's
function.</p>
<pre><code class="language-scheme editable">(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))
</code></pre>
<p>What are the values of the following expressions?</p>
<pre><code class="language-scheme editable">(A 1 10)
</code></pre>
<p>\</p>
<pre><code class="language-scheme editable">(A 2 4)
</code></pre>
<p>\</p>
<pre><code class="language-scheme editable">(A 3 3)
</code></pre>
<p>Consider the following procedures, where <code>A</code> is the procedure defined
above:</p>
<pre><code class="language-scheme editable">(define (f n) (A 0 n))
</code></pre>
<pre><code class="language-scheme editable">(define (g n) (A 1 n))
</code></pre>
<pre><code class="language-scheme editable">(define (h n) (A 2 n))
</code></pre>
<pre><code class="language-scheme editable">(define (k n) (* 5 n n))
</code></pre>
<p>Give concise mathematical definitions for the functions computed by the
procedures <code>f</code>, <code>g</code>, and <code>h</code> for positive integer values of <em>n</em>. For
example, <code>(k n)</code> computes 5<em>n</em>^2^.</p>
<h3 id="122--tree-recursion"><a class="header" href="#122--tree-recursion"><a href="book-Z-H-4.html#%_toc_%_sec_1.2.2">1.2.2  Tree Recursion</a></a></h3>
<p>Another common pattern of
computation is called <em>tree recursion</em>. As an example, consider
computing the sequence of Fibonacci numbers, in which each
number is the sum of the preceding two:</p>
<p><img src="ch1-Z-G-11.gif" alt="" /></p>
<p>In general, the Fibonacci numbers can be defined by the rule</p>
<p><img src="ch1-Z-G-12.gif" alt="" /></p>
<p>We can immediately translate this definition into a recursive procedure
for computing Fibonacci numbers:</p>
<pre><code class="language-scheme editable">(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
</code></pre>
<p><img src="ch1-Z-G-13.gif" alt="" /></p>
<p><strong>Figure 1.5:</strong>  The tree-recursive process generated in computing
<code>(fib 5)</code>.</p>
<p>Consider the pattern of this computation. To compute <code>(fib 5)</code>, we
compute <code>(fib 4)</code> and <code>(fib 3)</code>. To compute <code>(fib 4)</code>, we compute
<code>(fib 3)</code> and <code>(fib 2)</code>. In general, the evolved process looks like a
tree, as shown in figure <a href="book-Z-H-11.html#%_fig_1.5">1.5</a>. Notice that
the branches split into two at each level (except at the bottom); this
reflects the fact that the <code>fib</code> procedure calls itself twice each time
it is invoked.</p>
<p>This procedure is instructive as a prototypical tree recursion, but it
is a terrible way to compute Fibonacci numbers because it does so much
redundant computation. Notice in
figure <a href="book-Z-H-11.html#%_fig_1.5">1.5</a> that the entire computation of
<code>(fib 3)</code> -- almost half the work -- is duplicated. In fact, it is not
hard to show that the number of times the procedure will compute
<code>(fib 1)</code> or <code>(fib 0)</code> (the number of leaves in the above tree, in
general) is precisely <em>Fib</em>(<em>n</em> + 1). To get an idea of how bad this is,
one can show that the value of <em>Fib</em>(<em>n</em>) grows
exponentially with <em>n</em>. More precisely (see
exercise <a href="book-Z-H-11.html#%_thm_1.13">1.13</a>), <em>Fib</em>(<em>n</em>) is the closest
integer to <img src="book-Z-G-D-11.gif" alt="" />^<em>n</em>^
/<img src="book-Z-G-D-13.gif" alt="" />5, where</p>
<p><img src="ch1-Z-G-14.gif" alt="" /></p>
<p>is the <em>golden ratio</em>, which satisfies the equation</p>
<p><img src="ch1-Z-G-15.gif" alt="" /></p>
<p>Thus, the process uses a number of steps that grows exponentially with
the input. On the other hand, the space required grows only linearly
with the input, because we need keep track only of which nodes are above
us in the tree at any point in the computation. In general, the number
of steps required by a tree-recursive process will be proportional to
the number of nodes in the tree, while the space required will be
proportional to the maximum depth of the tree.</p>
<p>We can also formulate an iterative process for computing the Fibonacci
numbers. The idea is to use a pair of integers <em>a</em> and <em>b</em>, initialized
to <em>Fib</em>(1) = 1 and <em>Fib</em>(0) = 0, and to repeatedly apply the
simultaneous transformations</p>
<p><img src="ch1-Z-G-16.gif" alt="" /></p>
<p>It is not hard to show that, after applying this transformation <em>n</em>
times, <em>a</em> and <em>b</em> will be equal, respectively, to <em>Fib</em>(<em>n</em> + 1) and
<em>Fib</em>(<em>n</em>). Thus, we can compute Fibonacci numbers iteratively using the
procedure</p>
<pre><code class="language-scheme editable">(define (fib n)
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
</code></pre>
<p>This second method for computing <em>Fib</em>(<em>n</em>) is a linear iteration. The
difference in number of steps required by the two methods -- one linear
in <em>n</em>, one growing as fast as <em>Fib</em>(<em>n</em>) itself -- is enormous, even
for small inputs.</p>
<p>One should not conclude from this that tree-recursive processes are
useless. When we consider processes that operate on hierarchically
structured data rather than numbers, we will find that tree recursion is
a natural and powerful
tool.<a href="book-Z-H-11.html#footnote_Temp_51">^[32]{.small}^</a>
But even in numerical operations, tree-recursive processes can be useful
in helping us to understand and design programs. For instance, although
the first <code>fib</code> procedure is much less efficient than the second one, it
is more straightforward, being little more than a translation into Lisp
of the definition of the Fibonacci sequence. To formulate the iterative
algorithm required noticing that the computation could be recast as an
iteration with three state variables.</p>
<h4 id="example-counting-change"><a class="header" href="#example-counting-change"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_52">Example: Counting change</a></a></h4>
<p>It takes only a bit of cleverness to come up with the
iterative Fibonacci algorithm. In contrast, consider the following
problem: How many different ways can we make change of $ 1.00, given
half-dollars, quarters, dimes, nickels, and pennies? More generally, can
we write a procedure to compute the number of ways to change any given
amount of money?</p>
<p>This problem has a simple solution as a recursive procedure. Suppose we
think of the types of coins available as arranged in some order. Then
the following relation holds:</p>
<p>The number of ways to change amount <em>a</em> using <em>n</em> kinds of coins equals</p>
<ul>
<li>the number of ways to change amount <em>a</em> using all but the first kind
of coin, plus</li>
<li>the number of ways to change amount <em>a</em> - <em>d</em> using all <em>n</em> kinds of
coins, where <em>d</em> is the denomination of the first kind of coin.</li>
</ul>
<p>To see why this is true, observe that the ways to make change can be
divided into two groups: those that do not use any of the first kind of
coin, and those that do. Therefore, the total number of ways to make
change for some amount is equal to the number of ways to make change for
the amount without using any of the first kind of coin, plus the number
of ways to make change assuming that we do use the first kind of coin.
But the latter number is equal to the number of ways to make change for
the amount that remains after using a coin of the first kind.</p>
<p>Thus, we can recursively reduce the problem of changing a given amount
to the problem of changing smaller amounts using fewer kinds of coins.
Consider this reduction rule carefully, and convince yourself that we
can use it to describe an algorithm if we specify the following
degenerate
cases:<a href="book-Z-H-11.html#footnote_Temp_53">^[33]{.small}^</a></p>
<ul>
<li>If <em>a</em> is exactly 0, we should count that as 1 way to make change.</li>
<li>If <em>a</em> is less than 0, we should count that as 0 ways to make change.</li>
<li>If <em>n</em> is 0, we should count that as 0 ways to make change.</li>
</ul>
<p>We can easily translate this description into a recursive procedure:</p>
<pre><code class="language-scheme editable">(define (count-change amount)
  (cc amount 5))
(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (&lt; amount 0) (= kinds-of-coins 0)) 0)
        (else (+ (cc amount
                     (- kinds-of-coins 1))
                 (cc (- amount
                        (first-denomination kinds-of-coins))
                     kinds-of-coins)))))
(define (first-denomination kinds-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of-coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))
</code></pre>
<p>(The <code>first-denomination</code> procedure takes as input the number of kinds
of coins available and returns the denomination of the first kind. Here
we are thinking of the coins as arranged in order from largest to
smallest, but any order would do as well.) We can now answer our
original question about changing a dollar:</p>
<p><code>(count-change 100)</code><br />
<em><code>292</code></em>\</p>
<p><code>Count-change</code> generates a tree-recursive process with redundancies
similar to those in our first implementation of <code>fib</code>. (It will take
quite a while for that 292 to be computed.) On the other hand, it is not
obvious how to design a better algorithm for computing the result, and
we leave this problem as a challenge. The observation that a
tree-recursive process may be highly inefficient but often
easy to specify and understand has led people to propose that one could
get the best of both worlds by designing a ``smart compiler'' that
could transform tree-recursive procedures into more efficient procedures
that compute the same
result.<a href="book-Z-H-11.html#footnote_Temp_54">^[34]{.small}^</a></p>
<p><strong>Exercise 1.11.</strong>  A function <em>f</em> is defined by the
rule that <em>f</em>(<em>n</em>) = <em>n</em> if <em>n</em>&lt;3 and <em>f</em>(<em>n</em>) = <em>f</em>(<em>n</em> - 1) +
2<em>f</em>(<em>n</em> - 2) + 3<em>f</em>(<em>n</em> - 3) if <em>n</em>[&gt;]{.underline} 3. Write a
procedure that computes <em>f</em> by means of a recursive process. Write a
procedure that computes <em>f</em> by means of an iterative process.</p>
<p><strong>Exercise 1.12.</strong>  The following pattern
of numbers is called <em>Pascal's triangle</em>.</p>
<p><img src="ch1-Z-G-17.gif" alt="" /></p>
<p>The numbers at the edge of the triangle are all 1, and each number
inside the triangle is the sum of the two numbers above
it.<a href="book-Z-H-11.html#footnote_Temp_57">^[35]{.small}^</a>
Write a procedure that computes elements of Pascal's triangle by means
of a recursive process.</p>
<p><strong>Exercise 1.13.</strong>  Prove that <em>Fib</em>(<em>n</em>) is the closest
integer to
<img src="book-Z-G-D-11.gif" alt="" />5,
where <img src="book-Z-G-D-11.gif" alt="" /> = (1 +
<img src="book-Z-G-D-13.gif" alt="" />5)/2. Hint: Let
<img src="book-Z-G-D-12.gif" alt="" /> = (1 -
<img src="book-Z-G-D-13.gif" alt="" />5)/2. Use induction and the definition
of the Fibonacci numbers (see
section <a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a>) to prove that <em>Fib</em>(<em>n</em>)
= (<img src="book-Z-G-D-11.gif" alt="" />^<em>n</em>^ -
<img src="book-Z-G-D-12.gif" alt="" />5.</p>
<h3 id="123--orders-of-growth"><a class="header" href="#123--orders-of-growth"><a href="book-Z-H-4.html#%_toc_%_sec_1.2.3">1.2.3  Orders of Growth</a></a></h3>
<p>The previous examples illustrate that processes can
differ considerably in the rates at which they consume computational
resources. One convenient way to describe this difference is to use the
notion of <em>order of growth</em> to obtain a gross measure of
the resources required by a process as the inputs become
larger.</p>
<p>Let <em>n</em> be a parameter that measures the size of the problem, and let
<em>R</em>(<em>n</em>) be the amount of resources the process requires for a problem
of size <em>n</em>. In our previous examples we took <em>n</em> to be the number for
which a given function is to be computed, but there are other
possibilities. For instance, if our goal is to compute an approximation
to the square root of a number, we might take <em>n</em> to be the number of
digits accuracy required. For matrix multiplication we might take <em>n</em> to
be the number of rows in the matrices. In general there are a number of
properties of the problem with respect to which it will be desirable to
analyze a given process. Similarly, <em>R</em>(<em>n</em>) might measure the number of
internal storage registers used, the number of elementary machine
operations performed, and so on. In computers that do only a fixed
number of operations at a time, the time required will be proportional
to the number of elementary machine operations performed.</p>
<p>We say that <em>R</em>(<em>n</em>) has order of growth
<img src="book-Z-G-D-3.gif" alt="" />(<em>f</em>(<em>n</em>)), written <em>R</em>(<em>n</em>) =
<img src="book-Z-G-D-3.gif" alt="" />(<em>f</em>(<em>n</em>)) (pronounced ``theta of
<em>f</em>(<em>n</em>)''), if there are positive constants <em>k</em><del>1</del> and <em>k</em><del>2</del>
independent of <em>n</em> such that</p>
<p><img src="ch1-Z-G-18.gif" alt="" /></p>
<p>for any sufficiently large value of <em>n</em>. (In other words, for large <em>n</em>,
the value <em>R</em>(<em>n</em>) is sandwiched between <em>k</em><del>1</del><em>f</em>(<em>n</em>) and
<em>k</em><del>2</del><em>f</em>(<em>n</em>).)</p>
<p>For instance, with the linear
recursive process for computing factorial described in
section <a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a> the number of steps grows
proportionally to the input <em>n</em>. Thus, the steps required for this
process grows as <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>). We also saw
that the space required grows as <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>).
For the iterative factorial,
the number of steps is still <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>) but
the space is <img src="book-Z-G-D-3.gif" alt="" />(1) -- that is,
constant.<a href="book-Z-H-11.html#footnote_Temp_59">^[36]{.small}^</a>
The tree-recursive Fibonacci
computation requires
<img src="book-Z-G-D-3.gif" alt="" />^<em>n</em>^)
steps and space <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>), where
<img src="book-Z-G-D-11.gif" alt="" /> is the golden ratio described in
section <a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a>.</p>
<p>Orders of growth provide only a crude description of the behavior of a
process. For example, a process requiring <em>n</em>^2^ steps and a process
requiring 1000<em>n</em>^2^ steps and a process requiring 3<em>n</em>^2^ + 10<em>n</em> + 17
steps all have <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>^2^) order of
growth. On the other hand, order of growth provides a useful indication
of how we may expect the behavior of the process to change as we change
the size of the problem. For a
<img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>) (linear) process,
doubling the size will roughly double the amount of resources used. For
an exponential process, each increment in problem size
will multiply the resource utilization by a constant factor. In the
remainder of section <a href="book-Z-H-11.html#%_sec_1.2">1.2</a> we will examine
two algorithms whose order of growth is logarithmic, so
that doubling the problem size increases the resource requirement by a
constant amount.</p>
<p><strong>Exercise 1.14.</strong>  Draw the tree illustrating the
process generated by the <code>count-change</code> procedure of
section <a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a> in making change for 11
cents. What are the orders of growth of the space and number of steps
used by this process as the amount to be changed increases?</p>
<p><strong>Exercise 1.15.</strong>  The sine of an angle
(specified in radians) can be computed by making use of the
approximation <code>sin</code> <em>x</em> <img src="book-Z-G-D-20.gif" alt="" /> <em>x</em> if <em>x</em> is
sufficiently small, and the trigonometric identity</p>
<p><img src="ch1-Z-G-19.gif" alt="" /></p>
<p>to reduce the size of the argument of <code>sin</code>. (For purposes of this
exercise an angle is considered ``sufficiently small'' if its
magnitude is not greater than 0.1 radians.) These ideas are incorporated
in the following procedures:</p>
<pre><code class="language-scheme editable">(define (cube x) (* x x x))
(define (p x) (- (* 3 x) (* 4 (cube x))))
(define (sine angle)
   (if (not (&gt; (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
</code></pre>
<p>a.  How many times is the procedure <code>p</code> applied when <code>(sine 12.15)</code> is
evaluated?</p>
<p>b.  What is the order of growth in space and number of steps (as a
function of <em>a</em>) used by the process generated by the <code>sine</code> procedure
when <code>(sine a)</code> is evaluated?</p>
<h3 id="124--exponentiation"><a class="header" href="#124--exponentiation"><a href="book-Z-H-4.html#%_toc_%_sec_1.2.4">1.2.4  Exponentiation</a></a></h3>
<p>Consider the problem of computing the exponential of a
given number. We would like a procedure that takes as arguments a base
<em>b</em> and a positive integer exponent <em>n</em> and computes <em>b</em>^<em>n</em>^. One way
to do this is via the recursive definition</p>
<p><img src="ch1-Z-G-20.gif" alt="" /></p>
<p>which translates readily into the procedure</p>
<pre><code class="language-scheme editable">(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))
</code></pre>
<p>This is a linear recursive process, which requires
<img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>) steps and
<img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>) space. Just as with factorial, we
can readily formulate an equivalent linear iteration:</p>
<pre><code class="language-scheme editable">(define (expt b n)
  (expt-iter b n 1))

(define (expt-iter b counter product)
  (if (= counter 0)
      product
      (expt-iter b
                (- counter 1)
                (* b product)))) 
</code></pre>
<p>This version requires <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>) steps and
<img src="book-Z-G-D-3.gif" alt="" />(1) space.</p>
<p>We can compute exponentials in fewer steps by using
successive squaring. For instance, rather than computing <em>b</em>^8^ as</p>
<p><img src="ch1-Z-G-21.gif" alt="" /></p>
<p>we can compute it using three multiplications:</p>
<p><img src="ch1-Z-G-22.gif" alt="" /></p>
<p>This method works fine for exponents that are powers of 2. We can also
take advantage of successive squaring in computing exponentials in
general if we use the rule</p>
<p><img src="ch1-Z-G-23.png" alt="" /></p>
<p>We can express this method as a procedure:</p>
<pre><code class="language-scheme editable">(define (fast-expt b n)
  (cond ((= n 0) 1)
        ((even? n) (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
</code></pre>
<p>where the predicate to test whether an integer is even is defined in
terms of the primitive procedure <code>remainder</code>
by</p>
<pre><code class="language-scheme editable">(define (even? n)
  (= (remainder n 2) 0))
</code></pre>
<p>The process evolved by <code>fast-expt</code> grows
logarithmically with <em>n</em> in both space and number of steps. To see this,
observe that computing <em>b</em>^2<em>n</em>^ using <code>fast-expt</code> requires only one
more multiplication than computing <em>b</em>^<em>n</em>^. The size of the exponent we
can compute therefore doubles (approximately) with every new
multiplication we are allowed. Thus, the number of multiplications
required for an exponent of <em>n</em> grows about as fast as the logarithm of
<em>n</em> to the base 2. The process has
<img src="book-Z-G-D-3.gif" alt="" />(<code>log</code> <em>n</em>)
growth.<a href="book-Z-H-11.html#footnote_Temp_62">^[37]{.small}^</a></p>
<p>The difference between <img src="book-Z-G-D-3.gif" alt="" />(<code>log</code> <em>n</em>)
growth and <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>) growth becomes
striking as <em>n</em> becomes large. For example, <code>fast-expt</code> for <em>n</em> = 1000
requires only 14
multiplications.<a href="book-Z-H-11.html#footnote_Temp_63">^[38]{.small}^</a>
It is also possible to use the idea of successive squaring to devise an
iterative algorithm that computes exponentials with a logarithmic number
of steps (see exercise <a href="book-Z-H-11.html#%_thm_1.16">1.16</a>), although,
as is often the case with iterative algorithms, this is not written down
so straightforwardly as the recursive
algorithm.<a href="book-Z-H-11.html#footnote_Temp_64">^[39]{.small}^</a></p>
<p><strong>Exercise 1.16.</strong>  Design a procedure that evolves an
iterative exponentiation process that uses successive squaring and uses
a logarithmic number of steps, as does <code>fast-expt</code>. (Hint: Using the
observation that (<em>b</em>^<em>n</em>/2^)^2^ = (<em>b</em>^2^)^<em>n</em>/2^, keep, along with the
exponent <em>n</em> and the base <em>b</em>, an additional state variable <em>a</em>, and
define the state transformation in such a way that the product <em>a</em>
<em>b</em>^<em>n</em>^ is unchanged from state to state. At the beginning of the
process <em>a</em> is taken to be 1, and the answer is given by the value of
<em>a</em> at the end of the process. In general, the technique of defining an
<em>invariant quantity</em> that remains unchanged from state to
state is a powerful way to think about the design of
iterative algorithms.)</p>
<p><strong>Exercise 1.17.</strong>  The exponentiation algorithms in
this section are based on performing exponentiation by means of repeated
multiplication. In a similar way, one can perform integer multiplication
by means of repeated addition. The following multiplication procedure
(in which it is assumed that our language can only add, not multiply) is
analogous to the <code>expt</code> procedure:</p>
<pre><code class="language-scheme editable">(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
</code></pre>
<p>This algorithm takes a number of steps that is linear in <code>b</code>. Now
suppose we include, together with addition, operations <code>double</code>, which
doubles an integer, and <code>halve</code>, which divides an (even) integer by 2.
Using these, design a multiplication procedure analogous to <code>fast-expt</code>
that uses a logarithmic number of steps.</p>
<p><strong>Exercise 1.18.</strong>  Using the results of
exercises <a href="book-Z-H-11.html#%_thm_1.16">1.16</a>
and <a href="book-Z-H-11.html#%_thm_1.17">1.17</a>, devise a procedure that
generates an iterative process for multiplying two integers in terms of
adding, doubling, and halving and uses a logarithmic number of
steps.<a href="book-Z-H-11.html#footnote_Temp_68">^[40]{.small}^</a></p>
<p><strong>Exercise 1.19.</strong>   There is a clever
algorithm for computing the Fibonacci numbers in a logarithmic number of
steps. Recall the transformation of the state variables <em>a</em> and <em>b</em> in
the <code>fib-iter</code> process of section <a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a>:
<em>a</em> <img src="book-Z-G-D-14.gif" alt="" /> <em>a</em> + <em>b</em> and <em>b</em>
<img src="book-Z-G-D-14.gif" alt="" /> <em>a</em>. Call this transformation <em>T</em>,
and observe that applying <em>T</em> over and over again <em>n</em> times, starting
with 1 and 0, produces the pair <em>Fib</em>(<em>n</em> + 1) and <em>Fib</em>(<em>n</em>). In other
words, the Fibonacci numbers are produced by applying <em>T</em>^<em>n</em>^, the
<em>n</em>th power of the transformation <em>T</em>, starting with the pair (1,0). Now
consider <em>T</em> to be the special case of <em>p</em> = 0 and <em>q</em> = 1 in a family
of transformations <em>T</em><del><em>pq</em></del>, where <em>T</em><del><em>pq</em></del> transforms the pair
(<em>a</em>,<em>b</em>) according to <em>a</em> <img src="book-Z-G-D-14.gif" alt="" /> <em>bq</em> +
<em>aq</em> + <em>ap</em> and <em>b</em> <img src="book-Z-G-D-14.gif" alt="" /> <em>bp</em> + <em>aq</em>. Show
that if we apply such a transformation <em>T</em><del><em>pq</em></del> twice, the effect is
the same as using a single transformation <em>T</em><del><em>p</em>'<em>q</em>'</del> of the same
form, and compute <em>p</em>' and <em>q</em>' in terms of <em>p</em> and <em>q</em>. This gives us
an explicit way to square these transformations, and thus we can compute
<em>T</em>^<em>n</em>^ using successive squaring, as in the <code>fast-expt</code> procedure. Put
this all together to complete the following procedure, which runs in a
logarithmic number of
steps:<a href="book-Z-H-11.html#footnote_Temp_70">^[41]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (fib n)
  (fib-iter 1 0 0 1 n))
(define (fib-iter a b p q count)
  (cond ((= count 0) b)
        ((even? count)
         (fib-iter a
                   b
                   &lt;`*`??`*`&gt;      `*`; compute `*`p`*`'`
                   &lt;`*`??`*`&gt;      `*`; compute `*`q`*`'`
                   (/ count 2)))
        (else (fib-iter (+ (* b q) (* a q) (* a p))
                        (+ (* b p) (* a q))
                        p
                        q
                        (- count 1)))))
</code></pre>
<h3 id="125--greatest-common-divisors"><a class="header" href="#125--greatest-common-divisors"><a href="book-Z-H-4.html#%_toc_%_sec_1.2.5">1.2.5  Greatest Common Divisors</a></a></h3>
<p>The greatest common divisor (GCD) of two integers <em>a</em> and
<em>b</em> is defined to be the largest integer that divides both <em>a</em> and <em>b</em>
with no remainder. For example, the GCD of 16 and 28 is 4. In chapter 2,
when we investigate how to implement rational-number arithmetic, we will
need to be able to compute GCDs in order to reduce rational numbers to
lowest terms. (To reduce a rational number to lowest terms, we must
divide both the numerator and the denominator by their GCD. For example,
16/28 reduces to 4/7.) One way to find the GCD of two integers is to
factor them and search for common factors, but there is a famous
algorithm that is much more efficient.</p>
<p>The idea of the algorithm is based on the observation
that, if <em>r</em> is the remainder when <em>a</em> is divided by <em>b</em>, then the
common divisors of <em>a</em> and <em>b</em> are precisely the same as the common
divisors of <em>b</em> and <em>r</em>. Thus, we can use the equation</p>
<p><img src="ch1-Z-G-24.gif" alt="" /></p>
<p>to successively reduce the problem of computing a GCD to the problem of
computing the GCD of smaller and smaller pairs of integers. For example,</p>
<p><img src="ch1-Z-G-25.gif" alt="" /></p>
<p>reduces GCD(206,40) to GCD(2,0), which is 2. It is possible to show that
starting with any two positive integers and performing repeated
reductions will always eventually produce a pair where the second number
is 0. Then the GCD is the other number in the pair. This method for
computing the GCD is known as <em>Euclid's
Algorithm</em>.<a href="book-Z-H-11.html#footnote_Temp_71">^[42]{.small}^</a></p>
<p>It is easy to express Euclid's Algorithm as a procedure:</p>
<pre><code class="language-scheme editable">(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
</code></pre>
<p>This generates an iterative process, whose number of steps grows as the
logarithm of the numbers involved.</p>
<p>The fact that the number of steps required by Euclid's
Algorithm has logarithmic growth bears an interesting relation to the
Fibonacci numbers:</p>
<p><strong>Lamé's Theorem:</strong> If Euclid's Algorithm
requires <em>k</em> steps to compute the GCD of some pair, then the smaller
number in the pair must be greater than or equal to the <em>k</em>th Fibonacci
number.<a href="book-Z-H-11.html#footnote_Temp_72">^[43]{.small}^</a></p>
<p>We can use this theorem to get an order-of-growth estimate for Euclid's
Algorithm. Let <em>n</em> be the smaller of the two inputs to the procedure. If
the process takes <em>k</em> steps, then we must have <em>n</em>[&gt;]{.underline} <em>Fib</em>
(<em>k</em>) <img src="book-Z-G-D-20.gif" alt="" />
<img src="book-Z-G-D-11.gif" alt="" />5.
Therefore the number of steps <em>k</em> grows as the logarithm (to the base
<img src="book-Z-G-D-11.gif" alt="" />) of <em>n</em>. Hence, the order of growth
is <img src="book-Z-G-D-3.gif" alt="" />(<code>log</code> <em>n</em>).</p>
<p><strong>Exercise 1.20.</strong>  The
process that a procedure generates is of course dependent on the rules
used by the interpreter. As an example, consider the iterative <code>gcd</code>
procedure given above. Suppose we were to interpret this procedure using
normal-order evaluation, as discussed in
section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a>. (The
normal-order-evaluation rule for <code>if</code> is described in
exercise <a href="book-Z-H-10.html#%_thm_1.5">1.5</a>.) Using the substitution
method (for normal order), illustrate the process generated in
evaluating <code>(gcd 206 40)</code> and indicate the <code>remainder</code> operations that
are actually performed. How many <code>remainder</code> operations are actually
performed in the normal-order evaluation of <code>(gcd 206 40)</code>? In the
applicative-order evaluation?</p>
<h3 id="126--example-testing-for-primality"><a class="header" href="#126--example-testing-for-primality"><a href="book-Z-H-4.html#%_toc_%_sec_1.2.6">1.2.6  Example: Testing for Primality</a></a></h3>
<p>This section describes two methods for
checking the primality of an integer <em>n</em>, one with order of growth
<img src="book-Z-G-D-3.gif" alt="" /><em>n</em>),
and a ``probabilistic'' algorithm with order of growth
<img src="book-Z-G-D-3.gif" alt="" />(<code>log</code> <em>n</em>). The exercises at the end
of this section suggest programming projects based on these algorithms.</p>
<h4 id="searching-for-divisors"><a class="header" href="#searching-for-divisors"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_74">Searching for divisors</a></a></h4>
<p>Since ancient times, mathematicians have been fascinated by problems
concerning prime numbers, and many people have worked on the problem of
determining ways to test if numbers are prime. One way to test if a
number is prime is to find the number's divisors. The following program
finds the smallest integral divisor (greater than 1) of a given
number <em>n</em>. It does this in a straightforward way, by testing <em>n</em> for
divisibility by successive integers starting with 2.</p>
<pre><code class="language-scheme editable">(define (smallest-divisor n)
  (find-divisor n 2))
</code></pre>
<pre><code class="language-scheme editable">(define (find-divisor n test-divisor)
  (cond ((&gt; (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))
</code></pre>
<pre><code class="language-scheme editable">(define (divides? a b)
  (= (remainder b a) 0))
</code></pre>
<p>We can test whether a number is prime as follows: <em>n</em> is prime if and
only if <em>n</em> is its own smallest divisor.</p>
<p>(define (prime? n)
(= n (smallest-divisor n)))</p>
<p>The end test for <code>find-divisor</code> is based on the fact that if <em>n</em> is not
prime it must have a divisor less than or equal to
<img src="book-Z-G-D-13.gif" alt="" />
This means that the algorithm need only test divisors between 1 and
<img src="book-Z-G-D-13.gif" alt="" /><em>n</em>. Consequently, the number of steps
required to identify <em>n</em> as prime will have order of growth
<img src="book-Z-G-D-3.gif" alt="" /><em>n</em>).</p>
<h4 id="the-fermat-test"><a class="header" href="#the-fermat-test"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_76">The Fermat test</a></a></h4>
<p>The <img src="book-Z-G-D-3.gif" alt="" />(<code>log</code>
<em>n</em>) primality test is based on a result from number theory known as
Fermat's Little
Theorem.<a href="book-Z-H-11.html#footnote_Temp_77">^[45]{.small}^</a></p>
<p><strong>Fermat's Little Theorem:</strong> If <em>n</em> is a prime number and
<em>a</em> is any positive integer less than <em>n</em>, then <em>a</em> raised to the <em>n</em>th
power is congruent to <em>a</em> modulo <em>n</em>.</p>
<p>(Two numbers are said to be <em>congruent modulo</em> <em>n</em> if they
both have the same remainder when divided by <em>n</em>. The remainder of a
number <em>a</em> when divided by <em>n</em> is also referred to as the
<em>remainder of</em> <em>a</em> <em>modulo</em> <em>n</em>, or simply
as <em>a</em> <em>modulo</em> <em>n</em>.)</p>
<p>If <em>n</em> is not prime, then, in general, most of the numbers <em>a</em>&lt; <em>n</em>
will not satisfy the above relation. This leads to the following
algorithm for testing primality: Given a number <em>n</em>, pick a
random number <em>a</em> &lt; <em>n</em> and compute the remainder of
<em>a</em>^<em>n</em>^ modulo <em>n</em>. If the result is not equal to <em>a</em>, then <em>n</em> is
certainly not prime. If it is <em>a</em>, then chances are good that <em>n</em> is
prime. Now pick another random number <em>a</em> and test it with the same
method. If it also satisfies the equation, then we can be even more
confident that <em>n</em> is prime. By trying more and more values of <em>a</em>, we
can increase our confidence in the result. This algorithm is known as
the Fermat test.</p>
<p>To implement the Fermat test, we need a procedure that
computes the exponential of a number modulo another number:</p>
<pre><code class="language-scheme editable">(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))        
</code></pre>
<p>This is very similar to the <code>fast-expt</code> procedure of
section <a href="book-Z-H-11.html#%_sec_1.2.4">1.2.4</a>. It uses successive
squaring, so that the number of steps grows logarithmically with the
exponent.<a href="book-Z-H-11.html#footnote_Temp_78">^[46]{.small}^</a></p>
<p>The Fermat test is performed by choosing at random a number <em>a</em> between
1 and <em>n</em> - 1 inclusive and checking whether the remainder modulo <em>n</em> of
the <em>n</em>th power of <em>a</em> is equal to <em>a</em>. The random number <em>a</em> is chosen
using the procedure <code>random</code>, which we
assume is included as a primitive in Scheme. <code>Random</code> returns a
nonnegative integer less than its integer input. Hence, to obtain a
random number between 1 and <em>n</em> - 1, we call <code>random</code> with an input of
<em>n</em> - 1 and add 1 to the result:</p>
<pre><code class="language-scheme editable">(define (fermat-test n)
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))
</code></pre>
<p>The following procedure runs the test a given number of times, as
specified by a parameter. Its value is true if the test succeeds every
time, and false otherwise.</p>
<pre><code class="language-scheme editable">(define (fast-prime? n times)
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))
</code></pre>
<h4 id="probabilistic-methods"><a class="header" href="#probabilistic-methods"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_79">Probabilistic methods</a></a></h4>
<p>The Fermat test differs in character from
most familiar algorithms, in which one computes an answer that is
guaranteed to be correct. Here, the answer obtained is only probably
correct. More precisely, if <em>n</em> ever fails the Fermat test, we can be
certain that <em>n</em> is not prime. But the fact that <em>n</em> passes the test,
while an extremely strong indication, is still not a guarantee that <em>n</em>
is prime. What we would like to say is that for any number <em>n</em>, if we
perform the test enough times and find that <em>n</em> always passes the test,
then the probability of error in our primality test can be made as small
as we like.</p>
<p>Unfortunately, this assertion is not quite correct. There do exist
numbers that fool the Fermat test: numbers <em>n</em> that are not prime and
yet have the property that <em>a</em>^<em>n</em>^ is congruent to <em>a</em> modulo <em>n</em> for
all integers <em>a</em> &lt; <em>n</em>. Such numbers are extremely rare, so the Fermat
test is quite reliable in
practice.<a href="book-Z-H-11.html#footnote_Temp_80">^[47]{.small}^</a>
There are variations of the Fermat test that cannot be fooled. In these
tests, as with the Fermat method, one tests the primality of an integer
<em>n</em> by choosing a random integer <em>a</em>&lt;<em>n</em> and checking some condition
that depends upon <em>n</em> and <em>a</em>. (See
exercise <a href="book-Z-H-11.html#%_thm_1.28">1.28</a> for an example of such a
test.) On the other hand, in contrast to the Fermat test, one can prove
that, for any <em>n</em>, the condition does not hold for most of the integers
<em>a</em>&lt;<em>n</em> unless <em>n</em> is prime. Thus, if <em>n</em> passes the test for some
random choice of <em>a</em>, the chances are better than even that <em>n</em> is
prime. If <em>n</em> passes the test for two random choices of <em>a</em>, the chances
are better than 3 out of 4 that <em>n</em> is prime. By running the test with
more and more randomly chosen values of <em>a</em> we can make the probability
of error as small as we like.</p>
<p>The existence of tests for which one can prove that the chance of error
becomes arbitrarily small has sparked interest in algorithms of this
type, which have come to be known as <em>probabilistic algorithms</em>. There
is a great deal of research activity in this area, and probabilistic
algorithms have been fruitfully applied to many
fields.<a href="book-Z-H-11.html#footnote_Temp_81">^[48]{.small}^</a></p>
<p><strong>Exercise 1.21.</strong>  Use the <code>smallest-divisor</code> procedure
to find the smallest divisor of each of the following numbers: 199,
1999, 19999.</p>
<p><strong>Exercise 1.22.</strong>  Most
Lisp implementations include a primitive called <code>runtime</code> that returns
an integer that specifies the amount of time the system has been running
(measured, for example, in microseconds). The following
<code>timed-prime-test</code> procedure, when called with an integer <em>n</em>, prints
<em>n</em> and checks to see if <em>n</em> is prime. If <em>n</em> is prime, the procedure
prints three asterisks followed by the amount of time used in performing
the test.</p>
<pre><code class="language-scheme editable">(define (timed-prime-test n)
  (newline)
  (display n)
  (start-prime-test n (runtime)))
(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))
(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
</code></pre>
<p>Using this procedure, write a procedure <code>search-for-primes</code> that checks
the primality of consecutive odd integers in a specified range. Use your
procedure to find the three smallest primes larger than 1000; larger
than 10,000; larger than 100,000; larger than 1,000,000. Note the time
needed to test each prime. Since the testing algorithm has order of
growth of
<img src="book-Z-G-D-3.gif" alt="" /><em>n</em>),
you should expect that testing for primes around 10,000 should take
about <img src="book-Z-G-D-13.gif" alt="" />10 times as long as testing for
primes around 1000. Do your timing data bear this out? How well do the
data for 100,000 and 1,000,000 support the
<img src="book-Z-G-D-13.gif" alt="" /><em>n</em> prediction? Is your result
compatible with the notion that programs on your machine run in time
proportional to the number of steps required for the computation?</p>
<p><strong>Exercise 1.23.</strong>  The <code>smallest-divisor</code>
procedure shown at the start of this section does lots of needless
testing: After it checks to see if the number is divisible by 2 there is
no point in checking to see if it is divisible by any larger even
numbers. This suggests that the values used for <code>test-divisor</code> should
not be 2, 3, 4, 5, 6, <code>...</code>, but rather 2, 3, 5, 7, 9, <code>...</code>. To
implement this change, define a procedure <code>next</code> that returns 3 if its
input is equal to 2 and otherwise returns its input plus 2. Modify the
<code>smallest-divisor</code> procedure to use <code>(next test-divisor)</code> instead of
<code>(+ test-divisor 1)</code>. With <code>timed-prime-test</code> incorporating this
modified version of <code>smallest-divisor</code>, run the test for each of the 12
primes found in exercise <a href="book-Z-H-11.html#%_thm_1.22">1.22</a>. Since this
modification halves the number of test steps, you should expect it to
run about twice as fast. Is this expectation confirmed? If not, what is
the observed ratio of the speeds of the two algorithms, and how do you
explain the fact that it is different from 2?</p>
<p><strong>Exercise 1.24.</strong>  Modify the <code>timed-prime-test</code>
procedure of exercise <a href="book-Z-H-11.html#%_thm_1.22">1.22</a> to use
<code>fast-prime?</code> (the Fermat method), and test each of the 12 primes you
found in that exercise. Since the Fermat test has
<img src="book-Z-G-D-3.gif" alt="" />(<code>log</code> <em>n</em>) growth, how would you
expect the time to test primes near 1,000,000 to compare with the time
needed to test primes near 1000? Do your data bear this out? Can you
explain any discrepancy you find?</p>
<p><strong>Exercise 1.25.</strong>  Alyssa P. Hacker complains that we
went to a lot of extra work in writing <code>expmod</code>. After all, she says,
since we already know how to compute exponentials, we could have simply
written</p>
<pre><code class="language-scheme editable">(define (expmod base exp m)
  (remainder (fast-expt base exp) m))
</code></pre>
<p>Is she correct? Would this procedure serve as well for our fast prime
tester? Explain.</p>
<p><strong>Exercise 1.26.</strong>  Louis Reasoner is having great
difficulty doing exercise <a href="book-Z-H-11.html#%_thm_1.24">1.24</a>. His
<code>fast-prime?</code> test seems to run more slowly than his <code>prime?</code> test.
Louis calls his friend Eva Lu Ator over to help. When they examine
Louis's code, they find that he has rewritten the <code>expmod</code> procedure to
use an explicit multiplication, rather than calling <code>square</code>:</p>
<pre><code class="language-scheme editable">(define (expmod base exp m)
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (* (expmod base (/ exp 2) m)
                       (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))
</code></pre>
<p>``I don't see what difference that could make,'' says Louis. ``I
do.'' says Eva. ``By writing the procedure like that, you have
transformed the <img src="book-Z-G-D-3.gif" alt="" />(<code>log</code> <em>n</em>) process
into a <img src="book-Z-G-D-3.gif" alt="" />(<em>n</em>) process.'' Explain.</p>
<p><strong>Exercise 1.27.</strong>  Demonstrate that the
Carmichael numbers listed in
footnote <a href="book-Z-H-11.html#footnote_Temp_80">47</a> really do fool the
Fermat test. That is, write a procedure that takes an integer <em>n</em> and
tests whether <em>a</em>^<em>n</em>^ is congruent to <em>a</em> modulo <em>n</em> for every
<em>a</em>&lt;<em>n</em>, and try your procedure on the given Carmichael numbers.</p>
<p><strong>Exercise
1.28.</strong>  One
variant of the Fermat test that cannot be fooled is called the
<em>Miller-Rabin test</em> (Miller 1976; Rabin 1980). This starts from
an alternate form of Fermat's Little Theorem, which
states that if <em>n</em> is a prime number and <em>a</em> is any positive integer
less than <em>n</em>, then <em>a</em> raised to the (<em>n</em> - 1)st power is congruent to
1 modulo <em>n</em>. To test the primality of a number <em>n</em> by the Miller-Rabin
test, we pick a random number <em>a</em>&lt;<em>n</em> and raise <em>a</em> to the (<em>n</em> - 1)st
power modulo <em>n</em> using the <code>expmod</code> procedure. However, whenever we
perform the squaring step in <code>expmod</code>, we check to see if we have
discovered a ``nontrivial square root of 1 modulo <em>n</em>,'' that is, a
number not equal to 1 or <em>n</em> - 1 whose square is equal to 1 modulo <em>n</em>.
It is possible to prove that if such a nontrivial square root of 1
exists, then <em>n</em> is not prime. It is also possible to prove that if <em>n</em>
is an odd number that is not prime, then, for at least half the numbers
<em>a</em>&lt;<em>n</em>, computing <em>a</em>^<em>n</em>-1^ in this way will reveal a nontrivial
square root of 1 modulo <em>n</em>. (This is why the Miller-Rabin test cannot
be fooled.) Modify the <code>expmod</code> procedure to signal if it discovers a
nontrivial square root of 1, and use this to implement the Miller-Rabin
test with a procedure analogous to <code>fermat-test</code>. Check your procedure
by testing various known primes and non-primes. Hint: One convenient way
to make <code>expmod</code> signal is to have it return 0.</p>
<hr />
<p><a href="book-Z-H-11.html#call_footnote_Temp_46">^[29]{.small}^</a>
In a real program we would probably use the block structure introduced
in the last section to hide the definition of <code>fact-iter</code>:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (define (iter product counter)
    (if (&gt; counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
</code></pre>
<p>We avoided doing this here so as to minimize the number of things to
think about at once.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_47">^[30]{.small}^</a>
When we discuss the implementation of procedures on register machines in
chapter 5, we will see that any iterative process can be realized ``in
hardware'' as a machine that has a fixed set of registers and no
auxiliary memory. In contrast, realizing a recursive process requires a
machine that uses an auxiliary data structure known as a
<em>stack</em>.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_48">^[31]{.small}^</a>
Tail recursion has long been
known as a compiler
optimization trick. A coherent semantic basis for tail recursion was
provided by Carl Hewitt (1977), who explained it in terms
of the ``message-passing'' model of computation that we shall
discuss in chapter 3. Inspired by this, Gerald Jay Sussman and Guy Lewis
Steele Jr. (see Steele 1975) constructed a tail-recursive interpreter
for Scheme. Steele later showed how tail recursion is a consequence of
the natural way to compile procedure calls (Steele 1977). The IEEE
standard for Scheme requires that Scheme implementations
be tail-recursive.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_51">^[32]{.small}^</a>
An example of this was hinted at in
section <a href="book-Z-H-10.html#%_sec_1.1.3">1.1.3</a>: The interpreter itself
evaluates expressions using a tree-recursive process.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_53">^[33]{.small}^</a>
For example, work through in detail how the reduction rule applies to
the problem of making change for 10 cents using pennies and nickels.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_54">^[34]{.small}^</a>
One approach to coping with redundant computations is to arrange matters
so that we automatically construct a table of values as they are
computed. Each time we are asked to apply the procedure to some
argument, we first look to see if the value is already stored in the
table, in which case we avoid performing the redundant computation. This
strategy, known as <em>tabulation</em> or
<em>memoization</em>, can be implemented in a straightforward way. Tabulation
can sometimes be used to transform processes that require an exponential
number of steps (such as <code>count-change</code>) into processes whose space and
time requirements grow linearly with the input. See
exercise <a href="book-Z-H-22.html#%_thm_3.27">3.27</a>.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_57">^[35]{.small}^</a>
The elements of Pascal's triangle are called the <em>binomial
coefficients</em>, because the <em>n</em>th row consists of the
coefficients of the terms in the expansion of (<em>x</em> + <em>y</em>)^<em>n</em>^. This
pattern for computing the coefficients appeared in Blaise
Pascal's 1653 seminal work on probability theory, <em>Traité du triangle
arithmétique</em>. According to Knuth (1973), the same pattern
appears in the <em>Szu-yuen Yü-chien</em> (``The Precious Mirror of the Four
Elements''), published by
the Chinese mathematician Chu Shih-chieh in 1303, in the works of the
twelfth-century Persian poet and mathematician Omar Khayyam, and in the
works of the twelfth-century Hindu mathematician Bháscara Áchárya.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_59">^[36]{.small}^</a>
These statements mask a great deal of oversimplification. For instance,
if we count process steps as ``machine operations'' we are making
the assumption that the number of machine operations needed to perform,
say, a multiplication is independent of the size of the numbers to be
multiplied, which is false if the numbers are sufficiently large.
Similar remarks hold for the estimates of space. Like the design and
description of a process, the analysis of a process can be carried out
at various levels of abstraction.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_62">^[37]{.small}^</a>
More precisely, the number of multiplications required is equal to 1
less than the log base 2 of <em>n</em> plus the number of ones in the binary
representation of <em>n</em>. This total is always less than twice the log base
2 of <em>n</em>. The arbitrary constants <em>k</em><del>1</del> and <em>k</em><del>2</del> in the definition of
order notation imply that, for a logarithmic process, the base to which
logarithms are taken does not matter, so all such processes are
described as <img src="book-Z-G-D-3.gif" alt="" />(<code>log</code> <em>n</em>).</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_63">^[38]{.small}^</a>
You may wonder why anyone would care about raising numbers to the 1000th
power. See section <a href="book-Z-H-11.html#%_sec_1.2.6">1.2.6</a>.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_64">^[39]{.small}^</a>
This iterative algorithm is ancient. It appears in the <em>Chandah-sutra</em>
by Áchárya Pingala, written
before 200 B.C. See Knuth 1981, section 4.6.3, for a full discussion and
analysis of this and other methods of exponentiation.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_68">^[40]{.small}^</a>
This algorithm, which is sometimes known as
the ``Russian peasant method'' of multiplication, is ancient.
Examples of its use are found in the Rhind Papyrus, one of
the two oldest mathematical documents in existence, written about 1700
B.C. (and copied from an even older document) by an
Egyptian scribe named A'h-mose.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_70">^[41]{.small}^</a>
This exercise was suggested to us by Joe
Stoy, based on an example in Kaldewaij 1990.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_71">^[42]{.small}^</a>
Euclid's Algorithm is so called because it appears in
Euclid's <em>Elements</em> (Book 7, ca. 300 B.C.). According to Knuth (1973),
it can be considered the oldest known nontrivial
algorithm. The ancient Egyptian method of multiplication
(exercise <a href="book-Z-H-11.html#%_thm_1.18">1.18</a>) is surely older, but, as
Knuth explains, Euclid's algorithm is the oldest known to have been
presented as a general algorithm, rather than as a set of illustrative
examples.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_72">^[43]{.small}^</a>
This theorem was proved in 1845 by Gabriel Lamé, a French
mathematician and engineer known chiefly for his contributions to
mathematical physics. To prove the theorem, we consider pairs (<em>a</em><del><em>k</em></del>
,<em>b</em><del><em>k</em></del>), where <em>a</em><del><em>k</em></del>[&gt;]{.underline} <em>b</em><del><em>k</em></del>, for which Euclid's
Algorithm terminates in <em>k</em> steps. The proof is based on the claim that,
if (<em>a</em><del><em>k</em>+1</del>, <em>b</em><del><em>k</em>+1</del>) <img src="book-Z-G-D-15.gif" alt="" />
(<em>a</em><del><em>k</em></del>, <em>b</em><del><em>k</em></del>) <img src="book-Z-G-D-15.gif" alt="" /> (<em>a</em><del><em>k</em>-1</del>,
<em>b</em><del><em>k</em>-1</del>) are three successive pairs in the reduction process, then we
must have <em>b</em><del><em>k</em>+1</del>[&gt;]{.underline} <em>b</em><del><em>k</em></del> + <em>b</em><del><em>k</em>-1</del>. To verify
the claim, consider that a reduction step is defined by applying the
transformation <em>a</em><del><em>k</em>-1</del> = <em>b</em><del><em>k</em></del>, <em>b</em><del><em>k</em>-1</del> = remainder of <em>a</em><del><em>k</em></del>
divided by <em>b</em><del><em>k</em></del>. The second equation means that <em>a</em><del><em>k</em></del> =
<em>qb</em><del><em>k</em></del> + <em>b</em><del><em>k</em>-1</del> for some positive integer <em>q</em>. And since <em>q</em> must
be at least 1 we have <em>a</em><del><em>k</em></del> = <em>qb</em><del><em>k</em></del> + <em>b</em><del><em>k</em>-1</del> [&gt;]{.underline}
<em>b</em><del><em>k</em></del> + <em>b</em><del><em>k</em>-1</del>. But in the previous reduction step we have
<em>b</em><del><em>k</em>+1</del> = <em>a</em><del><em>k</em></del>. Therefore, <em>b</em><del><em>k</em>+1</del> = <em>a</em><del><em>k</em></del>[&gt;]{.underline}
<em>b</em><del><em>k</em></del> + <em>b</em><del><em>k</em>-1</del>. This verifies the claim. Now we can prove the
theorem by induction on <em>k</em>, the number of steps that the algorithm
requires to terminate. The result is true for <em>k</em> = 1, since this merely
requires that <em>b</em> be at least as large as <em>Fib</em>(1) = 1. Now, assume that
the result is true for all integers less than or equal to <em>k</em> and
establish the result for <em>k</em> + 1. Let (<em>a</em><del><em>k</em>+1</del>, <em>b</em><del><em>k</em>+1</del>)
<img src="book-Z-G-D-15.gif" alt="" /> (<em>a</em><del><em>k</em></del>, <em>b</em><del><em>k</em></del>)
<img src="book-Z-G-D-15.gif" alt="" /> (<em>a</em><del><em>k</em>-1</del>, <em>b</em><del><em>k</em>-1</del>) be
successive pairs in the reduction process. By our induction hypotheses,
we have <em>b</em><del><em>k</em>-1</del>[&gt;]{.underline} <em>Fib</em>(<em>k</em> - 1) and
<em>b</em><del><em>k</em></del>[&gt;]{.underline} <em>Fib</em>(<em>k</em>). Thus, applying the claim we just
proved together with the definition of the Fibonacci numbers gives
<em>b</em><del><em>k</em>+1</del> [&gt;]{.underline} <em>b</em><del><em>k</em></del> + <em>b</em><del><em>k</em>-1</del>[&gt;]{.underline}
<em>Fib</em>(<em>k</em>) + <em>Fib</em>(<em>k</em> - 1) = <em>Fib</em>(<em>k</em> + 1), which completes the proof
of Lamé's Theorem.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_75">^[44]{.small}^</a>
If <em>d</em> is a divisor of <em>n</em>, then so is <em>n</em>/<em>d</em>. But <em>d</em> and <em>n</em>/<em>d</em>
cannot both be greater than <img src="book-Z-G-D-13.gif" alt="" /><em>n</em>.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_77">^[45]{.small}^</a>
Pierre de Fermat (1601-1665) is considered to be the founder of
modern number theory. He obtained many
important number-theoretic results, but he usually announced just the
results, without providing his proofs. Fermat's Little
Theorem was stated in a letter he wrote in 1640. The first published
proof was given by Euler in 1736 (and an
earlier, identical proof was discovered in the unpublished
manuscripts of Leibniz). The most famous of Fermat's results -- known
as Fermat's Last Theorem -- was jotted down in 1637 in his copy of the
book <em>Arithmetic</em> (by the third-century Greek mathematician
Diophantus) with the remark ``I have discovered a truly
remarkable proof, but this margin is too small to contain it.''
Finding a proof of Fermat's Last Theorem became one of the most famous
challenges in number theory. A complete solution was
finally given in 1995 by Andrew Wiles of Princeton University.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_78">^[46]{.small}^</a>
The reduction steps in the cases where the exponent <em>e</em> is greater than
1 are based on the fact that, for any integers <em>x</em>, <em>y</em>, and <em>m</em>, we can
find the remainder of <em>x</em> times <em>y</em> modulo <em>m</em> by computing separately
the remainders of <em>x</em> modulo <em>m</em> and <em>y</em> modulo <em>m</em>, multiplying these,
and then taking the remainder of the result modulo <em>m</em>. For instance, in
the case where <em>e</em> is even, we compute the remainder of <em>b</em>^<em>e</em>/2^
modulo <em>m</em>, square this, and take the remainder modulo <em>m</em>. This
technique is useful because it means we can perform our computation
without ever having to deal with numbers much larger than <em>m</em>. (Compare
exercise <a href="book-Z-H-11.html#%_thm_1.25">1.25</a>.)</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_80">^[47]{.small}^</a>
Numbers that fool the Fermat test are called <em>Carmichael
numbers</em>, and little is known about them other than that they are
extremely rare. There are 255 Carmichael numbers below 100,000,000. The
smallest few are 561, 1105, 1729, 2465, 2821, and 6601. In testing
primality of very large numbers chosen at random, the chance of
stumbling upon a value that fools the Fermat test is less than the
chance that cosmic radiation will cause the computer to
make an error in carrying out a ``correct'' algorithm. Considering
an algorithm to be inadequate for the first reason but not for the
second illustrates the difference between
mathematics and engineering.</p>
<p><a href="book-Z-H-11.html#call_footnote_Temp_81">^[48]{.small}^</a>
One of the most striking applications of probabilistic
prime testing has been to the field of cryptography. Although it is now
computationally infeasible to factor an arbitrary 200-digit number, the
primality of such a number can be checked in a few seconds with the
Fermat test. This fact forms the basis of a technique for constructing
``unbreakable codes'' suggested by Rivest,
Shamir, and Adleman (1977). The resulting
<em>RSA algorithm</em> has become a widely used technique for
enhancing the security of electronic communications. Because of this and
related developments, the study of prime numbers, once
considered the epitome of a topic in ``pure'' mathematics to be
studied only for its own sake, now turns out to have important practical
applications to cryptography, electronic funds transfer, and information
retrieval.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="13-evaluating-combinations"><a class="header" href="#13-evaluating-combinations">1.3 Evaluating Combinations</a></h1>
<p>To evaluate a combination, do the following:</p>
<ol>
<li>Evaluate the subexpressions of the combination.</li>
<li>Apply the procedure that is the value of the leftmost subexpression (the operator) to the arguments that are the values of the other subexpressions (the operands).</li>
</ol>
<p>Even this simple rule requires refinement. For example, <code>(f 2)</code> where <code>f</code> is <code>+</code> is <code>(+ 2)</code>, which is not a valid expression. A few exceptions to the general rule are needed:</p>
<ul>
<li>Special forms, such as <code>define</code>, have their own evaluation rules.</li>
<li>A procedure call with no arguments, such as <code>(newline)</code>, is valid.</li>
</ul>
<p>Consider the evaluation of the following expression:</p>
<pre><code class="language-scheme editable">(* (+ 2 (* 4 6))
   (+ 3 5 7))
</code></pre>
<p>This can be represented as a tree:</p>
<pre><code>    *
   / \
  +   +
 / \   | \
2   *   3 5 7
   / \
  4   6
</code></pre>
<p>The evaluation process proceeds as follows:</p>
<ol>
<li>The arguments to the top-level <code>*</code> are evaluated.</li>
<li>The first argument, <code>(+ 2 (* 4 6))</code>, is evaluated.
<ol>
<li>The arguments to this <code>+</code> are evaluated.</li>
<li>The first argument is <code>2</code>.</li>
<li>The second argument, <code>(* 4 6)</code>, is evaluated to <code>24</code>.</li>
<li>The <code>+</code> procedure is applied to <code>2</code> and <code>24</code>, resulting in <code>26</code>.</li>
</ol>
</li>
<li>The second argument, <code>(+ 3 5 7)</code>, is evaluated.
<ol>
<li>The arguments to this <code>+</code> are evaluated.</li>
<li>The arguments are <code>3</code>, <code>5</code>, and <code>7</code>.</li>
<li>The <code>+</code> procedure is applied to <code>3</code>, <code>5</code>, and <code>7</code>, resulting in <code>15</code>.</li>
</ol>
</li>
<li>The <code>*</code> procedure is applied to <code>26</code> and <code>15</code>, resulting in <code>390</code>.</li>
</ol>
<p>This evaluation process is known as recursion. The evaluation rule is applied to the tree from the top down, and the results are passed back up from the bottom.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<h2 id="chapter-2"><a class="header" href="#chapter-2"><a href="book-Z-H-4.html#%_toc_%_chap_2">Chapter 2</a></a></h2>
<h1 id="building-abstractions-with-data"><a class="header" href="#building-abstractions-with-data"><a href="book-Z-H-4.html#%_toc_%_chap_2">Building Abstractions with Data</a></a></h1>
<div class="info">
We now come to the decisive step of mathematical abstraction: we
forget about what the symbols stand for. `...`\[The mathematician\]
need not be idle; there are many operations which he may carry out
with these symbols, without ever having to look at the things they
stand for.
<p>Hermann Weyl,  The Mathematical Way of Thinking</p>
</div>
<p>We concentrated in chapter 1 on
computational processes and on the role of procedures in program design.
We saw how to use primitive data (numbers) and primitive operations
(arithmetic operations), how to combine procedures to form compound
procedures through composition, conditionals, and the use of parameters,
and how to abstract procedures by using <code>define</code>. We saw that a
procedure can be regarded as a pattern for the local evolution of a
process, and we classified, reasoned about, and performed simple
algorithmic analyses of some common patterns for processes as embodied
in procedures. We also saw that higher-order procedures enhance the
power of our language by enabling us to manipulate, and thereby to
reason in terms of, general methods of computation. This is much of the
essence of programming.</p>
<p>In this chapter we are going to look at more complex data. All the
procedures in chapter 1 operate on simple numerical data, and simple
data are not sufficient for many of the problems we wish to address
using computation. Programs are typically designed to model complex
phenomena, and more often than not one must construct computational
objects that have several parts in order to model real-world phenomena
that have several aspects. Thus, whereas our focus in chapter 1 was on
building abstractions by combining procedures to form compound
procedures, we turn in this chapter to another key aspect of any
programming language: the means it provides for building abstractions by
combining data objects to form <em>compound data</em>.</p>
<p>Why do we want compound data in a programming language? For the same
reasons that we want compound procedures: to elevate the conceptual
level at which we can design our programs, to increase the modularity of
our designs, and to enhance the expressive power of our language. Just
as the ability to define procedures enables us to deal with processes at
a higher conceptual level than that of the primitive operations of the
language, the ability to construct compound data objects enables us to
deal with data at a higher conceptual level than that of the primitive
data objects of the language.</p>
<p>Consider the task of designing a system to perform
arithmetic with rational numbers. We could imagine an operation
<code>add-rat</code> that takes two rational numbers and produces their sum. In
terms of simple data, a rational number can be thought of as two
integers: a numerator and a denominator. Thus, we could design a program
in which each rational number would be represented by two integers (a
numerator and a denominator) and where <code>add-rat</code> would be implemented by
two procedures (one producing the numerator of the sum and one producing
the denominator). But this would be awkward, because we would then need
to explicitly keep track of which numerators corresponded to which
denominators. In a system intended to perform many operations on many
rational numbers, such bookkeeping details would clutter the programs
substantially, to say nothing of what they would do to our minds. It
would be much better if we could ``glue together'' a numerator and
denominator to form a pair -- a <em>compound data object</em> -- that our
programs could manipulate in a way that would be consistent with
regarding a rational number as a single conceptual unit.</p>
<p>The use of compound data also enables us to increase the modularity of
our programs. If we can manipulate rational numbers directly as objects
in their own right, then we can separate the part of our program that
deals with rational numbers per se from the details of how rational
numbers may be represented as pairs of integers. The general technique
of isolating the parts of a program that deal with how data objects are
represented from the parts of a program that deal with how data objects
are used is a powerful design methodology called <em>data
abstraction</em>. We will see how data abstraction makes programs much
easier to design, maintain, and modify.</p>
<p>The use of compound data leads to a real increase in the expressive
power of our programming language. Consider the idea of forming a
``linear combination'' <em>ax</em> + <em>by</em>. We might like to write a
procedure that would accept <em>a</em>, <em>b</em>, <em>x</em>, and <em>y</em> as arguments and
return the value of <em>ax</em> + <em>by</em>. This presents no difficulty if the
arguments are to be numbers, because we can readily define the procedure</p>
<p><code>(define (linear-combination a b x y) </code><br />
<code>  (+ (* a x) (* b y)))</code>\</p>
<p>But suppose we are not concerned only with numbers. Suppose we would
like to express, in procedural terms, the idea that one can form linear
combinations whenever addition and multiplication are defined -- for
rational numbers, complex numbers, polynomials, or whatever. We could
express this as a procedure of the form</p>
<p><code>(define (linear-combination a b x y)     </code><br />
<code>  (add (mul a x) (mul b y))) </code>\</p>
<p>where <code>add</code> and <code>mul</code> are not the primitive procedures <code>+</code> and <code>*</code> but
rather more complex things that will perform the appropriate operations
for whatever kinds of data we pass in as the arguments <code>a</code>, <code>b</code>, <code>x</code>,
and <code>y</code>. The key point is that the only thing <code>linear-combination</code>
should need to know about <code>a</code>, <code>b</code>, <code>x</code>, and <code>y</code> is that the procedures
<code>add</code> and <code>mul</code> will perform the appropriate manipulations. From the
perspective of the procedure <code>linear-combination</code>, it is irrelevant what
<code>a</code>, <code>b</code>, <code>x</code>, and <code>y</code> are and even more irrelevant how they might
happen to be represented in terms of more primitive data. This same
example shows why it is important that our programming language provide
the ability to manipulate compound objects directly: Without this, there
is no way for a procedure such as <code>linear-combination</code> to pass its
arguments along to <code>add</code> and <code>mul</code> without having to know their detailed
structure.<a href="book-Z-H-13.html#footnote_Temp_131">^[1]{.small}^</a>{#call_footnote_Temp_131}
We begin this chapter by implementing the rational-number arithmetic
system mentioned above. This will form the background for our discussion
of compound data and data abstraction. As with compound procedures, the
main issue to be addressed is that of abstraction as a technique for
coping with complexity, and we will see how data abstraction enables us
to erect suitable <em>abstraction barriers</em> between
different parts of a program.</p>
<p>We will see that the key to forming compound data is that a programming
language should provide some kind of ``glue'' so that data objects
can be combined to form more complex data objects. There are many
possible kinds of glue. Indeed, we will discover how to form compound
data using no special ``data'' operations at all, only procedures.
This will further blur the distinction between ``procedure'' and
``data,'' which was already becoming tenuous toward the end of
chapter 1. We will also explore some conventional techniques for
representing sequences and trees. One key idea in dealing with compound
data is the notion of <em>closure</em> -- that the glue we use
for combining data objects should allow us to combine not only primitive
data objects, but compound data objects as well. Another key idea is
that compound data objects can serve as <em>conventional
interfaces</em> for combining program modules in mix-and-match ways. We
illustrate some of these ideas by presenting a simple graphics language
that exploits closure.</p>
<p>We will then augment the representational power of our language by
introducing <em>symbolic expressions</em> --
data whose elementary parts can be arbitrary symbols rather than only
numbers. We explore various alternatives for representing sets of
objects. We will find that, just as a given numerical function can be
computed by many different computational processes, there are many ways
in which a given data structure can be represented in terms of simpler
objects, and the choice of representation can have significant impact on
the time and space requirements of processes that manipulate the data.
We will investigate these ideas in the context of symbolic
differentiation, the representation of sets, and the encoding of
information.</p>
<p>Next we will take up the problem of working with data that may be
represented differently by different parts of a program. This leads to
the need to implement <em>generic
operations</em>, which must handle many different types of data. Maintaining
modularity in the presence of generic operations requires more powerful
abstraction barriers than can be erected with simple data abstraction
alone. In particular, we introduce <em>data-directed programming</em> as a
technique that allows individual data representations to be designed in
isolation and then combined <em>additively</em> (i.e., without
modification). To illustrate the power of this approach to system
design, we close the chapter by applying what we have learned to the
implementation of a package for performing symbolic arithmetic on
polynomials, in which the coefficients of the polynomials can be
integers, rational numbers, complex numbers, and even other polynomials.</p>
<p>::: smallprint</p>
<hr />
<p>:::</p>
<p>::: footnote
<a href="book-Z-H-13.html#call_footnote_Temp_131">^[1]{.small}^</a>{#footnote_Temp_131}
The ability to directly manipulate procedures provides an analogous
increase in the expressive power of a programming language. For example,
in section <a href="book-Z-H-12.html#%_sec_1.3.1">1.3.1</a> we introduced the <code>sum</code>
procedure, which takes a procedure <code>term</code> as an argument and computes
the sum of the values of <code>term</code> over some specified interval. In order
to define <code>sum</code>, it is crucial that we be able to speak of a procedure
such as <code>term</code> as an entity in its own right, without regard for how
<code>term</code> might be expressed with more primitive operations. Indeed, if we
did not have the notion of ``a procedure,'' it is doubtful that we
would ever even think of the possibility of defining an operation such
as <code>sum</code>. Moreover, insofar as performing the summation is concerned,
the details of how <code>term</code> may be constructed from more primitive
operations are irrelevant.
:::</p>
<p>::: navigation
[Go to <a href="book.html">first</a>, <a href="book-Z-H-12.html">previous</a>,
<a href="book-Z-H-14.html">next</a> page;
  <a href="book-Z-H-4.html#%_toc_start">contents</a>;
  <a href="book-Z-H-38.html#%_index_start">index</a>]
:::</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="21-introduction-to-data-abstraction"><a class="header" href="#21-introduction-to-data-abstraction">2.1 Introduction to Data Abstraction</a></h1>
<p>In section 1.1, we saw how to create compound procedures from primitive procedures. In this section, we will see how to create compound data from primitive data.</p>
<p>We can think of a data object as having two aspects: how it is used and how it is constructed. For example, a rational number can be used by adding, subtracting, multiplying, and dividing it with other rational numbers. It can be constructed by specifying a numerator and a denominator.</p>
<p>We can use procedures to implement data abstraction. For example, we can represent a rational number as a pair of integers, a numerator and a denominator. We can then define procedures <code>make-rat</code>, <code>numer</code>, and <code>denom</code> to construct and access the parts of a rational number.</p>
<pre><code class="language-scheme editable">(define (make-rat n d)
  (cons n d))

(define (numer x)
  (car x))

(define (denom x)
  (cdr x))
</code></pre>
<p>We can then use these procedures to define arithmetic operations on rational numbers.</p>
<pre><code class="language-scheme editable">(define (add-rat x y)
  (make-rat (+ (* (numer x) (denom y))
               (* (numer y) (denom x)))
            (* (denom x) (denom y))))

(define (sub-rat x y)
  (make-rat (- (* (numer x) (denom y))
               (* (numer y) (denom x)))
            (* (denom x) (denom y))))

(define (mul-rat x y)
  (make-rat (* (numer x) (numer y))
            (* (denom x) (denom y))))

(define (div-rat x y)
  (make-rat (* (numer x) (denom y))
            (* (denom x) (numer y))))

(define (equal-rat? x y)
  (= (* (numer x) (denom y))
     (* (numer y) (denom x))))
</code></pre>
<p>We can now use these procedures to work with rational numbers.</p>
<pre><code class="language-scheme editable">(define one-half (make-rat 1 2))

(print-rat one-half)

(define one-third (make-rat 1 3))

(print-rat (add-rat one-half one-third))

(print-rat (mul-rat one-half one-third))

(print-rat (add-rat one-third one-third))
</code></pre>
<p>To complete the rational number system, we need a way to print rational numbers. We can define a procedure <code>print-rat</code> to do this.</p>
<pre><code class="language-scheme editable">(define (print-rat x)
  (display (numer x))
  (display "/")
  (display (denom x))
  (newline))
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="22-abstraction-barriers"><a class="header" href="#22-abstraction-barriers">2.2 Abstraction Barriers</a></h1>
<p>In the previous section, we saw how to represent rational numbers as pairs of integers. However, this representation is not abstract. The user of our rational number system knows that a rational number is represented as a pair, and can use <code>car</code> and <code>cdr</code> to access the numerator and denominator.</p>
<p>This is a problem because it means that we cannot change the representation of rational numbers without breaking the code that uses them. For example, we might want to change the representation to reduce rational numbers to lowest terms. If we do this, any code that uses <code>car</code> and <code>cdr</code> to access the numerator and denominator will break.</p>
<p>To solve this problem, we can use abstraction barriers to separate the implementation of a data object from its use. An abstraction barrier is a set of procedures that provides an interface to a data object. The user of the data object can only access it through the procedures in the interface. The implementation of the data object can be changed without affecting the user, as long as the interface remains the same.</p>
<p>For our rational number system, the abstraction barrier consists of the procedures <code>make-rat</code>, <code>numer</code>, and <code>denom</code>. The user of the system can use these procedures to create and access rational numbers, but cannot access the underlying representation.</p>
<p>This allows us to change the representation of rational numbers. For example, we can change <code>make-rat</code> to reduce rational numbers to lowest terms.</p>
<pre><code class="language-scheme editable">(define (make-rat n d)
  (let ((g (gcd n d)))
    (cons (/ n g) (/ d g))))
</code></pre>
<p>Here, <code>gcd</code> is a procedure that computes the greatest common divisor of two integers. We can define it as follows:</p>
<pre><code class="language-scheme editable">(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
</code></pre>
<p>Now, when we create a rational number, it is automatically reduced to lowest terms.</p>
<pre><code class="language-scheme editable">(define one-half (make-rat 1 2))

(print-rat one-half)

(define two-fourths (make-rat 2 4))

(print-rat two-fourths)
</code></pre>
<p>The output of the last expression is <code>1/2</code>, not <code>2/4</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="23-what-is-meant-by-data"><a class="header" href="#23-what-is-meant-by-data">2.3 What Is Meant by Data?</a></h1>
<p>We have seen how to represent compound data as pairs. We can use pairs to represent not only rational numbers, but also other kinds of data, such as line segments.</p>
<pre><code class="language-scheme editable">(define (make-point x y)
  (cons x y))

(define (x-point p)
  (car p))

(define (y-point p)
  (cdr p))

(define (print-point p)
  (newline)
  (display "(")
  (display (x-point p))
  (display ",")
  (display (y-point p))
  (display ")"))

(define (make-segment p1 p2)
  (cons p1 p2))

(define (start-segment s)
  (car s))

(define (end-segment s)
  (cdr s))
</code></pre>
<p>We can then define a procedure to find the midpoint of a line segment.</p>
<pre><code class="language-scheme editable">(define (midpoint-segment s)
  (let ((p1 (start-segment s))
        (p2 (end-segment s)))
    (make-point (average (x-point p1) (x-point p2))
                (average (y-point p1) (y-point p2)))))

(define (average x y)
  (/ (+ x y) 2))
</code></pre>
<p>This shows that we can represent different kinds of data using the same underlying structure (pairs). The meaning of the data is determined by the procedures that operate on it.</p>
<p>This is a very powerful idea. It means that we can create new kinds of data objects whenever we need them, simply by defining the appropriate constructor and selector procedures. This is the essence of data abstraction.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="24-extended-exercise-interval-arithmetic"><a class="header" href="#24-extended-exercise-interval-arithmetic">2.4 Extended Exercise: Interval Arithmetic</a></h1>
<p>Interval arithmetic is a way of computing with intervals of numbers. An interval is a range of numbers between a lower and an upper bound. For example, the interval from 3 to 5 is the set of all numbers between 3 and 5, inclusive.</p>
<p>We can represent an interval as a pair of numbers, the lower and upper bounds.</p>
<pre><code class="language-scheme editable">(define (make-interval a b)
  (cons a b))

(define (lower-bound i)
  (car i))

(define (upper-bound i)
  (cdr i))
</code></pre>
<p>We can define arithmetic operations on intervals. For example, the sum of two intervals is the interval whose lower bound is the sum of the lower bounds of the two intervals, and whose upper bound is the sum of the upper bounds of the two intervals.</p>
<pre><code class="language-scheme editable">(define (add-interval x y)
  (make-interval (+ (lower-bound x) (lower-bound y))
                 (+ (upper-bound x) (upper-bound y))))
</code></pre>
<p>The product of two intervals is more complicated. The lower bound of the product is the minimum of the four products of the endpoints, and the upper bound is the maximum of the four products of the endpoints.</p>
<pre><code class="language-scheme editable">(define (mul-interval x y)
  (let ((p1 (* (lower-bound x) (lower-bound y)))
        (p2 (* (lower-bound x) (upper-bound y)))
        (p3 (* (upper-bound x) (lower-bound y)))
        (p4 (* (upper-bound x) (upper-bound y))))
    (make-interval (min p1 p2 p3 p4)
                   (max p1 p2 p3 p4))))
</code></pre>
<p>Division of two intervals is also complicated. If the interval for the divisor contains 0, then the result is undefined. Otherwise, we can multiply the first interval by the reciprocal of the second interval.</p>
<pre><code class="language-scheme editable">(define (div-interval x y)
  (if (and (&lt;= (lower-bound y) 0)
           (&gt;= (upper-bound y) 0))
      (error "division by an interval containing 0")
      (mul-interval x
                    (make-interval (/ 1.0 (upper-bound y))
                                   (/ 1.0 (lower-bound y))))))
</code></pre>
<p>We can also define subtraction of two intervals.</p>
<pre><code class="language-scheme editable">(define (sub-interval x y)
  (make-interval (- (lower-bound x) (upper-bound y))
                 (- (upper-bound x) (lower-bound y))))
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="25-representing-complex-numbers"><a class="header" href="#25-representing-complex-numbers">2.5 Representing Complex Numbers</a></h1>
<p>We can represent complex numbers in two ways: rectangular form (real and imaginary parts) and polar form (magnitude and angle). We can use data abstraction to hide the representation from the user.</p>
<p>We can define a complex number package that provides procedures for creating and manipulating complex numbers. The package can be implemented using either representation, and the user does not need to know which representation is used.</p>
<p>Here is the interface to the complex number package:</p>
<pre><code class="language-scheme editable">(define (add-complex z1 z2) ...)
(define (sub-complex z1 z2) ...)
(define (mul-complex z1 z2) ...)
(define (div-complex z1 z2) ...)
(define (make-from-real-imag x y) ...)
(define (make-from-mag-ang r a) ...)
(define (real-part z) ...)
(define (imag-part z) ...)
(define (magnitude z) ...)
(define (angle z) ...)
</code></pre>
<p>We can implement the package using rectangular form as follows:</p>
<pre><code class="language-scheme editable">(define (make-from-real-imag x y) (cons x y))
(define (make-from-mag-ang r a) (cons (* r (cos a)) (* r (sin a))))

(define (real-part z) (car z))
(define (imag-part z) (cdr z))

(define (magnitude z)
  (sqrt (+ (square (real-part z))
           (square (imag-part z)))))

(define (angle z)
  (atan (imag-part z) (real-part z)))

(define (add-complex z1 z2)
  (make-from-real-imag (+ (real-part z1) (real-part z2))
                       (+ (imag-part z1) (imag-part z2))))

(define (sub-complex z1 z2)
  (make-from-real-imag (- (real-part z1) (real-part z2))
                       (- (imag-part z1) (imag-part z2))))

(define (mul-complex z1 z2)
  (make-from-mag-ang (* (magnitude z1) (magnitude z2))
                     (+ (angle z1) (angle z2))))

(define (div-complex z1 z2)
  (make-from-mag-ang (/ (magnitude z1) (magnitude z2))
                     (- (angle z1) (angle z2))))
</code></pre>
<p>We can also implement the package using polar form:</p>
<pre><code class="language-scheme editable">(define (make-from-real-imag x y)
  (cons (sqrt (+ (square x) (square y)))
        (atan y x)))
(define (make-from-mag-ang r a) (cons r a))

(define (real-part z)
  (* (magnitude z) (cos (angle z))))

(define (imag-part z)
  (* (magnitude z) (sin (angle z))))

(define (magnitude z) (car z))
(define (angle z) (cdr z))

(define (add-complex z1 z2)
  (make-from-real-imag (+ (real-part z1) (real-part z2))
                       (+ (imag-part z1) (imag-part z2))))

(define (sub-complex z1 z2)
  (make-from-real-imag (- (real-part z1) (real-part z2))
                       (- (imag-part z1) (imag-part z2))))

(define (mul-complex z1 z2)
  (make-from-mag-ang (* (magnitude z1) (magnitude z2))
                     (+ (angle z1) (angle z2))))

(define (div-complex z1 z2)
  (make-from-mag-ang (/ (magnitude z1) (magnitude z2))
                     (- (angle z1) (angle z2))))
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<p><a href="book-Z-H-4.html#%_toc_%_chap_3">Chapter 3</a></p>
<p><a href="book-Z-H-4.html#%_toc_%_chap_3">Modularity, Objects, and State</a></p>
<div class="info">
(Even while it changes, it stands still.)
<p>Heraclitus</p>
<p>Plus ça change, plus c'est la même chose.</p>
<p>Alphonse Karr</p>
</div>
<p>The preceding chapters introduced the basic elements from which programs
are made. We saw how primitive procedures and primitive data are
combined to construct compound entities, and we learned that abstraction
is vital in helping us to cope with the complexity of large systems. But
these tools are not sufficient for designing programs. Effective program
synthesis also requires organizational principles that can guide us in
formulating the overall design of a program. In particular, we need
strategies to help us structure large systems so that they will be
<em>modular</em>, that is, so that they can be divided ``naturally'' into
coherent parts that can be separately developed and maintained.</p>
<p>One powerful design strategy, which is
particularly appropriate to the construction of programs for modeling
physical systems, is to base the structure of our programs on the
structure of the system being modeled. For each object in the system, we
construct a corresponding computational object. For each system action,
we define a symbolic operation in our computational model. Our hope in
using this strategy is that extending the model to accommodate new
objects or new actions will require no strategic changes to the program,
only the addition of the new symbolic analogs of those objects or
actions. If we have been successful in our system organization, then to
add a new feature or debug an old one we will have to work on only a
localized part of the system.</p>
<p>To a large extent, then, the way we organize a large program is dictated
by our perception of the system to be modeled. In this chapter we will
investigate two prominent organizational strategies arising from two
rather different ``world views'' of the structure of systems. The
first organizational strategy concentrates on <em>objects</em>,
viewing a large system as a collection of distinct objects whose
behaviors may change over time. An alternative organizational strategy
concentrates on the <em>streams</em> of information that flow in
the system, much as an electrical engineer views a signal-processing
system.</p>
<p>Both the object-based approach and the stream-processing approach raise
significant linguistic issues in programming. With objects, we must be
concerned with how a computational object can change and yet maintain
its identity. This will force us to abandon our old substitution model
of computation (section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a>) in favor
of a more mechanistic but less theoretically tractable
<em>environment model</em> of computation. The difficulties of
dealing with objects, change, and identity are a fundamental consequence
of the need to grapple with time in our computational models. These
difficulties become even greater when we allow the possibility of
concurrent execution of programs. The stream approach can be most fully
exploited when we decouple simulated time in our model from the order of
the events that take place in the computer during evaluation. We will
accomplish this using a technique known as <em>delayed
evaluation</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="31--assignment-and-local-state"><a class="header" href="#31--assignment-and-local-state"><a href="book-Z-H-4.html#%_toc_%_sec_3.1">3.1  Assignment and Local State</a></a></h2>
<p>We ordinarily view the world as populated
by independent objects, each of which has a state that changes over
time. An object is said to <code>have state'' if its behavior is influenced by its history. A bank account, for example, has state in that the answer to the question </code>Can I withdraw $100?'' depends
upon the history of deposit and withdrawal transactions. We can
characterize an object's state by one or more <em>state
variables</em>, which among them maintain enough information about history
to determine the object's current behavior. In a simple banking system,
we could characterize the state of an account by a current balance
rather than by remembering the entire history of account transactions.</p>
<p>In a system composed of many objects, the objects are rarely completely
independent. Each may influence the states of others through
interactions, which serve to couple the state variables of one object to
those of other objects. Indeed, the view that a system is composed of
separate objects is most useful when the state variables of the system
can be grouped into closely coupled subsystems that are only loosely
coupled to other subsystems.</p>
<p>This view of a system can be a powerful framework for organizing
computational models of the system. For such a model to be modular, it
should be decomposed into computational objects that model the actual
objects in the system. Each computational object must have its own
<em>local state variables</em> describing the actual object's state. Since the
states of objects in the system being modeled change over time, the
state variables of the corresponding computational objects must also
change. If we choose to model the flow of time in the system by the
elapsed time in the computer, then we must have a way to construct
computational objects whose behaviors change as our programs run. In
particular, if we wish to model state variables by ordinary symbolic
names in the programming language, then the language must provide an
<em>assignment operator</em> to enable us to change the value
associated with a name.</p>
<h3 id="311--local-state-variables"><a class="header" href="#311--local-state-variables"><a href="book-Z-H-4.html#%_toc_%_sec_3.1.1">3.1.1  Local State Variables</a></a></h3>
<p>To
illustrate what we mean by having a computational object with
time-varying state, let us model the situation of withdrawing money from
a bank account. We will do this using a procedure <code>withdraw</code>, which
takes as argument an <code>amount</code> to be withdrawn. If there is enough money
in the account to accommodate the withdrawal, then <code>withdraw</code> should
return the balance remaining after the withdrawal. Otherwise, <code>withdraw</code>
should return the message <em>Insufficient funds.</em> For example, if we begin
with $100 in the account, we should obtain the following sequence of
responses using <code>withdraw</code>:</p>
<pre><code class="language-scheme editable">(withdraw 25)
</code></pre>
<p><em><code>75</code></em></p>
<pre><code class="language-scheme editable">(withdraw 25)
</code></pre>
<p><em><code>50</code></em></p>
<pre><code class="language-scheme editable">(withdraw 60)
</code></pre>
<p><em><code>"Insufficient funds"</code></em></p>
<pre><code class="language-scheme editable">(withdraw 15)
</code></pre>
<p><em><code>35</code></em></p>
<p>Observe that the expression <code>(withdraw 25)</code>, evaluated twice, yields
different values. This is a new kind of behavior for a procedure. Until
now, all our procedures could be viewed as specifications for computing
mathematical functions. A call to a procedure computed the value of the
function applied to the given arguments, and two calls to the same
procedure with the same arguments always produced the same
result.<a href="book-Z-H-20.html#footnote_Temp_321">^[1]{.small}^</a>{#call_footnote_Temp_321}</p>
<p>To implement <code>withdraw</code>, we can use a variable <code>balance</code> to indicate the
balance of money in the account and define <code>withdraw</code> as a procedure
that accesses <code>balance</code>. The <code>withdraw</code> procedure checks to see if
<code>balance</code> is at least as large as the requested <code>amount</code>. If so,
<code>withdraw</code> decrements <code>balance</code> by <code>amount</code> and returns the new value of
<code>balance</code>. Otherwise, <code>withdraw</code> returns the <em>Insufficient funds</em>
message. Here are the definitions of <code>balance</code> and <code>withdraw</code>:</p>
<pre><code class="language-scheme editable">(define balance 100)

(define (withdraw amount)
  (if (&gt;= balance amount)
      (begin (set! balance (- balance amount))
             balance)
      "Insufficient funds"))
</code></pre>
<p>Decrementing <code>balance</code> is accomplished by the expression</p>
<pre><code class="language-scheme editable">(set! balance (- balance amount))
</code></pre>
<p>This uses the <code>set!</code> special form, whose
syntax is</p>
<pre><code class="language-scheme editable">(set! &lt;name&gt; &lt;new-value&gt;)
</code></pre>
<p>Here &lt;<em>name</em>&gt; is a symbol and &lt;<em>new-value</em>&gt; is any expression.
<code>Set!</code> changes &lt;<em>name</em>&gt; so that its value is the result obtained by
evaluating &lt;<em>new-value</em>&gt;. In the case at hand, we are changing
<code>balance</code> so that its new value will be the result of subtracting
<code>amount</code> from the previous value of
<code>balance</code>.<a href="book-Z-H-20.html#footnote_Temp_322">^[2]{.small}^</a>{#call_footnote_Temp_322}</p>
<p><code>Withdraw</code> also uses the <code>begin</code> special
form to cause two expressions to be evaluated in the case where the <code>if</code>
test is true: first decrementing <code>balance</code> and then returning the value
of <code>balance</code>. In general, evaluating the expression</p>
<pre><code class="language-scheme editable">(begin &lt;exp~1~&gt; &lt;exp~2~&gt; ... &lt;exp~k~&gt;)
</code></pre>
<p>causes the expressions &lt;<em>exp~1~</em>&gt; through &lt;<em>exp~<em>k</em>~</em>&gt; to be
evaluated in sequence and the value of the final expression
&lt;<em>exp~<em>k</em>~</em>&gt; to be returned as the value of the entire <code>begin</code>
form.<a href="book-Z-H-20.html#footnote_Temp_323">^[3]{.small}^</a>{#call_footnote_Temp_323}</p>
<p>Although <code>withdraw</code> works as desired, the variable <code>balance</code> presents a
problem. As specified above, <code>balance</code> is a name defined in the global
environment and is freely accessible to be examined or modified by any
procedure. It would be much better if we could somehow make <code>balance</code>
internal to <code>withdraw</code>, so that <code>withdraw</code> would be the only procedure
that could access <code>balance</code> directly and any other procedure could
access <code>balance</code> only indirectly (through calls to <code>withdraw</code>). This
would more accurately model the notion that <code>balance</code> is a local state
variable used by <code>withdraw</code> to keep track of the state of the account.</p>
<p>We can make <code>balance</code> internal to <code>withdraw</code> by rewriting the definition
as follows:</p>
<pre><code class="language-scheme editable">(define new-withdraw
  (let ((balance 100))
    (lambda (amount)
      (if (&gt;= balance amount)
          (begin (set! balance (- balance amount))
                 balance)
          "Insufficient funds"))))
</code></pre>
<p>What we have done here is use <code>let</code> to establish an environment with a
local variable <code>balance</code>, bound to the initial value 100. Within this
local environment, we use <code>lambda</code> to create a procedure that takes
<code>amount</code> as an argument and behaves like our previous <code>withdraw</code>
procedure. This procedure -- returned as the result of evaluating the
<code>let</code> expression -- is <code>new-withdraw</code>, which behaves in precisely the
same way as <code>withdraw</code> but whose variable <code>balance</code> is not accessible by
any other
procedure.<a href="book-Z-H-20.html#footnote_Temp_324">^[4]{.small}^</a>{#call_footnote_Temp_324}</p>
<p>Combining <code>set!</code> with local variables is the general programming
technique we will use for constructing computational objects with local
state. Unfortunately, using this technique raises a serious problem:
When we first introduced procedures, we also introduced the substitution
model of evaluation (section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a>) to
provide an interpretation of what procedure application means. We said
that applying a procedure should be interpreted as evaluating the body
of the procedure with the formal parameters replaced by their values.
The trouble is that, as soon as we introduce assignment into our
language, substitution is no longer an adequate model of procedure
application. (We will see why this is so in
section <a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3</a>.) As a consequence, we
technically have at this point no way to understand why the
<code>new-withdraw</code> procedure behaves as claimed above. In order to really
understand a procedure such as <code>new-withdraw</code>, we will need to develop a
new model of procedure application. In
section <a href="book-Z-H-21.html#%_sec_3.2">3.2</a> we will introduce such a
model, together with an explanation of <code>set!</code> and local variables.
First, however, we examine some variations on the theme established by
<code>new-withdraw</code>.</p>
<p>The following procedure, <code>make-withdraw</code>, creates ``withdrawal
processors.'' The formal parameter <code>balance</code> in <code>make-withdraw</code>
specifies the initial amount of money in the
account.<a href="book-Z-H-20.html#footnote_Temp_325">^[5]{.small}^</a>{#call_footnote_Temp_325}</p>
<pre><code class="language-scheme editable">(define (make-withdraw balance)
  (lambda (amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds")))
</code></pre>
<p><code>Make-withdraw</code> can be used as follows to create two objects <code>W1</code> and
<code>W2</code>:</p>
<pre><code class="language-scheme editable">(define W1 (make-withdraw 100))
(define W2 (make-withdraw 100))
(W1 50)
</code></pre>
<p><em><code>50</code></em></p>
<pre><code class="language-scheme editable">(W2 70)
</code></pre>
<p><em><code>30</code></em></p>
<pre><code class="language-scheme editable">(W2 40)
</code></pre>
<p><em><code>"Insufficient funds"</code></em></p>
<pre><code class="language-scheme editable">(W1 40)
</code></pre>
<p><em><code>10</code></em></p>
<p>Observe that <code>W1</code> and <code>W2</code> are completely independent objects, each with
its own local state variable <code>balance</code>. Withdrawals from one do not
affect the other.</p>
<p>We can also create objects that handle deposits as well as withdrawals,
and thus we can represent simple bank accounts. Here is a procedure that
returns a ``bank-account object'' with a specified initial balance:</p>
<pre><code class="language-scheme editable">(define (make-account balance)
  (define (withdraw amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds"))
  (define (deposit amount)
    (set! balance (+ balance amount))
    balance)
  (define (dispatch m)
    (cond ((eq? m 'withdraw) withdraw)
          ((eq? m 'deposit) deposit)
          (else (error "Unknown request -- MAKE-ACCOUNT"
                       m))))
  dispatch)
</code></pre>
<p>Each call to <code>make-account</code> sets up an environment with a local state
variable <code>balance</code>. Within this environment, <code>make-account</code> defines
procedures <code>deposit</code> and <code>withdraw</code> that access <code>balance</code> and an
additional procedure <code>dispatch</code> that takes a ``message'' as input
and returns one of the two local procedures. The <code>dispatch</code> procedure
itself is returned as the value that represents the bank-account object.
This is precisely the <em>message-passing</em> style of
programming that we saw in
section <a href="book-Z-H-17.html#%_sec_2.4.3">2.4.3</a>, although here we are
using it in conjunction with the ability to modify local variables.</p>
<p><code>Make-account</code> can be used as follows:</p>
<pre><code class="language-scheme editable">(define acc (make-account 100))
((acc 'withdraw) 50)
</code></pre>
<p><em><code>50</code></em></p>
<pre><code class="language-scheme editable">((acc 'withdraw) 60)
</code></pre>
<p><em><code>"Insufficient funds"</code></em></p>
<pre><code class="language-scheme editable">((acc 'deposit) 40)
</code></pre>
<p><em><code>90</code></em></p>
<pre><code class="language-scheme editable">((acc 'withdraw) 60)
</code></pre>
<p><em><code>30</code></em></p>
<p>Each call to <code>acc</code> returns the locally defined <code>deposit</code> or <code>withdraw</code>
procedure, which is then applied to the specified <code>amount</code>. As was the
case with <code>make-withdraw</code>, another call to <code>make-account</code></p>
<pre><code class="language-scheme editable">(define acc2 (make-account 100))
</code></pre>
<p>will produce a completely separate account object, which maintains its
own local <code>balance</code>.</p>
<p><strong>Exercise 3.1.</strong>  An <em>accumulator</em> is a
procedure that is called repeatedly with a single numeric argument and
accumulates its arguments into a sum. Each time it is called, it returns
the currently accumulated sum. Write a procedure
<code>make-accumulator</code> that generates accumulators, each
maintaining an independent sum. The input to <code>make-accumulator</code> should
specify the initial value of the sum; for example</p>
<pre><code class="language-scheme editable">(define A (make-accumulator 5))
(A 10)
</code></pre>
<p><em><code>15</code></em></p>
<pre><code class="language-scheme editable">(A 10)
</code></pre>
<p><em><code>25</code></em></p>
<p><strong>Exercise 3.2.</strong>  In software-testing applications, it
is useful to be able to count the number of times a given procedure is
called during the course of a computation. Write a procedure
<code>make-monitored</code> that takes
as input a procedure, <code>f</code>, that itself takes one input. The result
returned by <code>make-monitored</code> is a third procedure, say <code>mf</code>, that keeps
track of the number of times it has been called by maintaining an
internal counter. If the input to <code>mf</code> is the special symbol
<code>how-many-calls?</code>, then <code>mf</code> returns the value of the counter. If the
input is the special symbol <code>reset-count</code>, then <code>mf</code> resets the counter
to zero. For any other input, <code>mf</code> returns the result of calling <code>f</code> on
that input and increments the counter. For instance, we could make a
monitored version of the <code>sqrt</code> procedure:</p>
<pre><code class="language-scheme editable">(define s (make-monitored sqrt))

(s 100)
</code></pre>
<p><em><code>10</code></em></p>
<pre><code class="language-scheme editable">(s 'how-many-calls?)
</code></pre>
<p><em><code>1</code></em></p>
<p><strong>Exercise 3.3.</strong>  Modify
the <code>make-account</code> procedure so that it creates password-protected
accounts. That is, <code>make-account</code> should take a symbol as an additional
argument, as in</p>
<pre><code class="language-scheme editable">(define acc (make-account 100 'secret-password))
</code></pre>
<p>The resulting account object should process a request only if it is
accompanied by the password with which the account was created, and
should otherwise return a complaint:</p>
<pre><code class="language-scheme editable">((acc 'secret-password 'withdraw) 40)
</code></pre>
<p><em><code>60</code></em></p>
<pre><code class="language-scheme editable">((acc 'some-other-password 'deposit) 50)
</code></pre>
<p><em><code>"Incorrect password"</code></em></p>
<p><strong>Exercise 3.4.</strong>  Modify the <code>make-account</code> procedure of
exercise <a href="book-Z-H-20.html#%_thm_3.3">3.3</a> by adding another local state
variable so that, if an account is accessed more than seven consecutive
times with an incorrect password, it invokes the procedure
<code>call-the-cops</code>.</p>
<h3 id="312--the-benefits-of-introducing-assignment"><a class="header" href="#312--the-benefits-of-introducing-assignment"><a href="book-Z-H-4.html#%_toc_%_sec_3.1.2">3.1.2  The Benefits of Introducing Assignment</a></a></h3>
<p>As we shall see,
introducing assignment into our programming language leads us into a
thicket of difficult conceptual issues. Nevertheless, viewing systems as
collections of objects with local state is a powerful technique for
maintaining a modular design. As a simple example, consider the design
of a procedure <code>rand</code> that, whenever it is called, returns an integer
chosen at random.</p>
<p>It is not at all clear what is meant by ``chosen at
random.'' What we presumably want is for successive calls to <code>rand</code> to
produce a sequence of numbers that has statistical properties of uniform
distribution. We will not discuss methods for generating suitable
sequences here. Rather, let us assume that we have a procedure
<code>rand-update</code> that has the property that if we start with a given number
<em>x</em><del>1</del> and form</p>
<p><em><code>x</code></em><del><code>2</code></del><code>= (rand-update</code><em><code>x</code></em><del><code>1</code></del><code>)</code>
<em><code>x</code></em><del><code>3</code></del><code>= (rand-update</code><em><code>x</code></em><del><code>2</code></del><code>)</code></p>
<p>then the sequence of values <em>x</em><del>1</del>, <em>x</em><del>2</del>, <em>x</em><del>3</del>, ..., will have the
desired statistical
properties.<a href="book-Z-H-20.html#footnote_Temp_330">^[6]{.small}^</a>{#call_footnote_Temp_330}</p>
<p>We can implement <code>rand</code> as a procedure with a local state variable <code>x</code>
that is initialized to some fixed value <code>random-init</code>. Each call to
<code>rand</code> computes <code>rand-update</code> of the current value of <code>x</code>, returns this
as the random number, and also stores this as the new value of <code>x</code>.</p>
<pre><code class="language-scheme editable">(define rand
  (let ((x random-init))
    (lambda ()
      (set! x (rand-update x))
      x)))
</code></pre>
<p>Of course, we could generate the same sequence of random numbers without
using assignment by simply calling <code>rand-update</code> directly. However, this
would mean that any part of our program that used random numbers would
have to explicitly remember the current value of <code>x</code> to be passed as an
argument to <code>rand-update</code>. To realize what an annoyance this would be,
consider using random numbers to implement a technique called
<em>Monte Carlo simulation</em>.</p>
<p>The Monte Carlo method consists of choosing sample experiments at random
from a large set and then making deductions on the basis of the
probabilities estimated from tabulating the results of those
experiments. For example, we can approximate
<img src="book-Z-G-D-9.gif" alt="" />{border="0"} using the fact that
6/<img src="book-Z-G-D-9.gif" alt="" />{border="0"}^2^ is the probability that two
integers chosen at random will have no factors in common; that is, that
their greatest common divisor will be
1.<a href="book-Z-H-20.html#footnote_Temp_331">^[7]{.small}^</a>{#call_footnote_Temp_331}
To obtain the approximation to <img src="book-Z-G-D-9.gif" alt="" />{border="0"}, we
perform a large number of experiments. In each experiment we choose two
integers at random and perform a test to see if their GCD
is 1. The fraction of times that the test is passed gives us our
estimate of 6/<img src="book-Z-G-D-9.gif" alt="" />{border="0"}^2^, and from this we
obtain our approximation to <img src="book-Z-G-D-9.gif" alt="" />{border="0"}.</p>
<p>The heart of our program is a procedure <code>monte-carlo</code>, which takes as
arguments the number of times to try an experiment, together with the
experiment, represented as a no-argument procedure that will return
either true or false each time it is run. <code>Monte-carlo</code> runs the
experiment for the designated number of trials and returns a number
telling the fraction of the trials in which the experiment was found to
be true.</p>
<pre><code class="language-scheme editable">(define (estimate-pi trials)
  (sqrt (/ 6 (monte-carlo trials cesaro-test))))
(define (cesaro-test)
  (= (gcd (rand) (rand)) 1))
(define (monte-carlo trials experiment)
  (define (iter trials-remaining trials-passed)
    (cond ((= trials-remaining 0)
           (/ trials-passed trials))
          ((experiment)
           (iter (- trials-remaining 1) (+ trials-passed 1)))
          (else
           (iter (- trials-remaining 1) trials-passed))))
  (iter trials 0))
</code></pre>
<p>Now let us try the same computation using <code>rand-update</code> directly rather
than <code>rand</code>, the way we would be forced to proceed if we did not use
assignment to model local state:</p>
<pre><code class="language-scheme editable">(define (estimate-pi trials)
  (sqrt (/ 6 (random-gcd-test trials random-init))))
(define (random-gcd-test trials initial-x)
  (define (iter trials-remaining trials-passed x)
    (let ((x1 (rand-update x)))
      (let ((x2 (rand-update x1)))
        (cond ((= trials-remaining 0)  
               (/ trials-passed trials))
              ((= (gcd x1 x2) 1)
               (iter (- trials-remaining 1)
                     (+ trials-passed 1)
                     x2))
              (else
               (iter (- trials-remaining 1)
                     trials-passed
                     x2))))))
  (iter trials 0 initial-x))
</code></pre>
<p>While the program is still simple, it betrays some painful breaches of
modularity. In our first version of the program, using <code>rand</code>, we can
express the Monte Carlo method directly as a general <code>monte-carlo</code>
procedure that takes as an argument an arbitrary <code>experiment</code> procedure.
In our second version of the program, with no local state for the
random-number generator, <code>random-gcd-test</code> must explicitly manipulate
the random numbers <code>x1</code> and <code>x2</code> and recycle <code>x2</code> through the iterative
loop as the new input to <code>rand-update</code>. This explicit handling of the
random numbers intertwines the structure of accumulating test results
with the fact that our particular experiment uses two random numbers,
whereas other Monte Carlo experiments might use one random number or
three. Even the top-level procedure <code>estimate-pi</code> has to be concerned
with supplying an initial random number. The fact that the random-number
generator's insides are leaking out into other parts of the program
makes it difficult for us to isolate the Monte Carlo idea so that it can
be applied to other tasks. In the first version of the program,
assignment encapsulates the state of the random-number generator within
the <code>rand</code> procedure, so that the details of random-number generation
remain independent of the rest of the program.</p>
<p>The general phenomenon illustrated by the Monte Carlo example is this:
From the point of view of one part of a complex process, the other parts
appear to change with time. They have hidden time-varying local state.
If we wish to write computer programs whose structure reflects this
decomposition, we make computational objects (such as bank accounts and
random-number generators) whose behavior changes with time. We model
state with local state variables, and we model the changes of state with
assignments to those variables.</p>
<p>It is tempting to conclude this discussion by saying that, by
introducing assignment and the technique of hiding state in local
variables, we are able to structure systems in a more modular fashion
than if all state had to be manipulated explicitly, by passing
additional parameters. Unfortunately, as we shall see, the story is not
so simple.</p>
<p><strong>Exercise
3.5.</strong>  <em>Monte Carlo
integration</em> is a method of estimating definite integrals by means of
Monte Carlo simulation. Consider computing the area of a region of space
described by a predicate <em>P</em>(<em>x</em>, <em>y</em>) that is true for points (<em>x</em>,
<em>y</em>) in the region and false for points not in the region. For example,
the region contained within a circle of radius 3 centered at (5, 7) is
described by the predicate that tests whether (<em>x</em> - 5)^2^ + (<em>y</em> -
7)^2^[&lt;]{.underline} 3^2^. To estimate the area of the region described
by such a predicate, begin by choosing a rectangle that contains the
region. For example, a rectangle with diagonally opposite corners at (2,
4) and (8, 10) contains the circle above. The desired integral is the
area of that portion of the rectangle that lies in the region. We can
estimate the integral by picking, at random, points (<em>x</em>,<em>y</em>) that lie
in the rectangle, and testing <em>P</em>(<em>x</em>, <em>y</em>) for each point to determine
whether the point lies in the region. If we try this with many points,
then the fraction of points that fall in the region should give an
estimate of the proportion of the rectangle that lies in the region.
Hence, multiplying this fraction by the area of the entire rectangle
should produce an estimate of the integral.</p>
<p>Implement Monte Carlo integration as a procedure
<code>estimate-integral</code> that takes as arguments a predicate
<code>P</code>, upper and lower bounds <code>x1</code>, <code>x2</code>, <code>y1</code>, and <code>y2</code> for the
rectangle, and the number of trials to perform in order to produce the
estimate. Your procedure should use the same <code>monte-carlo</code> procedure
that was used above to estimate <img src="book-Z-G-D-9.gif" alt="" />{border="0"}. Use
your <code>estimate-integral</code> to produce an estimate of
<img src="book-Z-G-D-9.gif" alt="" />{border="0"} by measuring the area of a unit
circle.</p>
<p>You will find it useful to have a procedure that returns a number chosen
at random from a given range. The following <code>random-in-range</code> procedure
implements this in terms of the <code>random</code> procedure used in
section <a href="book-Z-H-11.html#%_sec_1.2.6">1.2.6</a>, which returns a
nonnegative number less than its
input.<a href="book-Z-H-20.html#footnote_Temp_333">^[8]{.small}^</a>{#call_footnote_Temp_333}</p>
<pre><code class="language-scheme editable">(define (random-in-range low high)
  (let ((range (- high low)))
    (+ low (random range))))
</code></pre>
<p><strong>Exercise 3.6.</strong>  It is
useful to be able to reset a random-number generator to produce a
sequence starting from a given value. Design a new <code>rand</code> procedure that
is called with an argument that is either the symbol <code>generate</code> or the
symbol <code>reset</code> and behaves as follows: <code>(rand 'generate)</code> produces a new
random number; <code>((rand 'reset) &lt;</code><em><code>new-value</code></em><code>&gt;)</code> resets the internal
state variable to the designated &lt;<em>new-value</em>&gt;. Thus, by resetting the
state, one can generate repeatable sequences. These are very handy to
have when testing and debugging programs that use random numbers.</p>
<h3 id="313--the-costs-of-introducing-assignment"><a class="header" href="#313--the-costs-of-introducing-assignment"><a href="book-Z-H-4.html#%_toc_%_sec_3.1.3">3.1.3  The Costs of Introducing Assignment</a></a></h3>
<p>As we have seen, the <code>set!</code> operation enables us to
model objects that have local state. However, this advantage comes at a
price. Our programming language can no longer be interpreted in terms of
the substitution model of procedure application that we introduced in
section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a>. Moreover, no simple model
with ``nice'' mathematical properties can be an adequate framework
for dealing with objects and assignment in programming languages.</p>
<p>So long as we do not use assignments, two evaluations of the same
procedure with the same arguments will produce the same result, so that
procedures can be viewed as computing mathematical functions.
Programming without any use of assignments, as we did throughout the
first two chapters of this book, is accordingly known as
<em>functional programming</em>.</p>
<p>To understand how assignment complicates matters,
consider a simplified version of the <code>make-withdraw</code> procedure of
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a> that does not bother to
check for an insufficient amount:</p>
<pre><code class="language-scheme editable">(define (make-simplified-withdraw balance)
  (lambda (amount)
    (set! balance (- balance amount))
    balance))
(define W (make-simplified-withdraw 25))
(W 20)
</code></pre>
<p><em><code>5</code></em></p>
<pre><code class="language-scheme editable">(W 10)
</code></pre>
<p><em><code>- 5</code></em></p>
<p>Compare this procedure with the following <code>make-decrementer</code> procedure,
which does not use <code>set!</code>:</p>
<pre><code class="language-scheme editable">(define (make-decrementer balance)
  (lambda (amount)
    (- balance amount)))
</code></pre>
<p><code>Make-decrementer</code> returns a procedure that subtracts its input from a
designated amount <code>balance</code>, but there is no accumulated effect over
successive calls, as with <code>make-simplified-withdraw</code>:</p>
<pre><code class="language-scheme editable">(define D (make-decrementer 25))
(D 20)
</code></pre>
<p><em><code>5</code></em></p>
<pre><code class="language-scheme editable">(D 10)
</code></pre>
<p><em><code>15</code></em></p>
<p>We can use the substitution model to explain how <code>make-decrementer</code>
works. For instance, let us analyze the evaluation of the expression</p>
<pre><code class="language-scheme editable">((make-decrementer 25) 20)
</code></pre>
<p>We first simplify the operator of the combination by substituting 25 for
<code>balance</code> in the body of <code>make-decrementer</code>. This reduces the expression
to</p>
<pre><code class="language-scheme editable">((lambda (amount) (- 25 amount)) 20)
</code></pre>
<p>Now we apply the operator by substituting 20 for <code>amount</code> in the body of
the <code>lambda</code> expression:</p>
<pre><code class="language-scheme editable">(- 25 20)
</code></pre>
<p>The final answer is 5.</p>
<p>Observe, however, what happens if we attempt a similar substitution
analysis with <code>make-simplified-withdraw</code>:</p>
<pre><code class="language-scheme editable">((make-simplified-withdraw 25) 20)
</code></pre>
<p>We first simplify the operator by substituting 25 for <code>balance</code> in the
body of <code>make-simplified-withdraw</code>. This reduces the expression
to^[9]{.small}^](book-Z-H-20.html#footnote_Temp_335){#call_footnote_Temp_335}</p>
<pre><code class="language-scheme editable">((lambda (amount) (set! balance (- 25 amount)) 25) 20)
</code></pre>
<p>Now we apply the operator by substituting 20 for <code>amount</code> in the body of
the <code>lambda</code> expression:</p>
<pre><code class="language-scheme editable">(set! balance (- 25 20)) 25
</code></pre>
<p>If we adhered to the substitution model, we would have to say that the
meaning of the procedure application is to first set <code>balance</code> to 5 and
then return 25 as the value of the expression. This gets the wrong
answer. In order to get the correct answer, we would have to somehow
distinguish the first occurrence of <code>balance</code> (before the effect of the
<code>set!</code>) from the second occurrence of <code>balance</code> (after the effect of the
<code>set!</code>), and the substitution model cannot do this.</p>
<p>The trouble here is that substitution is based ultimately on the notion
that the symbols in our language are essentially names for values. But
as soon as we introduce <code>set!</code> and the idea that the value of a variable
can change, a variable can no longer be simply a name. Now a variable
somehow refers to a place where a value can be stored, and the value
stored at this place can change. In
section <a href="book-Z-H-21.html#%_sec_3.2">3.2</a> we will see how environments
play this role of ``place'' in our computational model.</p>
<h4 id="sameness-and-change"><a class="header" href="#sameness-and-change"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_336">Sameness and change</a></a></h4>
<p>The issue surfacing here is more profound
than the mere breakdown of a particular model of computation. As soon as
we introduce change into our computational models, many notions that
were previously straightforward become problematical. Consider the
concept of two things being ``the same.''</p>
<p>Suppose we call <code>make-decrementer</code> twice with the same argument to
create two procedures:</p>
<pre><code class="language-scheme editable">(define D1 (make-decrementer 25))
(define D2 (make-decrementer 25))
</code></pre>
<p>Are <code>D1</code> and <code>D2</code> the same? An acceptable answer is yes, because <code>D1</code>
and <code>D2</code> have the same computational behavior -- each is a procedure
that subtracts its input from 25. In fact, <code>D1</code> could be substituted for
<code>D2</code> in any computation without changing the result.</p>
<p>Contrast this with making two calls to <code>make-simplified-withdraw</code>:</p>
<pre><code class="language-scheme editable">(define W1 (make-simplified-withdraw 25))
(define W2 (make-simplified-withdraw 25))
</code></pre>
<p>Are <code>W1</code> and <code>W2</code> the same? Surely not, because calls to <code>W1</code> and <code>W2</code>
have distinct effects, as shown by the following sequence of
interactions:</p>
<pre><code class="language-scheme editable">(W1 20)
</code></pre>
<p><em><code>5</code></em></p>
<pre><code class="language-scheme editable">(W1 20)
</code></pre>
<p><em><code>- 15</code></em></p>
<pre><code class="language-scheme editable">(W2 20)
</code></pre>
<p><em><code>5</code></em></p>
<p>Even though <code>W1</code> and <code>W2</code> are ``equal'' in the sense that they are
both created by evaluating the same expression,
<code>(make-simplified-withdraw 25)</code>, it is not true that <code>W1</code> could be
substituted for <code>W2</code> in any expression without changing the result of
evaluating the expression.</p>
<p>A language that supports the concept that ``equals can be substituted
for equals'' in an expresssion without changing the value of the
expression is said to be
<em>referentially
transparent</em>. Referential transparency is violated when we include
<code>set!</code> in our computer language. This makes it tricky to determine when
we can simplify expressions by substituting equivalent expressions.
Consequently, reasoning about programs that use assignment becomes
drastically more difficult.</p>
<p>Once we forgo referential transparency, the notion of what it means for
computational objects to be <code>the same'' becomes difficult to capture in a formal way. Indeed, the meaning of </code>same'' in the real
world that our programs model is hardly clear in itself. In general, we
can determine that two apparently identical objects are indeed <code>the same one'' only by modifying one object and then observing whether the other object has changed in the same way. But how can we tell if an object has </code>changed'' other than by observing the <code>same'' object twice and seeing whether some property of the object differs from one observation to the next? Thus, we cannot determine </code>change''
without some <em>a priori</em> notion of ``sameness,'' and we cannot
determine sameness without observing the effects of change.</p>
<p>As an example of how this issue arises in programming,
consider the situation where Peter and Paul have a bank account with
$100 in it. There is a substantial difference between modeling this as</p>
<pre><code class="language-scheme editable">(define peter-acc (make-account 100))
(define paul-acc (make-account 100))
</code></pre>
<p>and modeling it as</p>
<pre><code class="language-scheme editable">(define peter-acc (make-account 100))
(define paul-acc peter-acc)
</code></pre>
<p>In the first situation, the two bank accounts are distinct. Transactions
made by Peter will not affect Paul's account, and vice versa. In the
second situation, however, we have defined <code>paul-acc</code> to be <em>the same
thing</em> as <code>peter-acc</code>. In effect, Peter and Paul now have a joint bank
account, and if Peter makes a withdrawal from <code>peter-acc</code> Paul will
observe less money in <code>paul-acc</code>. These two similar but distinct
situations can cause confusion in building computational models. With
the shared account, in particular, it can be especially confusing that
there is one object (the bank account) that has two different names
(<code>peter-acc</code> and <code>paul-acc</code>); if we are searching for all the places in
our program where <code>paul-acc</code> can be changed, we must remember to look
also at things that change
<code>peter-acc</code>.<a href="book-Z-H-20.html#footnote_Temp_337">^[10]{.small}^</a>{#call_footnote_Temp_337}</p>
<p>With reference to the above remarks on <code>sameness'' and </code>change,'' observe that if Peter and Paul could only examine their
bank balances, and could not perform operations that changed the
balance, then the issue of whether the two accounts are distinct would
be moot. In general, so long as we never modify data objects, we can
regard a compound data object to be precisely the totality of its
pieces. For example, a rational number is determined by giving its
numerator and its denominator. But this view is no longer valid in the
presence of change, where a compound data object has an <code>identity'' that is something different from the pieces of which it is composed. A bank account is still </code>the same'' bank account even if we change
the balance by making a withdrawal; conversely, we could have two
different bank accounts with the same state information. This
complication is a consequence, not of our programming language, but of
our perception of a bank account as an object. We do not, for example,
ordinarily regard a rational number as a changeable object with
identity, such that we could change the numerator and still have ``the
same'' rational number.</p>
<h4 id="pitfalls-of-imperative-programming"><a class="header" href="#pitfalls-of-imperative-programming"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_338">Pitfalls of imperative programming</a></a></h4>
<p>In contrast to functional programming, programming that makes extensive
use of assignment is known as <em>imperative
programming</em>. In addition to raising complications about computational
models, programs written in imperative style are susceptible to bugs
that cannot occur in functional programs. For example, recall the
iterative factorial program from
section <a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a>:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (define (iter product counter)
    (if (&gt; counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
</code></pre>
<p>Instead of passing arguments in the internal iterative loop, we could
adopt a more imperative style by using explicit assignment to update the
values of the variables <code>product</code> and <code>counter</code>:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (let ((product 1)
        (counter 1))
    (define (iter)
      (if (&gt; counter n)
          product
          (begin (set! product (* counter product))
                 (set! counter (+ counter 1))
                 (iter))))
    (iter)))
</code></pre>
<p>This does not change the results produced
by the program, but it does introduce a subtle trap. How do we decide
the order of the assignments? As it happens, the program is correct as
written. But writing the assignments in the opposite order</p>
<pre><code class="language-scheme editable">(set! counter (+ counter 1))
(set! product (* counter product))
</code></pre>
<p>would have produced a different, incorrect result. In general,
programming with assignment forces us to carefully consider the relative
orders of the assignments to make sure that each statement is using the
correct version of the variables that have been changed. This issue
simply does not arise in functional
programs.<a href="book-Z-H-20.html#footnote_Temp_339">^[11]{.small}^</a>{#call_footnote_Temp_339}
The complexity of imperative programs becomes even worse if we consider
applications in which several processes execute concurrently. We will
return to this in section <a href="book-Z-H-23.html#%_sec_3.4">3.4</a>. First,
however, we will address the issue of providing a computational model
for expressions that involve assignment, and explore the uses of objects
with local state in designing simulations.</p>
<p><strong>Exercise 3.7.</strong>  Consider the bank
account objects created by <code>make-account</code>, with the password
modification described in exercise <a href="book-Z-H-20.html#%_thm_3.3">3.3</a>.
Suppose that our banking system requires the ability to make joint
accounts. Define a procedure <code>make-joint</code> that
accomplishes this. <code>Make-joint</code> should take three arguments. The first
is a password-protected account. The second argument must match the
password with which the account was defined in order for the
<code>make-joint</code> operation to proceed. The third argument is a new password.
<code>Make-joint</code> is to create an additional access to the original account
using the new password. For example, if <code>peter-acc</code> is a bank account
with password <code>open-sesame</code>, then</p>
<pre><code class="language-scheme editable">(define paul-acc
  (make-joint peter-acc 'open-sesame 'rosebud))
</code></pre>
<p>will allow one to make transactions on <code>peter-acc</code> using the name
<code>paul-acc</code> and the password <code>rosebud</code>. You may wish to modify your
solution to exercise <a href="book-Z-H-20.html#%_thm_3.3">3.3</a> to accommodate
this new feature.</p>
<p><strong>Exercise 3.8.</strong>  When we
defined the evaluation model in
section <a href="book-Z-H-10.html#%_sec_1.1.3">1.1.3</a>, we said that the first
step in evaluating an expression is to evaluate its subexpressions. But
we never specified the order in which the subexpressions should be
evaluated (e.g., left to right or right to left). When we introduce
assignment, the order in which the arguments to a procedure are
evaluated can make a difference to the result. Define a simple procedure
<code>f</code> such that evaluating <code>(+ (f 0) (f 1))</code> will return 0 if the
arguments to <code>+</code> are evaluated from left to right but will return 1 if
the arguments are evaluated from right to left.</p>
<p>::: smallprint</p>
<hr />
<p>:::</p>
<p>::: footnote
^[1]{.small}^](book-Z-H-20.html#call_footnote_Temp_321){#footnote_Temp_321}
Actually, this is not quite true. One exception was the
random-number generator in
section <a href="book-Z-H-11.html#%_sec_1.2.6">1.2.6</a>. Another exception
involved the operation/type tables we introduced in
section <a href="book-Z-H-17.html#%_sec_2.4.3">2.4.3</a>, where the values of two
calls to <code>get</code> with the same arguments depended on intervening calls to
<code>put</code>. On the other hand, until we introduce assignment, we have no way
to create such procedures ourselves.</p>
<p>^[2]{.small}^](book-Z-H-20.html#call_footnote_Temp_322){#footnote_Temp_322}
The value of a <code>set!</code> expression is
implementation-dependent. <code>Set!</code> should be used only for its effect, not
for its value.</p>
<p>The name <code>set!</code> reflects a
naming convention used in Scheme: Operations that change the values of
variables (or that change data structures, as we will see in
section <a href="book-Z-H-22.html#%_sec_3.3">3.3</a>) are given names that end with
an exclamation point. This is similar to the convention of designating
predicates by names that end with a question mark.</p>
<p>^[3]{.small}^](book-Z-H-20.html#call_footnote_Temp_323){#footnote_Temp_323}
We have already used <code>begin</code> implicitly in our programs,
because in Scheme the body of a procedure can be a sequence of
expressions. Also, the &lt;<em>consequent</em>&gt; part of each clause in a
<code>cond</code> expression can be a sequence of
expressions rather than a single expression.</p>
<p>^[4]{.small}^](book-Z-H-20.html#call_footnote_Temp_324){#footnote_Temp_324}
In programming-language jargon, the variable <code>balance</code> is said to be
<em>encapsulated</em> within the <code>new-withdraw</code>
procedure. Encapsulation reflects the general system-design principle
known as the <em>hiding principle</em>: One can
make a system more modular and robust by protecting parts of the system
from each other; that is, by providing information access only to those
parts of the system that have a ``need to know.''</p>
<p>^[5]{.small}^](book-Z-H-20.html#call_footnote_Temp_325){#footnote_Temp_325}
In contrast with <code>new-withdraw</code> above, we do not have to use <code>let</code> to
make <code>balance</code> a local variable, since formal parameters are already
local. This will be clearer after the discussion of the environment
model of evaluation in section <a href="book-Z-H-21.html#%_sec_3.2">3.2</a>. (See
also exercise <a href="book-Z-H-21.html#%_thm_3.10">3.10</a>.)</p>
<p>^[6]{.small}^](book-Z-H-20.html#call_footnote_Temp_330){#footnote_Temp_330}
One common way to implement <code>rand-update</code> is to use the rule that <em>x</em> is
updated to <em>ax</em> + <em>b</em> modulo <em>m</em>, where <em>a</em>, <em>b</em>, and <em>m</em> are
appropriately chosen integers. Chapter 3 of Knuth 1981
includes an extensive discussion of techniques for generating sequences
of random numbers and establishing their statistical properties.
Notice that the <code>rand-update</code> procedure computes a mathematical function:
Given the same input twice, it produces the same output. Therefore, the
number sequence produced by <code>rand-update</code> certainly is not <code>random,'' if by </code>random'' we insist that each number in the sequence is
unrelated to the preceding number. The relation between ``real
randomness'' and so-called <em>pseudo-random</em> sequences,
which are produced by well-determined computations and yet have suitable
statistical properties, is a complex question involving difficult issues
in mathematics and philosophy.
Kolmogorov, Solomonoff, and
Chaitin have made great progress in clarifying these issues; a
discussion can be found in Chaitin 1975.</p>
<p>^[7]{.small}^](book-Z-H-20.html#call_footnote_Temp_331){#footnote_Temp_331}
This theorem is due to E. Cesàro. See section 4.5.2 of
Knuth 1981 for a discussion and a proof.</p>
<p>^[8]{.small}^](book-Z-H-20.html#call_footnote_Temp_333){#footnote_Temp_333}
MIT Scheme provides such a procedure. If
<code>random</code> is given an exact integer (as in
section <a href="book-Z-H-11.html#%_sec_1.2.6">1.2.6</a>) it returns an exact
integer, but if it is given a decimal value (as in this exercise) it
returns a decimal value.</p>
<p>^[9]{.small}^](book-Z-H-20.html#call_footnote_Temp_335){#footnote_Temp_335}
We don't substitute for the occurrence of <code>balance</code> in the <code>set!</code>
expression because the &lt;<em>name</em>&gt; in a <code>set!</code> is not evaluated. If we
did substitute for it, we would get <code>(set! 25 (- 25 amount))</code>, which
makes no sense.</p>
<p>^[10]{.small}^](book-Z-H-20.html#call_footnote_Temp_337){#call_footnote_Temp_337}
The phenomenon of a single computational object being accessed by more
than one name is known as <em>aliasing</em>. The joint bank
account situation illustrates a very simple example of an alias. In
section <a href="book-Z-H-22.html#%_sec_3.3">3.3</a> we will see much more complex
examples, such as <code>distinct'' compound data structures that share parts. Bugs can occur in our programs if we forget that a change to an object may also, as a </code>side effect,'' change a <code>different'' object because the two </code>different'' objects are actually a single
object appearing under different aliases. These so-called <em>side-effect
bugs</em> are so difficult to locate and to analyze that some people have
proposed that programming languages be designed in such a way as to not
allow side effects or aliasing
(Lampson et
al. 1981; Morris, Schmidt, and Wadler 1980).</p>
<p>^[11]{.small}^](book-Z-H-20.html#call_footnote_Temp_339){#footnote_Temp_339}
In view of this, it is ironic that introductory programming is most
often taught in a highly imperative style. This may be a vestige of a
belief, common throughout the 1960s and 1970s, that programs that call
procedures must inherently be less efficient than programs that perform
assignments. (Steele (1977) debunks this argument.)
Alternatively it may reflect a view that step-by-step assignment is
easier for beginners to visualize than procedure call. Whatever the
reason, it often saddles beginning programmers with ``should I set
this variable before or after that one'' concerns that can complicate
programming and obscure the important ideas.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="32--the-environment-model-of-evaluation"><a class="header" href="#32--the-environment-model-of-evaluation"><a href="book-Z-H-4.html#%_toc_%_sec_3.2">3.2  The Environment Model of Evaluation</a></a></h2>
<p>When we introduced compound procedures in chapter 1, we
used the substitution model of evaluation
(section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a>) to define what is meant
by applying a procedure to arguments:</p>
<ul>
<li>To apply a compound procedure to arguments, evaluate the body of the
procedure with each formal parameter replaced by the corresponding
argument.</li>
</ul>
<p>Once we admit assignment into our programming language, such a
definition is no longer adequate. In particular,
section <a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3</a> argued that, in the
presence of assignment, a variable can no longer be considered to be
merely a name for a value. Rather, a variable must somehow designate a
``place'' in which values can be stored. In our new model of
evaluation, these places will be maintained in structures called
<em>environments</em>.</p>
<p>An environment is a sequence of <em>frames</em>. Each frame is a
table (possibly empty) of <em>bindings</em>, which associate
variable names with their corresponding values. (A single frame may
contain at most one binding for any variable.) Each frame also has a
pointer to its <em>enclosing environment</em>,
unless, for the purposes of discussion, the frame is considered to be
<em>global</em>. The <em>value of a
variable</em> with respect to an environment is the value given by the
binding of the variable in the first frame in the environment that
contains a binding for that variable. If no frame in the sequence
specifies a binding for the variable, then the variable is said to be
<em>unbound</em> in the environment.</p>
<p><img src="ch3-Z-G-2.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.1:</strong>  A simple environment structure.</p>
<p>Figure <a href="book-Z-H-21.html#%_fig_3.1">3.1</a> shows a simple environment
structure consisting of three frames, labeled I, II, and III. In the
diagram, A, B, C, and D are pointers to environments. C and D point to
the same environment. The variables <code>z</code> and <code>x</code> are bound in frame II,
while <code>y</code> and <code>x</code> are bound in frame I. The value of <code>x</code> in environment
D is 3. The value of <code>x</code> with respect to environment B is also 3. This
is determined as follows: We examine the first frame in the sequence
(frame III) and do not find a binding for <code>x</code>, so we proceed to the
enclosing environment D and find the binding in frame I. On the other
hand, the value of <code>x</code> in environment A is 7, because the first frame in
the sequence (frame II) contains a binding of <code>x</code> to 7. With respect to
environment A, the binding of <code>x</code> to 7 in frame II is said to
<em>shadow</em> the binding of <code>x</code> to 3 in frame I.</p>
<p>The environment is crucial to the evaluation process, because it
determines the context in which an expression should be evaluated.
Indeed, one could say that expressions in a programming language do not,
in themselves, have any meaning. Rather, an expression acquires a
meaning only with respect to some environment in which it is evaluated.
Even the interpretation of an expression as straightforward as <code>(+ 1 1)</code>
depends on an understanding that one is operating in a context in which
<code>+</code> is the symbol for addition. Thus, in our model of evaluation we will
always speak of evaluating an expression with respect to some
environment. To describe interactions with the interpreter, we will
suppose that there is a global environment, consisting of
a single frame (with no enclosing environment) that includes values for
the symbols associated with the primitive procedures. For example, the
idea that <code>+</code> is the symbol for addition is captured by saying that the
symbol <code>+</code> is bound in the global environment to the primitive addition
procedure.</p>
<h3 id="321--the-rules-for-evaluation"><a class="header" href="#321--the-rules-for-evaluation"><a href="book-Z-H-4.html#%_toc_%_sec_3.2.1">3.2.1  The Rules for Evaluation</a></a></h3>
<p>The overall specification of how the interpreter
evaluates a combination remains the same as when we first introduced it
in section <a href="book-Z-H-10.html#%_sec_1.1.3">1.1.3</a>:</p>
<ul>
<li>To evaluate a combination:</li>
</ul>
<blockquote>
<ol>
<li>
<p>Evaluate the subexpressions of the
combination.<a href="book-Z-H-21.html#footnote_Temp_342">^[12]{.small}^</a>{#call_footnote_Temp_342}</p>
</li>
<li>
<p>Apply the value of the operator subexpression to the values of the
operand subexpressions.</p>
</li>
</ol>
</blockquote>
<p>The environment model of evaluation replaces the substitution model in
specifying what it means to apply a compound procedure to arguments.</p>
<p>In the environment model of evaluation, a procedure is always a pair
consisting of some code and a pointer to an environment. Procedures are
created in one way only: by evaluating a <code>lambda</code> expression.
This produces a procedure whose code is obtained from the
text of the <code>lambda</code> expression and whose environment is the environment
in which the <code>lambda</code> expression was evaluated to produce the procedure.
For example, consider the procedure definition</p>
<pre><code class="language-scheme editable">(define (square x)
  (* x x))
</code></pre>
<p>evaluated in the global environment. The procedure definition syntax is
just syntactic sugar for an underlying implicit <code>lambda</code> expression. It
would have been equivalent to have used</p>
<pre><code class="language-scheme editable">(define square
  (lambda (x) (* x x)))
</code></pre>
<p>which evaluates <code>(lambda (x) (* x x))</code> and binds <code>square</code> to the
resulting value, all in the global environment.</p>
<p>Figure <a href="book-Z-H-21.html#%_fig_3.2">3.2</a> shows the result of evaluating
this <code>define</code> expression. The procedure object is a pair whose code
specifies that the procedure has one formal parameter, namely <code>x</code>, and a
procedure body <code>(* x x)</code>. The environment part of the procedure is a
pointer to the global environment, since that is the environment in
which the <code>lambda</code> expression was evaluated to produce the procedure. A
new binding, which associates the procedure object with the symbol
<code>square</code>, has been added to the global frame. In general, <code>define</code>
creates definitions by adding bindings to frames.</p>
<p><img src="ch3-Z-G-3.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.2:</strong>  Environment structure produced by evaluating
<code>(define (square x) (* x x))</code> in the global environment.</p>
<p>Now that we have seen how procedures are created, we can describe how
procedures are applied. The environment model specifies: To apply a
procedure to arguments, create a new environment containing a frame that
binds the parameters to the values of the arguments. The enclosing
environment of this frame is the environment specified by the procedure.
Now, within this new environment, evaluate the procedure body.</p>
<p>To show how this rule is followed,
figure <a href="book-Z-H-21.html#%_fig_3.3">3.3</a> illustrates the environment
structure created by evaluating the expression <code>(square 5)</code> in the
global environment, where <code>square</code> is the procedure generated in
figure <a href="book-Z-H-21.html#%_fig_3.2">3.2</a>. Applying the procedure results
in the creation of a new environment, labeled E1 in the figure, that
begins with a frame in which <code>x</code>, the formal parameter for the
procedure, is bound to the argument 5. The pointer leading upward from
this frame shows that the frame's enclosing environment is the global
environment. The global environment is chosen here, because this is the
environment that is indicated as part of the <code>square</code> procedure object.
Within E1, we evaluate the body of the procedure, <code>(* x x)</code>. Since the
value of <code>x</code> in E1 is 5, the result is <code>(* 5 5)</code>, or 25.</p>
<p><img src="ch3-Z-G-4.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.3:</strong>  Environment created by evaluating <code>(square 5)</code> in the
global environment.</p>
<p>The environment model of procedure application can be summarized by two
rules:</p>
<ul>
<li>
<p>A procedure object is applied to a set of arguments by constructing a
frame, binding the formal parameters of the procedure to the arguments
of the call, and then evaluating the body of the procedure in the
context of the new environment constructed. The new frame has as its
enclosing environment the environment part of the procedure object
being applied.</p>
</li>
<li>
<p>A procedure is created by evaluating a <code>lambda</code> expression relative to
a given environment. The resulting procedure object is a pair
consisting of the text of the <code>lambda</code> expression and a pointer to the
environment in which the procedure was created.</p>
</li>
</ul>
<p>We also specify that defining a symbol using <code>define</code>
creates a binding in the current environment frame and assigns to the
symbol the indicated
value.<a href="book-Z-H-21.html#footnote_Temp_343">^[13]{.small}^</a>{#call_footnote_Temp_343}
Finally, we specify the behavior of <code>set!</code>, the operation that forced us
to introduce the environment model in the first place. Evaluating the
expression <code>(set! &lt;</code><em><code>variable</code></em><code>&gt; &lt;</code><em><code>value</code></em><code>&gt;)</code> in some environment
locates the binding of the variable in the environment and changes that
binding to indicate the new value. That is, one finds the first frame in
the environment that contains a binding for the variable and modifies
that frame. If the variable is unbound in the environment, then <code>set!</code>
signals an error.</p>
<p>These evaluation rules, though considerably more complex than the
substitution model, are still reasonably straightforward. Moreover, the
evaluation model, though abstract, provides a correct description of how
the interpreter evaluates expressions. In chapter 4 we shall see how
this model can serve as a blueprint for implementing a working
interpreter. The following sections elaborate the details of the model
by analyzing some illustrative programs.</p>
<h3 id="322--applying-simple-procedures"><a class="header" href="#322--applying-simple-procedures"><a href="book-Z-H-4.html#%_toc_%_sec_3.2.2">3.2.2  Applying Simple Procedures</a></a></h3>
<p>When we introduced the
substitution model in section <a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a> we
showed how the combination <code>(f 5)</code> evaluates to 136, given the following
procedure definitions:</p>
<pre><code class="language-scheme editable">(define (square x)
  (* x x))
(define (sum-of-squares x y)
  (+ (square x) (square y)))
(define (f a)
  (sum-of-squares (+ a 1) (* a 2)))
</code></pre>
<p>We can analyze the same example using the environment model.
Figure <a href="book-Z-H-21.html#%_fig_3.4">3.4</a> shows the three procedure
objects created by evaluating the definitions of <code>f</code>, <code>square</code>, and
<code>sum-of-squares</code> in the global environment. Each procedure object
consists of some code, together with a pointer to the global
environment.</p>
<p><img src="ch3-Z-G-5.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.4:</strong>  Procedure objects in the global frame.</p>
<p>In figure <a href="book-Z-H-21.html#%_fig_3.5">3.5</a> we see the environment
structure created by evaluating the expression <code>(f 5)</code>. The call to <code>f</code>
creates a new environment E1 beginning with a frame in which <code>a</code>, the
formal parameter of <code>f</code>, is bound to the argument 5. In E1, we evaluate
the body of <code>f</code>:</p>
<pre><code class="language-scheme editable">(sum-of-squares (+ a 1) (* a 2))
</code></pre>
<p><img src="ch3-Z-G-6.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.5:</strong>  Environments created by evaluating <code>(f 5)</code> using the
procedures in figure <a href="book-Z-H-21.html#%_fig_3.4">3.4</a>.</p>
<p>To evaluate this combination, we first evaluate the subexpressions. The
first subexpression, <code>sum-of-squares</code>, has a value that is a procedure
object. (Notice how this value is found: We first look in the first
frame of E1, which contains no binding for <code>sum-of-squares</code>. Then we
proceed to the enclosing environment, i.e. the global environment, and
find the binding shown in figure <a href="book-Z-H-21.html#%_fig_3.4">3.4</a>.) The
other two subexpressions are evaluated by applying the primitive
operations <code>+</code> and <code>*</code> to evaluate the two combinations <code>(+ a 1)</code> and
<code>(* a 2)</code> to obtain 6 and 10, respectively.</p>
<p>Now we apply the procedure object <code>sum-of-squares</code> to the arguments 6
and 10. This results in a new environment E2 in which the formal
parameters <code>x</code> and <code>y</code> are bound to the arguments. Within E2 we evaluate
the combination <code>(+ (square x) (square y))</code>. This leads us to evaluate
<code>(square x)</code>, where <code>square</code> is found in the global frame and <code>x</code> is 6.
Once again, we set up a new environment, E3, in which <code>x</code> is bound to 6,
and within this we evaluate the body of <code>square</code>, which is <code>(* x x)</code>.
Also as part of applying <code>sum-of-squares</code>, we must evaluate the
subexpression <code>(square y)</code>, where <code>y</code> is 10. This second call to
<code>square</code> creates another environment, E4, in which <code>x</code>, the formal
parameter of <code>square</code>, is bound to 10. And within E4 we must evaluate
<code>(* x x)</code>.</p>
<p>The important point to observe is that each call to <code>square</code> creates a
new environment containing a binding for <code>x</code>. We can see here how the
different frames serve to keep separate the different local variables
all named <code>x</code>. Notice that each frame created by <code>square</code> points to the
global environment, since this is the environment indicated by the
<code>square</code> procedure object.</p>
<p>After the subexpressions are evaluated, the results are returned. The
values generated by the two calls to <code>square</code> are added by
<code>sum-of-squares</code>, and this result is returned by <code>f</code>. Since our focus
here is on the environment structures, we will not dwell on how these
returned values are passed from call to call; however, this is also an
important aspect of the evaluation process, and we will return to it in
detail in chapter 5.</p>
<p><strong>Exercise
3.9.</strong>  In
section <a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a> we used the substitution
model to analyze two procedures for computing factorials, a recursive
version</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
</code></pre>
<p>and an iterative version</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (fact-iter 1 1 n))
(define (fact-iter product counter max-count)
  (if (&gt; counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
</code></pre>
<p>Show the environment structures created by evaluating <code>(factorial 6)</code>
using each version of the <code>factorial</code>
procedure.<a href="book-Z-H-21.html#footnote_Temp_345">^[14]{.small}^</a>{#call_footnote_Temp_345}</p>
<h3 id="323--frames-as-the-repository-of-local-state"><a class="header" href="#323--frames-as-the-repository-of-local-state"><a href="book-Z-H-4.html#%_toc_%_sec_3.2.3">3.2.3  Frames as the Repository of Local State</a></a></h3>
<p>We can turn
to the environment model to see how procedures and assignment can be
used to represent objects with local state. As an example, consider the
``withdrawal processor'' from
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a> created by calling the
procedure</p>
<pre><code class="language-scheme editable">(define (make-withdraw balance)
  (lambda (amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds")))
</code></pre>
<p>Let us describe the evaluation of</p>
<pre><code class="language-scheme editable">(define W1 (make-withdraw 100))
</code></pre>
<p>followed by</p>
<pre><code class="language-scheme editable">(W1 50)
</code></pre>
<p><em><code>50</code></em></p>
<p>Figure <a href="book-Z-H-21.html#%_fig_3.6">3.6</a> shows the result of defining
the <code>make-withdraw</code> procedure in the global environment. This produces a
procedure object that contains a pointer to the global environment. So
far, this is no different from the examples we have already seen, except
that the body of the procedure is itself a <code>lambda</code> expression.</p>
<p><img src="ch3-Z-G-7.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.6:</strong>  Result of defining <code>make-withdraw</code> in the global
environment.</p>
<p>The interesting part of the computation happens when we apply the
procedure <code>make-withdraw</code> to an argument:</p>
<pre><code class="language-scheme editable">(define W1 (make-withdraw 100))
</code></pre>
<p>We begin, as usual, by setting up an environment E1 in which the formal
parameter <code>balance</code> is bound to the argument 100. Within this
environment, we evaluate the body of <code>make-withdraw</code>, namely the
<code>lambda</code> expression. This constructs a new procedure object, whose code
is as specified by the <code>lambda</code> and whose environment is E1, the
environment in which the <code>lambda</code> was evaluated to produce the
procedure. The resulting procedure object is the value returned by the
call to <code>make-withdraw</code>. This is bound to <code>W1</code> in the global
environment, since the <code>define</code> itself is being evaluated in the global
environment. Figure <a href="book-Z-H-21.html#%_fig_3.7">3.7</a> shows the
resulting environment structure.</p>
<p><img src="ch3-Z-G-8.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.7:</strong>  Result of evaluating <code>(define W1 (make-withdraw 100))</code>.</p>
<p>Now we can analyze what happens when <code>W1</code> is applied to an argument:</p>
<pre><code class="language-scheme editable">(W1 50)
</code></pre>
<p><em><code>50</code></em></p>
<p>We begin by constructing a frame in which <code>amount</code>, the formal parameter
of <code>W1</code>, is bound to the argument 50. The crucial point to observe is
that this frame has as its enclosing environment not the global
environment, but rather the environment E1, because this is the
environment that is specified by the <code>W1</code> procedure object. Within this
new environment, we evaluate the body of the procedure:</p>
<pre><code class="language-scheme editable">(if (&gt;= balance amount)
    (begin (set! balance (- balance amount))
           balance)
    "Insufficient funds")
</code></pre>
<p>The resulting environment structure is shown in
figure <a href="book-Z-H-21.html#%_fig_3.8">3.8</a>. The expression being evaluated
references both <code>amount</code> and <code>balance</code>. <code>Amount</code> will be found in the
first frame in the environment, while <code>balance</code> will be found by
following the enclosing-environment pointer to E1.</p>
<p><img src="ch3-Z-G-9.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.8:</strong>  Environments created by applying the procedure object
<code>W1</code>.</p>
<p>When the <code>set!</code> is executed, the binding of <code>balance</code> in E1 is changed.
At the completion of the call to <code>W1</code>, <code>balance</code> is 50, and the frame
that contains <code>balance</code> is still pointed to by the procedure object
<code>W1</code>. The frame that binds <code>amount</code> (in which we executed the code that
changed <code>balance</code>) is no longer relevant, since the procedure call that
constructed it has terminated, and there are no pointers to that frame
from other parts of the environment. The next time <code>W1</code> is called, this
will build a new frame that binds <code>amount</code> and whose enclosing
environment is E1. We see that E1 serves as the ``place'' that holds
the local state variable for the procedure object <code>W1</code>.
Figure <a href="book-Z-H-21.html#%_fig_3.9">3.9</a> shows the situation after the
call to <code>W1</code>.</p>
<p><img src="ch3-Z-G-10.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.9:</strong>  Environments after the call to <code>W1</code>.</p>
<p>Observe what happens when we create a second ``withdraw'' object by
making another call to <code>make-withdraw</code>:</p>
<pre><code class="language-scheme editable">(define W2 (make-withdraw 100))
</code></pre>
<p>This produces the environment structure of
figure <a href="book-Z-H-21.html#%_fig_3.10">3.10</a>, which shows that <code>W2</code> is a
procedure object, that is, a pair with some code and an environment. The
environment E2 for <code>W2</code> was created by the call to <code>make-withdraw</code>. It
contains a frame with its own local binding for <code>balance</code>. On the other
hand, <code>W1</code> and <code>W2</code> have the same code: the code specified by the
<code>lambda</code> expression in the body of
<code>make-withdraw</code>.<a href="book-Z-H-21.html#footnote_Temp_346">^[15]{.small}^</a>{#call_footnote_Temp_346}
We see here why <code>W1</code> and <code>W2</code> behave as independent objects. Calls to
<code>W1</code> reference the state variable <code>balance</code> stored in E1, whereas calls
to <code>W2</code> reference the <code>balance</code> stored in E2. Thus, changes to the local
state of one object do not affect the other object.</p>
<p><img src="ch3-Z-G-11.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.10:</strong>  Using <code>(define W2 (make-withdraw 100))</code> to create a
second object.</p>
<p><strong>Exercise 3.10.</strong>  In the <code>make-withdraw</code> procedure,
the local variable <code>balance</code> is created as a parameter of
<code>make-withdraw</code>. We could also create the local state variable
explicitly, using <code>let</code>, as follows:</p>
<pre><code class="language-scheme editable">(define (make-withdraw initial-amount)
  (let ((balance initial-amount))
    (lambda (amount)
      (if (&gt;= balance amount)
          (begin (set! balance (- balance amount))
                 balance)
          "Insufficient funds"))))
</code></pre>
<p>Recall from
section <a href="book-Z-H-12.html#%_sec_1.3.2">1.3.2</a> that <code>let</code> is simply
syntactic sugar for a procedure call:</p>
<pre><code class="language-scheme editable">(let ((&lt;var&gt; &lt;exp&gt;)) &lt;body&gt;)
</code></pre>
<p>is interpreted as an alternate syntax for</p>
<pre><code class="language-scheme editable">((lambda (&lt;var&gt;) &lt;body&gt;) &lt;exp&gt;)
</code></pre>
<p>Use the environment model to analyze this alternate version of
<code>make-withdraw</code>, drawing figures like the ones above to illustrate the
interactions</p>
<pre><code class="language-scheme editable">(define W1 (make-withdraw 100))

(W1 50)

(define W2 (make-withdraw 100))
</code></pre>
<p>Show that the two versions of <code>make-withdraw</code> create objects with the
same behavior. How do the environment structures differ for the two
versions?</p>
<h3 id="324--internal-definitions"><a class="header" href="#324--internal-definitions"><a href="book-Z-H-4.html#%_toc_%_sec_3.2.4">3.2.4  Internal Definitions</a></a></h3>
<p>Section <a href="book-Z-H-10.html#%_sec_1.1.8">1.1.8</a> introduced the idea that
procedures can have internal definitions, thus leading to a block
structure as in the following procedure to compute square roots:</p>
<pre><code class="language-scheme editable">(define (sqrt x)
  (define (good-enough? guess)
    (&lt; (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
        guess
        (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))
</code></pre>
<p>Now we can use the environment model to see why these internal
definitions behave as desired.
Figure <a href="book-Z-H-21.html#%_fig_3.11">3.11</a> shows the point in the
evaluation of the expression <code>(sqrt 2)</code> where the internal procedure
<code>good-enough?</code> has been called for the first time with <code>guess</code> equal to
1.</p>
<p><img src="ch3-Z-G-12.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.11:</strong>  <code>Sqrt</code> procedure with internal definitions.</p>
<p>Observe the structure of the environment. <code>Sqrt</code> is a symbol in the
global environment that is bound to a procedure object whose associated
environment is the global environment. When <code>sqrt</code> was called, a new
environment E1 was formed, subordinate to the global environment, in
which the parameter <code>x</code> is bound to 2. The body of <code>sqrt</code> was then
evaluated in E1. Since the first expression in the body of <code>sqrt</code> is</p>
<pre><code class="language-scheme editable">(define (good-enough? guess)
  (&lt; (abs (- (square guess) x)) 0.001))
</code></pre>
<p>evaluating this expression defined the procedure <code>good-enough?</code> in the
environment E1. To be more precise, the symbol <code>good-enough?</code> was added
to the first frame of E1, bound to a procedure object whose associated
environment is E1. Similarly, <code>improve</code> and <code>sqrt-iter</code> were defined as
procedures in E1. For conciseness,
figure <a href="book-Z-H-21.html#%_fig_3.11">3.11</a> shows only the procedure
object for <code>good-enough?</code>.</p>
<p>After the local procedures were defined, the expression
<code>(sqrt-iter 1.0)</code> was evaluated, still in environment E1. So the
procedure object bound to <code>sqrt-iter</code> in E1 was called with 1 as an
argument. This created an environment E2 in which <code>guess</code>, the parameter
of <code>sqrt-iter</code>, is bound to 1. <code>Sqrt-iter</code> in turn called <code>good-enough?</code>
with the value of <code>guess</code> (from E2) as the argument for <code>good-enough?</code>.
This set up another environment, E3, in which <code>guess</code> (the parameter of
<code>good-enough?</code>) is bound to 1. Although <code>sqrt-iter</code> and <code>good-enough?</code>
both have a parameter named <code>guess</code>, these are two distinct local
variables located in different frames. Also, E2 and E3 both have E1 as
their enclosing environment, because the <code>sqrt-iter</code> and <code>good-enough?</code>
procedures both have E1 as their environment part. One consequence of
this is that the symbol <code>x</code> that appears in the body of <code>good-enough?</code>
will reference the binding of <code>x</code> that appears in E1, namely the value
of <code>x</code> with which the original <code>sqrt</code> procedure was called. The
environment model thus explains the two key properties that make local
procedure definitions a useful technique for modularizing programs:</p>
<ul>
<li>The names of the local procedures do not interfere with names external
to the enclosing procedure, because the local procedure names will be
bound in the frame that the procedure creates when it is run, rather
than being bound in the global environment.</li>
<li>The local procedures can access the arguments of the enclosing
procedure, simply by using parameter names as free variables. This is
because the body of the local procedure is evaluated in an environment
that is subordinate to the evaluation environment for the enclosing
procedure.</li>
</ul>
<p><strong>Exercise
3.11.</strong>  In
section <a href="book-Z-H-21.html#%_sec_3.2.3">3.2.3</a> we saw how the environment
model described the behavior of procedures with local state. Now we have
seen how internal definitions work. A typical message-passing procedure
contains both of these aspects. Consider the bank account procedure of
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a>:</p>
<pre><code class="language-scheme editable">(define (make-account balance)
  (define (withdraw amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds")))
  (define (deposit amount)
    (set! balance (+ balance amount))
    balance)
  (define (dispatch m)
    (cond ((eq? m 'withdraw) withdraw)
          ((eq? m 'deposit) deposit)
          (else (error "Unknown request -- MAKE-ACCOUNT"
                       m))))
  dispatch)
</code></pre>
<p>Show the environment structure generated by the sequence of interactions</p>
<pre><code class="language-scheme editable">(define acc (make-account 50))

((acc 'deposit) 40)
</code></pre>
<p><em><code>90</code></em></p>
<pre><code class="language-scheme editable">((acc 'withdraw) 60)
</code></pre>
<p><em><code>30</code></em></p>
<p>Where is the local state for <code>acc</code> kept? Suppose we define another
account</p>
<pre><code class="language-scheme editable">(define acc2 (make-account 100))
</code></pre>
<p>How are the local states for the two accounts kept distinct? Which parts
of the environment structure are shared between <code>acc</code> and <code>acc2</code>?</p>
<hr />
<p>^[12]{.small}^](book-Z-H-21.html#call_footnote_Temp_342){#footnote_Temp_342}
Assignment introduces a subtlety into step 1 of the evaluation rule. As
shown in exercise <a href="book-Z-H-20.html#%_thm_3.8">3.8</a>, the presence of
assignment allows us to write expressions that will produce different
values depending on the order in which the subexpressions in a
combination are evaluated. Thus, to be
precise, we should specify an evaluation order in step 1 (e.g., left to
right or right to left). However, this order should always be considered
to be an implementation detail, and one should never write programs that
depend on some particular order. For instance, a sophisticated compiler
might optimize a program by varying the order in which subexpressions
are evaluated.</p>
<p>^[13]{.small}^](book-Z-H-21.html#call_footnote_Temp_343){#footnote_Temp_343}
If there is already a binding for the variable in the current frame,
then the binding is changed. This is convenient because it allows
redefinition of symbols; however, it also means that <code>define</code> can be
used to change values, and this brings up the issues of assignment
without explicitly using <code>set!</code>. Because of this, some
people prefer redefinitions of existing symbols to signal errors or
warnings.</p>
<p>^[14]{.small}^](book-Z-H-21.html#call_footnote_Temp_345){#footnote_Temp_345}
The environment model will not clarify our claim in
section <a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a> that the interpreter can
execute a procedure such as <code>fact-iter</code> in a constant amount of space
using tail recursion. We will discuss tail recursion when we
deal with the control structure of the
interpreter in section <a href="book-Z-H-34.html#%_sec_5.4">5.4</a>.</p>
<p>^[15]{.small}^](book-Z-H-21.html#call_footnote_Temp_346){#footnote_Temp_346}
Whether <code>W1</code> and <code>W2</code> share the same physical code stored in the
computer, or whether they each keep a copy of the code, is a detail of
the implementation. For the interpreter we implement in chapter 4, the
code is in fact shared.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="33--modeling-with-mutable-data"><a class="header" href="#33--modeling-with-mutable-data"><a href="book-Z-H-4.html#%_toc_%_sec_3.3">3.3  Modeling with Mutable Data</a></a></h2>
<p>Chapter 2 dealt with compound data as a means for
constructing computational objects that have several parts, in order to
model real-world objects that have several aspects. In that chapter we
introduced the discipline of data abstraction, according to which data
structures are specified in terms of constructors, which create data
objects, and selectors, which access the parts of compound data objects.
But we now know that there is another aspect of data that chapter 2 did
not address. The desire to model systems composed of objects that have
changing state leads us to the need to modify compound data objects, as
well as to construct and select from them. In order to model compound
objects with changing state, we will design data abstractions to
include, in addition to selectors and constructors, operations called
<em>mutators</em>, which modify data objects. For instance,
modeling a banking system requires us to change account balances. Thus,
a data structure for representing bank accounts might admit an operation</p>
<pre><code class="language-scheme editable">(set-balance! &lt;account&gt; &lt;new-value&gt;)
</code></pre>
<p>that changes the balance of the designated account to the designated new
value. Data objects for which mutators are defined are known as <em>mutable
data objects</em>.</p>
<p>Chapter 2 introduced pairs as a general-purpose ``glue'' for
synthesizing compound data. We begin this section by defining basic
mutators for pairs, so that pairs can serve as building blocks for
constructing mutable data objects. These mutators greatly enhance the
representational power of pairs, enabling us to build data structures
other than the sequences and trees that we worked with in
section <a href="book-Z-H-15.html#%_sec_2.2">2.2</a>. We also present some examples
of simulations in which complex systems are modeled as collections of
objects with local state.</p>
<h3 id="331--mutable-list-structure"><a class="header" href="#331--mutable-list-structure"><a href="book-Z-H-4.html#%_toc_%_sec_3.3.1">3.3.1  Mutable List Structure</a></a></h3>
<p>The basic
operations on pairs -- <code>cons</code>, <code>car</code>, and <code>cdr</code> -- can be used to
construct list structure and to select parts from list structure, but
they are incapable of modifying list structure. The same is true of the
list operations we have used so far, such as <code>append</code> and <code>list</code>, since
these can be defined in terms of <code>cons</code>, <code>car</code>, and <code>cdr</code>. To modify
list structures we need new operations.</p>
<p><img src="ch3-Z-G-13.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.12:</strong>  Lists <code>x</code>: <code>((a b) c d)</code> and <code>y</code>: <code>(e f)</code>.</p>
<p><img src="ch3-Z-G-14.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.13:</strong>  Effect of <code>(set-car! x y)</code> on the lists in
figure <a href="book-Z-H-22.html#%_fig_3.12">3.12</a>.</p>
<p><img src="ch3-Z-G-15.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.14:</strong>  Effect of <code>(define z (cons y (cdr x)))</code> on the lists
in figure <a href="book-Z-H-22.html#%_fig_3.12">3.12</a>.</p>
<p><img src="ch3-Z-G-16.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.15:</strong>  Effect of <code>(set-cdr! x y)</code> on the lists in
figure <a href="book-Z-H-22.html#%_fig_3.12">3.12</a>.</p>
<p>The
primitive mutators for pairs are <code>set-car!</code> and <code>set-cdr!</code>. <code>Set-car!</code>
takes two arguments, the first of which must be a pair. It modifies this
pair, replacing the <code>car</code> pointer by a pointer to the second argument of
<code>set-car!</code>.<a href="book-Z-H-22.html#footnote_Temp_349">^[16]{.small}^</a>{#call_footnote_Temp_349}</p>
<p>As an example, suppose that <code>x</code> is bound to the list <code>((a b) c d)</code> and
<code>y</code> to the list <code>(e f)</code> as illustrated in
figure <a href="book-Z-H-22.html#%_fig_3.12">3.12</a>. Evaluating the expression
<code>(set-car! x y)</code> modifies the pair to which <code>x</code> is bound, replacing its
<code>car</code> by the value of <code>y</code>. The result of the operation is shown in
figure <a href="book-Z-H-22.html#%_fig_3.13">3.13</a>. The structure <code>x</code> has been
modified and would now be printed as <code>((e f) c d)</code>. The pairs
representing the list <code>(a b)</code>, identified by the pointer that was
replaced, are now detached from the original
structure.<a href="book-Z-H-22.html#footnote_Temp_350">^[17]{.small}^</a>{#call_footnote_Temp_350}</p>
<p>Compare figure <a href="book-Z-H-22.html#%_fig_3.13">3.13</a> with
figure <a href="book-Z-H-22.html#%_fig_3.14">3.14</a>, which illustrates the result
of executing <code>(define z (cons y (cdr x)))</code> with <code>x</code> and <code>y</code> bound to the
original lists of figure <a href="book-Z-H-22.html#%_fig_3.12">3.12</a>. The
variable <code>z</code> is now bound to a new pair created by the <code>cons</code> operation;
the list to which <code>x</code> is bound is unchanged.</p>
<p>The <code>set-cdr!</code> operation is similar to <code>set-car!</code>. The only difference
is that the <code>cdr</code> pointer of the pair, rather than the <code>car</code> pointer, is
replaced. The effect of executing <code>(set-cdr! x y)</code> on the lists of
figure <a href="book-Z-H-22.html#%_fig_3.12">3.12</a> is shown in
figure <a href="book-Z-H-22.html#%_fig_3.15">3.15</a>. Here the <code>cdr</code> pointer of
<code>x</code> has been replaced by the pointer to <code>(e f)</code>. Also, the list <code>(c d)</code>,
which used to be the <code>cdr</code> of <code>x</code>, is now detached from the structure.</p>
<p><code>Cons</code> builds new list structure by creating new pairs,
while <code>set-car!</code> and <code>set-cdr!</code> modify existing pairs. Indeed, we could
implement <code>cons</code> in terms of the two mutators, together with a procedure
<code>get-new-pair</code>, which returns a new pair that is not part of any
existing list structure. We obtain the new pair, set its <code>car</code> and <code>cdr</code>
pointers to the designated objects, and return the new pair as the
result of the
<code>cons</code>.<a href="book-Z-H-22.html#footnote_Temp_351">^[18]{.small}^</a>{#call_footnote_Temp_351}</p>
<pre><code class="language-scheme editable">(define (cons x y)
  (let ((new (get-new-pair)))
    (set-car! new x)
    (set-cdr! new y)
    new))
</code></pre>
<p><strong>Exercise 3.12.</strong>  The following
procedure for appending lists was introduced in
section <a href="book-Z-H-15.html#%_sec_2.2.1">2.2.1</a>:</p>
<pre><code class="language-scheme editable">(define (append x y)
  (if (null? x)
      y
      (cons (car x) (append (cdr x) y))))
</code></pre>
<p><code>Append</code> forms a new list by successively <code>cons</code>ing the elements of <code>x</code>
onto <code>y</code>. The procedure <code>append!</code> is similar to <code>append</code>, but it is a
mutator rather than a constructor. It appends the lists by splicing them
together, modifying the final pair of <code>x</code> so that its <code>cdr</code> is now <code>y</code>.
(It is an error to call <code>append!</code> with an empty <code>x</code>.)</p>
<pre><code class="language-scheme editable">(define (append! x y)
  (set-cdr! (last-pair x) y)
  x)
</code></pre>
<p>Here <code>last-pair</code> is a procedure that returns the last pair in its
argument:</p>
<pre><code class="language-scheme editable">(define (last-pair x)
  (if (null? (cdr x))
      x
      (last-pair (cdr x))))
</code></pre>
<p>Consider the interaction</p>
<pre><code class="language-scheme editable">(define x (list 'a 'b))
(define y (list 'c 'd))
(define z (append x y))
z
</code></pre>
<p><em><code>(a b c d)</code></em></p>
<pre><code class="language-scheme editable">(cdr x)
</code></pre>
<p><code>&lt;</code><em><code>response</code></em><code>&gt;</code></p>
<pre><code class="language-scheme editable">(define w (append! x y))
w
</code></pre>
<p><em><code>(a b c d)</code></em></p>
<pre><code class="language-scheme editable">(cdr x)
</code></pre>
<p><code>&lt;</code><em><code>response</code></em><code>&gt;</code></p>
<p>What are the missing &lt;<em>response</em>&gt;s? Draw box-and-pointer diagrams to
explain your answer.</p>
<p><strong>Exercise 3.13.</strong>  Consider the
following <code>make-cycle</code> procedure, which uses the <code>last-pair</code> procedure
defined in exercise <a href="book-Z-H-22.html#%_thm_3.12">3.12</a>:</p>
<pre><code class="language-scheme editable">(define (make-cycle x)
  (set-cdr! (last-pair x) x)
  x)
</code></pre>
<p>Draw a box-and-pointer diagram that shows the structure <code>z</code> created by</p>
<pre><code class="language-scheme editable">(define z (make-cycle (list 'a 'b 'c)))
</code></pre>
<p>What happens if we try to compute <code>(last-pair z)</code>?</p>
<p><strong>Exercise 3.14.</strong>  The following procedure is quite
useful, although obscure:</p>
<pre><code class="language-scheme editable">(define (mystery x)
  (define (loop x y)
    (if (null? x)
        y
        (let ((temp (cdr x)))
          (set-cdr! x y)
          (loop temp x))))
  (loop x '()))
</code></pre>
<p><code>Loop</code> uses the ``temporary'' variable <code>temp</code> to hold the old value
of the <code>cdr</code> of <code>x</code>, since the <code>set-cdr!</code> on the next line destroys the
<code>cdr</code>. Explain what <code>mystery</code> does in general. Suppose <code>v</code> is defined by
<code>(define v (list 'a 'b 'c 'd))</code>. Draw the box-and-pointer diagram that
represents the list to which <code>v</code> is bound. Suppose that we now evaluate
<code>(define w (mystery v))</code>. Draw box-and-pointer diagrams that show the
structures <code>v</code> and <code>w</code> after evaluating this expression. What would be
printed as the values of <code>v</code> and <code>w</code> ?</p>
<h4 id="sharing-and-identity"><a class="header" href="#sharing-and-identity"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_355">Sharing and identity</a></a></h4>
<p>We
mentioned in section <a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3</a> the
theoretical issues of <code>sameness'' and </code>change'' raised by the
introduction of assignment. These issues arise in practice when
individual pairs are <em>shared</em> among different data objects. For example,
consider the structure formed by</p>
<pre><code class="language-scheme editable">(define x (list 'a 'b))
(define z1 (cons x x))
</code></pre>
<p>As shown in figure <a href="book-Z-H-22.html#%_fig_3.16">3.16</a>, <code>z1</code> is a pair
whose <code>car</code> and <code>cdr</code> both point to the same pair <code>x</code>. This sharing of
<code>x</code> by the <code>car</code> and <code>cdr</code> of <code>z1</code> is a consequence of the
straightforward way in which <code>cons</code> is implemented. In general, using
<code>cons</code> to construct lists will result in an interlinked structure of
pairs in which many individual pairs are shared by many different
structures.</p>
<p><img src="ch3-Z-G-17.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.16:</strong>  The list <code>z1</code> formed by <code>(cons x x)</code>.</p>
<p><img src="ch3-Z-G-18.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.17:</strong>  The list <code>z2</code> formed by
<code>(cons (list 'a 'b) (list 'a 'b))</code>.</p>
<p>In contrast to figure <a href="book-Z-H-22.html#%_fig_3.16">3.16</a>,
figure <a href="book-Z-H-22.html#%_fig_3.17">3.17</a> shows the structure created
by</p>
<pre><code class="language-scheme editable">(define z2 (cons (list 'a 'b) (list 'a 'b)))
</code></pre>
<p>In this structure, the pairs in the two <code>(a b)</code> lists are distinct,
although the actual symbols are
shared.<a href="book-Z-H-22.html#footnote_Temp_356">^[19]{.small}^</a>{#call_footnote_Temp_356}</p>
<p>When thought of as a list, <code>z1</code> and <code>z2</code> both represent ``the same''
list, <code>((a b) a b)</code>. In general, sharing is completely undetectable if
we operate on lists using only <code>cons</code>, <code>car</code>, and <code>cdr</code>. However, if we
allow mutators on list structure, sharing becomes significant. As an
example of the difference that sharing can make, consider the following
procedure, which modifies the <code>car</code> of the structure to which it is
applied:</p>
<pre><code class="language-scheme editable">(define (set-to-wow! x)
  (set-car! (car x) 'wow)
  x)
</code></pre>
<p>Even though <code>z1</code> and <code>z2</code> are ``the same'' structure, applying
<code>set-to-wow!</code> to them yields different results. With <code>z1</code>, altering the
<code>car</code> also changes the <code>cdr</code>, because in <code>z1</code> the <code>car</code> and the <code>cdr</code>
are the same pair. With <code>z2</code>, the <code>car</code> and <code>cdr</code> are distinct, so
<code>set-to-wow!</code> modifies only the <code>car</code>:</p>
<pre><code class="language-scheme editable">z1
</code></pre>
<p><em><code>((a b) a b)</code></em></p>
<pre><code class="language-scheme editable">(set-to-wow! z1)
</code></pre>
<p><em><code>((wow b) wow b)</code></em></p>
<pre><code class="language-scheme editable">z2
</code></pre>
<p><em><code>((a b) a b)</code></em></p>
<pre><code class="language-scheme editable">(set-to-wow! z2)
</code></pre>
<p><em><code>((wow b) a b)</code></em></p>
<p>One way to detect sharing in list structures is to use the predicate
<code>eq?</code>, which we introduced in
section <a href="book-Z-H-16.html#%_sec_2.3.1">2.3.1</a> as a way to test whether
two symbols are equal. More generally, <code>(eq? x y)</code> tests whether <code>x</code> and
<code>y</code> are the same object (that is, whether <code>x</code> and <code>y</code> are equal as
pointers). Thus, with <code>z1</code> and <code>z2</code> as defined in
figures <a href="book-Z-H-22.html#%_fig_3.16">3.16</a>
and <a href="book-Z-H-22.html#%_fig_3.17">3.17</a>, <code>(eq? (car z1) (cdr z1))</code> is
true and <code>(eq? (car z2) (cdr z2))</code> is false.</p>
<p>As will be seen in the following sections, we can exploit
sharing to greatly extend the repertoire of data structures that can be
represented by pairs. On the other hand, sharing can also be dangerous,
since modifications made to structures will also affect other structures
that happen to share the modified parts. The mutation operations
<code>set-car!</code> and <code>set-cdr!</code> should be used with care; unless we have a
good understanding of how our data objects are shared, mutation can have
unanticipated
results.<a href="book-Z-H-22.html#footnote_Temp_357">^[20]{.small}^</a>{#call_footnote_Temp_357}</p>
<p><strong>Exercise 3.15.</strong>  Draw box-and-pointer diagrams to
explain the effect of <code>set-to-wow!</code> on the structures <code>z1</code> and <code>z2</code>
above.</p>
<p><strong>Exercise 3.16.</strong>  Ben Bitdiddle decides to write a
procedure to count the number of pairs in any list structure. <code>It's easy,'' he reasons. </code>The number of pairs in any structure is the
number in the <code>car</code> plus the number in the <code>cdr</code> plus one more to count
the current pair.'' So Ben writes the following procedure:</p>
<pre><code class="language-scheme editable">(define (count-pairs x)
  (if (not (pair? x))
      0
      (+ (count-pairs (car x))
         (count-pairs (cdr x))
         1)))
</code></pre>
<p>Show that this procedure is not correct. In particular, draw
box-and-pointer diagrams representing list structures made up of exactly
three pairs for which Ben's procedure would return 3; return 4; return
7; never return at all.</p>
<p><strong>Exercise 3.17.</strong>  Devise a correct version of the
<code>count-pairs</code> procedure of exercise <a href="book-Z-H-22.html#%_thm_3.16">3.16</a>
that returns the number of distinct pairs in any structure. (Hint:
Traverse the structure, maintaining an auxiliary data structure that is
used to keep track of which pairs have already been counted.)</p>
<p><strong>Exercise 3.18.</strong>  Write a procedure
that examines a list and determines whether it contains a cycle, that
is, whether a program that tried to find the end of the list by taking
successive <code>cdr</code>s would go into an infinite loop.
Exercise <a href="book-Z-H-22.html#%_thm_3.13">3.13</a> constructed such lists.</p>
<p><strong>Exercise 3.19.</strong>  Redo
exercise <a href="book-Z-H-22.html#%_thm_3.18">3.18</a> using an algorithm that
takes only a constant amount of space. (This requires a very clever
idea.)</p>
<h4 id="mutation-is-just-assignment"><a class="header" href="#mutation-is-just-assignment"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_363">Mutation is just assignment</a></a></h4>
<p>When we
introduced compound data, we observed in
section <a href="book-Z-H-14.html#%_sec_2.1.3">2.1.3</a> that pairs can be
represented purely in terms of procedures:</p>
<pre><code class="language-scheme editable">(define (cons x y)
  (define (dispatch m)
    (cond ((eq? m 'car) x)
          ((eq? m 'cdr) y)
          (else (error "Undefined operation -- CONS" m))))
  dispatch)
(define (car z) (z 'car))
(define (cdr z) (z 'cdr))
</code></pre>
<p>The same observation is true for mutable data. We can implement mutable
data objects as procedures using assignment and local state. For
instance, we can extend the above pair implementation to handle
<code>set-car!</code> and <code>set-cdr!</code> in a manner analogous to the way we
implemented bank accounts using <code>make-account</code> in
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a>:</p>
<pre><code class="language-scheme editable">(define (cons x y)
  (define (set-x! v) (set! x v))
  (define (set-y! v) (set! y v))
  (define (dispatch m)
    (cond ((eq? m 'car) x)
          ((eq? m 'cdr) y)
          ((eq? m 'set-car!) set-x!)
          ((eq? m 'set-cdr!) set-y!)
          (else (error "Undefined operation -- CONS" m))))
  dispatch)
(define (car z) (z 'car))
(define (cdr z) (z 'cdr))
(define (set-car! z new-value)
  ((z 'set-car!) new-value)
  z)
(define (set-cdr! z new-value)
  ((z 'set-cdr!) new-value)
  z)
</code></pre>
<p>Assignment is all that is needed, theoretically, to account for the
behavior of mutable data. As soon as we admit <code>set!</code> to our language, we
raise all the issues, not only of assignment, but of mutable data in
general.<a href="book-Z-H-22.html#footnote_Temp_364">^[21]{.small}^</a>{#call_footnote_Temp_364}</p>
<p><strong>Exercise 3.20.</strong>  Draw environment diagrams to
illustrate the evaluation of the sequence of expressions</p>
<pre><code class="language-scheme editable">(define x (cons 1 2))
(define z (cons x x))
(set-car! (cdr z) 17)
(car x)
</code></pre>
<p><em><code>17</code></em></p>
<p>using the procedural implementation of pairs given above. (Compare
exercise <a href="book-Z-H-21.html#%_thm_3.11">3.11</a>.)</p>
<h3 id="332--representing-queues"><a class="header" href="#332--representing-queues"><a href="book-Z-H-4.html#%_toc_%_sec_3.3.2">3.3.2  Representing Queues</a></a></h3>
<p>The mutators <code>set-car!</code> and <code>set-cdr!</code> enable us to use
pairs to construct data structures that cannot be built with <code>cons</code>,
<code>car</code>, and <code>cdr</code> alone. This section shows how to use pairs to represent
a data structure called a queue.
Section <a href="book-Z-H-22.html#%_sec_3.3.3">3.3.3</a> will show how to represent
data structures called tables.</p>
<p>A <em>queue</em> is a sequence in which items are inserted at one end (called
the <em>rear</em> of the queue) and deleted from the other end
(the <em>front</em>). Figure <a href="book-Z-H-22.html#%_fig_3.18">3.18</a>
shows an initially empty queue in which the items <code>a</code> and <code>b</code> are
inserted. Then <code>a</code> is removed, <code>c</code> and <code>d</code> are inserted, and <code>b</code> is
removed. Because items are always removed in the order in which they are
inserted, a queue is sometimes called a <em>FIFO</em> (first in,
first out) buffer.</p>
<hr />
<h2>Operation                   Resulting Queue
<code>(define q (make-queue))</code><br />
<code>(insert-queue! q 'a)</code>      <code>a</code>
<code>(insert-queue! q 'b)</code>      <code>a b</code>
<code>(delete-queue! q)</code>         <code>b</code>
<code>(insert-queue! q 'c)</code>      <code>b c</code>
<code>(insert-queue! q 'd)</code>      <code>b c d</code>
<code>(delete-queue! q)</code>         <code>c d</code></h2>
<p><strong>Figure 3.18:</strong>  Queue operations.</p>
<p>In terms of data abstraction, we can
regard a queue as defined by the following set of operations:</p>
<ul>
<li>a constructor:
<pre><code class="language-scheme editable">(make-queue)
</code></pre>
returns an empty queue (a queue containing no items).</li>
<li>two selectors:
<pre><code class="language-scheme editable">(empty-queue? &lt;queue&gt;)
</code></pre>
tests if the queue is empty.
<pre><code class="language-scheme editable">(front-queue &lt;queue&gt;)
</code></pre>
returns the object at the front of the queue, signaling an error if
the queue is empty; it does not modify the queue.</li>
<li>two mutators:
<pre><code class="language-scheme editable">(insert-queue! &lt;queue&gt; &lt;item&gt;)
</code></pre>
inserts the item at the rear of the queue and returns the modified
queue as its value.
<pre><code class="language-scheme editable">(delete-queue! &lt;queue&gt;)
</code></pre>
removes the item at the front of the queue and returns the modified
queue as its value, signaling an error if the queue is empty before
the deletion.</li>
</ul>
<p>Because a queue is a sequence of items, we could certainly represent it
as an ordinary list; the front of the queue would be the <code>car</code> of the
list, inserting an item in the queue would amount to appending a new
element at the end of the list, and deleting an item from the queue
would just be taking the <code>cdr</code> of the list. However, this representation
is inefficient, because in order to insert an item we must scan the list
until we reach the end. Since the only method we have for scanning a
list is by successive <code>cdr</code> operations, this scanning requires
<img src="book-Z-G-D-3.gif" alt="" />{border="0"}(<em>n</em>) steps for a list of <em>n</em> items. A
simple modification to the list representation overcomes this
disadvantage by allowing the queue operations to be implemented so that
they require <img src="book-Z-G-D-3.gif" alt="" />{border="0"}(1) steps; that is, so
that the number of steps needed is independent of the length of the
queue.</p>
<p>The difficulty with the list representation arises from the need to scan
to find the end of the list. The reason we need to scan is that,
although the standard way of representing a list as a chain of pairs
readily provides us with a pointer to the beginning of the list, it
gives us no easily accessible pointer to the end. The modification that
avoids the drawback is to represent the queue as a list, together with
an additional pointer that indicates the final pair in the list. That
way, when we go to insert an item, we can consult the rear pointer and
so avoid scanning the list.</p>
<p>A queue is represented, then, as a pair of pointers, <code>front-ptr</code> and
<code>rear-ptr</code>, which indicate, respectively, the first and last pairs in an
ordinary list. Since we would like the queue to be an identifiable
object, we can use <code>cons</code> to combine the two pointers. Thus, the queue
itself will be the <code>cons</code> of the two pointers.
Figure <a href="book-Z-H-22.html#%_fig_3.19">3.19</a> illustrates this
representation.</p>
<p><img src="ch3-Z-G-19.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.19:</strong>  Implementation of a queue as a list with front and
rear pointers.</p>
<p>To define the queue operations we use the following procedures, which
enable us to select and to modify the front and rear pointers of a
queue:</p>
<pre><code class="language-scheme editable">(define (front-ptr queue) (car queue))
(define (rear-ptr queue) (cdr queue))
(define (set-front-ptr! queue item) (set-car! queue item))
(define (set-rear-ptr! queue item) (set-cdr! queue item))
</code></pre>
<p>Now we can implement the actual queue operations. We will consider a
queue to be empty if its front pointer is the empty list:</p>
<pre><code class="language-scheme editable">(define (empty-queue? queue) (null? (front-ptr queue)))
</code></pre>
<p>The <code>make-queue</code> constructor returns, as an initially empty queue, a
pair whose <code>car</code> and <code>cdr</code> are both the empty list:</p>
<pre><code class="language-scheme editable">(define (make-queue) (cons '() '()))
</code></pre>
<p>To select the item at the front of the queue, we return the <code>car</code> of the
pair indicated by the front pointer:</p>
<pre><code class="language-scheme editable">(define (front-queue queue)
  (if (empty-queue? queue)
      (error "FRONT called with an empty queue" queue)
      (car (front-ptr queue))))
</code></pre>
<p>To insert an item in a queue, we follow the method whose result is
indicated in figure <a href="book-Z-H-22.html#%_fig_3.20">3.20</a>. We first create
a new pair whose <code>car</code> is the item to be inserted and whose <code>cdr</code> is the
empty list. If the queue was initially empty, we set the front and rear
pointers of the queue to this new pair. Otherwise, we modify the final
pair in the queue to point to the new pair, and also set the rear
pointer to the new pair.</p>
<p><img src="ch3-Z-G-20.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.20:</strong>  Result of using <code>(insert-queue! q 'd)</code> on the queue of
figure <a href="book-Z-H-22.html#%_fig_3.19">3.19</a>.</p>
<pre><code class="language-scheme editable">(define (insert-queue! queue item)
  (let ((new-pair (cons item '())))
    (cond ((empty-queue? queue)
           (set-front-ptr! queue new-pair)
           (set-rear-ptr! queue new-pair)
           queue)
          (else
           (set-cdr! (rear-ptr queue) new-pair)
           (set-rear-ptr! queue new-pair)
           queue)))) 
</code></pre>
<p>To delete the item at the front of the queue, we merely modify the front
pointer so that it now points at the second item in the queue, which can
be found by following the <code>cdr</code> pointer of the first item (see
figure <a href="book-Z-H-22.html#%_fig_3.21">3.21</a>):^[22]{.small}^](book-Z-H-22.html#footnote_Temp_366){#call_footnote_Temp_366}</p>
<p><img src="ch3-Z-G-21.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.21:</strong>  Result of using <code>(delete-queue! q)</code> on the queue of
figure <a href="book-Z-H-22.html#%_fig_3.20">3.20</a>.</p>
<pre><code class="language-scheme editable">(define (delete-queue! queue)
  (cond ((empty-queue? queue)
         (error "DELETE! called with an empty queue" queue))
        (else
         (set-front-ptr! queue (cdr (front-ptr queue)))
         queue))) 
</code></pre>
<p><strong>Exercise 3.21.</strong>  Ben Bitdiddle decides to test the
queue implementation described above. He types in the procedures to the
Lisp interpreter and proceeds to try them out:</p>
<pre><code class="language-scheme editable">(define q1 (make-queue))
(insert-queue! q1 'a)
</code></pre>
<p><em><code>((a) a)</code></em></p>
<pre><code class="language-scheme editable">(insert-queue! q1 'b)
</code></pre>
<p><em><code>((a b) b)</code></em></p>
<pre><code class="language-scheme editable">(delete-queue! q1)
</code></pre>
<p><em><code>((b) b)</code></em></p>
<pre><code class="language-scheme editable">(delete-queue! q1)
</code></pre>
<p><em><code>(() b)</code></em></p>
<p><code>It's all wrong!'' he complains. </code>The interpreter's response
shows that the last item is inserted into the queue twice. And when I
delete both items, the second <code>b</code> is still there, so the queue isn't
empty, even though it's supposed to be.'' Eva Lu Ator suggests that
Ben has misunderstood what is happening. <code>It's not that the items are going into the queue twice,'' she explains. </code>It's just that
the standard Lisp printer doesn't know how to make sense of the queue
representation. If you want to see the queue printed correctly, you'll
have to define your own print procedure for queues.'' Explain what Eva
Lu is talking about. In particular, show why Ben's examples produce the
printed results that they do. Define a procedure
<code>print-queue</code> that takes a queue as input and prints the
sequence of items in the queue.</p>
<p><strong>Exercise 3.22.</strong>  Instead of
representing a queue as a pair of pointers, we can build a queue as a
procedure with local state. The local state will consist of pointers to
the beginning and the end of an ordinary list. Thus, the <code>make-queue</code>
procedure will have the form</p>
<pre><code class="language-scheme editable">(define (make-queue)
  (let ((front-ptr ...)
        (rear-ptr ...))
    &lt;definitions of internal procedures&gt;
    (define (dispatch m) ...)
    dispatch))
</code></pre>
<p>Complete the definition of <code>make-queue</code> and provide implementations of
the queue operations using this representation.</p>
<p><strong>Exercise 3.23.</strong>  A
<em>deque</em> (``double-ended queue'') is a sequence in which items can be
inserted and deleted at either the front or the rear. Operations on
deques are the constructor <code>make-deque</code>, the predicate <code>empty-deque?</code>,
selectors <code>front-deque</code> and <code>rear-deque</code>, and mutators
<code>front-insert-deque!</code>, <code>rear-insert-deque!</code>, <code>front-delete-deque!</code>, and
<code>rear-delete-deque!</code>. Show how to represent deques using pairs, and give
implementations of the
operations.<a href="book-Z-H-22.html#footnote_Temp_370">^[23]{.small}^</a>{#call_footnote_Temp_370}
All operations should be accomplished in
<img src="book-Z-G-D-3.gif" alt="" />{border="0"}(1) steps.</p>
<h3 id="333--representing-tables"><a class="header" href="#333--representing-tables"><a href="book-Z-H-4.html#%_toc_%_sec_3.3.3">3.3.3  Representing Tables</a></a></h3>
<p>When we studied various ways of
representing sets in chapter 2, we mentioned in
section <a href="book-Z-H-16.html#%_sec_2.3.3">2.3.3</a> the task of maintaining a
table of records indexed by identifying keys. In the implementation of
data-directed programming in
section <a href="book-Z-H-17.html#%_sec_2.4.3">2.4.3</a>, we made extensive use of
two-dimensional tables, in which information is stored and retrieved
using two keys. Here we see how to build tables as mutable list
structures.</p>
<p>We first consider a one-dimensional table, in which each
value is stored under a single key. We implement the table as a list of
records, each of which is implemented as a pair consisting of a key and
the associated value. The records are glued together to form a list by
pairs whose <code>car</code>s point to successive records. These gluing pairs are
called the <em>backbone</em> of the table. In order to have a
place that we can change when we add a new record to the table, we build
the table as a <em>headed list</em>. A headed
list has a special backbone pair at the beginning, which holds a dummy
``record'' -- in this case the arbitrarily chosen symbol <code>*table*</code>.
Figure <a href="book-Z-H-22.html#%_fig_3.22">3.22</a> shows the box-and-pointer
diagram for the table</p>
<p><code>a:  1</code>
<code>b:  2</code>
<code>c:  3</code></p>
<p><img src="ch3-Z-G-22.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.22:</strong>  A table represented as a headed list.</p>
<p>To extract information from a table we use the <code>lookup</code> procedure, which
takes a key as argument and returns the associated value (or false if
there is no value stored under that key). <code>Lookup</code> is defined in terms
of the <code>assoc</code> operation, which expects a key and a list of records as
arguments. Note that <code>assoc</code> never sees the dummy record. <code>Assoc</code>
returns the record that has the given key as its
<code>car</code>.<a href="book-Z-H-22.html#footnote_Temp_371">^[24]{.small}^</a>{#call_footnote_Temp_371}
<code>Lookup</code> then checks to see that the resulting record returned by
<code>assoc</code> is not false, and returns the value (the <code>cdr</code>) of the record.</p>
<pre><code class="language-scheme editable">(define (lookup key table)
  (let ((record (assoc key (cdr table))))
    (if record
        (cdr record)
        false)))
(define (assoc key records)
  (cond ((null? records) false)
        ((equal? key (caar records)) (car records))
        (else (assoc key (cdr records)))))
</code></pre>
<p>To insert a value in a table under a specified key, we first use <code>assoc</code>
to see if there is already a record in the table with this key. If not,
we form a new record by <code>cons</code>ing the key with the value, and insert
this at the head of the table's list of records, after the dummy
record. If there already is a record with this key, we set the <code>cdr</code> of
this record to the designated new value. The header of the table
provides us with a fixed location to modify in order to insert the new
record.<a href="book-Z-H-22.html#footnote_Temp_372">^[25]{.small}^</a>{#call_footnote_Temp_372}</p>
<pre><code class="language-scheme editable">(define (insert! key value table)
  (let ((record (assoc key (cdr table))))
    (if record
        (set-cdr! record value)
        (set-cdr! table
                  (cons (cons key value) (cdr table)))))
  'ok)
</code></pre>
<p>To construct a new table, we simply create a list containing the symbol
<code>*table*</code>:</p>
<pre><code class="language-scheme editable">(define (make-table)
  (list '*table*))
</code></pre>
<h4 id="two-dimensional-tables"><a class="header" href="#two-dimensional-tables"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_373">Two-dimensional tables</a></a></h4>
<p>In a two-dimensional table, each value is indexed by two
keys. We can construct such a table as a one-dimensional table in which
each key identifies a subtable.
Figure <a href="book-Z-H-22.html#%_fig_3.23">3.23</a> shows the box-and-pointer
diagram for the table</p>
<p><code>math:</code>
<code>  +:</code>  <code>43</code>
<code>  -:</code>  <code>45</code>
<code>  *:</code>  <code>42</code>
<code>letters:</code>
<code>  a:</code>  <code>97</code>
<code>  b:</code>  <code>98</code></p>
<p>which has two subtables. (The subtables don't need a special header
symbol, since the key that identifies the subtable serves this purpose.)</p>
<p><img src="ch3-Z-G-23.gif" alt="" />{border="0"}</p>
<p><strong>Figure 3.23:</strong>  A two-dimensional table.</p>
<p>When we look up an item, we use the first key to identify the correct
subtable. Then we use the second key to identify the record within the
subtable.</p>
<pre><code class="language-scheme editable">(define (lookup key-1 key-2 table)
  (let ((subtable (assoc key-1 (cdr table))))
    (if subtable
        (let ((record (assoc key-2 (cdr subtable))))
          (if record
              (cdr record)
              false))
        false)))
</code></pre>
<p>To insert a new item under a pair of keys, we use <code>assoc</code> to see if
there is a subtable stored under the first key. If not, we build a new
subtable containing the single record (<code>key-2</code>, <code>value</code>) and insert it
into the table under the first key. If a subtable already exists for the
first key, we insert the new record into this subtable, using the
insertion method for one-dimensional tables described above:</p>
<pre><code class="language-scheme editable">(define (insert! key-1 key-2 value table)
  (let ((subtable (assoc key-1 (cdr table))))
    (if subtable
        (let ((record (assoc key-2 (cdr subtable))))
          (if record
              (set-cdr! record value)
              (set-cdr! subtable
                        (cons (cons key-2 value)
                              (cdr subtable)))))
        (set-cdr! table
                  (cons (list key-1
                              (cons key-2 value))
                        (cdr table)))))
  'ok)
</code></pre>
<h4 id="creating-local-tables"><a class="header" href="#creating-local-tables"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_374">Creating local tables</a></a></h4>
<p>The <code>lookup</code> and <code>insert!</code> operations defined above take
the table as an argument. This enables us to use programs that access
more than one table. Another way to deal with multiple tables is to have
separate <code>lookup</code> and <code>insert!</code> procedures for each table. We can do
this by representing a table procedurally, as an object that maintains
an internal table as part of its local state. When sent an appropriate
message, this ``table object'' supplies the procedure with which to
operate on the internal table. Here is a generator for two-dimensional
tables represented in this fashion:</p>
<pre><code class="language-scheme editable">(define (make-table)
  (let ((local-table (list '*table*)))
    (define (lookup key-1 key-2)
      (let ((subtable (assoc key-1 (cdr local-table))))
        (if subtable
            (let ((record (assoc key-2 (cdr subtable))))
              (if record
                  (cdr record)
                  false))
            false)))
    (define (insert! key-1 key-2 value)
      (let ((subtable (assoc key-1 (cdr local-table))))
        (if subtable
            (let ((record (assoc key-2 (cdr subtable))))
              (if record
                  (set-cdr! record value)
                  (set-cdr! subtable
                            (cons (cons key-2 value)
                                  (cdr subtable)))))
            (set-cdr! local-table
                      (cons (list key-1
                                  (cons key-2 value))
                            (cdr local-table)))))
      'ok)    
    (define (dispatch m)
      (cond ((eq? m 'lookup-proc) lookup)
            ((eq? m 'insert-proc!) insert!)
            (else (error "Unknown operation -- TABLE" m))))
    dispatch))
</code></pre>
<p>Using <code>make-table</code>, we could implement the <code>get</code> and <code>put</code> operations
used in section <a href="book-Z-H-17.html#%_sec_2.4.3">2.4.3</a> for data-directed
programming, as follows:</p>
<pre><code class="language-scheme editable">(define operation-table (make-table))
(define get (operation-table 'lookup-proc))
(define put (operation-table 'insert-proc!))
</code></pre>
<p><code>Get</code> takes as arguments two keys, and <code>put</code> takes as arguments two keys
and a value. Both operations access the same local table, which is
encapsulated within the object created by the call to <code>make-table</code>.</p>
<p><strong>Exercise 3.24.</strong>  In the
table implementations above, the keys are tested for equality using
<code>equal?</code> (called by <code>assoc</code>). This is not always the appropriate test.
For instance, we might have a table with numeric keys in which we don't
need an exact match to the number we're looking up, but only a number
within some tolerance of it. Design a table constructor <code>make-table</code>
that takes as an argument a <code>same-key?</code> procedure that will be used to
test ``equality'' of keys. <code>Make-table</code> should return a <code>dispatch</code>
procedure that can be used to access appropriate <code>lookup</code> and <code>insert!</code>
procedures for a local table.</p>
<p><strong>Exercise 3.25.</strong>  Generalizing one- and
two-dimensional tables, show how to implement a table in which values
are stored under an arbitrary number of keys and different values may be
stored under different numbers of keys. The <code>lookup</code> and <code>insert!</code>
procedures should take as input a list of keys used to access the table.</p>
<p><strong>Exercise 3.26.</strong>  To
search a table as implemented above, one needs to scan through the list
of records. This is basically the unordered list representation of
section <a href="book-Z-H-16.html#%_sec_2.3.3">2.3.3</a>. For large tables, it may
be more efficient to structure the table in a different manner. Describe
a table implementation where the (key, value) records are organized
using a binary tree, assuming that keys can be ordered in some way
(e.g., numerically or alphabetically). (Compare
exercise <a href="book-Z-H-16.html#%_thm_2.66">2.66</a> of chapter 2.)</p>
<p><strong>Exercise
3.27.</strong>  <em>Memoization</em>
(also called <em>tabulation</em>) is a technique that enables a procedure to
record, in a local table, values that have previously been computed.
This technique can make a vast difference in the performance of a
program. A memoized procedure maintains a table in which values of
previous calls are stored using as keys the arguments that produced the
values. When the memoized procedure is asked to compute a value, it
first checks the table to see if the value is already there and, if so,
just returns that value. Otherwise, it computes the new value in the
ordinary way and stores this in the table. As an example of memoization,
recall from section <a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a> the
exponential process for computing Fibonacci numbers:</p>
<pre><code class="language-scheme editable">(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
</code></pre>
<p>The memoized version of the same procedure is</p>
<pre><code class="language-scheme editable">(define memo-fib
  (memoize (lambda (n)
             (cond ((= n 0) 0)
                   ((= n 1) 1)
                   (else (+ (memo-fib (- n 1))
                            (memo-fib (- n 2))))))))
</code></pre>
<p>where the memoizer is defined as</p>
<pre><code class="language-scheme editable">(define (memoize f)
  (let ((table (make-table)))
    (lambda (x)
      (let ((previously-computed-result (lookup x table)))
        (or previously-computed-result
            (let ((result (f x)))
              (insert! x result table)
              result))))))
</code></pre>
<p>Draw an environment diagram to analyze the computation of
<code>(memo-fib 3)</code>. Explain why <code>memo-fib</code> computes the <em>n</em>th Fibonacci
number in a number of steps proportional to <em>n</em>. Would the scheme still
work if we had simply defined <code>memo-fib</code> to be <code>(memoize fib)</code>?</p>
<p>...</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="34--concurrency-time-is-of-the-essence"><a class="header" href="#34--concurrency-time-is-of-the-essence"><a href="book-Z-H-4.html#%_toc_%_sec_3.4">3.4  Concurrency: Time Is of the Essence</a></a></h2>
<p>We've seen the power of computational objects with
local state as tools for modeling. Yet, as
section <a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3</a> warned, this power
extracts a price: the loss of referential transparency, giving rise to a
thicket of questions about sameness and change, and the need to abandon
the substitution model of evaluation in favor of the more intricate
environment model.</p>
<p>The central issue lurking beneath the complexity of
state, sameness, and change is that by introducing assignment we are
forced to admit <em>time</em> into our computational models. Before we
introduced assignment, all our programs were timeless, in the sense that
any expression that has a value always has the same value. In contrast,
recall the example of modeling withdrawals from a bank account and
returning the resulting balance, introduced at the beginning of
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a>:</p>
<pre><code class="language-scheme editable">(withdraw 25)
</code></pre>
<p><em><code>75</code></em></p>
<pre><code class="language-scheme editable">(withdraw 25)
</code></pre>
<p><em><code>50</code></em></p>
<p>Here successive evaluations of the same expression yield different
values. This behavior arises from the fact that the execution of
assignment statements (in this case, assignments to the variable
<code>balance</code>) delineates <em>moments in time</em> when values change. The result
of evaluating an expression depends not only on the expression itself,
but also on whether the evaluation occurs before or after these moments.
Building models in terms of computational objects with local state
forces us to confront time as an essential concept in programming.</p>
<p>We can go further in structuring computational models to match our
perception of the physical world. Objects in the world do not change one
at a time in sequence. Rather we perceive them as acting <em>concurrently</em>
-- all at once. So it is often natural to model systems as collections
of computational processes that execute concurrently. Just as we can
make our programs modular by organizing models in terms of objects with
separate local state, it is often appropriate to divide computational
models into parts that evolve separately and concurrently. Even if the
programs are to be executed on a sequential computer, the practice of
writing programs as if they were to be executed concurrently forces the
programmer to avoid inessential timing constraints and thus makes
programs more modular.</p>
<p>In addition to making programs more modular, concurrent computation can
provide a speed advantage over sequential computation. Sequential
computers execute only one operation at a time, so the amount of time it
takes to perform a task is proportional to the total number of
operations
performed.<a href="book-Z-H-23.html#footnote_Temp_405">^[34]{.small}^</a>
However, if it is possible to decompose a problem into pieces that are
relatively independent and need to communicate only rarely, it may be
possible to allocate pieces to separate computing processors, producing
a speed advantage proportional to the number of processors available.</p>
<p>Unfortunately, the complexities introduced by assignment become even
more problematic in the presence of concurrency. The fact of concurrent
execution, either because the world operates in parallel or because our
computers do, entails additional complexity in our understanding of
time.</p>
<h3 id="341--the-nature-of-time-in-concurrent-systems"><a class="header" href="#341--the-nature-of-time-in-concurrent-systems"><a href="book-Z-H-4.html#%_toc_%_sec_3.4.1">3.4.1  The Nature of Time in Concurrent Systems</a></a></h3>
<p>On the surface, time seems straightforward. It is an
ordering imposed on
events.<a href="book-Z-H-23.html#footnote_Temp_406">^[35]{.small}^</a>
For any events <em>A</em> and <em>B</em>, either <em>A</em> occurs before <em>B</em>, <em>A</em> and <em>B</em>
are simultaneous, or <em>A</em> occurs after <em>B</em>. For instance, returning to
the bank account example, suppose that Peter withdraws $10 and Paul
withdraws $25 from a joint account that initially
contains $100, leaving $65 in the account. Depending on the order of
the two withdrawals, the sequence of balances in the account is either
$100 <img src="book-Z-G-D-15.gif" alt="" /> $90
<img src="book-Z-G-D-15.gif" alt="" /> $65 or $100
<img src="book-Z-G-D-15.gif" alt="" /> $75
<img src="book-Z-G-D-15.gif" alt="" /> $65. In a computer implementation of
the banking system, this changing sequence of balances could be modeled
by successive assignments to a variable <code>balance</code>.</p>
<p>In complex situations, however, such a view can be problematic. Suppose
that Peter and Paul, and other people besides, are accessing the same
bank account through a network of banking machines distributed all over
the world. The actual sequence of balances in the account will depend
critically on the detailed timing of the accesses and the details of the
communication among the machines.</p>
<p>This indeterminacy in the order of events can pose
serious problems in the design of concurrent systems. For instance,
suppose that the withdrawals made by Peter and Paul are implemented as
two separate processes sharing a common variable <code>balance</code>, each process
specified by the procedure given in
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a>:</p>
<pre><code class="language-scheme editable">(define (withdraw amount)
  (if (&gt;= balance amount)
      (begin (set! balance (- balance amount))
             balance)
      "Insufficient funds"))
</code></pre>
<p>If the two processes operate independently, then Peter might test the
balance and attempt to withdraw a legitimate amount. However, Paul might
withdraw some funds in between the time that Peter checks the balance
and the time Peter completes the withdrawal, thus invalidating Peter's
test.</p>
<p>Things can be worse still. Consider the expression</p>
<pre><code class="language-scheme editable">(set! balance (- balance amount))
</code></pre>
<p>executed as part of each withdrawal process. This consists of three
steps: (1) accessing the value of the <code>balance</code> variable; (2) computing
the new balance; (3) setting <code>balance</code> to this new value. If Peter and
Paul's withdrawals execute this statement concurrently, then the two
withdrawals might interleave the order in which they access <code>balance</code>
and set it to the new value.</p>
<p>The timing diagram in figure <a href="book-Z-H-23.html#%_fig_3.29">3.29</a> depicts
an order of events where <code>balance</code> starts at 100, Peter withdraws 10,
Paul withdraws 25, and yet the final value of <code>balance</code> is 75. As shown
in the diagram, the reason for this anomaly is that Paul's assignment
of 75 to <code>balance</code> is made under the assumption that the value of
<code>balance</code> to be decremented is 100. That assumption, however, became
invalid when Peter changed <code>balance</code> to 90. This is a catastrophic
failure for the banking system, because the total amount of money in the
system is not conserved. Before the transactions, the total amount of
money was $100. Afterwards, Peter has $10, Paul has $25, and the bank
has
$75.<a href="book-Z-H-23.html#footnote_Temp_407">^[36]{.small}^</a></p>
<p>The general phenomenon illustrated here is
that several processes may share a common state variable. What makes
this complicated is that more than one process may be trying to
manipulate the shared state at the same time. For the bank account
example, during each transaction, each customer should be able to act as
if the other customers did not exist. When a customer changes the
balance in a way that depends on the balance, he must be able to assume
that, just before the moment of change, the balance is still what he
thought it was.</p>
<h4 id="correct-behavior-of-concurrent-programs"><a class="header" href="#correct-behavior-of-concurrent-programs"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_408">Correct behavior of concurrent programs</a></a></h4>
<p>The above example typifies the subtle bugs that can
creep into concurrent programs. The root of this complexity lies in the
assignments to variables that are shared among the different processes.
We already know that we must be careful in writing programs that use
<code>set!</code>, because the results of a computation depend on the order in
which the assignments
occur.<a href="book-Z-H-23.html#footnote_Temp_409">^[37]{.small}^</a>
With concurrent processes we must be especially careful about
assignments, because we may not be able to control the order of the
assignments made by the different processes. If several such changes
might be made concurrently (as with two depositors accessing a joint
account) we need some way to ensure that our system behaves correctly.
For example, in the case of withdrawals from a joint bank account, we
must ensure that money is conserved. To make concurrent programs behave
correctly, we may have to place some restrictions on concurrent
execution.</p>
<p><img src="ch3-Z-G-31.gif" alt="" /></p>
<p><strong>Figure 3.29:</strong>  Timing diagram showing how interleaving the order of
events in two banking withdrawals can lead to an incorrect final
balance.</p>
<p>One possible restriction on concurrency would stipulate that no two
operations that change any shared state variables can occur at the same
time. This is an extremely stringent requirement. For distributed
banking, it would require the system designer to ensure that only one
transaction could proceed at a time. This would be both inefficient and
overly conservative. Figure <a href="book-Z-H-23.html#%_fig_3.30">3.30</a> shows
Peter and Paul sharing a bank account, where Paul has a private account
as well. The diagram illustrates two withdrawals from the shared account
(one by Peter and one by Paul) and a deposit to Paul's private
account.<a href="book-Z-H-23.html#footnote_Temp_410">^[38]{.small}^</a>
The two withdrawals from the shared account must not be concurrent
(since both access and update the same account), and Paul's deposit and
withdrawal must not be concurrent (since both access and update the
amount in Paul's wallet). But there should be no problem permitting
Paul's deposit to his private account to proceed concurrently with
Peter's withdrawal from the shared account.</p>
<p><img src="ch3-Z-G-32.gif" alt="" /></p>
<p><strong>Figure 3.30:</strong>  Concurrent deposits and withdrawals from a joint
account in Bank1 and a private account in Bank2.</p>
<p>A less stringent restriction on concurrency would ensure that a
concurrent system produces the same result as if the processes had run
sequentially in some order. There are two important aspects to this
requirement. First, it does not require the processes to actually run
sequentially, but only to produce results that are the same <em>as if</em> they
had run sequentially. For the example in
figure <a href="book-Z-H-23.html#%_fig_3.30">3.30</a>, the designer of the bank
account system can safely allow Paul's deposit and Peter's withdrawal
to happen concurrently, because the net result will be the same as if
the two operations had happened sequentially. Second, there may be more
than one possible ``correct'' result produced by a concurrent
program, because we require only that the result be the same as for
<em>some</em> sequential order. For example, suppose that Peter and Paul's
joint account starts out with $100, and Peter deposits $40 while Paul
concurrently withdraws half the money in the account. Then sequential
execution could result in the account balance being either $70 or $90
(see
exercise <a href="book-Z-H-23.html#%_thm_3.38">3.38</a>).^[39]{.small}^](book-Z-H-23.html#footnote_Temp_411)</p>
<p>There are still weaker requirements for correct execution of concurrent
programs. A program for simulating diffusion (say, the
flow of heat in an object) might consist of a large number of processes,
each one representing a small volume of space, that update their values
concurrently. Each process repeatedly changes its value to the average
of its own value and its neighbors' values. This algorithm converges to
the right answer independent of the order in which the operations are
done; there is no need for any restrictions on concurrent use of the
shared values.</p>
<p><strong>Exercise 3.38.</strong>  Suppose that Peter, Paul, and Mary
share a joint bank account that initially contains $100. Concurrently,
Peter deposits $10, Paul withdraws $20, and Mary withdraws half the
money in the account, by executing the following commands:</p>
<hr />
<p>Peter:   <code>(set! balance (+ balance 10))</code>
Paul:    <code>(set! balance (- balance 20))</code>
Mary:    <code>(set! balance (- balance (/ balance 2)))</code></p>
<hr />
<p>a. List all the different possible values for <code>balance</code> after these
three transactions have been completed, assuming that the banking system
forces the three processes to run sequentially in some order.</p>
<p>b. What are some other values that could be produced if the system
allows the processes to be interleaved? Draw timing diagrams like the
one in figure <a href="book-Z-H-23.html#%_fig_3.29">3.29</a> to explain how these
values can occur.</p>
<h3 id="342--mechanisms-for-controlling-concurrency"><a class="header" href="#342--mechanisms-for-controlling-concurrency"><a href="book-Z-H-4.html#%_toc_%_sec_3.4.2">3.4.2  Mechanisms for Controlling Concurrency</a></a></h3>
<p>We've seen that the difficulty in dealing with
concurrent processes is rooted in the need to consider the interleaving
of the order of events in the different processes. For example, suppose
we have two processes, one with three ordered events (<em>a</em>,<em>b</em>,<em>c</em>) and
one with three ordered events (<em>x</em>,<em>y</em>,<em>z</em>). If the two processes run
concurrently, with no constraints on how their execution is interleaved,
then there are 20 different possible orderings for the events that are
consistent with the individual orderings for the two processes:</p>
<p><img src="ch3-Z-G-33.gif" alt="" /></p>
<p>As programmers designing this system, we would have to consider the
effects of each of these 20 orderings and check that each behavior is
acceptable. Such an approach rapidly becomes unwieldy as the numbers of
processes and events increase.</p>
<p>A more practical approach to the design of concurrent systems is to
devise general mechanisms that allow us to constrain the interleaving of
concurrent processes so that we can be sure that the program behavior is
correct. Many mechanisms have been developed for this purpose. In this
section, we describe one of them, the <em>serializer</em>.</p>
<h4 id="serializing-access-to-shared-state"><a class="header" href="#serializing-access-to-shared-state"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_413">Serializing access to shared state</a></a></h4>
<p>Serialization implements the following idea: Processes
will execute concurrently, but there will be certain collections of
procedures that cannot be executed concurrently. More precisely,
serialization creates distinguished sets of procedures such that only
one execution of a procedure in each serialized set is permitted to
happen at a time. If some procedure in the set is being executed, then a
process that attempts to execute any procedure in the set will be forced
to wait until the first execution has finished.</p>
<p>We can use serialization to control access to shared variables. For
example, if we want to update a shared variable based on the previous
value of that variable, we put the access to the previous value of the
variable and the assignment of the new value to the variable in the same
procedure. We then ensure that no other procedure that assigns to the
variable can run concurrently with this procedure by serializing all of
these procedures with the same serializer. This guarantees that the
value of the variable cannot be changed between an access and the
corresponding assignment.</p>
<h4 id="serializers-in-scheme"><a class="header" href="#serializers-in-scheme"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_414">Serializers in Scheme</a></a></h4>
<p>To make the above mechanism more concrete, suppose that we have extended
Scheme to include a procedure called <code>parallel-execute</code>:</p>
<pre><code class="language-scheme editable">(parallel-execute &lt;p~1~&gt; &lt;p~2~&gt; ... &lt;p~k~&gt;)
</code></pre>
<p>Each &lt;<em>p</em>&gt; must be a procedure of no arguments. <code>Parallel-execute</code>
creates a separate process for each &lt;<em>p</em>&gt;, which applies &lt;<em>p</em>&gt; (to
no arguments). These processes all run
concurrently.<a href="book-Z-H-23.html#footnote_Temp_415">^[40]{.small}^</a></p>
<p>As an example of how this is used, consider</p>
<pre><code class="language-scheme editable">(define x 10)

(parallel-execute (lambda () (set! x (* x x)))
                  (lambda () (set! x (+ x 1))))
</code></pre>
<p>This creates two concurrent processes -- <em>P</em><del>1</del>, which sets <code>x</code> to <code>x</code>
times <code>x</code>, and <em>P</em><del>2</del>, which increments <code>x</code>. After execution is
complete, <code>x</code> will be left with one of five possible values, depending
on the interleaving of the events of <em>P</em><del>1</del> and <em>P</em><del>2</del>:</p>
<hr />
<p>101:   <em>P</em><del>1</del> sets <code>x</code> to 100 and then <em>P</em><del>2</del> increments <code>x</code> to 101.
121:   <em>P</em><del>2</del> increments <code>x</code> to 11 and then <em>P</em><del>1</del> sets <code>x</code> to <code>x</code> times <code>x</code>.
110:   <em>P</em><del>2</del> changes <code>x</code> from 10 to 11 between the two times that <em>P</em><del>1</del> accesses the value of <code>x</code> during the evaluation of <code>(* x x)</code>.
11:    <em>P</em><del>2</del> accesses <code>x</code>, then <em>P</em><del>1</del> sets <code>x</code> to 100, then <em>P</em><del>2</del> sets <code>x</code>.
100:   <em>P</em><del>1</del> accesses <code>x</code> (twice), then <em>P</em><del>2</del> sets <code>x</code> to 11, then <em>P</em><del>1</del> sets <code>x</code>.</p>
<hr />
<p>We can constrain the concurrency by using serialized procedures, which
are created by <em>serializers</em>. Serializers are constructed by
<code>make-serializer</code>, whose implementation is given below. A serializer
takes a procedure as argument and returns a serialized procedure that
behaves like the original procedure. All calls to a given serializer
return serialized procedures in the same set.</p>
<p>Thus, in contrast to the example above, executing</p>
<pre><code class="language-scheme editable">(define x 10)

(define s (make-serializer))

(parallel-execute (s (lambda () (set! x (* x x))))
                  (s (lambda () (set! x (+ x 1)))))
</code></pre>
<p>can produce only two possible values for <code>x</code>, 101 or 121. The other
possibilities are eliminated, because the execution of <em>P</em><del>1</del> and <em>P</em><del>2</del>
cannot be interleaved.</p>
<p>Here is a version of the <code>make-account</code> procedure from
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a>, where the deposits and
withdrawals have been serialized:</p>
<pre><code class="language-scheme editable">(define (make-account balance)
  (define (withdraw amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds"))
  (define (deposit amount)
    (set! balance (+ balance amount))
    balance)
  (let ((protected (make-serializer)))
    (define (dispatch m)
      (cond ((eq? m 'withdraw) (protected withdraw))
            ((eq? m 'deposit) (protected deposit))
            ((eq? m 'balance) balance)
            (else (error "Unknown request -- MAKE-ACCOUNT"
                         m))))
    dispatch))
</code></pre>
<p>With this implementation, two processes cannot be withdrawing from or
depositing into a single account concurrently. This eliminates the
source of the error illustrated in
figure <a href="book-Z-H-23.html#%_fig_3.29">3.29</a>, where Peter changes the
account balance between the times when Paul accesses the balance to
compute the new value and when Paul actually performs the assignment. On
the other hand, each account has its own serializer, so that deposits
and withdrawals for different accounts can proceed concurrently.</p>
<p><strong>Exercise 3.39.</strong>  Which of the five possibilities in
the parallel execution shown above remain if we instead serialize
execution as follows:</p>
<pre><code class="language-scheme editable">(define x 10)

(define s (make-serializer))

(parallel-execute (lambda () (set! x ((s (lambda () (* x x))))))
                  (s (lambda () (set! x (+ x 1)))))
</code></pre>
<p><strong>Exercise 3.40.</strong>  Give all possible values of <code>x</code> that
can result from executing</p>
<pre><code class="language-scheme editable">(define x 10)

(parallel-execute (lambda () (set! x (* x x)))
                  (lambda () (set! x (* x x x))))
</code></pre>
<p>Which of these possibilities remain if we instead use serialized
procedures:</p>
<pre><code class="language-scheme editable">(define x 10)

(define s (make-serializer))

(parallel-execute (s (lambda () (set! x (* x x))))
                  (s (lambda () (set! x (* x x x)))))
</code></pre>
<p><strong>Exercise 3.41.</strong>  Ben Bitdiddle worries that it would
be better to implement the bank account as follows (where the commented
line has been changed):</p>
<pre><code class="language-scheme editable">(define (make-account balance)
  (define (withdraw amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds"))
  (define (deposit amount)
    (set! balance (+ balance amount))
    balance)
  ;; continued on next page
  (let ((protected (make-serializer)))
    (define (dispatch m)
      (cond ((eq? m 'withdraw) (protected withdraw))
            ((eq? m 'deposit) (protected deposit))
            ((eq? m 'balance)
             ((protected (lambda () balance)))) ; serialized
            (else (error "Unknown request -- MAKE-ACCOUNT"
                         m))))
    dispatch))
</code></pre>
<p>because allowing unserialized access to the bank balance can result in
anomalous behavior. Do you agree? Is there any scenario that
demonstrates Ben's concern?</p>
<p><strong>Exercise 3.42.</strong>  Ben Bitdiddle suggests that it's a
waste of time to create a new serialized procedure in response to every
<code>withdraw</code> and <code>deposit</code> message. He says that <code>make-account</code> could be
changed so that the calls to <code>protected</code> are done outside the <code>dispatch</code>
procedure. That is, an account would return the same serialized
procedure (which was created at the same time as the account) each time
it is asked for a withdrawal procedure.</p>
<pre><code class="language-scheme editable">(define (make-account balance)
  (define (withdraw amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds"))
  (define (deposit amount)
    (set! balance (+ balance amount))
    balance)
  (let ((protected (make-serializer)))
    (let ((protected-withdraw (protected withdraw))
          (protected-deposit (protected deposit)))
      (define (dispatch m)
        (cond ((eq? m 'withdraw) protected-withdraw)
              ((eq? m 'deposit) protected-deposit)
              ((eq? m 'balance) balance)
              (else (error "Unknown request -- MAKE-ACCOUNT"
                           m))))
      dispatch)))
</code></pre>
<p>Is this a safe change to make? In particular, is there any difference in
what concurrency is allowed by these two versions of <code>make-account</code> ?</p>
<h4 id="complexity-of-using-multiple-shared-resources"><a class="header" href="#complexity-of-using-multiple-shared-resources"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_420">Complexity of using multiple shared resources</a></a></h4>
<p>Serializers provide a powerful
abstraction that helps isolate the complexities of concurrent programs
so that they can be dealt with carefully and (hopefully) correctly.
However, while using serializers is relatively straightforward when
there is only a single shared resource (such as a single bank account),
concurrent programming can be treacherously difficult when there are
multiple shared resources.</p>
<p>To illustrate one of the difficulties that can arise, suppose we wish to
swap the balances in two bank accounts. We access each account to find
the balance, compute the difference between the balances, withdraw this
difference from one account, and deposit it in the other account. We
could implement this as
follows:<a href="book-Z-H-23.html#footnote_Temp_421">^[41]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (exchange account1 account2)
  (let ((difference (- (account1 'balance)
                       (account2 'balance))))
    ((account1 'withdraw) difference)
    ((account2 'deposit) difference)))
</code></pre>
<p>This procedure works well when only a single process is trying to do the
exchange. Suppose, however, that Peter and Paul both have access to
accounts <em>a</em>1, <em>a</em>2, and <em>a</em>3, and that Peter exchanges <em>a</em>1 and <em>a</em>2
while Paul concurrently exchanges <em>a</em>1 and <em>a</em>3. Even with account
deposits and withdrawals serialized for individual accounts (as in the
<code>make-account</code> procedure shown above in this section), <code>exchange</code> can
still produce incorrect results. For example, Peter might compute the
difference in the balances for <em>a</em>1 and <em>a</em>2, but then Paul might change
the balance in <em>a</em>1 before Peter is able to complete the
exchange.<a href="book-Z-H-23.html#footnote_Temp_422">^[42]{.small}^</a>
For correct behavior, we must arrange for the <code>exchange</code> procedure to
lock out any other concurrent accesses to the accounts during the entire
time of the exchange.</p>
<p>One way we can accomplish this is by using both accounts' serializers
to serialize the entire <code>exchange</code> procedure. To do this, we will
arrange for access to an account's serializer. Note that we are
deliberately breaking the modularity of the bank-account object by
exposing the serializer. The following version of <code>make-account</code> is
identical to the original version given in
section <a href="book-Z-H-20.html#%_sec_3.1.1">3.1.1</a>, except that a serializer
is provided to protect the balance variable, and the serializer is
exported via message passing:</p>
<pre><code class="language-scheme editable">(define (make-account-and-serializer balance)
  (define (withdraw amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds"))
  (define (deposit amount)
    (set! balance (+ balance amount))
    balance)
  (let ((balance-serializer (make-serializer)))
    (define (dispatch m)
      (cond ((eq? m 'withdraw) withdraw)
            ((eq? m 'deposit) deposit)
            ((eq? m 'balance) balance)
            ((eq? m 'serializer) balance-serializer)
            (else (error "Unknown request -- MAKE-ACCOUNT"
                         m))))
    dispatch))
</code></pre>
<p>We can use this to do serialized deposits and withdrawals. However,
unlike our earlier serialized account, it is now the responsibility of
each user of bank-account objects to explicitly manage the
serialization, for example as
follows:<a href="book-Z-H-23.html#footnote_Temp_423">^[43]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (deposit account amount)
  (let ((s (account 'serializer))
        (d (account 'deposit)))
    ((s d) amount)))
</code></pre>
<p>Exporting the serializer in this way gives us enough flexibility to
implement a serialized exchange program. We simply serialize the
original <code>exchange</code> procedure with the serializers for both accounts:</p>
<pre><code class="language-scheme editable">(define (serialized-exchange account1 account2)
  (let ((serializer1 (account1 'serializer))
        (serializer2 (account2 'serializer)))
    ((serializer1 (serializer2 exchange))
     account1
     account2)))
</code></pre>
<p><strong>Exercise 3.43.</strong>  Suppose that the balances in three
accounts start out as $10, $20, and $30, and that multiple processes
run, exchanging the balances in the accounts. Argue that if the
processes are run sequentially, after any number of concurrent
exchanges, the account balances should be $10, $20, and $30 in some
order. Draw a timing diagram like the one in
figure <a href="book-Z-H-23.html#%_fig_3.29">3.29</a> to show how this condition
can be violated if the exchanges are implemented using the first version
of the account-exchange program in this section. On the other hand,
argue that even with this <code>exchange</code> program, the sum of the balances in
the accounts will be preserved. Draw a timing diagram to show how even
this condition would be violated if we did not serialize the
transactions on individual accounts.</p>
<p><strong>Exercise 3.44.</strong>  Consider the problem
of transferring an amount from one account to another. Ben Bitdiddle
claims that this can be accomplished with the following procedure, even
if there are multiple people concurrently transferring money among
multiple accounts, using any account mechanism that serializes deposit
and withdrawal transactions, for example, the version of <code>make-account</code>
in the text above.</p>
<pre><code class="language-scheme editable">(define (transfer from-account to-account amount)
  ((from-account 'withdraw) amount)
  ((to-account 'deposit) amount))
</code></pre>
<p>Louis Reasoner claims that there is a problem here, and that we need to
use a more sophisticated method, such as the one required for dealing
with the exchange problem. Is Louis right? If not, what is the essential
difference between the transfer problem and the exchange problem? (You
should assume that the balance in <code>from-account</code> is at least <code>amount</code>.)</p>
<p><strong>Exercise 3.45.</strong>  Louis Reasoner thinks our
bank-account system is unnecessarily complex and error-prone now that
deposits and withdrawals aren't automatically serialized. He suggests
that <code>make-account-and-serializer</code> should have exported the serializer
(for use by such procedures as <code>serialized-exchange</code>) in addition to
(rather than instead of) using it to serialize accounts and deposits as
<code>make-account</code> did. He proposes to redefine accounts as follows:</p>
<pre><code class="language-scheme editable">(define (make-account-and-serializer balance)
  (define (withdraw amount)
    (if (&gt;= balance amount)
        (begin (set! balance (- balance amount))
               balance)
        "Insufficient funds"))
  (define (deposit amount)
    (set! balance (+ balance amount))
    balance)
  (let ((balance-serializer (make-serializer)))
    (define (dispatch m)
      (cond ((eq? m 'withdraw) (balance-serializer withdraw))
            ((eq? m 'deposit) (balance-serializer deposit))
            ((eq? m 'balance) balance)
            ((eq? m 'serializer) balance-serializer)
            (else (error "Unknown request -- MAKE-ACCOUNT"
                         m))))
    dispatch))
</code></pre>
<p>Then deposits are handled as with the original <code>make-account</code>:</p>
<pre><code class="language-scheme editable">(define (deposit account amount)
  ((account 'deposit) amount))
</code></pre>
<p>Explain what is wrong with Louis's reasoning. In particular, consider
what happens when <code>serialized-exchange</code> is called.</p>
<h4 id="implementing-serializers"><a class="header" href="#implementing-serializers"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_427">Implementing serializers</a></a></h4>
<p>We implement serializers in terms of a more primitive
synchronization mechanism called a <em>mutex</em>. A mutex is an
object that supports two operations -- the mutex can be
<em>acquired</em>, and the mutex can be
<em>released</em>. Once a mutex has been acquired, no other
acquire operations on that mutex may proceed until the mutex is
released.<a href="book-Z-H-23.html#footnote_Temp_428">^[44]{.small}^</a>
In our implementation, each serializer has an associated mutex. Given a
procedure <code>p</code>, the serializer returns a procedure that acquires the
mutex, runs <code>p</code>, and then releases the mutex. This ensures that only one
of the procedures produced by the serializer can be running at once,
which is precisely the serialization property that we need to guarantee.</p>
<pre><code class="language-scheme editable">(define (make-serializer)
  (let ((mutex (make-mutex)))
    (lambda (p)
      (define (serialized-p . args)
        (mutex 'acquire)
        (let ((val (apply p args)))
          (mutex 'release)
          val))
      serialized-p)))
</code></pre>
<p>The mutex is a mutable object (here we'll use a one-element list, which
we'll refer to as a <em>cell</em>) that can hold the value true
or false. When the value is false, the mutex is available to be
acquired. When the value is true, the mutex is unavailable, and any
process that attempts to acquire the mutex must wait.</p>
<p>Our mutex constructor <code>make-mutex</code> begins by initializing the cell
contents to false. To acquire the mutex, we test the cell. If the mutex
is available, we set the cell contents to true and proceed. Otherwise,
we wait in a loop, attempting to acquire over and over again, until we
find that the mutex is
available.<a href="book-Z-H-23.html#footnote_Temp_429">^[45]{.small}^</a>
To release the mutex, we set the cell contents to false.</p>
<pre><code class="language-scheme editable">(define (make-mutex)
  (let ((cell (list false)))           
    (define (the-mutex m)
      (cond ((eq? m 'acquire)
             (if (test-and-set! cell)
                 (the-mutex 'acquire))) ; retry
            ((eq? m 'release) (clear! cell))))
    the-mutex))
(define (clear! cell)
  (set-car! cell false))
</code></pre>
<p><code>Test-and-set!</code> tests the cell and returns the result of the test. In
addition, if the test was false, <code>test-and-set!</code> sets the cell contents
to true before returning false. We can express this behavior as the
following procedure:</p>
<pre><code class="language-scheme editable">(define (test-and-set! cell)
  (if (car cell)
      true
      (begin (set-car! cell true)
             false)))
</code></pre>
<p>However, this implementation of <code>test-and-set!</code> does not suffice as it
stands. There is a crucial subtlety here, which is the essential place
where concurrency control enters the system: The <code>test-and-set!</code>
operation must be performed <em>atomically</em>. That is, we
must guarantee that, once a process has tested the cell and found it to
be false, the cell contents will actually be set to true before any
other process can test the cell. If we do not make this guarantee, then
the mutex can fail in a way similar to the bank-account failure in
figure <a href="book-Z-H-23.html#%_fig_3.29">3.29</a>. (See
exercise <a href="book-Z-H-23.html#%_thm_3.46">3.46</a>.)</p>
<p>The actual implementation of <code>test-and-set!</code> depends on the details of
how our system runs concurrent processes. For example, we might be
executing concurrent processes on a sequential processor using a
time-slicing mechanism that cycles through the processes,
permitting each process to run for a short time before interrupting it
and moving on to the next process. In that case, <code>test-and-set!</code> can
work by disabling time slicing during the testing and
setting.<a href="book-Z-H-23.html#footnote_Temp_430">^[46]{.small}^</a>
Alternatively, multiprocessing computers provide instructions that
support atomic operations directly in
hardware.<a href="book-Z-H-23.html#footnote_Temp_431">^[47]{.small}^</a></p>
<p><strong>Exercise 3.46.</strong>  Suppose that we implement
<code>test-and-set!</code> using an ordinary procedure as shown in the text,
without attempting to make the operation atomic. Draw a timing diagram
like the one in figure <a href="book-Z-H-23.html#%_fig_3.29">3.29</a> to
demonstrate how the mutex implementation can fail by allowing two
processes to acquire the mutex at the same time.</p>
<p><strong>Exercise 3.47.</strong>  A semaphore (of size
<em>n</em>) is a generalization of a mutex. Like a mutex, a semaphore supports
acquire and release operations, but it is more general in that up to <em>n</em>
processes can acquire it concurrently. Additional processes that attempt
to acquire the semaphore must wait for release operations. Give
implementations of semaphores</p>
<p>a. in terms of mutexes</p>
<p>b. in terms of atomic <code>test-and-set!</code> operations.</p>
<h4 id="deadlock"><a class="header" href="#deadlock"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_434">Deadlock</a></a></h4>
<p>Now that we have seen how to implement
serializers, we can see that account exchanging still has a problem,
even with the <code>serialized-exchange</code> procedure above. Imagine that Peter
attempts to exchange <em>a</em>1 with <em>a</em>2 while Paul concurrently attempts to
exchange <em>a</em>2 with <em>a</em>1. Suppose that Peter's process reaches the point
where it has entered a serialized procedure protecting <em>a</em>1 and, just
after that, Paul's process enters a serialized procedure protecting
<em>a</em>2. Now Peter cannot proceed (to enter a serialized procedure
protecting <em>a</em>2) until Paul exits the serialized procedure protecting
<em>a</em>2. Similarly, Paul cannot proceed until Peter exits the serialized
procedure protecting <em>a</em>1. Each process is stalled forever, waiting for
the other. This situation is called a <em>deadlock</em>. Deadlock is always a
danger in systems that provide concurrent access to multiple shared
resources.</p>
<p>One way to avoid the deadlock in this situation is to
give each account a unique identification number and rewrite
<code>serialized-exchange</code> so that a process will always attempt to enter a
procedure protecting the lowest-numbered account first. Although this
method works well for the exchange problem, there are other situations
that require more sophisticated deadlock-avoidance techniques, or where
deadlock cannot be avoided at all. (See
exercises <a href="book-Z-H-23.html#%_thm_3.48">3.48</a>
and <a href="book-Z-H-23.html#%_thm_3.49">3.49</a>.)<a href="book-Z-H-23.html#footnote_Temp_435">^[48]{.small}^</a></p>
<p><strong>Exercise 3.48.</strong>  Explain in detail why
the deadlock-avoidance method described above, (i.e., the accounts are
numbered, and each process attempts to acquire the smaller-numbered
account first) avoids deadlock in the exchange problem. Rewrite
<code>serialized-exchange</code> to incorporate this idea. (You will also need to
modify <code>make-account</code> so that each account is created with a number,
which can be accessed by sending an appropriate message.)</p>
<p><strong>Exercise 3.49.</strong>  Give a scenario where the
deadlock-avoidance mechanism described above does not work. (Hint: In
the exchange problem, each process knows in advance which accounts it
will need to get access to. Consider a situation where a process must
get access to some shared resources before it can know which additional
shared resources it will require.)</p>
<h4 id="concurrency-time-and-communication"><a class="header" href="#concurrency-time-and-communication"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_438">Concurrency, time, and communication</a></a></h4>
<p>We've seen how programming concurrent systems requires controlling the
ordering of events when different processes access shared state, and
we've seen how to achieve this control through judicious use of
serializers. But the problems of concurrency lie deeper than this,
because, from a fundamental point of view, it's not always clear what
is meant by ``shared state.''</p>
<p>Mechanisms such as <code>test-and-set!</code> require processes to examine a global
shared flag at arbitrary times. This is problematic and inefficient to
implement in modern high-speed processors, where due to optimization
techniques such as pipelining and cached memory, the contents of memory
may not be in a consistent state at every instant. In contemporary
multiprocessing systems, therefore, the serializer paradigm is being
supplanted by new approaches to concurrency
control.<a href="book-Z-H-23.html#footnote_Temp_439">^[49]{.small}^</a></p>
<p>The problematic aspects of shared state also arise in large, distributed
systems. For instance, imagine a distributed banking system where
individual branch banks maintain local values for bank balances and
periodically compare these with values maintained by other branches. In
such a system the value of ``the account balance'' would be
undetermined, except right after synchronization. If Peter deposits
money in an account he holds jointly with Paul, when should we say that
the account balance has changed -- when the balance in the local branch
changes, or not until after the synchronization? And if Paul accesses
the account from a different branch, what are the reasonable constraints
to place on the banking system such that the behavior is
``correct''? The only thing that might matter for correctness is the
behavior observed by Peter and Paul individually and the ``state''
of the account immediately after synchronization. Questions about the
``real'' account balance or the order of events between
synchronizations may be irrelevant or
meaningless.<a href="book-Z-H-23.html#footnote_Temp_440">^[50]{.small}^</a></p>
<p>The basic phenomenon here is that synchronizing different
processes, establishing shared state, or imposing an order on events
requires communication among the processes. In essence, any notion of
time in concurrency control must be intimately tied to
communication.<a href="book-Z-H-23.html#footnote_Temp_441">^[51]{.small}^</a>
It is intriguing that a similar connection between time and
communication also arises in the Theory of Relativity,
where the speed of light (the fastest signal that can be used to
synchronize events) is a fundamental constant relating time and space.
The complexities we encounter in dealing with time and state in our
computational models may in fact mirror a fundamental complexity of the
physical universe.</p>
<hr />
<p>^[34]{.small}^](book-Z-H-23.html#call_footnote_Temp_405)
Most real processors actually execute a few operations at a time,
following a strategy called <em>pipelining</em>. Although this
technique greatly improves the effective utilization of the hardware, it
is used only to speed up the execution of a sequential instruction
stream, while retaining the behavior of the sequential program.</p>
<p>^[35]{.small}^](book-Z-H-23.html#call_footnote_Temp_406)
To quote some graffiti seen on a Cambridge building wall:
``Time is a device that was invented to keep everything from happening
at once.''</p>
<p>^[36]{.small}^](book-Z-H-23.html#call_footnote_Temp_407)
An even worse failure for this system could occur if the two <code>set!</code>
operations attempt to change the balance simultaneously, in which case
the actual data appearing in memory might end up being a random
combination of the information being written by the two processes. Most
computers have interlocks on the primitive memory-write operations,
which protect against such simultaneous access. Even this seemingly
simple kind of protection, however, raises implementation challenges in
the design of multiprocessing computers, where elaborate
<em>cache-coherence</em> protocols are required to ensure that
the various processors will maintain a consistent view of memory
contents, despite the fact that data may be replicated (``cached'')
among the different processors to increase the speed of memory access.</p>
<p>^[37]{.small}^](book-Z-H-23.html#call_footnote_Temp_409)
The factorial program in section <a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3</a>
illustrates this for a single sequential process.</p>
<p>^[38]{.small}^](book-Z-H-23.html#call_footnote_Temp_410)
The columns show the contents of Peter's wallet, the joint account (in
Bank1), Paul's wallet, and Paul's private account (in Bank2), before
and after each withdrawal (W) and deposit (D). Peter withdraws $10 from
Bank1; Paul deposits $5 in Bank2, then withdraws $25 from Bank1.</p>
<p>^[39]{.small}^](book-Z-H-23.html#call_footnote_Temp_411)
A more formal way to express this idea is to say that concurrent
programs are inherently <em>nondeterministic</em>. That is, they
are described not by single-valued functions, but by functions whose
results are sets of possible values. In
section <a href="book-Z-H-28.html#%_sec_4.3">4.3</a> we will study a language for
expressing nondeterministic computations.</p>
<p>^[40]{.small}^](book-Z-H-23.html#call_footnote_Temp_415)
<code>Parallel-execute</code> is not part of standard Scheme, but it can be
implemented in MIT Scheme. In our implementation, the new concurrent
processes also run concurrently with the original Scheme process. Also,
in our implementation, the value returned by <code>parallel-execute</code> is a
special control object that can be used to halt the newly created
processes.</p>
<p>^[41]{.small}^](book-Z-H-23.html#call_footnote_Temp_421)
We have simplified <code>exchange</code> by exploiting the fact that our <code>deposit</code>
message accepts negative amounts. (This is a serious bug in our banking
system!)</p>
<p>^[42]{.small}^](book-Z-H-23.html#call_footnote_Temp_422)
If the account balances start out as $10, $20, and $30, then after
any number of concurrent exchanges, the balances should still be $10,
$20, and $30 in some order. Serializing the deposits to individual
accounts is not sufficient to guarantee this. See
exercise <a href="book-Z-H-23.html#%_thm_3.43">3.43</a>.</p>
<p>^[43]{.small}^](book-Z-H-23.html#call_footnote_Temp_423)
Exercise <a href="book-Z-H-23.html#%_thm_3.45">3.45</a> investigates why deposits
and withdrawals are no longer automatically serialized by the account.</p>
<p>^[44]{.small}^](book-Z-H-23.html#call_footnote_Temp_428)
The term ``mutex'' is an abbreviation for <em>mutual
exclusion</em>. The general problem of arranging a mechanism that permits
concurrent processes to safely share resources is called the mutual
exclusion problem. Our mutex is a simple variant of the
<em>semaphore</em> mechanism (see
exercise <a href="book-Z-H-23.html#%_thm_3.47">3.47</a>), which was introduced in
the ``THE'' Multiprogramming System developed at the
Technological University of Eindhoven and named for the
university's initials in Dutch (Dijkstra 1968a). The acquire and
release operations were originally called
P and V, from the Dutch
words <em>passeren</em> (to pass) and <em>vrijgeven</em> (to release), in reference to
the semaphores used on railroad systems. Dijkstra's classic exposition
(1968b) was one of the first to clearly present the issues of
concurrency control, and showed how to use semaphores to handle a
variety of concurrency problems.</p>
<p>^[45]{.small}^](book-Z-H-23.html#call_footnote_Temp_429)
In most time-shared operating systems, processes that are
blocked by a mutex do not waste time
``busy-waiting'' as above. Instead, the system schedules another
process to run while the first is waiting, and the blocked process is
awakened when the mutex becomes available.</p>
<p>^[46]{.small}^](book-Z-H-23.html#call_footnote_Temp_430)
In MIT Scheme for a single processor, which uses a time-slicing model,
<code>test-and-set!</code> can be implemented as follows:</p>
<pre><code class="language-scheme editable">(define (test-and-set! cell)
  (without-interrupts
   (lambda ()
     (if (car cell)
         true
         (begin (set-car! cell true)
                false)))))
</code></pre>
<p><code>Without-interrupts</code> disables time-slicing interrupts while its
procedure argument is being executed.</p>
<p>^[47]{.small}^](book-Z-H-23.html#call_footnote_Temp_431)
There are many variants of such instructions --
including test-and-set, test-and-clear, swap, compare-and-exchange,
load-reserve, and store-conditional -- whose design must be carefully
matched to the machine's processor-memory interface. One issue that
arises here is to determine what happens if two processes attempt to
acquire the same resource at exactly the same time by using such an
instruction. This requires some mechanism for making a decision about
which process gets control. Such a mechanism is called an
<em>arbiter</em>. Arbiters usually boil down to some sort of
hardware device. Unfortunately, it is possible to prove that one cannot
physically construct a fair arbiter that works 100% of the time unless
one allows the arbiter an arbitrarily long time to make its decision.
The fundamental phenomenon here was originally observed by the
fourteenth-century French philosopher Jean Buridan in his
commentary on Aristotle's <em>De caelo</em>. Buridan argued
that a perfectly rational dog placed between two equally
attractive sources of food will starve to death, because it is incapable
of deciding which to go to first.</p>
<p>^[48]{.small}^](book-Z-H-23.html#call_footnote_Temp_435)
The general technique for avoiding deadlock by numbering the
shared resources and acquiring them in order is due to
Havender (1968). Situations
where deadlock cannot be avoided require <em>deadlock-recovery</em> methods,
which entail having processes ``back out'' of the deadlocked state
and try again. Deadlock-recovery mechanisms are widely used in database
management systems, a topic that is treated in detail in Gray and Reuter
1993.</p>
<p>^[49]{.small}^](book-Z-H-23.html#call_footnote_Temp_439)
One such alternative to serialization is called <em>barrier
synchronization</em>. The programmer permits concurrent processes to execute
as they please, but establishes certain synchronization points
(``barriers'') through which no process can proceed until all the
processes have reached the barrier. Modern processors provide machine
instructions that permit programmers to establish synchronization points
at places where consistency is required. The PowerPC
^<em>TM</em>^, for example, includes for this purpose two instructions called
SYNC and EIEIO (Enforced In-order
Execution of Input/Output).</p>
<p>^[50]{.small}^](book-Z-H-23.html#call_footnote_Temp_440)
This may seem like a strange point of view, but there are
systems that work this way. International charges to
credit-card accounts, for example, are normally cleared on a per-country
basis, and the charges made in different countries are periodically
reconciled. Thus the account balance may be different in different
countries.</p>
<p>^[51]{.small}^](book-Z-H-23.html#call_footnote_Temp_441)
For distributed systems, this perspective was pursued by
Lamport (1978), who showed how to use communication to
establish ``global clocks'' that can be used to establish orderings
on events in distributed systems.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="35-streams"><a class="header" href="#35-streams"><a href="book-Z-H-4.html#%_toc_%_sec_3.5">3.5 Streams</a></a></h2>
<p>We've gained a good understanding of assignment as a
tool in modeling, as well as an appreciation of the complex problems
that assignment raises. It is time to ask whether we could have gone
about things in a different way, so as to avoid some of these problems.
In this section, we explore an alternative approach to modeling state,
based on data structures called <em>streams</em>. As we shall see, streams can
mitigate some of the complexity of modeling state.</p>
<p>Let's step back and review where this complexity comes from. In an
attempt to model real-world phenomena, we made some apparently
reasonable decisions: We modeled real-world objects with local state by
computational objects with local variables. We identified time variation
in the real world with time variation in the computer. We implemented
the time variation of the states of the model objects in the computer
with assignments to the local variables of the model objects.</p>
<p>Is there another approach? Can we avoid identifying time in the computer
with time in the modeled world? Must we make the model change with time
in order to model phenomena in a changing world? Think about the issue
in terms of mathematical functions. We can describe the time-varying
behavior of a quantity <em>x</em> as a function of time <em>x</em>(<em>t</em>). If we
concentrate on <em>x</em> instant by instant, we think of it as a changing
quantity. Yet if we concentrate on the entire time history of values, we
do not emphasize change -- the function itself does not
change.<a href="book-Z-H-24.html#footnote_Temp_442">^[52]{.small}^</a></p>
<p>If time is measured in discrete steps, then we can model a time function
as a (possibly infinite) sequence. In this section, we will see how to
model change in terms of sequences that represent the time histories of
of the systems being modeled. To accomplish this, we introduce new data
structures called <em>streams</em>. From an abstract point of view, a stream is
simply a sequence. However, we will find that the straightforward
implementation of streams as lists (as in
section
<a href="book-Z-H-15.html#%_sec_2.2.1">2.2.1</a>) doesn't fully reveal the
power of stream processing. As an alternative, we introduce the
technique of <em>delayed evaluation</em>, which enables us to
represent very large (even infinite) sequences as streams.</p>
<p>Stream processing lets us model systems that have state without ever
using assignment or mutable data. This has important implications, both
theoretical and practical, because we can build models that avoid the
drawbacks inherent in introducing assignment. On the other hand, the
stream framework raises difficulties of its own, and the question of
which modeling technique leads to more modular and more easily
maintained systems remains open.</p>
<h3 id="351"><a class="header" href="#351">[3.5.1</a></h3>
<p>Streams Are Delayed Lists](book-Z-H-4.html#%<em>toc</em>%_sec_3.5.1)</p>
<p>As we saw in
section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>, sequences can serve as
standard interfaces for combining program modules. We formulated
powerful abstractions for manipulating sequences, such as <code>map</code>,
<code>filter</code>, and <code>accumulate</code>, that capture a wide variety of operations in
a manner that is both succinct and elegant.</p>
<p>Unfortunately, if we represent sequences as lists, this elegance is
bought at the price of severe inefficiency with respect to both the time
and space required by our computations. When we represent manipulations
on sequences as transformations of lists, our programs must construct
and copy data structures (which may be huge) at every step of a process.</p>
<p>To see why this is true, let us compare two programs for computing the
sum of all the prime numbers in an interval. The first program is
written in standard iterative
style:<a href="book-Z-H-24.html#footnote_Temp_443">^[53]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (sum-primes a b)
  (define (iter count accum)
    (cond ((&gt; count b) accum)
          ((prime? count) (iter (+ count 1) (+ count accum)))
          (else (iter (+ count 1) accum))))
  (iter a 0))
</code></pre>
<p>The second program performs the same computation using the sequence
operations of section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>:</p>
<pre><code class="language-scheme editable">(define (sum-primes a b)
  (accumulate +
              0
              (filter prime? (enumerate-interval a b))))
</code></pre>
<p>In carrying out the computation, the first program needs to store only
the sum being accumulated. In contrast, the filter in the second program
cannot do any testing until <code>enumerate-interval</code> has constructed a
complete list of the numbers in the interval. The filter generates
another list, which in turn is passed to <code>accumulate</code> before being
collapsed to form a sum. Such large intermediate storage is not needed
by the first program, which we can think of as enumerating the interval
incrementally, adding each prime to the sum as it is generated.</p>
<p>The inefficiency in using lists becomes painfully apparent if we use the
sequence paradigm to compute the second prime in the interval from
10,000 to 1,000,000 by evaluating the expression</p>
<pre><code class="language-scheme editable">(car (cdr (filter prime?
                   (enumerate-interval 10000 1000000))))
</code></pre>
<p>This expression does find the second prime, but the computational
overhead is outrageous. We construct a list of almost a million
integers, filter this list by testing each element for primality, and
then ignore almost all of the result. In a more traditional programming
style, we would interleave the enumeration and the filtering, and stop
when we reached the second prime.</p>
<p>Streams are a clever idea that allows one to use sequence manipulations
without incurring the costs of manipulating sequences as lists. With
streams we can achieve the best of both worlds: We can formulate
programs elegantly as sequence manipulations, while attaining the
efficiency of incremental computation. The basic idea is to arrange to
construct a stream only partially, and to pass the partial construction
to the program that consumes the stream. If the consumer attempts to
access a part of the stream that has not yet been constructed, the
stream will automatically construct just enough more of itself to
produce the required part, thus preserving the illusion that the entire
stream exists. In other words, although we will write programs as if we
were processing complete sequences, we design our stream implementation
to automatically and transparently interleave the construction of the
stream with its use.</p>
<p>On the surface, streams are just lists with different names for the
procedures that manipulate them. There is a constructor,
<code>cons-stream</code>, and two selectors,
<code>stream-car</code> and <code>stream-cdr</code>, which
satisfy the constraints</p>
<p><img src="ch3-Z-G-34.gif" alt="" /></p>
<p>There is a distinguishable object,
<code>the-empty-stream</code>, which
cannot be the result of any <code>cons-stream</code> operation, and which can be
identified with the predicate
<code>stream-null?</code>.<a href="book-Z-H-24.html#footnote_Temp_444">^[54]{.small}^</a>
Thus we can make and use streams, in just the same way as we can make
and use lists, to represent aggregate data arranged in a sequence. In
particular, we can build stream analogs of the list operations from
chapter
2, such as <code>list-ref</code>, <code>map</code>, and
<code>for-each</code>:<a href="book-Z-H-24.html#footnote_Temp_445">^[55]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (stream-ref s n)
  (if (= n 0)
      (stream-car s)
      (stream-ref (stream-cdr s) (- n 1))))
(define (stream-map proc s)
  (if (stream-null? s)
      the-empty-stream
      (cons-stream (proc (stream-car s))
                   (stream-map proc (stream-cdr s)))))
(define (stream-for-each proc s)
  (if (stream-null? s)
      'done
      (begin (proc (stream-car s))
             (stream-for-each proc (stream-cdr s)))))
</code></pre>
<p><code>Stream-for-each</code> is useful for viewing streams:</p>
<pre><code class="language-scheme editable">(define (display-stream s)
  (stream-for-each display-line s))

(define (display-line x)
  (newline)
  (display x))
</code></pre>
<p>To make the stream implementation automatically and transparently
interleave the construction of a stream with its use, we will arrange
for the <code>cdr</code> of a stream to be evaluated when it is accessed by the
<code>stream-cdr</code> procedure rather than when the stream is constructed by
<code>cons-stream</code>. This implementation choice is reminiscent of our
discussion of rational numbers in
section
<a href="book-Z-H-14.html#%_sec_2.1.2">2.1.2</a>, where we saw that we can
choose to implement rational numbers so that the reduction of numerator
and denominator to lowest terms is performed either at construction time
or at selection time. The two rational-number implementations produce
the same data abstraction, but the choice has an effect on efficiency.
There is a similar relationship between streams and ordinary lists. As a
data abstraction, streams are the same as lists. The difference is the
time at which the elements are evaluated. With ordinary lists, both the
<code>car</code> and the <code>cdr</code> are evaluated at construction time. With streams,
the <code>cdr</code> is evaluated at selection time.</p>
<p>Our implementation of streams will be
based on a special form called <code>delay</code>. Evaluating <code>(delay &lt;</code><em><code>exp</code></em><code>&gt;)</code>
does not evaluate the expression &lt;<em>exp</em>&gt;, but rather returns a
so-called <em>delayed object</em>, which we can think of as a
``promise'' to evaluate &lt;<em>exp</em>&gt; at some future time. As a
companion to <code>delay</code>, there is a procedure called <code>force</code>
that takes a delayed object as argument and performs the evaluation --
in effect, forcing the <code>delay</code> to fulfill its promise. We will see below
how <code>delay</code> and <code>force</code> can be implemented, but first let us use these
to construct streams.</p>
<p><code>Cons-stream</code> is a special form defined so
that</p>
<pre><code class="language-scheme editable">(cons-stream &lt;a&gt; &lt;b&gt;)
</code></pre>
<p>is equivalent to</p>
<pre><code class="language-scheme editable">(cons &lt;a&gt; (delay &lt;b&gt;))
</code></pre>
<p>What this means is that we will construct streams using pairs. However,
rather than placing the value of the rest of the stream into the <code>cdr</code>
of the pair we will put there a promise to compute the rest if it is
ever requested. <code>Stream-car</code> and <code>stream-cdr</code> can now be defined as
procedures:</p>
<pre><code class="language-scheme editable">(define (stream-car stream) (car stream))

(define (stream-cdr stream) (force (cdr stream)))
</code></pre>
<p><code>Stream-car</code> selects the <code>car</code> of the pair; <code>stream-cdr</code> selects the
<code>cdr</code> of the pair and evaluates the delayed expression found there to
obtain the rest of the
stream.<a href="book-Z-H-24.html#footnote_Temp_446">^[56]{.small}^</a></p>
<h4 id="the-stream-implementation-in-action"><a class="header" href="#the-stream-implementation-in-action"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_447">The stream implementation in action</a></a></h4>
<p>To see how this implementation behaves, let us analyze the
``outrageous'' prime computation we saw above, reformulated in terms of
streams:</p>
<pre><code class="language-scheme editable">(stream-car
 (stream-cdr
  (stream-filter prime?
                 (stream-enumerate-interval 10000 1000000))))
</code></pre>
<p>We will see that it does indeed work efficiently.</p>
<p>We begin by calling <code>stream-enumerate-interval</code> with the arguments
10,000 and 1,000,000. <code>Stream-enumerate-interval</code> is the stream analog
of <code>enumerate-interval</code> (section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>):</p>
<pre><code class="language-scheme editable">(define (stream-enumerate-interval low high)
  (if (&gt; low high)
      the-empty-stream
      (cons-stream
       low
       (stream-enumerate-interval (+ low 1) high))))
</code></pre>
<p>and thus the result returned by <code>stream-enumerate-interval</code>, formed by
the <code>cons-stream</code>,
is^[57]{.small}^](book-Z-H-24.html#footnote_Temp_448)</p>
<pre><code class="language-scheme editable">(cons 10000
      (delay (stream-enumerate-interval 10001 1000000)))
</code></pre>
<p>That is, <code>stream-enumerate-interval</code> returns a stream represented as a
pair whose <code>car</code> is 10,000 and whose <code>cdr</code> is a promise to enumerate
more of the interval if so requested. This stream is now filtered for
primes, using the stream analog of the <code>filter</code> procedure
(section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>):</p>
<pre><code class="language-scheme editable">(define (stream-filter pred stream)
  (cond ((stream-null? stream) the-empty-stream)
        ((pred (stream-car stream))
         (cons-stream (stream-car stream)
                      (stream-filter pred
                                     (stream-cdr stream))))
        (else (stream-filter pred (stream-cdr stream)))))
</code></pre>
<p><code>Stream-filter</code> tests the <code>stream-car</code> of the stream (the <code>car</code> of the
pair, which is 10,000). Since this is not prime, <code>stream-filter</code>
examines the <code>stream-cdr</code> of its input stream. The call to <code>stream-cdr</code>
forces evaluation of the delayed <code>stream-enumerate-interval</code>, which now
returns</p>
<pre><code class="language-scheme editable">(cons 10001
      (delay (stream-enumerate-interval 10002 1000000)))
</code></pre>
<p><code>Stream-filter</code> now looks at the <code>stream-car</code> of this stream, 10,001,
sees that this is not prime either, forces another <code>stream-cdr</code>, and so
on, until <code>stream-enumerate-interval</code> yields the prime 10,007, whereupon
<code>stream-filter</code>, according to its definition, returns</p>
<pre><code class="language-scheme editable">(cons-stream (stream-car stream)
             (stream-filter pred (stream-cdr stream)))
</code></pre>
<p>which in this case is</p>
<pre><code class="language-scheme editable">(cons 10007
      (delay
        (stream-filter
         prime?
         (cons 10008
               (delay
                 (stream-enumerate-interval 10009
                                            1000000))))))
</code></pre>
<p>This result is now passed to <code>stream-cdr</code> in our original expression.
This forces the delayed <code>stream-filter</code>, which in turn keeps forcing the
delayed <code>stream-enumerate-interval</code> until it finds the next prime, which
is 10,009. Finally, the result passed to <code>stream-car</code> in our original
expression is</p>
<pre><code class="language-scheme editable">(cons 10009
      (delay
        (stream-filter
         prime?
         (cons 10010
               (delay
                 (stream-enumerate-interval 10011
                                            1000000))))))
</code></pre>
<p><code>Stream-car</code> returns 10,009, and the computation is complete. Only as
many integers were tested for primality as were necessary to find the
second prime, and the interval was enumerated only as far as was
necessary to feed the prime filter.</p>
<p>In general, we can think of delayed evaluation as
<code>demand-driven\'\' programming, whereby each stage in the stream process is activated only enough to satisfy the next stage. What we have done is to decouple the actual order of events in the computation from the apparent structure of our procedures. We write procedures as if the streams existed </code>all at once'' when,
in reality, the computation is performed incrementally, as in
traditional programming styles.</p>
<h4 id="implementing-delay-and-force"><a class="header" href="#implementing-delay-and-force"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_449">Implementing <code>delay</code> and <code>force</code></a></a></h4>
<p>Although <code>delay</code> and <code>force</code> may seem like mysterious
operations, their implementation is really quite straightforward.
<code>Delay</code> must package an expression so that it can be evaluated later on
demand, and we can accomplish this simply by treating the expression as
the body of a procedure. <code>Delay</code> can be a special form such that</p>
<pre><code class="language-scheme editable">(delay &lt;exp&gt;)
</code></pre>
<p>is syntactic sugar for</p>
<pre><code class="language-scheme editable">(lambda () &lt;exp&gt;)
</code></pre>
<p><code>Force</code> simply calls the procedure (of no arguments) produced by
<code>delay</code>, so we can implement <code>force</code> as a procedure:</p>
<pre><code class="language-scheme editable">(define (force delayed-object)
  (delayed-object))
</code></pre>
<p>This implementation suffices for <code>delay</code>
and <code>force</code> to work as advertised, but there is an important
optimization that we can include. In many applications, we end up
forcing the same delayed object many times. This can lead to serious
inefficiency in recursive programs involving streams. (See
exercise
<a href="book-Z-H-24.html#%_thm_3.57">3.57</a>.) The solution is to build
delayed objects so that the first time they are forced, they store the
value that is computed. Subsequent forcings will simply return the
stored value without repeating the computation. In other words, we
implement <code>delay</code> as a special-purpose memoized procedure similar to the
one described in exercise
<a href="book-Z-H-22.html#%_thm_3.27">3.27</a>. One way
to accomplish this is to use the following procedure, which takes as
argument a procedure (of no arguments) and returns a memoized version of
the procedure. The first time the memoized procedure is run, it saves
the computed result. On subsequent evaluations, it simply returns the
result.</p>
<pre><code class="language-scheme editable">(define (memo-proc proc)
  (let ((already-run? false) (result false))
    (lambda ()
      (if (not already-run?)
          (begin (set! result (proc))
                 (set! already-run? true)
                 result)
          result))))
</code></pre>
<p><code>Delay</code> is then defined so that <code>(delay &lt;</code><em><code>exp</code></em><code>&gt;)</code> is equivalent to</p>
<pre><code class="language-scheme editable">(memo-proc (lambda () &lt;exp&gt;))
</code></pre>
<p>and <code>force</code> is as defined
previously.<a href="book-Z-H-24.html#footnote_Temp_450">^[58]{.small}^</a></p>
<p><strong>Exercise 3.50.</strong>
Complete the following definition,
which generalizes <code>stream-map</code> to allow procedures that take multiple
arguments, analogous to <code>map</code> in
section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>,
footnote
<a href="book-Z-H-15.html#footnote_Temp_166">12</a>.</p>
<pre><code class="language-scheme editable">(define (stream-map proc . argstreams)
  (if (&lt;*??*&gt;) (car argstreams))
      the-empty-stream
      (&lt;*??*&gt;
       (apply proc (map &lt;*??*&gt; argstreams))
       (apply stream-map
              (cons proc (map &lt;*??*&gt; argstreams))))))
</code></pre>
<p><strong>Exercise 3.51.</strong>
In order to take a
closer look at delayed evaluation, we will use the following procedure,
which simply returns its argument after printing it:</p>
<pre><code class="language-scheme editable">(define (show x)
  (display-line x)
  x)
</code></pre>
<p>What does the interpreter print in response to evaluating each
expression in the following
sequence?<a href="book-Z-H-24.html#footnote_Temp_453">^[59]{.small}^</a></p>
<pre><code class="language-scheme editable">(define x (stream-map show (stream-enumerate-interval 0 10)))
(stream-ref x 5)
(stream-ref x 7)
</code></pre>
<p><strong>Exercise 3.52.</strong>
Consider the sequence
of expressions</p>
<pre><code class="language-scheme editable">(define sum 0)
(define (accum x)
  (set! sum (+ x sum))
  sum)
(define seq (stream-map accum (stream-enumerate-interval 1 20)))
(define y (stream-filter even? seq))
(define z (stream-filter (lambda (x) (= (remainder x 5) 0))
                         seq))
(stream-ref y 7)
(display-stream z)
</code></pre>
<p>What is the value of <code>sum</code> after each of the above expressions is
evaluated? What is the printed response to evaluating the <code>stream-ref</code>
and <code>display-stream</code> expressions? Would these responses differ if we had
implemented <code>(delay &lt;</code><em><code>exp</code></em><code>&gt;)</code> simply as <code>(lambda () &lt;</code><em><code>exp</code></em><code>&gt;)</code>
without using the optimization provided by <code>memo-proc</code> ? Explain.</p>
<h3 id="352"><a class="header" href="#352">[3.5.2</a></h3>
<p>Infinite Streams](book-Z-H-4.html#%<em>toc</em>%_sec_3.5.2)</p>
<p>We have seen how to support the illusion of manipulating
streams as complete entities even though, in actuality, we compute only
as much of the stream as we need to access. We can exploit this
technique to represent sequences efficiently as streams, even if the
sequences are very long. What is more striking, we can use streams to
represent sequences that are infinitely long. For instance, consider the
following definition of the stream of positive integers:</p>
<pre><code class="language-scheme editable">(define (integers-starting-from n)
  (cons-stream n (integers-starting-from (+ n 1))))

(define integers (integers-starting-from 1))
</code></pre>
<p>This makes sense because <code>integers</code> will be a pair whose <code>car</code> is 1 and
whose <code>cdr</code> is a promise to produce the integers beginning with 2. This
is an infinitely long stream, but in any given time we can examine only
a finite portion of it. Thus, our programs will never know that the
entire infinite stream is not there.</p>
<p>Using <code>integers</code> we can define other infinite streams, such as the
stream of integers that are not divisible by 7:</p>
<pre><code class="language-scheme editable">(define (divisible? x y) (= (remainder x y) 0))
(define no-sevens
  (stream-filter (lambda (x) (not (divisible? x 7)))
                 integers))
</code></pre>
<p>Then we can find integers not divisible by 7 simply by accessing
elements of this stream:</p>
<pre><code class="language-scheme editable">(stream-ref no-sevens 100)
</code></pre>
<p><em><code>117</code></em></p>
<p>In analogy with <code>integers</code>, we can define the infinite stream of
Fibonacci numbers:</p>
<pre><code class="language-scheme editable">(define (fibgen a b)
  (cons-stream a (fibgen b (+ a b))))
(define fibs (fibgen 0 1))
</code></pre>
<p><code>Fibs</code> is a pair whose <code>car</code> is 0 and whose <code>cdr</code> is a promise to
evaluate <code>(fibgen 1 1)</code>. When we evaluate this delayed <code>(fibgen 1 1)</code>,
it will produce a pair whose <code>car</code> is 1 and whose <code>cdr</code> is a promise to
evaluate <code>(fibgen 1 2)</code>, and so on.</p>
<p>For a look at a more exciting infinite stream, we can
generalize the <code>no-sevens</code> example to construct the infinite stream of
prime numbers, using a method known as the <em>sieve of
Eratosthenes</em>.<a href="book-Z-H-24.html#footnote_Temp_455">^[60]{.small}^</a>
We start with the integers beginning with 2, which is the first prime.
To get the rest of the primes, we start by filtering the multiples of 2
from the rest of the integers. This leaves a stream beginning with 3,
which is the next prime. Now we filter the multiples of 3 from the rest
of this stream. This leaves a stream beginning with 5, which is the next
prime, and so on. In other words, we construct the primes by a sieving
process, described as follows: To sieve a stream <code>S</code>, form a stream
whose first element is the first element of <code>S</code> and the rest of which is
obtained by filtering all multiples of the first element of <code>S</code> out of
the rest of <code>S</code> and sieving the result. This process is readily
described in terms of stream operations:</p>
<pre><code class="language-scheme editable">(define (sieve stream)
  (cons-stream
   (stream-car stream)
   (sieve (stream-filter
           (lambda (x)
             (not (divisible? x (stream-car stream))))
           (stream-cdr stream)))))

(define primes (sieve (integers-starting-from 2)))
</code></pre>
<p>Now to find a particular prime we need only ask for it:</p>
<pre><code class="language-scheme editable">(stream-ref primes 50)
</code></pre>
<p><em><code>233</code></em></p>
<p>It is interesting to contemplate the signal-processing system set up by
<code>sieve</code>, shown in the <code>Henderson diagram\'\' in figure [3.31](book-Z-H-24.html#%_fig_3.31).[^[61]{.small}^](book-Z-H-24.html#footnote_Temp_456) The input stream feeds into an </code>un<code>cons</code>er'' that separates the
first element of the stream from the rest of the stream. The first
element is used to construct a divisibility filter, through which the
rest is passed, and the output of the filter is fed to another sieve
box. Then the original first element is <code>cons</code>ed onto the output of the
internal sieve to form the output stream. Thus, not only is the stream
infinite, but the signal processor is also infinite, because the sieve
contains a sieve within it.</p>
<p><img src="ch3-Z-G-35.gif" alt="" /></p>
<p><strong>Figure 3.31:</strong>
The prime sieve viewed as a signal-processing system.</p>
<h4 id="defining-streams-implicitly"><a class="header" href="#defining-streams-implicitly"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_457">Defining streams implicitly</a></a></h4>
<p>The <code>integers</code> and <code>fibs</code> streams above were defined by
specifying ``generating'' procedures that explicitly compute the
stream elements one by one. An alternative way to specify streams is to
take advantage of delayed evaluation to define streams implicitly. For
example, the following expression defines the stream <code>ones</code> to be an
infinite stream of ones:</p>
<pre><code class="language-scheme editable">(define ones (cons-stream 1 ones))
</code></pre>
<p>This works much like the definition of a recursive procedure: <code>ones</code> is
a pair whose <code>car</code> is 1 and whose <code>cdr</code> is a promise to evaluate <code>ones</code>.
Evaluating the <code>cdr</code> gives us again a 1 and a promise to evaluate
<code>ones</code>, and so on.</p>
<p>We can do more interesting things by manipulating streams with
operations such as <code>add-streams</code>, which produces the elementwise sum of
two given
streams:<a href="book-Z-H-24.html#footnote_Temp_458">^[62]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (add-streams s1 s2)
  (stream-map + s1 s2))
</code></pre>
<p>Now we can define the integers as follows:</p>
<pre><code class="language-scheme editable">(define integers (cons-stream 1 (add-streams ones integers)))
</code></pre>
<p>This defines <code>integers</code> to be a stream whose first element is 1 and the
rest of which is the sum of <code>ones</code> and <code>integers</code>. Thus, the second
element of <code>integers</code> is 1 plus the first element of <code>integers</code>, or 2;
the third element of <code>integers</code> is 1 plus the second element of
<code>integers</code>, or 3; and so on. This definition works because, at any
point, enough of the <code>integers</code> stream has been generated so that we can
feed it back into the definition to produce the next integer.</p>
<p>We can define the Fibonacci numbers in the same style:</p>
<pre><code class="language-scheme editable">(define fibs
  (cons-stream 0
               (cons-stream 1
                            (add-streams (stream-cdr fibs)
                                         fibs))))
</code></pre>
<p>This definition says that <code>fibs</code> is a stream beginning with 0 and 1,
such that the rest of the stream can be generated by adding <code>fibs</code> to
itself shifted by one place:</p>
<hr />
<hr />
<hr />
<ul>
<li></li>
</ul>
<p>1
1
2
3
5
8
13
21
<code>...</code> = <code>(stream-cdr fibs)</code></p>
<p>0
1
1
2
3
5
8
13
<code>...</code> = <code>fibs</code></p>
<p>0
1
1
2
3
5
8
13
21
34
<code>...</code> = <code>fibs</code></p>
<hr />
<p><code>Scale-stream</code> is another useful procedure in formulating such stream
definitions. This multiplies each item in a stream by a given constant:</p>
<pre><code class="language-scheme editable">(define (scale-stream stream factor)
  (stream-map (lambda (x) (* x factor)) stream))
</code></pre>
<p>For example,</p>
<pre><code class="language-scheme editable">(define double (cons-stream 1 (scale-stream double 2)))
</code></pre>
<p>produces the stream of powers of 2: 1, 2, 4, 8, 16, 32, <code>...</code>.</p>
<p>An alternate definition of the stream of primes can be given by starting
with the integers and filtering them by testing for primality. We will
need the first prime, 2, to get started:</p>
<pre><code class="language-scheme editable">(define primes
  (cons-stream
   2
   (stream-filter prime? (integers-starting-from 3))))
</code></pre>
<p>This definition is not so straightforward as it appears, because we will
test whether a number <em>n</em> is prime by checking whether <em>n</em> is divisible
by a prime (not by just any integer) less than or equal to
<img src="book-Z-G-D-13.gif" alt="" /><em>n</em>:</p>
<pre><code class="language-scheme editable">(define (prime? n)
  (define (iter ps)
    (cond ((&gt; (square (stream-car ps)) n) true)
          ((divisible? n (stream-car ps)) false)
          (else (iter (stream-cdr ps)))))
  (iter primes))
</code></pre>
<p>This is a recursive definition, since <code>primes</code> is defined in terms of
the <code>prime?</code> predicate, which itself uses the <code>primes</code> stream. The
reason this procedure works is that, at any point, enough of the
<code>primes</code> stream has been generated to test the primality of the numbers
we need to check next. That is, for every <em>n</em> we test for primality,
either <em>n</em> is not prime (in which case there is a prime already
generated that divides it) or <em>n</em> is prime (in which case there is a
prime already generated -- i.e., a prime less than <em>n</em> -- that is
greater than
<img src="book-Z-G-D-13.gif" alt="" /></p>
<p><strong>Exercise 3.53.</strong>
Without running the program,
describe the elements of the stream defined by</p>
<pre><code class="language-scheme editable">(define s (cons-stream 1 (add-streams s s)))
</code></pre>
<p><strong>Exercise 3.54.</strong>
Define a procedure
<code>mul-streams</code>, analogous to
<code>add-streams</code>, that produces the elementwise product of its two input
streams. Use this together with the stream of <code>integers</code> to complete the
following definition of the stream whose <em>n</em>th element (counting from 0)
is <em>n</em> + 1 factorial:</p>
<pre><code class="language-scheme editable">(define factorials (cons-stream 1 (mul-streams &lt;*??*&gt; &lt;*??*&gt;)))
</code></pre>
<p><strong>Exercise 3.55.</strong>
Define a procedure
<code>partial-sums</code> that takes as argument a stream <em>S</em> and
returns the stream whose elements are <em>S</em><del>0</del>, <em>S</em><del>0</del> + <em>S</em><del>1</del>, <em>S</em><del>0</del> +
<em>S</em><del>1</del> + <em>S</em><del>2</del>, <code>...</code>. For example, <code>(partial-sums integers)</code> should be
the stream 1, 3, 6, 10, 15, <code>...</code>.</p>
<p><strong>Exercise 3.56.</strong>
A famous problem, first raised by
R. Hamming, is to enumerate, in ascending order with no
repetitions, all positive integers with no prime factors other than 2,
3, or 5. One obvious way to do this is to simply test each integer in
turn to see whether it has any factors other than 2, 3, and 5. But this
is very inefficient, since, as the integers get larger, fewer and fewer
of them fit the requirement. As an alternative, let us call the required
stream of numbers <code>S</code> and notice the following facts about it.</p>
<ul>
<li><code>S</code> begins with 1.</li>
<li>The elements of <code>(scale-stream S 2)</code> are also elements of <code>S</code>.</li>
<li>The same is true for <code>(scale-stream S 3)</code> and <code>(scale-stream 5 S)</code>.</li>
<li>These are all the elements of <code>S</code>.</li>
</ul>
<p>Now all we have to do is combine elements from these
sources. For this we define a procedure <code>merge</code> that combines two
ordered streams into one ordered result stream, eliminating repetitions:</p>
<pre><code class="language-scheme editable">(define (merge s1 s2)
  (cond ((stream-null? s1) s2)
        ((stream-null? s2) s1)
        (else
         (let ((s1car (stream-car s1))
               (s2car (stream-car s2)))
           (cond ((&lt; s1car s2car)
                  (cons-stream s1car (merge (stream-cdr s1) s2)))
                 ((&gt; s1car s2car)
                  (cons-stream s2car (merge s1 (stream-cdr s2))))
                 (else
                  (cons-stream s1car
                               (merge (stream-cdr s1)
                                      (stream-cdr s2)))))))))
</code></pre>
<p>Then the required stream may be constructed with <code>merge</code>, as follows:</p>
<pre><code class="language-scheme editable">(define S (cons-stream 1 (merge &lt;*??*&gt; &lt;*??*&gt;)))
</code></pre>
<p>Fill in the missing expressions in the places marked &lt;<em>??</em>&gt; above.</p>
<p><strong>Exercise 3.57.</strong>
How many additions
are performed when we compute the <em>n</em>th Fibonacci number using the
definition of <code>fibs</code> based on the <code>add-streams</code> procedure? Show that the
number of additions would be exponentially greater if we had implemented
<code>(delay &lt;</code><em><code>exp</code></em><code>&gt;)</code> simply as <code>(lambda () &lt;</code><em><code>exp</code></em><code>&gt;)</code>, without using
the optimization provided by the <code>memo-proc</code> procedure described in
section
<a href="book-Z-H-24.html#%_sec_3.5.1">3.5.1</a>.<a href="book-Z-H-24.html#footnote_Temp_465">^[64]{.small}^</a></p>
<p><strong>Exercise 3.58.</strong>
Give an interpretation of the stream
computed by the following procedure:</p>
<pre><code class="language-scheme editable">(define (expand num den radix)
  (cons-stream
   (quotient (* num radix) den)
   (expand (remainder (* num radix) den) den radix)))
</code></pre>
<p>(<code>Quotient</code> is a primitive that returns
the integer quotient of two integers.) What are the successive elements
produced by <code>(expand 1 7 10)</code> ? What is produced by <code>(expand 3 8 10)</code> ?</p>
<p><strong>Exercise 3.59.</strong>
In
section
<a href="book-Z-H-18.html#%_sec_2.5.3">2.5.3</a> we saw how to implement a
polynomial arithmetic system representing polynomials as lists of terms.
In a similar way, we can work with <em>power series</em>, such as</p>
<p><img src="ch3-Z-G-36.gif" alt="" /></p>
<p><img src="ch3-Z-G-37.gif" alt="" /></p>
<p><img src="ch3-Z-G-38.gif" alt="" /></p>
<p>represented as infinite streams. We will represent the series <em>a</em><del>0</del> +
<em>a</em><del>1</del> <em>x</em> + <em>a</em><del>2</del> <em>x</em>^2^ + <em>a</em><del>3</del> <em>x</em>^3^ + <code> </code> as the stream whose
elements are the coefficients <em>a</em><del>0</del>, <em>a</em><del>1</del>, <em>a</em><del>2</del>, <em>a</em><del>3</del>, <code>...</code>.</p>
<p>a. The integral of the series <em>a</em><del>0</del> +
<em>a</em><del>1</del> <em>x</em> + <em>a</em><del>2</del> <em>x</em>^2^ + <em>a</em><del>3</del> <em>x</em>^3^ + <code> </code> is the series</p>
<p><img src="ch3-Z-G-39.gif" alt="" /></p>
<p>where <em>c</em> is any constant. Define a procedure
<code>integrate-series</code> that takes as input a stream <em>a</em><del>0</del>,
<em>a</em><del>1</del>, <em>a</em><del>2</del>, <code> </code> representing a power series and returns the stream
<em>a</em><del>0</del>, (1/2)<em>a</em><del>1</del>, (1/3)<em>a</em><del>2</del>, <code> </code> of coefficients of the
non-constant terms of the integral of the series. (Since the result has
no constant term, it doesn't represent a power series; when we use
<code>integrate-series</code>, we will <code>cons</code> on the appropriate constant.)</p>
<p>b. The function <em>x</em>
<img src="book-Z-G-D-17.gif" alt="" /> <em>e</em>^<em>x</em>^ is its
own derivative. This implies that <em>e</em>^<em>x</em>^ and the integral of <em>e</em>^<em>x</em>^
are the same series, except for the constant term, which is <em>e</em>^0^ = 1.
Accordingly, we can generate the series for <em>e</em>^<em>x</em>^ as</p>
<pre><code class="language-scheme editable">(define exp-series
  (cons-stream 1 (integrate-series exp-series)))
</code></pre>
<p>Show how to generate the series for sine and cosine, starting from the
facts that the derivative of sine is cosine and the derivative of cosine
is the negative of sine:</p>
<pre><code class="language-scheme editable">(define cosine-series
  (cons-stream 1 &lt;*??*&gt;))
(define sine-series
  (cons-stream 0 &lt;*??*&gt;))
</code></pre>
<p><strong>Exercise
3.60.</strong>
With
power series represented as streams of coefficients as in
exercise
<a href="book-Z-H-24.html#%_thm_3.59">3.59</a>, adding series is
implemented by <code>add-streams</code>. Complete the definition of the following
procedure for multiplying series:</p>
<pre><code class="language-scheme editable">(define (mul-series s1 s2)
  (cons-stream &lt;*??*&gt; (add-streams &lt;*??*&gt; &lt;*??*&gt;)))
</code></pre>
<p>You can test your procedure by verifying that <em>sin</em>^2^ <em>x</em> + <em>cos</em>^2^
<em>x</em> = 1, using the series from
exercise
<a href="book-Z-H-24.html#%_thm_3.59">3.59</a>.</p>
<p><strong>Exercise 3.61.</strong>
Let <em>S</em> be a power series
(exercise
<a href="book-Z-H-24.html#%_thm_3.59">3.59</a>) whose constant term is 1.
Suppose we want to find the power series 1/<em>S</em>, that is, the series <em>X</em>
such that <em>S</em> · <em>X</em> = 1. Write <em>S</em> = 1 + <em>S</em><del><em>R</em></del> where <em>S</em><del><em>R</em></del> is the
part of <em>S</em> after the constant term. Then we can solve for <em>X</em> as
follows:</p>
<p><img src="ch3-Z-G-40.gif" alt="" /></p>
<p>In other words, <em>X</em> is the power series whose constant term is 1 and
whose higher-order terms are given by the negative of <em>S</em><del><em>R</em></del> times
<em>X</em>. Use this idea to write a procedure <code>invert-unit-series</code> that
computes 1/<em>S</em> for a power series <em>S</em> with constant term 1. You will
need to use <code>mul-series</code> from
exercise
<a href="book-Z-H-24.html#%_thm_3.60">3.60</a>.</p>
<p><strong>Exercise
3.62.</strong>
Use the results of
exercises
<a href="book-Z-H-24.html#%_thm_3.60">3.60</a>
and
<a href="book-Z-H-24.html#%_thm_3.61">3.61</a> to define a procedure
<code>div-series</code> that divides two power series. <code>Div-series</code> should work for
any two series, provided that the denominator series begins with a
nonzero constant term. (If the denominator has a zero constant term,
then <code>div-series</code> should signal an error.) Show how to use <code>div-series</code>
together with the result of exercise
<a href="book-Z-H-24.html#%_thm_3.59">3.59</a>
to generate the power series for tangent.</p>
<h3 id="353"><a class="header" href="#353">[3.5.3</a></h3>
<p>Exploiting the Stream Paradigm](book-Z-H-4.html#%<em>toc</em>%_sec_3.5.3)</p>
<p>Streams with delayed evaluation can be a powerful modeling tool,
providing many of the benefits of local state and assignment. Moreover,
they avoid some of the theoretical tangles that accompany the
introduction of assignment into a programming language.</p>
<p>The stream approach can be illuminating because it allows
us to build systems with different module boundaries than systems
organized around assignment to state variables. For example, we can
think of an entire time series (or signal) as a focus of interest,
rather than the values of the state variables at individual moments.
This makes it convenient to combine and compare components of state from
different moments.</p>
<h4 id="formulating-iterations-as-stream-processes"><a class="header" href="#formulating-iterations-as-stream-processes"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_471">Formulating iterations as stream processes</a></a></h4>
<p>In section
<a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a>, we
introduced iterative processes, which proceed by updating state
variables. We know now that we can represent state as a ``timeless''
stream of values rather than as a set of variables to be updated. Let's
adopt this perspective in revisiting the square-root procedure from
section
<a href="book-Z-H-10.html#%_sec_1.1.7">1.1.7</a>. Recall that the idea is
to generate a sequence of better and better guesses for the square root
of <em>x</em> by applying over and over again the procedure that improves
guesses:</p>
<pre><code class="language-scheme editable">(define (sqrt-improve guess x)
  (average guess (/ x guess)))
</code></pre>
<p>In our original <code>sqrt</code> procedure, we made these guesses
be the successive values of a state variable. Instead we can generate
the infinite stream of guesses, starting with an initial guess of
1:<a href="book-Z-H-24.html#footnote_Temp_472">^[65]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (sqrt-stream x)
  (define guesses
    (cons-stream 1.0
                 (stream-map (lambda (guess)
                               (sqrt-improve guess x))
                             guesses)))
  guesses)
(display-stream (sqrt-stream 2))
</code></pre>
<p><em><code>1.</code></em>
<em><code>1.5</code></em>
<em><code>1.4166666666666665</code></em>
<em><code>1.4142156862745097</code></em>
<em><code>1.4142135623746899</code></em>
<code>...</code></p>
<p>We can generate more and more terms of the stream to get better and
better guesses. If we like, we can write a procedure that keeps
generating terms until the answer is good enough. (See
exercise
<a href="book-Z-H-24.html#%_thm_3.64">3.64</a>.)</p>
<p>Another
iteration that we can treat in the same way is to generate an
approximation to <img src="book-Z-G-D-9.gif" alt="" />, based upon the
alternating series that we saw in
section
<a href="book-Z-H-12.html#%_sec_1.3.1">1.3.1</a>:</p>
<p><img src="ch3-Z-G-41.gif" alt="" /></p>
<p>We first generate the stream of summands of the series (the reciprocals
of the odd integers, with alternating signs). Then we take the stream of
sums of more and more terms (using the <code>partial-sums</code> procedure of
exercise
<a href="book-Z-H-24.html#%_thm_3.55">3.55</a>) and scale the result by 4:</p>
<pre><code class="language-scheme editable">(define (pi-summands n)
  (cons-stream (/ 1.0 n)
               (stream-map - (pi-summands (+ n 2)))))
(define pi-stream
  (scale-stream (partial-sums (pi-summands 1)) 4))
(display-stream pi-stream)
</code></pre>
<p><em><code>4.</code></em>
<em><code>2.666666666666667</code></em>
<em><code>3.466666666666667</code></em>
<em><code>2.8952380952380956</code></em>
<em><code>3.3396825396825403</code></em>
<em><code>2.9760461760461765</code></em>
<em><code>3.2837384837384844</code></em>
<em><code>3.017071817071818</code></em>
<code>...</code></p>
<p>This gives us a stream of better and better approximations to
<img src="book-Z-G-D-9.gif" alt="" />, although the approximations converge
rather slowly. Eight terms of the sequence bound the value of
<img src="book-Z-G-D-9.gif" alt="" /> between 3.284 and 3.017.</p>
<p>So far, our use of the stream of states approach is not
much different from updating state variables. But streams give us an
opportunity to do some interesting tricks. For example, we can transform
a stream with a <em>sequence accelerator</em> that converts a
sequence of approximations to a new sequence that converges to the same
value as the original, only faster.</p>
<p>One such accelerator, due to the eighteenth-century Swiss mathematician
Leonhard Euler, works well with sequences that are
partial sums of alternating series (series of terms with alternating
signs). In Euler's technique, if <em>S</em><del><em>n</em></del> is the <em>n</em>th term of the
original sum sequence, then the accelerated sequence has terms</p>
<p><img src="ch3-Z-G-42.gif" alt="" /></p>
<p>Thus, if the original sequence is represented as a stream of values, the
transformed sequence is given by</p>
<pre><code class="language-scheme editable">(define (euler-transform s)
  (let ((s0 (stream-ref s 0))         ; *S*~*n*-1~*
        (s1 (stream-ref s 1))         ; *S*~*n*~*
        (s2 (stream-ref s 2)))         ; *S*~*n*+1~*
    (cons-stream (- s2 (/ (square (- s2 s1))
                          (+ s0 (* -2 s1) s2)))
                 (euler-transform (stream-cdr s)))))
</code></pre>
<p>We can demonstrate Euler acceleration with our sequence of
approximations to <img src="book-Z-G-D-9.gif" alt="" />:</p>
<pre><code class="language-scheme editable">(display-stream (euler-transform pi-stream))
</code></pre>
<p><em><code>3.166666666666667</code></em>
<em><code>3.1333333333333337</code></em>
<em><code>3.1452380952380956</code></em>
<em><code>3.13968253968254</code></em>
<em><code>3.1427128427128435</code></em>
<em><code>3.1408813408813416</code></em>
<em><code>3.142071817071818</code></em>
<em><code>3.1412548236077655</code></em>
<code>...</code></p>
<p>Even better, we can accelerate the accelerated sequence, and recursively
accelerate that, and so on. Namely, we create a stream of streams (a
structure we'll call a <em>tableau</em>) in which each stream
is the transform of the preceding one:</p>
<pre><code class="language-scheme editable">(define (make-tableau transform s)
  (cons-stream s
               (make-tableau transform
                             (transform s))))
</code></pre>
<p>The tableau has the form</p>
<p><img src="ch3-Z-G-43.gif" alt="" /></p>
<p>Finally, we form a sequence by taking the first term in each row of the
tableau:</p>
<pre><code class="language-scheme editable">(define (accelerated-sequence transform s)
  (stream-map stream-car
              (make-tableau transform s)))
</code></pre>
<p>We can demonstrate this kind of ``super-acceleration'' of the
<img src="book-Z-G-D-9.gif" alt="" /> sequence:</p>
<pre><code class="language-scheme editable">(display-stream (accelerated-sequence euler-transform
                                      pi-stream))
</code></pre>
<p><em><code>4.</code></em>
<em><code>3.166666666666667</code></em>
<em><code>3.142105263157895</code></em>
<em><code>3.141599357319005</code></em>
<em><code>3.1415927140337785</code></em>
<em><code>3.1415926539752927</code></em>
<em><code>3.1415926535911765</code></em>
<em><code>3.141592653589778</code></em>
<code>...</code></p>
<p>The result is impressive. Taking eight terms of the sequence yields the
correct value of <img src="book-Z-G-D-9.gif" alt="" /> to 14 decimal places.
If we had used only the original <img src="book-Z-G-D-9.gif" alt="" />
sequence, we would need to compute on the order of 10^13^ terms (i.e.,
expanding the series far enough so that the individual terms are less
then 10^-13^) to get that much accuracy! We could have implemented these
acceleration techniques without using streams. But the stream
formulation is particularly elegant and convenient because the entire
sequence of states is available to us as a data structure that can be
manipulated with a uniform set of operations.</p>
<p><strong>Exercise 3.63.</strong>
Louis Reasoner asks why the
<code>sqrt-stream</code> procedure was not written in the following more
straightforward way, without the local variable <code>guesses</code>:</p>
<pre><code class="language-scheme editable">(define (sqrt-stream x)
  (cons-stream 1.0
               (stream-map (lambda (guess)
                             (sqrt-improve guess x))
                           (sqrt-stream x))))
</code></pre>
<p>Alyssa P. Hacker replies that this version of the procedure is
considerably less efficient because it performs redundant computation.
Explain Alyssa's answer. Would the two versions still differ in
efficiency if our implementation of <code>delay</code> used only
<code>(lambda () &lt;</code><em><code>exp</code></em><code>&gt;)</code> without using the optimization provided by
<code>memo-proc</code> (section
<a href="book-Z-H-24.html#%_sec_3.5.1">3.5.1</a>)?</p>
<p><strong>Exercise 3.64.</strong>
Write a procedure
<code>stream-limit</code> that takes as arguments a stream and a
number (the tolerance). It should examine the stream until it finds two
successive elements that differ in absolute value by less than the
tolerance, and return the second of the two elements. Using this, we
could compute square roots up to a given tolerance by</p>
<pre><code class="language-scheme editable">(define (sqrt x tolerance)
  (stream-limit (sqrt-stream x) tolerance))
</code></pre>
<p><strong>Exercise 3.65.</strong>
Use the series</p>
<p><img src="ch3-Z-G-44.gif" alt="" /></p>
<p>to compute three sequences of approximations to the natural logarithm of
2, in the same way we did above for <img src="book-Z-G-D-9.gif" alt="" />.
How rapidly do these sequences converge?</p>
<h4 id="infinite-streams-of-pairs"><a class="header" href="#infinite-streams-of-pairs"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_476">Infinite streams of pairs</a></a></h4>
<p>In
section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>, we saw how the sequence
paradigm handles traditional nested loops as processes defined on
sequences of pairs. If we generalize this technique to infinite streams,
then we can write programs that are not easily represented as loops,
because the ``looping'' must range over an infinite set.</p>
<p>For example, suppose we want to generalize the
<code>prime-sum-pairs</code> procedure of
section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a> to produce the stream of
pairs of <em>all</em> integers (<em>i</em>,<em>j</em>) with <em>i</em>
[&lt;]{.underline} <em>j</em> such
that <em>i</em> + <em>j</em> is prime. If <code>int-pairs</code> is the sequence of all pairs of
integers (<em>i</em>,<em>j</em>) with <em>i</em>
[&lt;]{.underline} <em>j</em>, then our required
stream is
simply^[66]{.small}^](book-Z-H-24.html#footnote_Temp_477)</p>
<pre><code class="language-scheme editable">(stream-filter (lambda (pair)
                 (prime? (+ (car pair) (cadr pair))))
               int-pairs)
</code></pre>
<p>Our problem, then, is to produce the stream <code>int-pairs</code>. More generally,
suppose we have two streams <em>S</em> = (<em>S</em><del><em>i</em></del>) and <em>T</em> = (<em>T</em><del><em>j</em></del>), and
imagine the infinite rectangular array</p>
<p><img src="ch3-Z-G-45.gif" alt="" /></p>
<p>We wish to generate a stream that contains all the pairs in the array
that lie on or above the diagonal, i.e., the pairs</p>
<p><img src="ch3-Z-G-46.gif" alt="" /></p>
<p>(If we take both <em>S</em> and <em>T</em> to be the stream of integers, then this
will be our desired stream <code>int-pairs</code>.)</p>
<p>Call the general stream of pairs <code>(pairs S T)</code>, and consider it to be
composed of three parts: the pair (<em>S</em><del>0</del>,<em>T</em><del>0</del>), the rest of the pairs
in the first row, and the remaining
pairs:<a href="book-Z-H-24.html#footnote_Temp_478">^[67]{.small}^</a></p>
<p><img src="ch3-Z-G-47.gif" alt="" /></p>
<p>Observe that the third piece in this decomposition (pairs that are not
in the first row) is (recursively) the pairs formed from
<code>(stream-cdr S)</code> and <code>(stream-cdr T)</code>. Also note that the second piece
(the rest of the first row) is</p>
<pre><code class="language-scheme editable">(stream-map (lambda (x) (list (stream-car s) x))
            (stream-cdr t))
</code></pre>
<p>Thus we can form our stream of pairs as follows:</p>
<pre><code class="language-scheme editable">(define (pairs s t)
  (cons-stream
   (list (stream-car s) (stream-car t))
   (&lt;*combine-in-some-way*&gt;
    (stream-map (lambda (x) (list (stream-car s) x))
                (stream-cdr t))
    (pairs (stream-cdr s) (stream-cdr t)))))
</code></pre>
<p>In order to complete the procedure, we must choose some
way to combine the two inner streams. One idea is to use the stream
analog of the <code>append</code> procedure from
section
<a href="book-Z-H-15.html#%_sec_2.2.1">2.2.1</a>:</p>
<pre><code class="language-scheme editable">(define (stream-append s1 s2)
  (if (stream-null? s1)
      s2
      (cons-stream (stream-car s1)
                   (stream-append (stream-cdr s1) s2))))
</code></pre>
<p>This is unsuitable for infinite streams, however, because it takes all
the elements from the first stream before incorporating the second
stream. In particular, if we try to generate all pairs of positive
integers using</p>
<pre><code class="language-scheme editable">(pairs integers integers)
</code></pre>
<p>our stream of results will first try to run through all pairs with the
first integer equal to 1, and hence will never produce pairs with any
other value of the first integer.</p>
<p>To handle infinite streams, we need to devise an order of combination
that ensures that every element will eventually be reached if we let our
program run long enough. An elegant way to accomplish this is with the
following <code>interleave</code>
procedure:<a href="book-Z-H-24.html#footnote_Temp_479">^[68]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (interleave s1 s2)
  (if (stream-null? s1)
      s2
      (cons-stream (stream-car s1)
                   (interleave s2 (stream-cdr s1)))))
</code></pre>
<p>Since <code>interleave</code> takes elements alternately from the two streams,
every element of the second stream will eventually find its way into the
interleaved stream, even if the first stream is infinite.</p>
<p>We can thus generate the required stream of pairs as</p>
<pre><code class="language-scheme editable">(define (pairs s t)
  (cons-stream
   (list (stream-car s) (stream-car t))
   (interleave
    (stream-map (lambda (x) (list (stream-car s) x))
                (stream-cdr t))
    (pairs (stream-cdr s) (stream-cdr t)))))
</code></pre>
<p><strong>Exercise 3.66.</strong>
Examine the stream
<code>(pairs integers integers)</code>. Can you make any general comments about the
order in which the pairs are placed into the stream? For example, about
how many pairs precede the pair (1,100)? the pair (99,100)? the pair
(100,100)? (If you can make precise mathematical statements here, all
the better. But feel free to give more qualitative answers if you find
yourself getting bogged down.)</p>
<p><strong>Exercise 3.67.</strong>
Modify the <code>pairs</code> procedure so that
<code>(pairs integers integers)</code> will produce the stream of <em>all</em> pairs of
integers (<em>i</em>,<em>j</em>) (without the condition <em>i</em>
[&lt;]{.underline} <em>j</em>).
Hint: You will need to mix in an additional stream.</p>
<p><strong>Exercise 3.68.</strong>
Louis Reasoner thinks that building
a stream of pairs from three parts is unnecessarily complicated. Instead
of separating the pair (<em>S</em><del>0</del>,<em>T</em><del>0</del>) from the rest of the pairs in the
first row, he proposes to work with the whole first row, as follows:</p>
<pre><code class="language-scheme editable">(define (pairs s t)
  (interleave
   (stream-map (lambda (x) (list (stream-car s) x))
               t)
   (pairs (stream-cdr s) (stream-cdr t))))
</code></pre>
<p>Does this work? Consider what happens if we evaluate
<code>(pairs integers integers)</code> using Louis's definition of <code>pairs</code>.</p>
<p><strong>Exercise 3.69.</strong>
Write a procedure <code>triples</code> that
takes three infinite streams, <em>S</em>, <em>T</em>, and <em>U</em>, and produces the stream
of triples (<em>S</em><del><em>i</em></del>,<em>T</em><del><em>j</em></del>,<em>U</em><del><em>k</em></del>) such that <em>i</em>
[&lt;]{.underline}
<em>j</em>
[&lt;]{.underline} <em>k</em>. Use <code>triples</code> to generate the stream of all
Pythagorean triples of positive integers, i.e., the
triples (<em>i</em>,<em>j</em>,<em>k</em>) such that <em>i</em>
[&lt;]{.underline} <em>j</em> and <em>i</em>^2^ +
<em>j</em>^2^ = <em>k</em>^2^.</p>
<p><strong>Exercise 3.70.</strong>
It
would be nice to be able to generate streams in which the pairs appear
in some useful order, rather than in the order that results from an <em>ad
hoc</em> interleaving process. We can use a technique similar to the <code>merge</code>
procedure of exercise
<a href="book-Z-H-24.html#%_thm_3.56">3.56</a>, if we define
a way to say that one pair of integers is <code>less than\'\' another. One way to do this is to define a </code>weighting function'' <em>W</em>(<em>i</em>,<em>j</em>)
and stipulate that (<em>i</em><del>1</del>,<em>j</em><del>1</del>) is less than (<em>i</em><del>2</del>,<em>j</em><del>2</del>) if
<em>W</em>(<em>i</em><del>1</del>,<em>j</em><del>1</del>) &lt; <em>W</em>(<em>i</em><del>2</del>,<em>j</em><del>2</del>). Write a procedure
<code>merge-weighted</code> that is like <code>merge</code>, except that <code>merge-weighted</code>
takes an additional argument <code>weight</code>, which is a procedure that
computes the weight of a pair, and is used to determine the order in
which elements should appear in the resulting merged
stream.<a href="book-Z-H-24.html#footnote_Temp_485">^[69]{.small}^</a>
Using this, generalize <code>pairs</code> to a procedure <code>weighted-pairs</code> that
takes two streams, together with a procedure that computes a weighting
function, and generates the stream of pairs, ordered according to
weight. Use your procedure to generate</p>
<p>a. the stream of all pairs of positive integers (<em>i</em>,<em>j</em>) with <em>i</em>
[&lt;]{.underline} <em>j</em> ordered according to the sum <em>i</em> + <em>j</em></p>
<p>b. the stream of all pairs of positive integers (<em>i</em>,<em>j</em>) with <em>i</em>
[&lt;]{.underline} <em>j</em>, where neither <em>i</em> nor <em>j</em> is divisible by 2, 3, or
5, and the pairs are ordered according to the sum 2 <em>i</em> + 3 <em>j</em> + 5 <em>i</em>
<em>j</em>.</p>
<p><strong>Exercise 3.71.</strong>
Numbers that can be
expressed as the sum of two cubes in more than one way are sometimes
called <em>Ramanujan numbers</em>, in honor of the mathematician Srinivasa
Ramanujan.<a href="book-Z-H-24.html#footnote_Temp_487">^[70]{.small}^</a>
Ordered streams of pairs provide an elegant solution to the problem of
computing these numbers. To find a number that can be written as the sum
of two cubes in two different ways, we need only generate the stream of
pairs of integers (<em>i</em>,<em>j</em>) weighted according to the sum <em>i</em>^3^ +
<em>j</em>^3^ (see exercise
<a href="book-Z-H-24.html#%_thm_3.70">3.70</a>), then search
the stream for two consecutive pairs with the same weight. Write a
procedure to generate the Ramanujan numbers. The first such number is
1,729. What are the next five?</p>
<p><strong>Exercise 3.72.</strong>
In a similar way to
exercise
<a href="book-Z-H-24.html#%_thm_3.71">3.71</a> generate a stream of all
numbers that can be written as the sum of two squares in three different
ways (showing how they can be so written).</p>
<h4 id="streams-as-signals"><a class="header" href="#streams-as-signals"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_489">Streams as signals</a></a></h4>
<p>We began our discussion of streams by
describing them as computational analogs of the ``signals'' in
signal-processing systems. In fact, we can use streams to model
signal-processing systems in a very direct way, representing the values
of a signal at successive time intervals as consecutive elements of a
stream. For instance, we can implement an <em>integrator</em> or
<em>summer</em> that, for an input stream <em>x</em> = (<em>x</em><del><em>i</em></del>), an initial value
<em>C</em>, and a small increment <em>dt</em>, accumulates the sum</p>
<p><img src="ch3-Z-G-48.gif" alt="" /></p>
<p>and returns the stream of values <em>S</em> = (<em>S</em><del><em>i</em></del>). The following
<code>integral</code> procedure is reminiscent of the ``implicit style''
definition of the stream of integers
(section
<a href="book-Z-H-24.html#%_sec_3.5.2">3.5.2</a>):</p>
<pre><code class="language-scheme editable">(define (integral integrand initial-value dt)
  (define int
    (cons-stream initial-value
                 (add-streams (scale-stream integrand dt)
                              int)))
  int)
</code></pre>
<p><img src="ch3-Z-G-49.gif" alt="" /></p>
<p><strong>Figure 3.32:</strong>
The <code>integral</code> procedure viewed as a signal-processing
system.</p>
<p>Figure
<a href="book-Z-H-24.html#%_fig_3.32">3.32</a> is a picture of a
signal-processing system that corresponds to the <code>integral</code> procedure.
The input stream is scaled by <em>dt</em> and passed through an adder, whose
output is passed back through the same adder. The self-reference in the
definition of <code>int</code> is reflected in the figure by the feedback loop that
connects the output of the adder to one of the inputs.</p>
<p><strong>Exercise 3.73.</strong></p>
<p><img src="ch3-Z-G-50.gif" alt="" />
<em>v</em> = <em>v</em><del>0</del> +
(1/<em>C</em>)<img src="book-Z-G-D-19.gif" alt="" />0^<em>t</em>^<em>i</em> <em>dt</em> + <em>R</em> <em>i</em></p>
<p><img src="ch3-Z-G-51.gif" alt="" /></p>
<p><strong>Figure 3.33:</strong>
An RC circuit and the associated signal-flow diagram.</p>
<p>We can model electrical
circuits using streams to represent the values of currents or voltages
at a sequence of times. For instance, suppose we have an <em>RC circuit</em>
consisting of a resistor of resistance <em>R</em> and a capacitor of
capacitance <em>C</em> in series. The voltage response <em>v</em> of the circuit to an
injected current <em>i</em> is determined by the formula in
figure
<a href="book-Z-H-24.html#%_fig_3.33">3.33</a>, whose structure is shown by
the accompanying signal-flow diagram.</p>
<p>Write a procedure <code>RC</code> that models this circuit. <code>RC</code> should take as
inputs the values of <em>R</em>, <em>C</em>, and <em>dt</em> and should return a procedure
that takes as inputs a stream representing the current <em>i</em> and an
initial value for the capacitor voltage <em>v</em><del>0</del> and produces as output
the stream of voltages <em>v</em>. For example, you should be able to use <code>RC</code>
to model an RC circuit with <em>R</em> = 5 ohms, <em>C</em> = 1 farad, and a
0.5-second time step by evaluating <code>(define RC1 (RC 5 1 0.5))</code>. This
defines <code>RC1</code> as a procedure that takes a stream representing the time
sequence of currents and an initial capacitor voltage and produces the
output stream of voltages.</p>
<p><strong>Exercise 3.74.</strong>
Alyssa
P. Hacker is designing a system to process signals coming from physical
sensors. One important feature she wishes to produce is a signal that
describes the <em>zero crossings</em> of the input signal. That is, the
resulting signal should be + 1 whenever the input signal changes from
negative to positive, - 1 whenever the input signal changes from
positive to negative, and 0 otherwise. (Assume that the sign of a 0
input is positive.) For example, a typical input signal with its
associated zero-crossing signal would be</p>
<p><code>...</code>1
2
1.5
1
0.5
-0.1
-2
-3
-2
-0.5
0.2
3
4
<code>...</code>...<code>0 0 0 0 0 -1 0 0 0 0 1 0 0</code>...`</p>
<p>In Alyssa's system, the signal from the sensor is represented as a
stream <code>sense-data</code> and the stream <code>zero-crossings</code> is the corresponding
stream of zero crossings. Alyssa first writes a procedure
<code>sign-change-detector</code> that takes two values as arguments and compares
the signs of the values to produce an appropriate 0, 1, or - 1. She then
constructs her zero-crossing stream as follows:</p>
<pre><code class="language-scheme editable">(define (make-zero-crossings input-stream last-value)
  (cons-stream
   (sign-change-detector (stream-car input-stream) last-value)
   (make-zero-crossings (stream-cdr input-stream)
                        (stream-car input-stream))))

(define zero-crossings (make-zero-crossings sense-data 0))
</code></pre>
<p>Alyssa's boss, Eva Lu Ator, walks by and suggests that this program is
approximately equivalent to the following one, which uses the
generalized version of <code>stream-map</code> from
exercise
<a href="book-Z-H-24.html#%_thm_3.50">3.50</a>:</p>
<pre><code class="language-scheme editable">(define zero-crossings
  (stream-map sign-change-detector sense-data &lt;*expression*&gt;))
</code></pre>
<p>Complete the program by supplying the indicated &lt;<em>expression</em>&gt;.</p>
<p><strong>Exercise
3.75.</strong>
Unfortunately,
Alyssa's zero-crossing detector in
exercise
<a href="book-Z-H-24.html#%_thm_3.74">3.74</a> proves to be insufficient,
because the noisy signal from the sensor leads to spurious zero
crossings. Lem E. Tweakit, a hardware specialist, suggests that Alyssa
smooth the signal to filter out the noise before extracting the zero
crossings. Alyssa takes his advice and decides to extract the zero
crossings from the signal constructed by averaging each value of the
sense data with the previous value. She explains the problem to her
assistant, Louis Reasoner, who attempts to implement the idea, altering
Alyssa's program as follows:</p>
<pre><code class="language-scheme editable">(define (make-zero-crossings input-stream last-value)
  (let ((avpt (/ (+ (stream-car input-stream) last-value) 2)))
    (cons-stream (sign-change-detector avpt last-value)
                 (make-zero-crossings (stream-cdr input-stream)
                                      avpt))))
</code></pre>
<p>This does not correctly implement Alyssa's plan. Find the bug that
Louis has installed and fix it without changing the structure of the
program. (Hint: You will need to increase the number of arguments to
<code>make-zero-crossings</code>.)</p>
<p><strong>Exercise
3.76.</strong>
Eva
Lu Ator has a criticism of Louis's approach in
exercise
<a href="book-Z-H-24.html#%_thm_3.75">3.75</a>. The program he wrote is
not modular, because it intermixes the operation of smoothing with the
zero-crossing extraction. For example, the extractor should not have to
be changed if Alyssa finds a better way to condition her input signal.
Help Louis by writing a procedure <code>smooth</code> that takes a stream as input
and produces a stream in which each element is the average of two
successive input stream elements. Then use <code>smooth</code> as a component to
implement the zero-crossing detector in a more modular style.</p>
<h3 id="354"><a class="header" href="#354">[3.5.4</a></h3>
<p>Streams and Delayed Evaluation](book-Z-H-4.html#%<em>toc</em>%_sec_3.5.4)</p>
<p>The <code>integral</code> procedure at the end of
the preceding section shows how we can use streams to model
signal-processing systems that contain feedback loops.
The feedback loop for the adder shown in
figure
<a href="book-Z-H-24.html#%_fig_3.32">3.32</a> is modeled by the fact that
<code>integral</code>'s internal stream <code>int</code> is defined in terms
of itself:</p>
<pre><code class="language-scheme editable">(define int
  (cons-stream initial-value
               (add-streams (scale-stream integrand dt)
                            int)))
</code></pre>
<p>The interpreter's ability to deal with such an implicit definition
depends on the <code>delay</code> that is incorporated into <code>cons-stream</code>. Without
this <code>delay</code>, the interpreter could not construct <code>int</code> before
evaluating both arguments to <code>cons-stream</code>, which would require that
<code>int</code> already be defined. In general, <code>delay</code> is crucial for using
streams to model signal-processing systems that contain loops. Without
<code>delay</code>, our models would have to be formulated so that the inputs to
any signal-processing component would be fully evaluated before the
output could be produced. This would outlaw loops.</p>
<p>Unfortunately, stream models of systems with loops may require uses of
<code>delay</code> beyond the ``hidden'' <code>delay</code> supplied by <code>cons-stream</code>.
For instance, figure
<a href="book-Z-H-24.html#%_fig_3.34">3.34</a> shows a
signal-processing system for solving the differential
equation <em>dy</em>/<em>dt</em> = <em>f</em>(<em>y</em>) where <em>f</em> is a given function. The figure
shows a mapping component, which applies <em>f</em> to its input signal, linked
in a feedback loop to an integrator in a manner very similar to that of
the analog computer circuits that are actually used to solve such
equations.</p>
<p><img src="ch3-Z-G-52.gif" alt="" /></p>
<p><strong>Figure 3.34:</strong>
An ``analog computer circuit'' that solves the
equation <em>dy</em>/<em>dt</em> = <em>f</em>(<em>y</em>).</p>
<p>Assuming we are given an initial value <em>y</em><del>0</del> for <em>y</em>, we could try to
model this system using the procedure</p>
<pre><code class="language-scheme editable">(define (solve f y0 dt)
  (define y (integral dy y0 dt))
  (define dy (stream-map f y))
  y)
</code></pre>
<p>This procedure does not work, because in the first line of <code>solve</code> the
call to <code>integral</code> requires that the input <code>dy</code> be defined, which does
not happen until the second line of <code>solve</code>.</p>
<p>On the other hand, the intent of our definition does make sense, because
we can, in principle, begin to generate the <code>y</code> stream without knowing
<code>dy</code>. Indeed, <code>integral</code> and many other stream operations have
properties similar to those of <code>cons-stream</code>, in that we can generate
part of the answer given only partial information about the arguments.
For <code>integral</code>, the first element of the output stream is the specified
<code>initial-value</code>. Thus, we can generate the first element of the output
stream without evaluating the integrand <code>dy</code>. Once we know the first
element of <code>y</code>, the <code>stream-map</code> in the second line of <code>solve</code> can begin
working to generate the first element of <code>dy</code>, which will produce the
next element of <code>y</code>, and so on.</p>
<p>To take advantage of this idea, we will redefine <code>integral</code> to expect
the integrand stream to be a
<em>delayed argument</em>.
<code>Integral</code> will <code>force</code> the integrand to be evaluated only when it is
required to generate more than the first element of the output stream:</p>
<pre><code class="language-scheme editable">(define (integral delayed-integrand initial-value dt)
  (define int
    (cons-stream initial-value
                 (let ((integrand (force delayed-integrand)))
                   (add-streams (scale-stream integrand dt)
                                int))))
  int)
</code></pre>
<p>Now we can implement our <code>solve</code> procedure by delaying the evaluation of
<code>dy</code> in the definition of
<code>y</code>:<a href="book-Z-H-24.html#footnote_Temp_494">^[71]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (solve f y0 dt)
  (define y (integral (delay dy) y0 dt))
  (define dy (stream-map f y))
  y)
</code></pre>
<p>In general, every caller of <code>integral</code> must now <code>delay</code> the integrand
argument. We can demonstrate that the <code>solve</code> procedure works by
approximating <em>e</em>
<img src="book-Z-G-D-20.gif" alt="" />
2.718 by computing the value at <em>y</em> = 1 of the solution to the
differential equation <em>dy</em>/<em>dt</em> = <em>y</em> with initial condition <em>y</em>(0) = 1:</p>
<pre><code class="language-scheme editable">(stream-ref (solve (lambda (y) y) 1 0.001) 1000)
</code></pre>
<p><em><code>2.716924</code></em></p>
<p><strong>Exercise 3.77.</strong>
The <code>integral</code> procedure used above
was analogous to the ``implicit'' definition of the infinite stream
of integers in section
<a href="book-Z-H-24.html#%_sec_3.5.2">3.5.2</a>.
Alternatively, we can give a definition of <code>integral</code> that is more like
<code>integers-starting-from</code> (also in
section
<a href="book-Z-H-24.html#%_sec_3.5.2">3.5.2</a>):</p>
<pre><code class="language-scheme editable">(define (integral integrand initial-value dt)
  (cons-stream initial-value
               (if (stream-null? integrand)
                   the-empty-stream
                   (integral (stream-cdr integrand)
                             (+ (* dt (stream-car integrand))
                                initial-value)
                             dt))))
</code></pre>
<p>When used in systems with loops, this procedure has the same problem as
does our original version of <code>integral</code>. Modify the procedure so that it
expects the <code>integrand</code> as a delayed argument and hence can be used in
the <code>solve</code> procedure shown above.</p>
<p><strong>Exercise 3.78.</strong></p>
<p><img src="ch3-Z-G-53.gif" alt="" /></p>
<p><strong>Figure 3.35:</strong>
Signal-flow diagram for the solution to a second-order
linear differential equation.</p>
<p>Consider the problem of designing a signal-processing
system to study the homogeneous second-order linear differential
equation</p>
<p><img src="ch3-Z-G-54.gif" alt="" /></p>
<p>The output stream, modeling <em>y</em>, is generated by a network that contains
a loop. This is because the value of <em>d</em>^2^<em>y</em>/<em>dt</em>^2^ depends upon the
values of <em>y</em> and <em>dy</em>/<em>dt</em> and both of these are determined by
integrating <em>d</em>^2^<em>y</em>/<em>dt</em>^2^. The diagram we would like to encode is
shown in figure
<a href="book-Z-H-24.html#%_fig_3.35">3.35</a>. Write a procedure
<code>solve-2nd</code> that takes as arguments the constants <em>a</em>, <em>b</em>, and <em>dt</em> and
the initial values <em>y</em><del>0</del> and <em>dy</em><del>0</del> for <em>y</em> and <em>dy</em>/<em>dt</em> and
generates the stream of successive values of <em>y</em>.</p>
<p><strong>Exercise 3.79.</strong>
Generalize the
<code>solve-2nd</code> procedure of exercise
<a href="book-Z-H-24.html#%_thm_3.78">3.78</a> so
that it can be used to solve general second-order differential equations
<em>d</em>^2^ <em>y</em>/<em>dt</em>^2^ = <em>f</em>(<em>dy</em>/<em>dt</em>, <em>y</em>).</p>
<p><strong>Exercise
3.80.</strong>
A <em>series RLC
circuit</em> consists of a resistor, a capacitor, and an inductor connected
in series, as shown in figure
<a href="book-Z-H-24.html#%_fig_3.36">3.36</a>. If
<em>R</em>, <em>L</em>, and <em>C</em> are the resistance, inductance, and capacitance, then
the relations between voltage (<em>v</em>) and current (<em>i</em>) for the three
components are described by the equations</p>
<p><img src="ch3-Z-G-55.gif" alt="" /></p>
<p>and the circuit connections dictate the relations</p>
<p><img src="ch3-Z-G-56.gif" alt="" /></p>
<p>Combining these equations shows that the state of the circuit
(summarized by <em>v</em><del><em>C</em></del>, the voltage across the capacitor, and <em>i</em><del><em>L</em></del>,
the current in the inductor) is described by the pair of differential
equations</p>
<p><img src="ch3-Z-G-57.gif" alt="" /></p>
<p>The signal-flow diagram representing this system of differential
equations is shown in figure
<a href="book-Z-H-24.html#%_fig_3.37">3.37</a>.</p>
<p><img src="ch3-Z-G-58.gif" alt="" /></p>
<p><strong>Figure 3.36:</strong>
A series RLC circuit.</p>
<p><img src="ch3-Z-G-59.gif" alt="" /></p>
<p><strong>Figure 3.37:</strong>
A signal-flow diagram for the solution to a series RLC
circuit.</p>
<p>Write a procedure <code>RLC</code> that takes as arguments the parameters <em>R</em>, <em>L</em>,
and <em>C</em> of the circuit and the time increment <em>dt</em>. In a manner similar
to that of the <code>RC</code> procedure of
exercise
<a href="book-Z-H-24.html#%_thm_3.73">3.73</a>, <code>RLC</code> should produce a
procedure that takes the initial values of the state variables,
<em>v</em>~<em>C</em>~0~~ and <em>i</em>~<em>L</em>~0~~, and produces a pair (using <code>cons</code>) of the
streams of states <em>v</em><del><em>C</em></del> and <em>i</em><del><em>L</em></del>. Using <code>RLC</code>, generate the pair
of streams that models the behavior of a series RLC circuit with <em>R</em> = 1
ohm, <em>C</em> = 0.2 farad, <em>L</em> = 1 henry, <em>dt</em> = 0.1 second, and initial
values <em>i</em>~<em>L</em>~0~~ = 0 amps and <em>v</em>~<em>C</em>~0~~ = 10 volts.</p>
<h4 id="normal-order-evaluation"><a class="header" href="#normal-order-evaluation"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_499">Normal-order evaluation</a></a></h4>
<p>The examples in this section illustrate
how the explicit use of <code>delay</code> and <code>force</code> provides great programming
flexibility, but the same examples also show how this can make our
programs more complex. Our new <code>integral</code> procedure, for instance, gives
us the power to model systems with loops, but we must now remember that
<code>integral</code> should be called with a delayed integrand, and every
procedure that uses <code>integral</code> must be aware of this. In effect, we have
created two classes of procedures: ordinary procedures and procedures
that take delayed arguments. In general, creating separate classes of
procedures forces us to create separate classes of higher-order
procedures as
well.<a href="book-Z-H-24.html#footnote_Temp_500">^[72]{.small}^</a></p>
<p>One way to avoid the need for two different classes of procedures is to
make all procedures take delayed arguments. We could adopt a model of
evaluation in which all arguments to procedures are automatically
delayed and arguments are forced only when they are actually needed (for
example, when they are required by a primitive operation). This would
transform our language to use normal-order evaluation, which we first
described when we introduced the substitution model for evaluation in
section
<a href="book-Z-H-10.html#%_sec_1.1.5">1.1.5</a>. Converting to
normal-order evaluation provides a uniform and elegant way to simplify
the use of delayed evaluation, and this would be a natural strategy to
adopt if we were concerned only with stream processing. In
section
<a href="book-Z-H-27.html#%_sec_4.2">4.2</a>, after we have studied the
evaluator, we will see how to transform our language in just this way.
Unfortunately, including delays in procedure calls wreaks havoc with our
ability to design programs that depend on the order of events, such as
programs that use assignment, mutate data, or perform input or output.
Even the single <code>delay</code> in <code>cons-stream</code> can cause great confusion, as
illustrated by exercises
<a href="book-Z-H-24.html#%_thm_3.51">3.51</a>
and
<a href="book-Z-H-24.html#%_thm_3.52">3.52</a>. As far as anyone knows,
mutability and delayed evaluation do not mix well in programming
languages, and devising ways to deal with both of these at once is an
active area of research.</p>
<h3 id="355"><a class="header" href="#355">[3.5.5</a></h3>
<p>Modularity of Functional Programs and Modularity of Objects](book-Z-H-4.html#%<em>toc</em>%_sec_3.5.5)</p>
<p>As we saw in
section
<a href="book-Z-H-20.html#%_sec_3.1.2">3.1.2</a>, one of the major benefits
of introducing assignment is that we can increase the modularity of our
systems by encapsulating, or ``hiding,'' parts of the state of a
large system within local variables. Stream models can provide an
equivalent modularity without the use of assignment. As an
illustration, we can reimplement the Monte
Carlo estimation of <img src="book-Z-G-D-9.gif" alt="" />, which we examined
in section
<a href="book-Z-H-20.html#%_sec_3.1.2">3.1.2</a>, from a
stream-processing point of view.</p>
<p>The key modularity issue was that we wished to hide the internal state
of a random-number generator from programs that used random numbers. We
began with a procedure <code>rand-update</code>, whose successive values furnished
our supply of random numbers, and used this to produce a random-number
generator:</p>
<pre><code class="language-scheme editable">(define rand
  (let ((x random-init))
    (lambda ()
      (set! x (rand-update x))
      x)))
</code></pre>
<p>In the stream formulation there is no random-number generator <em>per se</em>,
just a stream of random numbers produced by successive calls to
<code>rand-update</code>:</p>
<p><code>(define random-numbers</code>
<code>(cons-stream random-init</code>
`(stream-map rand-update random-numbers)))</p>
<pre><code>
We use this to construct the stream of outcomes of the Cesàro experiment
performed on consecutive pairs in the `random-numbers` stream:

`(define cesaro-stream`
  `(map-successive-pairs (lambda (r1 r2) (= (gcd r1 r2) 1))`
                        `random-numbers)))

`(define (map-successive-pairs f s)`
  `(cons-stream`
   `(f (stream-car s) (stream-car (stream-cdr s)))`
   `(map-successive-pairs f (stream-cdr (stream-cdr s))))))
</code></pre>
<p>The <code>cesaro-stream</code> is now fed to a <code>monte-carlo</code> procedure, which
produces a stream of estimates of probabilities. The results are then
converted into a stream of estimates of
<img src="book-Z-G-D-9.gif" alt="" />. This version of the program doesn't
need a parameter telling how many trials to perform. Better estimates of
<img src="book-Z-G-D-9.gif" alt="" /> (from performing more experiments) are
obtained by looking farther into the <code>pi</code> stream:</p>
<p><code>(define (monte-carlo experiment-stream passed failed)</code>
<code>(define (next passed failed)</code>
<code>(cons-stream</code>
<code>(/ passed (+ passed failed)))</code>
<code>(monte-carlo</code>
<code>(stream-cdr experiment-stream) passed failed))))</code>
<code>(if (stream-car experiment-stream)</code>
<code>(next (+ passed 1) failed)</code>
`(next passed (+ failed 1))))))</p>
<p><code>(define pi</code>
<code>(stream-map (lambda (p) (sqrt (/ 6 p)))</code>
<code>(monte-carlo cesaro-stream 0 0))))</code></p>
<pre><code>
There is considerable modularity in this approach,
because we still can formulate a general `monte-carlo` procedure that
can deal with arbitrary experiments. Yet there is no assignment or local
state.

 **Exercise
3.81.**
Exercise
[3.6](book-Z-H-20.html#%_thm_3.6)
discussed generalizing the random-number generator to allow one to reset
the random-number sequence so as to produce repeatable sequences of
``random\'\' numbers. Produce a stream formulation of this same
generator that operates on an input stream of requests to `generate` a
new random number or to `reset` the sequence to a specified value and
that produces the desired stream of random numbers. Don\'t use
assignment in your solution.

 **Exercise
3.82.**
Redo
exercise
[3.5](book-Z-H-20.html#%_thm_3.5) on Monte Carlo integration in
terms of streams. The stream version of `estimate-integral` will not
have an argument telling how many trials to perform. Instead, it will
produce a stream of estimates based on successively more trials.



#### [A functional-programming view of time](book-Z-H-4.html#%_toc_%_sec_Temp_503)

 Let us now return to the issues of
objects and state that were raised at the beginning of this chapter and
examine them in a new light. We introduced assignment and mutable
objects to provide a mechanism for modular construction of programs that
model systems with state. We constructed computational objects with
local state variables and used assignment to modify these variables. We
modeled the temporal behavior of the objects in the world by the
temporal behavior of the corresponding computational objects.

Now we have seen that streams provide an alternative way to model
objects with local state. We can model a changing quantity, such as the
local state of some object, using a stream that represents the time
history of successive states. In essence, we represent time explicitly,
using streams, so that we decouple time in our simulated world from the
sequence of events that take place during evaluation. Indeed, because of
the presence of `delay` there may be little relation between simulated
time in the model and the order of events during the evaluation.

In order to contrast these two approaches to modeling, let us reconsider
the implementation of a ``withdrawal processor\'\' that
monitors the balance in a bank account. In
section
[3.1.3](book-Z-H-20.html#%_sec_3.1.3) we implemented a
simplified version of such a processor:

```scheme,editable
(define (make-simplified-withdraw balance)
  (lambda (amount)
    (set! balance (- balance amount))
    balance))
</code></pre>
<p>Calls to <code>make-simplified-withdraw</code> produce computational objects, each
with a local state variable <code>balance</code> that is decremented by successive
calls to the object. The object takes an <code>amount</code> as an argument and
returns the new balance. We can imagine the user of a bank account
typing a sequence of inputs to such an object and observing the sequence
of returned values shown on a display screen.</p>
<p>Alternatively, we can model a withdrawal processor as a procedure that
takes as input a balance and a stream of amounts to withdraw and
produces the stream of successive balances in the account:</p>
<pre><code class="language-scheme editable">(define (stream-withdraw balance amount-stream)
  (cons-stream
   balance
   (stream-withdraw (- balance (stream-car amount-stream))
                    (stream-cdr amount-stream))))
</code></pre>
<p><code>Stream-withdraw</code> implements a well-defined mathematical function whose
output is fully determined by its input. Suppose, however, that the
input <code>amount-stream</code> is the stream of successive values typed by the
user and that the resulting stream of balances is displayed. Then, from
the perspective of the user who is typing values and watching results,
the stream process has the same behavior as the object created by
<code>make-simplified-withdraw</code>. However, with the stream version, there is
no assignment, no local state variable, and consequently none of the
theoretical difficulties that we encountered in
section
<a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3</a>. Yet the system has state!</p>
<p>This is really remarkable. Even though <code>stream-withdraw</code> implements a
well-defined mathematical function whose behavior does not change, the
user's perception here is one of interacting with a system that has a
changing state. One way to resolve this paradox is to realize that it is
the user's temporal existence that imposes state on the system. If the
user could step back from the interaction and think in terms of streams
of balances rather than individual transactions, the system would appear
stateless.<a href="book-Z-H-24.html#footnote_Temp_504">^[73]{.small}^</a></p>
<p>From the point of view of one part of a complex process, the other parts
appear to change with time. They have hidden time-varying local state.
If we wish to write programs that model this kind of natural
decomposition in our world (as we see it from our viewpoint as a part of
that world) with structures in our computer, we make computational
objects that are not functional -- they must change with time. We model
state with local state variables, and we model the changes of state with
assignments to those variables. By doing this we make the time of
execution of a computation model time in the world that we are part of,
and thus we get ``objects'' in our computer.</p>
<p>Modeling with objects is powerful and intuitive, largely because this
matches the perception of interacting with a world of which we are part.
However, as we've seen repeatedly throughout this chapter, these models
raise thorny problems of constraining the order of events and of
synchronizing multiple processes. The possibility of avoiding these
problems has stimulated the development of
<em>functional programming languages</em>, which
do not include any provision for assignment or mutable data. In such a
language, all procedures implement well-defined mathematical functions
of their arguments, whose behavior does not change. The functional
approach is extremely attractive for
dealing with concurrent
systems.<a href="book-Z-H-24.html#footnote_Temp_505">^[74]{.small}^</a></p>
<p>On the other hand, if we look closely, we can see time-related problems
creeping into functional models as well. One particularly troublesome
area arises when we wish to design interactive systems, especially ones
that model interactions between independent entities. For instance,
consider once more the implementation a banking system that permits
joint bank accounts. In a conventional system using assignment and
objects, we would model the fact that Peter and Paul share an account by
having both Peter and Paul send their transaction requests to the same
bank-account object, as we saw in
section
<a href="book-Z-H-20.html#%_sec_3.1.3">3.1.3</a>. From the stream point of
view, where there are no ``objects'' <em>per se</em>, we have already
indicated that a bank account can be modeled as a process that operates
on a stream of transaction requests to produce a stream of responses.
Accordingly, we could model the fact that Peter and Paul have a joint
bank account by merging Peter's stream of transaction requests with
Paul's stream of requests and feeding the result to the bank-account
stream process, as shown in figure
<a href="book-Z-H-24.html#%_fig_3.38">3.38</a>.</p>
<p><img src="ch3-Z-G-60.gif" alt="" /></p>
<p><strong>Figure 3.38:</strong>
A joint bank account, modeled by merging two streams
of transaction requests.</p>
<p>The trouble with this formulation is in the notion of
<em>merge</em>. It will not do to merge the two streams by simply taking
alternately one request from Peter and one request from Paul. Suppose
Paul accesses the account only very rarely. We could hardly force Peter
to wait for Paul to access the account before he could issue a second
transaction. However such a merge is implemented, it must interleave the
two transaction streams in some way that is constrained by <code>real time\'\' as perceived by Peter and Paul, in the sense that, if Peter and Paul meet, they can agree that certain transactions were processed before the meeting, and other transactions were processed after the meeting.[^[75]{.small}^](book-Z-H-24.html#footnote_Temp_506) This is precisely the same constraint that we had to deal with in section [3.4.1](book-Z-H-23.html#%_sec_3.4.1), where we found the need to introduce explicit synchronization to ensure a </code>correct'' order
of events in concurrent processing of objects with state. Thus, in an
attempt to support the functional style, the need to merge inputs from
different agents reintroduces the same problems that the functional
style was meant to eliminate.</p>
<p>We began this chapter with the goal of building computational models
whose structure matches our perception of the real world we are trying
to model. We can model the world as a collection of separate,
time-bound, interacting objects with state, or we can model the world as
a single, timeless, stateless unity. Each view has powerful advantages,
but neither view alone is completely satisfactory. A grand unification
has yet to
emerge.<a href="book-Z-H-24.html#footnote_Temp_507">^[76]{.small}^</a></p>
<hr />
<p>^[52]{.small}^](book-Z-H-24.html#call_footnote_Temp_442)
Physicists sometimes adopt this view by introducing the
``world lines'' of particles as a device for
reasoning about motion. We've also already mentioned
(section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>) that this is the natural
way to think about signal-processing systems. We will explore
applications of streams to signal processing in
section
<a href="book-Z-H-24.html#%_sec_3.5.3">3.5.3</a>.</p>
<p>^[53]{.small}^](book-Z-H-24.html#call_footnote_Temp_443)
Assume that we have a predicate <code>prime?</code> (e.g., as in
section
<a href="book-Z-H-11.html#%_sec_1.2.6">1.2.6</a>) that tests for primality.</p>
<p>^[54]{.small}^](book-Z-H-24.html#call_footnote_Temp_444)
In the MIT implementation,
<code>the-empty-stream</code> is the
same as the empty list ``'()'', and <code>stream-null?</code> is the same as <code>null?</code>.</p>
<p>^[55]{.small}^](book-Z-H-24.html#call_footnote_Temp_445)
This should bother you. The fact that we are defining such similar
procedures for streams and lists indicates that we are missing some
underlying abstraction. Unfortunately, in order to exploit this
abstraction, we will need to exert finer control over the process of
evaluation than we can at present. We will discuss this point further at
the end of section
<a href="book-Z-H-24.html#%_sec_3.5.4">3.5.4</a>. In
section
<a href="book-Z-H-27.html#%_sec_4.2">4.2</a>, we'll develop a framework
that unifies lists and streams.</p>
<p>^[56]{.small}^](book-Z-H-24.html#call_footnote_Temp_446)
Although <code>stream-car</code> and <code>stream-cdr</code> can
be defined as procedures, <code>cons-stream</code> must be a special form. If
<code>cons-stream</code> were a procedure, then, according to our model of
evaluation, evaluating <code>(cons-stream &lt;</code><em><code>a</code></em><code>&gt; &lt;</code><em><code>b</code></em><code>&gt;)</code> would
automatically cause &lt;<em>b</em>&gt; to be evaluated, which is precisely what we
do not want to happen. For the same reason, <code>delay</code> must be a special
form, though <code>force</code> can be an ordinary procedure.</p>
<p>^[57]{.small}^](book-Z-H-24.html#call_footnote_Temp_448)
The numbers shown here do not really appear in the delayed expression.
What actually appears is the original expression, in an environment in
which the variables are bound to the appropriate numbers. For example,
<code>(+ low 1)</code> with <code>low</code> bound to 10,000 actually appears where <code>10001</code> is
shown.</p>
<p>^[58]{.small}^](book-Z-H-24.html#call_footnote_Temp_450)
There are many possible implementations of streams other than the one
described in this section. Delayed evaluation, which is the key to
making streams practical, was inherent in
Algol 60's <em>call-by-name</em>
parameter-passing method. The use of this mechanism to implement streams
was first described by Landin (1965). Delayed evaluation
for streams was introduced into Lisp by
Friedman and Wise (1976). In their
implementation, <code>cons</code> always delays evaluating its arguments, so that
lists automatically behave as streams. The memoizing optimization is
also known as
<em>call-by-need</em>.
The Algol community would refer to our original delayed objects as
<em>call-by-name thunks</em> and to the optimized versions as <em>call-by-need
thunks</em>.</p>
<p>^[59]{.small}^](book-Z-H-24.html#call_footnote_Temp_453)
Exercises such as
<a href="book-Z-H-24.html#%_thm_3.51">3.51</a>
and
<a href="book-Z-H-24.html#%_thm_3.52">3.52</a> are valuable for testing our
understanding of how <code>delay</code> works. On the other hand, intermixing
delayed evaluation with printing -- and, even worse, with assignment
-- is extremely confusing, and instructors of courses on computer
languages have traditionally tormented their students with examination
questions such as the ones in this section. Needless to say, writing
programs that depend on such subtleties is odious
programming style. Part of the power of stream processing is that it
lets us ignore the order in which events actually happen in our
programs. Unfortunately, this is precisely what we cannot afford to do
in the presence of assignment, which forces us to be concerned with time
and change.</p>
<p>^[60]{.small}^](book-Z-H-24.html#call_footnote_Temp_455)
Eratosthenes, a third-century B.C.
Alexandrian Greek philosopher, is famous
for giving the first accurate estimate of the circumference of the
Earth, which he computed by observing shadows cast at noon on the day of
the summer solstice. Eratosthenes's sieve method, although ancient, has
formed the basis for special-purpose hardware ``sieves'' that, until
recently, were the most powerful tools in existence for locating large
primes. Since the 70s, however, these methods have been superseded by
outgrowths of the probabilistic techniques discussed in
section
<a href="book-Z-H-11.html#%_sec_1.2.6">1.2.6</a>.</p>
<p>^[61]{.small}^](book-Z-H-24.html#call_footnote_Temp_456)
This style of diagram was first used by Peter Henderson (1982) in
showing the connections between functional programming and
signal-processing ideas.</p>
<p>^[62]{.small}^](book-Z-H-24.html#call_footnote_Temp_458)
This uses the generalized <code>stream-map</code> from
exercise
<a href="book-Z-H-24.html#%_thm_3.50">3.50</a>.</p>
<p>^[63]{.small}^](book-Z-H-24.html#call_footnote_Temp_459)
This is a subtle argument. For a proof, see Knuth 1981,
section 4.5.4. The argument is based on the fact that if <em>p</em><del><em>n</em></del> is the
<em>n</em>th prime, then <em>p</em><del><em>n</em></del> &gt; <em>n</em> ln <em>n</em> for <em>n</em> &gt; 1. For <em>n</em> &gt; 4, we
have <em>p</em><del><em>n</em></del>^2^ &gt; <em>n</em>^2^ (ln <em>n</em>)^2^ &gt; 2<em>n</em> ln <em>n</em> &gt; <em>p</em><del>2<em>n</em></del>. Thus,
to test if 2<em>n</em> is prime, we need to check for divisibility by primes up
to <em>p</em><del>2<em>n</em></del>. But we are guaranteed that <em>p</em><del><em>n</em></del>^2^ &gt; <em>p</em><del>2<em>n</em></del>, so we
need only check for divisibility by primes up to <em>p</em><del><em>n</em></del>. Thus, to
generate the primes up to 2<em>n</em>, we need only have already generated the
primes up to <em>n</em>. This is a variant of an argument made by
M. Minsky, H. Abelson, and L. Sussman in a 1972
AI Memo (number 259A).</p>
<p>^[64]{.small}^](book-Z-H-24.html#call_footnote_Temp_465)
This exercise shows how call-by-need can be exponentially more efficient
than call-by-name for some programs. On the other hand, Friedman and
Wise (1976) showed that for some programs, call-by-name can be
exponentially more efficient than call-by-need.</p>
<p>^[65]{.small}^](book-Z-H-24.html#call_footnote_Temp_472)
We can't use <code>(sqrt-stream x)</code> in the <code>stream-map</code> expression, because
that would result in an infinite loop. Can you explain why? (See
exercise
<a href="book-Z-H-24.html#%_thm_3.63">3.63</a>.)</p>
<p>^[66]{.small}^](book-Z-H-24.html#call_footnote_Temp_477)
We are assuming here that we have a <code>prime?</code> predicate. This would be
written in terms of the stream of primes, as in
section
<a href="book-Z-H-24.html#%_sec_3.5.2">3.5.2</a>.</p>
<p>^[67]{.small}^](book-Z-H-24.html#call_footnote_Temp_478)
This decomposition is similar to the <code>up-diagonal</code> strategy we used in
section
<a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a>.</p>
<p>^[68]{.small}^](book-Z-H-24.html#call_footnote_Temp_479)
<code>Interleave</code> is a variant of the <code>shuffle</code> procedure presented by
Vuillemin (1974).</p>
<p>^[69]{.small}^](book-Z-H-24.html#call_footnote_Temp_485)
We can use <code>merge-weighted</code> to implement the <code>merge</code> procedure of
exercise
<a href="book-Z-H-24.html#%_thm_3.56">3.56</a> by using a weighting
function that is just the value of the number in the stream.</p>
<p>^[70]{.small}^](book-Z-H-24.html#call_footnote_Temp_487)
Once, when the mathematician G. H. Hardy was visiting Ramanujan in the
hospital, he remarked that the number of his taxicab, 1729, was a
<code>dull number.\'\' Ramanujan replied, </code>No, Hardy! It is a very
interesting number. It is the smallest number expressible as the sum of
two cubes in two different ways.'' The trick of using weighted
pairs to generate the Ramanujan numbers was shown to us by Charles
Leiserson.</p>
<p>^[71]{.small}^](book-Z-H-24.html#call_footnote_Temp_494)
This method of solving differential equations is a variation on the
<em>Euler-Cauchy method</em>, which approximates the solution at a sequence of
points separated by a time step <em>dt</em>.</p>
<p>^[72]{.small}^](book-Z-H-24.html#call_footnote_Temp_500)
For example, we would need a <code>stream-map-delayed</code> that is like
<code>stream-map</code> except that it takes a procedure that expects a delayed
argument. We would also need a separate <code>stream-filter-delayed</code>, and so
on. This is a similar problem to the one we encountered in
section
<a href="book-Z-H-15.html#%_sec_2.2.4">2.2.4</a> when we implemented a generic
<code>accumulate</code> procedure that could be used for both lists and trees. We
can solve this problem using a similar technique, by equipping our data
objects with type tags. See
exercise
<a href="book-Z-H-26.html#%_thm_4.3">4.3</a>.</p>
<p>^[73]{.small}^](book-Z-H-24.html#call_footnote_Temp_504)
This is the same idea that we exploited in
section
<a href="book-Z-H-23.html#%_sec_3.4.1">3.4.1</a> to show that a concurrent
system can be correct even if its processes are interleaved, provided
that the net result is equivalent to some sequential ordering of the
processes. From the point of view of an observer of the complete time
history of the states, any such ordering is as good as any other. From
the point of view of a user interacting with the system, however, the
order of events can matter.</p>
<p>^[74]{.small}^](book-Z-H-24.html#call_footnote_Temp_505)
John Backus, the inventor of Fortran, gave high
visibility
to functional programming when he was awarded the ACM Turing award in
1978. His acceptance speech (Backus 1978) strongly advocated the
functional approach. A good overview of functional programming is given
in Henderson 1980 and in Darlington, Henderson, and Turner 1982.</p>
<p>^[75]{.small}^](book-Z-H-24.html#call_footnote_Temp_506)
Observe that, for any two streams, there is in general more than one
acceptable order of interleaving. Thus,
technically, ``merge'' is a relation rather than a function -- the
answer is not a deterministic function of the inputs. We already
mentioned (footnote
<a href="book-Z-H-23.html#footnote_Temp_411">39</a>) that
nondeterminism is essential when dealing with concurrency. The merge
relation illustrates the same essential nondeterminism, from the
functional perspective. In section
<a href="book-Z-H-28.html#%_sec_4.3">4.3</a>, we
will look at nondeterminism from yet another point of view.</p>
<p>^[76]{.small}^](book-Z-H-24.html#call_footnote_Temp_507)
The object model approximates the world by dividing it into separate
pieces. The functional model does not modularize along object
boundaries. The object model is useful when the unshared
state of the ``objects'' is much larger than the state that they
share. An example of a place where the object viewpoint fails is
quantum mechanics, where thinking of things as individual
particles leads to paradoxes and confusions. Unifying the object view
with the functional view may have little to do with programming, but
rather with fundamental epistemological issues.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<p><a href="book-Z-H-4.html#%_toc_%_chap_4">Chapter 4</a></p>
<p><a href="book-Z-H-4.html#%_toc_%_chap_4">Metalinguistic Abstraction</a></p>
<div class="info">
`...` It\'s in words that the magic is \-- Abracadabra, Open Sesame,
and the rest \-- but the magic words in one story aren\'t magical in 
the next. The real magic is to understand which words work, and when,
and for what; the trick is to learn the trick.\
`...` And those words are made from the letters of our alphabet: a
couple-dozen squiggles we can draw with the pen. This is the key! And
the treasure, too, if we can only get our hands on it! It\'s as if
\-- as if the key to the treasure *is* the treasure!
<p>John Barth, <em>Chimera</em></p>
</div>
<p>In our study of program design, we have seen that expert programmers
control the complexity of their designs with the same general techniques
used by designers of all complex systems. They combine primitive
elements to form compound objects, they abstract compound objects to
form higher-level building blocks, and they preserve modularity by
adopting appropriate large-scale views of system structure. In
illustrating these techniques, we have used Lisp as a language for
describing processes and for constructing computational data objects and
processes to model complex phenomena in the real world. However, as we
confront increasingly complex problems, we will find that Lisp, or
indeed any fixed programming language, is not sufficient for our needs.
We must constantly turn to new languages in order to express our ideas
more effectively. Establishing new languages is a powerful strategy for
controlling complexity in engineering design; we can often enhance our
ability to deal with a complex problem by adopting a new language that
enables us to describe (and hence to think about) the problem in a
different way, using primitives, means of combination, and means of
abstraction that are particularly well suited to the problem at
hand.<a href="book-Z-H-25.html#footnote_Temp_508">^[1]{.small}^</a>{#call_footnote_Temp_508}</p>
<p>Programming is endowed with a multitude of
languages. There are physical languages, such as the machine languages
for particular computers. These languages are concerned with the
representation of data and control in terms of individual bits of
storage and primitive machine instructions. The machine-language
programmer is concerned with using the given hardware to erect systems
and utilities for the efficient implementation of resource-limited
computations. High-level languages, erected on a machine-language
substrate, hide concerns about the representation of data as collections
of bits and the representation of programs as sequences of primitive
instructions. These languages have means of combination and abstraction,
such as procedure definition, that are appropriate to the larger-scale
organization of systems.</p>
<p><em>Metalinguistic abstraction</em> --
establishing new languages -- plays an important role in all branches
of engineering design. It is particularly important to computer
programming, because in programming not only can we formulate new
languages but we can also implement these languages by constructing
evaluators. An <em>evaluator</em> (or <em>interpreter</em>) for a
programming language is a procedure that, when applied to an expression
of the language, performs the actions required to evaluate that
expression.</p>
<p>It is no exaggeration to regard this as the most fundamental idea in
programming:</p>
<blockquote>
<p>The evaluator, which determines the meaning of expressions in a
programming language, is just another program.</p>
</blockquote>
<p>To appreciate this point is to change our images of ourselves as
programmers. We come to see ourselves as designers of languages, rather
than only users of languages designed by others.</p>
<p>In fact, we can regard almost any program as the evaluator for some
language. For instance, the polynomial manipulation system of
section <a href="book-Z-H-18.html#%_sec_2.5.3">2.5.3</a> embodies the rules of
polynomial arithmetic and implements them in terms of operations on
list-structured data. If we augment this system with procedures to read
and print polynomial expressions, we have the core of a special-purpose
language for dealing with problems in symbolic mathematics. The
digital-logic simulator of section <a href="book-Z-H-22.html#%_sec_3.3.4">3.3.4</a>
and the constraint propagator of
section <a href="book-Z-H-22.html#%_sec_3.3.5">3.3.5</a> are legitimate languages
in their own right, each with its own primitives, means of combination,
and means of abstraction. Seen from this perspective, the technology for
coping with large-scale computer systems merges with the technology for
building new computer languages, and computer science
itself becomes no more (and no less) than the discipline of constructing
appropriate descriptive languages.</p>
<p>We now embark on a tour of the technology by which languages are
established in terms of other languages. In this chapter we shall use
Lisp as a base, implementing evaluators as Lisp procedures.
Lisp is particularly well suited to this task, because of
its ability to represent and manipulate symbolic expressions. We will
take the first step in understanding how languages are implemented by
building an evaluator for Lisp itself. The language implemented by our
evaluator will be a subset of the Scheme dialect of Lisp that we use in
this book. Although the evaluator described in this chapter is written
for a particular dialect of Lisp, it contains the essential structure of
an evaluator for any expression-oriented language designed for writing
programs for a sequential machine. (In fact, most language processors
contain, deep within them, a little ``Lisp'' evaluator.) The
evaluator has been simplified for the purposes of illustration and
discussion, and some features have been left out that would be important
to include in a production-quality Lisp system. Nevertheless, this
simple evaluator is adequate to execute most of the programs in this
book.<a href="book-Z-H-25.html#footnote_Temp_509">^[2]{.small}^</a>{#call_footnote_Temp_509}</p>
<p>An important advantage of making the evaluator accessible as a Lisp
program is that we can implement alternative evaluation rules by
describing these as modifications to the evaluator program. One place
where we can use this power to good effect is to gain extra control over
the ways in which computational models embody the notion of time, which
was so central to the discussion in chapter 3. There, we mitigated some
of the complexities of state and assignment by using streams to decouple
the representation of time in the world from time in the computer. Our
stream programs, however, were sometimes cumbersome, because they were
constrained by the applicative-order evaluation of Scheme. In
section <a href="book-Z-H-27.html#%_sec_4.2">4.2</a>, we'll change the underlying
language to provide for a more elegant approach, by modifying the
evaluator to provide for <em>normal-order evaluation</em>.</p>
<p>Section <a href="book-Z-H-28.html#%_sec_4.3">4.3</a> implements a more ambitious
linguistic change, whereby expressions have many values, rather than
just a single value. In this language of <em>nondeterministic computing</em>,
it is natural to express processes that generate all possible values for
expressions and then search for those values that satisfy certain
constraints. In terms of models of computation and time, this is like
having time branch into a set of ``possible futures'' and then
searching for appropriate time lines. With our nondeterministic
evaluator, keeping track of multiple values and performing searches are
handled automatically by the underlying mechanism of the language.</p>
<p>In section <a href="book-Z-H-29.html#%_sec_4.4">4.4</a> we implement a
<em>logic-programming</em> language in which knowledge is expressed in terms of
relations, rather than in terms of computations with inputs and outputs.
Even though this makes the language drastically different from Lisp, or
indeed from any conventional language, we will see that the
logic-programming evaluator shares the essential structure of the Lisp
evaluator.</p>
<p>::: smallprint</p>
<hr />
<p>:::</p>
<p>::: footnote
<a href="book-Z-H-25.html#call_footnote_Temp_508">^[1]{.small}^</a>{#footnote_Temp_508}
The same idea is pervasive throughout all of engineering. For example,
electrical engineers use many different languages for describing
circuits. Two of these are the language of electrical <em>networks</em> and the
language of electrical <em>systems</em>. The network language emphasizes the
physical modeling of devices in terms of discrete electrical elements.
The primitive objects of the network language are primitive electrical
components such as resistors, capacitors, inductors, and transistors,
which are characterized in terms of physical variables called voltage
and current. When describing circuits in the network language, the
engineer is concerned with the physical characteristics of a design. In
contrast, the primitive objects of the system language are
signal-processing modules such as filters and amplifiers. Only the
functional behavior of the modules is relevant, and signals are
manipulated without concern for their physical realization as voltages
and currents. The system language is erected on the network language, in
the sense that the elements of signal-processing systems are constructed
from electrical networks. Here, however, the concerns are with the
large-scale organization of electrical devices to solve a given
application problem; the physical feasibility of the parts is assumed.
This layered collection of languages is another example of the
stratified design technique illustrated by the picture language of
section <a href="book-Z-H-15.html#%_sec_2.2.4">2.2.4</a>.</p>
<p><a href="book-Z-H-25.html#call_footnote_Temp_509">^[2]{.small}^</a>{#footnote_Temp_509}
The most important features that our evaluator leaves out are mechanisms
for handling errors and supporting debugging. For a more extensive
discussion of evaluators, see
Friedman, Wand, and Haynes
1992, which gives an exposition of programming languages that proceeds
via a sequence of evaluators written in Scheme.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="41-the-metacircular-evaluator"><a class="header" href="#41-the-metacircular-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_4.1">4.1 The Metacircular Evaluator</a></a></h2>
<p>Our evaluator for Lisp will be implemented as a Lisp
program. It may seem circular to think about evaluating Lisp programs
using an evaluator that is itself implemented in Lisp. However,
evaluation is a process, so it is appropriate to describe the evaluation
process using Lisp, which, after all, is our tool for describing
processes.<a href="book-Z-H-26.html#footnote_Temp_510">^[3]{.small}^</a>
An evaluator that is written in the same language
that it evaluates is said to be
<em>metacircular</em>.</p>
<p>The metacircular evaluator is essentially
a Scheme formulation of the environment model of evaluation described in
section
<a href="book-Z-H-21.html#%_sec_3.2">3.2</a>. Recall that the model has two
basic parts:</p>
<blockquote>
<p>1. To evaluate a combination (a compound expression other than a
special form), evaluate the subexpressions and then apply the value of
the operator subexpression to the values of the operand
subexpressions.</p>
<p>2. To apply a compound procedure to a set of arguments, evaluate the
body of the procedure in a new environment. To construct this
environment, extend the environment part of the procedure object by a
frame in which the formal parameters of the procedure are bound to the
arguments to which the procedure is applied.</p>
</blockquote>
<p>These two rules describe the essence of the evaluation
process, a basic cycle in which expressions to be evaluated in
environments are reduced to procedures to be applied to arguments, which
in turn are reduced to new expressions to be evaluated in new
environments, and so on, until we get down to symbols, whose values are
looked up in the environment, and to primitive procedures, which are
applied directly (see
figure
<a href="book-Z-H-26.html#%_fig_4.1">4.1</a>).<a href="book-Z-H-26.html#footnote_Temp_511">^[4]{.small}^</a>
This evaluation cycle will be embodied by the interplay between the two
critical procedures in the evaluator, <code>eval</code> and <code>apply</code>, which are
described in section
<a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a> (see
figure
<a href="book-Z-H-26.html#%_fig_4.1">4.1</a>).</p>
<p>The implementation of the evaluator will depend upon procedures that
define the <em>syntax</em> of the expressions to be evaluated. We will use
data abstraction to make the evaluator independent of the
representation of the language. For example, rather than committing to a
choice that an assignment is to be represented by a list beginning with
the symbol <code>set!</code> we use an abstract predicate <code>assignment?</code> to test for
an assignment, and we use abstract selectors <code>assignment-variable</code> and
<code>assignment-value</code> to access the parts of an assignment. Implementation
of expressions will be described in detail in
section
<a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a>. There are also
operations, described in section
<a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a>,
that specify the representation of procedures and environments. For
example, <code>make-procedure</code> constructs compound procedures,
<code>lookup-variable-value</code> accesses the values of variables, and
<code>apply-primitive-procedure</code> applies a primitive procedure to a given
list of arguments.</p>
<h3 id="411"><a class="header" href="#411">[4.1.1</a></h3>
<p>The Core of the Evaluator](book-Z-H-4.html#%<em>toc</em>%_sec_4.1.1)</p>
<p><img src="ch4-Z-G-1.gif" alt="" /></p>
<p><strong>Figure 4.1:</strong></p>
<p>The <code>eval</code>-<code>apply</code> cycle exposes the essence of a
computer language.</p>
<p>The evaluation process can be described as the interplay between two
procedures: <code>eval</code> and <code>apply</code>.</p>
<h4 id="eval"><a class="header" href="#eval"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_512">Eval</a></a></h4>
<p><code>Eval</code> takes as arguments an expression and an
environment. It classifies the expression and directs its evaluation.
<code>Eval</code> is structured as a case analysis of the syntactic type of the
expression to be evaluated. In order to keep the procedure general, we
express the determination of the type of an expression abstractly,
making no commitment to any particular representation for
the various types of expressions. Each type of expression has a
predicate that tests for it and an abstract means for selecting its
parts. This <em>abstract syntax</em> makes it
easy to see how we can change the syntax of the language by using the
same evaluator, but with a different collection of syntax procedures.</p>
<h5 id="primitive-expressions"><a class="header" href="#primitive-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_513">Primitive expressions</a></a></h5>
<ul>
<li>For self-evaluating expressions, such as
numbers, <code>eval</code> returns the expression itself.</li>
<li><code>Eval</code> must look up variables in the environment to find their values.</li>
</ul>
<h5 id="special-forms"><a class="header" href="#special-forms"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_514">Special forms</a></a></h5>
<ul>
<li></li>
<li>For quoted expressions, <code>eval</code> returns the expression that was quoted.</li>
<li>An assignment to (or a definition of) a variable must recursively call
<code>eval</code> to compute the new value to be associated with the variable.
The environment must be modified to change (or create) the binding of
the variable.</li>
<li>An <code>if</code> expression requires special processing of its parts, so as to
evaluate the consequent if the predicate is true, and otherwise to
evaluate the alternative.</li>
<li>A <code>lambda</code> expression must be transformed into an applicable procedure
by packaging together the parameters and body specified by the
<code>lambda</code> expression with the environment of the evaluation.</li>
<li>A <code>begin</code> expression requires evaluating its sequence of expressions
in the order in which they appear.</li>
<li>A case analysis (<code>cond</code>) is transformed into a nest of <code>if</code>
expressions and then evaluated.</li>
</ul>
<h5 id="combinations"><a class="header" href="#combinations"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_515">Combinations</a></a></h5>
<ul>
<li>For a procedure application, <code>eval</code> must recursively evaluate the
operator part and the operands of the combination. The resulting
procedure and arguments are passed to <code>apply</code>, which handles the
actual procedure application.</li>
</ul>
<p>Here is the definition of <code>eval</code>:</p>
<pre><code class="language-scheme editable">(define (eval exp env)
  (cond ((self-evaluating? exp) exp)
        ((variable? exp) (lookup-variable-value exp env))
        ((quoted? exp) (text-of-quotation exp))
        ((assignment? exp) (eval-assignment exp env))
        ((definition? exp) (eval-definition exp env))
        ((if? exp) (eval-if exp env))
        ((lambda? exp)
         (make-procedure (lambda-parameters exp)
                         (lambda-body exp)
                         env))
        ((begin? exp) 
         (eval-sequence (begin-actions exp) env))
        ((cond? exp) (eval (cond-&gt;if exp) env))
        ((application? exp)
         (apply (eval (operator exp) env)
                (list-of-values (operands exp) env)))
        (else
         (error "Unknown expression type -- EVAL" exp))))
</code></pre>
<p>For clarity, <code>eval</code> has been implemented
as a case analysis using <code>cond</code>. The disadvantage of this is that our
procedure handles only a few distinguishable types of expressions, and
no new ones can be defined without editing the definition of <code>eval</code>. In
most Lisp implementations, dispatching on the type of an expression is
done in a data-directed style. This allows a user to add new types of
expressions that <code>eval</code> can distinguish, without modifying the
definition of <code>eval</code> itself. (See
exercise
<a href="book-Z-H-26.html#%_thm_4.3">4.3</a>.)</p>
<h4 id="apply"><a class="header" href="#apply"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_516">Apply</a></a></h4>
<p><code>Apply</code> takes two arguments, a procedure and a list of arguments to
which the procedure should be applied. <code>Apply</code> classifies procedures
into two kinds: It calls <code>apply-primitive-procedure</code> to
apply primitives; it applies compound procedures by sequentially
evaluating the expressions that make up the body of the procedure. The
environment for the evaluation of the body of a compound procedure is
constructed by extending the base environment carried by the procedure
to include a frame that binds the parameters of the procedure to the
arguments to which the procedure is to be applied. Here is the
definition of <code>apply</code>:</p>
<pre><code class="language-scheme editable">(define (apply procedure arguments)
  (cond ((primitive-procedure? procedure)
         (apply-primitive-procedure procedure arguments))
        ((compound-procedure? procedure)
         (eval-sequence
          (procedure-body procedure)
          (extend-environment
           (procedure-parameters procedure)
           arguments
           (procedure-environment procedure))))
        (else
         (error
          "Unknown procedure type -- APPLY" procedure))))
</code></pre>
<h4 id="procedure-arguments"><a class="header" href="#procedure-arguments"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_517">Procedure arguments</a></a></h4>
<p>When <code>eval</code> processes a procedure application, it uses <code>list-of-values</code>
to produce the list of arguments to which the procedure is to be
applied. <code>List-of-values</code> takes as an argument the operands of the
combination. It evaluates each operand and returns a list of the
corresponding
values:<a href="book-Z-H-26.html#footnote_Temp_518">^[5]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (list-of-values exps env)
  (if (no-operands? exps)
      '()
      (cons (eval (first-operand exps) env)
            (list-of-values (rest-operands exps) env))))
</code></pre>
<h4 id="conditionals"><a class="header" href="#conditionals"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_519">Conditionals</a></a></h4>
<p><code>Eval-if</code> evaluates the predicate part of an <code>if</code> expression in the
given environment. If the result is true, <code>eval-if</code> evaluates the
consequent, otherwise it evaluates the alternative:</p>
<pre><code class="language-scheme editable">(define (eval-if exp env)
  (if (true? (eval (if-predicate exp) env))
      (eval (if-consequent exp) env)
      (eval (if-alternative exp) env)))
</code></pre>
<p>The use of <code>true?</code> in <code>eval-if</code> highlights the issue of
the connection between an implemented language and an implementation
language. The <code>if-predicate</code> is evaluated in the language being
implemented and thus yields a value in that language. The interpreter
predicate <code>true?</code> translates that value into a value that can be tested
by the <code>if</code> in the implementation language: The metacircular
representation of truth might not be the same as that of the underlying
Scheme.<a href="book-Z-H-26.html#footnote_Temp_520">^[6]{.small}^</a></p>
<h4 id="sequences"><a class="header" href="#sequences"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_521">Sequences</a></a></h4>
<p><code>Eval-sequence</code> is used by <code>apply</code> to evaluate the sequence of
expressions in a procedure body and by <code>eval</code> to evaluate the sequence
of expressions in a <code>begin</code> expression. It takes as arguments a sequence
of expressions and an environment, and evaluates the expressions in the
order in which they occur. The value returned is the value of the final
expression.</p>
<pre><code class="language-scheme editable">(define (eval-sequence exps env)
  (cond ((last-exp? exps) (eval (first-exp exps) env))
        (else (eval (first-exp exps) env)
              (eval-sequence (rest-exps exps) env))))
</code></pre>
<h4 id="assignments-and-definitions"><a class="header" href="#assignments-and-definitions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_522">Assignments and definitions</a></a></h4>
<p>The following procedure handles assignments to variables. It calls
<code>eval</code> to find the value to be assigned and transmits the variable and
the resulting value to <code>set-variable-value!</code> to be installed in the
designated environment.</p>
<pre><code class="language-scheme editable">(define (eval-assignment exp env)
  (set-variable-value! (assignment-variable exp)
                       (eval (assignment-value exp) env)
                       env)
  'ok)
</code></pre>
<p>Definitions of variables are handled in a similar
manner.<a href="book-Z-H-26.html#footnote_Temp_523">^[7]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (eval-definition exp env)
  (define-variable! (definition-variable exp)
                    (eval (definition-value exp) env)
                    env)
  'ok)
</code></pre>
<p>We have chosen here to return the symbol <code>ok</code> as the value of an
assignment or a
definition.<a href="book-Z-H-26.html#footnote_Temp_524">^[8]{.small}^</a></p>
<p><strong>Exercise 4.1.</strong></p>
<p>Notice
that we cannot tell whether the metacircular evaluator evaluates
operands from left to right or from right to left. Its evaluation order
is inherited from the underlying Lisp: If the arguments to <code>cons</code> in
<code>list-of-values</code> are evaluated from left to right, then <code>list-of-values</code>
will evaluate operands from left to right; and if the arguments to
<code>cons</code> are evaluated from right to left, then <code>list-of-values</code> will
evaluate operands from right to left.</p>
<p>Write a version of <code>list-of-values</code> that evaluates operands from left to
right regardless of the order of evaluation in the underlying Lisp. Also
write a version of <code>list-of-values</code> that evaluates operands from right
to left.</p>
<h3 id="412"><a class="header" href="#412">[4.1.2</a></h3>
<p>Representing Expressions](book-Z-H-4.html#%<em>toc</em>%_sec_4.1.2)</p>
<p>The evaluator is
reminiscent of the symbolic differentiation program discussed in
section
<a href="book-Z-H-16.html#%_sec_2.3.2">2.3.2</a>. Both programs operate on
symbolic expressions. In both programs, the result of operating on a
compound expression is determined by operating recursively on the pieces
of the expression and combining the results in a way that depends on the
type of the expression. In both programs we used data
abstraction to decouple the general rules of operation from the details
of how expressions are represented. In the differentiation program this
meant that the same differentiation procedure could deal with algebraic
expressions in prefix form, in infix form, or in some other form. For
the evaluator, this means that the syntax of the language being
evaluated is determined solely by the procedures that classify and
extract pieces of expressions.</p>
<p>Here is the specification of the syntax of our language:</p>
<p>¤ The only self-evaluating items are numbers and strings:</p>
<pre><code class="language-scheme editable">(define (self-evaluating? exp)
  (cond ((number? exp) true)
        ((string? exp) true)
        (else false)))
</code></pre>
<p>¤ Variables are represented by symbols:</p>
<pre><code class="language-scheme editable">(define (variable? exp) (symbol? exp))
</code></pre>
<p>¤ Quotations have the form
<code>(quote &lt;</code><em><code>text-of-quotation</code></em><code>&gt;)</code>:<a href="book-Z-H-26.html#footnote_Temp_526">^[9]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (quoted? exp)
  (tagged-list? exp 'quote))

(define (text-of-quotation exp) (cadr exp))
</code></pre>
<p><code>Quoted?</code> is defined in terms of the procedure <code>tagged-list?</code>, which
identifies lists beginning with a designated symbol:</p>
<pre><code class="language-scheme editable">(define (tagged-list? exp tag)
  (if (pair? exp)
      (eq? (car exp) tag)
      false))
</code></pre>
<p>¤ Assignments have the form <code>(set! &lt;</code><em><code>var</code></em><code>&gt; &lt;</code><em><code>value</code></em><code>&gt;)</code>:</p>
<pre><code class="language-scheme editable">(define (assignment? exp)
  (tagged-list? exp 'set!))
(define (assignment-variable exp) (cadr exp))
(define (assignment-value exp) (caddr exp))
</code></pre>
<p>¤ Definitions have the form</p>
<p><code>(define &lt;</code><em><code>var</code></em><code>&gt; &lt;</code><em><code>value</code></em><code>&gt;)</code></p>
<p>or the form</p>
<p><code>(define (&lt;</code><em><code>var</code></em><code>&gt; &lt;</code><em><code>parameter</code><del><code>1</code></del></em><code>&gt; ... &lt;</code><em><code>parameter</code>~</em><code>n</code><em>~</em>`&gt;)</p>
<p>&lt;<code>*</code>body<code>*</code>&gt;)`</p>
<p>The latter form (standard procedure
definition) is syntactic sugar for</p>
<p><code>(define &lt;</code><em><code>var</code></em>`&gt;</p>
<p>(lambda
(&lt;<code>*</code>parameter<code>~</code>1<code>~*</code>&gt;
...
&lt;<code>*</code>parameter<code>~*</code>n<code>*~*</code>&gt;)</p>
<p>&lt;<code>*</code>body<code>*</code>&gt;))`</p>
<p>The corresponding syntax procedures are the following:</p>
<pre><code class="language-scheme editable">(define (definition? exp)
  (tagged-list? exp 'define))
(define (definition-variable exp)
  (if (symbol? (cadr exp))
      (cadr exp)
      (caadr exp)))
(define (definition-value exp)
  (if (symbol? (cadr exp))
      (caddr exp)
      (make-lambda (cdadr exp)   ; formal parameters
                   (cddr exp)))) ; body
</code></pre>
<p>¤ <code>Lambda</code> expressions are lists that begin with the symbol <code>lambda</code>:</p>
<pre><code class="language-scheme editable">(define (lambda? exp) (tagged-list? exp 'lambda))
(define (lambda-parameters exp) (cadr exp))
(define (lambda-body exp) (cddr exp))
</code></pre>
<p>We also provide a constructor for <code>lambda</code> expressions, which is used by
<code>definition-value</code>, above:</p>
<pre><code class="language-scheme editable">(define (make-lambda parameters body)
  (cons 'lambda (cons parameters body)))
</code></pre>
<p>¤ Conditionals begin with <code>if</code> and have a predicate, a consequent, and
an (optional) alternative. If the expression has no alternative part, we
provide <code>false</code> as the
alternative.<a href="book-Z-H-26.html#footnote_Temp_527">^[10]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (if? exp) (tagged-list? exp 'if))
(define (if-predicate exp) (cadr exp))
(define (if-consequent exp) (caddr exp))
(define (if-alternative exp)
  (if (not (null? (cdddr exp)))
      (cadddr exp)
      'false))
</code></pre>
<p>We also provide a constructor for <code>if</code> expressions, to be used by
<code>cond-&gt;if</code> to transform <code>cond</code> expressions into <code>if</code> expressions:</p>
<pre><code class="language-scheme editable">(define (make-if predicate consequent alternative)
  (list 'if predicate consequent alternative))
</code></pre>
<p>¤ <code>Begin</code> packages a sequence of expressions into a single expression.
We include syntax operations on <code>begin</code> expressions to extract the
actual sequence from the <code>begin</code> expression, as well as selectors that
return the first expression and the rest of the expressions in the
sequence.<a href="book-Z-H-26.html#footnote_Temp_528">^[11]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (begin? exp) (tagged-list? exp 'begin))
(define (begin-actions exp) (cdr exp))
(define (last-exp? seq) (null? (cdr seq)))
(define (first-exp seq) (car seq))
(define (rest-exps seq) (cdr seq))
</code></pre>
<p>We also include a constructor <code>sequence-&gt;exp</code> (for use by <code>cond-&gt;if</code>)
that transforms a sequence into a single expression, using <code>begin</code> if
necessary:</p>
<pre><code class="language-scheme editable">(define (sequence-&gt;exp seq)
  (cond ((null? seq) seq)
        ((last-exp? seq) (first-exp seq))
        (else (make-begin seq))))
(define (make-begin seq) (cons 'begin seq))
</code></pre>
<p>¤ A procedure application is any compound expression that is not one of
the above expression types. The <code>car</code> of the expression is the operator,
and the <code>cdr</code> is the list of operands:</p>
<pre><code class="language-scheme editable">(define (application? exp) (pair? exp))
(define (operator exp) (car exp))
(define (operands exp) (cdr exp))
(define (no-operands? ops) (null? ops))
(define (first-operand ops) (car ops))
(define (rest-operands ops) (cdr ops))
</code></pre>
<h4 id="derived-expressions"><a class="header" href="#derived-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_529">Derived expressions</a></a></h4>
<p>Some
special forms in our language can be defined in terms of expressions
involving other special forms, rather than being implemented directly.
One example is <code>cond</code>, which can be implemented as a nest of <code>if</code>
expressions. For example, we can reduce the problem of evaluating the
expression</p>
<pre><code class="language-scheme editable">(cond ((&gt; x 0) x)
      ((= x 0) (display 'zero) 0)
      (else (- x)))
</code></pre>
<p>to the problem of evaluating the following expression involving <code>if</code> and
<code>begin</code> expressions:</p>
<pre><code class="language-scheme editable">(if (&gt; x 0)
    x
    (if (= x 0)
        (begin (display 'zero)
               0)
        (- x)))
</code></pre>
<p>Implementing the evaluation of <code>cond</code> in this way simplifies the
evaluator because it reduces the number of special forms for which the
evaluation process must be explicitly specified.</p>
<p>We include syntax procedures that extract the parts of a <code>cond</code>
expression, and a procedure <code>cond-&gt;if</code> that transforms <code>cond</code>
expressions into <code>if</code> expressions. A case analysis begins with <code>cond</code>
and has a list of predicate-action clauses. A clause is an <code>else</code> clause
if its predicate is the symbol
<code>else</code>.<a href="book-Z-H-26.html#footnote_Temp_530">^[12]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (cond? exp) (tagged-list? exp 'cond))
(define (cond-clauses exp) (cdr exp))
(define (cond-else-clause? clause)
  (eq? (cond-predicate clause) 'else))
(define (cond-predicate clause) (car clause))
(define (cond-actions clause) (cdr clause))
(define (cond-&gt;if exp)
  (expand-clauses (cond-clauses exp)))

(define (expand-clauses clauses)
  (if (null? clauses)
      'false                         ; no else clause
      (let ((first (car clauses))
            (rest (cdr clauses)))
        (if (cond-else-clause? first)
            (if (null? rest)
                (sequence-&gt;exp (cond-actions first))
                (error "ELSE clause isn't last -- COND-&gt;IF"
                       clauses))
            (make-if (cond-predicate first)
                     (sequence-&gt;exp (cond-actions first))
                     (expand-clauses rest))))))
</code></pre>
<p>Expressions (such as <code>cond</code>) that we choose to implement as syntactic
transformations are called <em>derived expressions</em>. <code>Let</code> expressions are
also derived expressions (see
exercise
<a href="book-Z-H-26.html#%_thm_4.6">4.6</a>).<a href="book-Z-H-26.html#footnote_Temp_531">^[13]{.small}^</a></p>
<p><strong>Exercise 4.2.</strong></p>
<p>Louis Reasoner plans to
reorder the <code>cond</code> clauses in <code>eval</code> so that the clause for procedure
applications appears before the clause for assignments. He argues that
this will make the interpreter more efficient: Since programs usually
contain more applications than assignments, definitions, and so on, his
modified <code>eval</code> will usually check fewer clauses than the original
<code>eval</code> before identifying the type of an expression.</p>
<p>a. What is wrong with Louis's plan? (Hint: What will Louis's
evaluator do with the expression <code>(define x 3)</code>?)</p>
<p>b. Louis is upset that his plan didn't work. He is
willing to go to any lengths to make his evaluator recognize procedure
applications before it checks for most other kinds of expressions. Help
him by changing the syntax of the evaluated language so that procedure
applications start with <code>call</code>. For example, instead of <code>(factorial 3)</code>
we will now have to write <code>(call factorial 3)</code> and instead of <code>(+ 1 2)</code>
we will have to write <code>(call + 1 2)</code>.</p>
<p><strong>Exercise
4.3.</strong></p>
<p>Rewrite <code>eval</code> so
that the dispatch is done in data-directed style. Compare this with the
data-directed differentiation procedure of
exercise
<a href="book-Z-H-17.html#%_thm_2.73">2.73</a>. (You may use the <code>car</code> of
a compound expression as the type of the expression, as is appropriate
for the syntax implemented in this section.) .</p>
<p><strong>Exercise
4.4.</strong></p>
<p>Recall the
definitions of the special forms <code>and</code> and <code>or</code> from chapter
1:</p>
<ul>
<li><code>and</code>: The expressions are evaluated from left to right. If any
expression evaluates to false, false is returned; any remaining
expressions are not evaluated. If all the expressions evaluate to true
values, the value of the last expression is returned. If there are no
expressions then true is returned.</li>
<li><code>or</code>: The expressions are evaluated from left to right. If any
expression evaluates to a true value, that value is returned; any
remaining expressions are not evaluated. If all expressions evaluate
to false, or if there are no expressions, then false is returned.</li>
</ul>
<p>Install <code>and</code> and <code>or</code> as new special forms for the evaluator by
defining appropriate syntax procedures and evaluation procedures
<code>eval-and</code> and <code>eval-or</code>. Alternatively, show how to implement <code>and</code> and
<code>or</code> as derived expressions.</p>
<p><strong>Exercise
4.5.</strong></p>
<p>Scheme allows an
additional syntax for <code>cond</code> clauses,
<code>(&lt;</code><em><code>test</code></em><code>&gt; =&gt; &lt;</code><em><code>recipient</code></em><code>&gt;)</code>. If &lt;<em>test</em>&gt; evaluates to a true
value, then &lt;<em>recipient</em>&gt; is evaluated. Its value must be a procedure
of one argument; this procedure is then invoked on the value of the
&lt;<em>test</em>&gt;, and the result is returned as the value of the <code>cond</code>
expression. For example</p>
<pre><code class="language-scheme editable">(cond ((assoc 'b '((a 1) (b 2))) =&gt; cadr)
      (else false))
</code></pre>
<p>returns 2. Modify the handling of <code>cond</code> so that it supports this
extended syntax.</p>
<p><strong>Exercise 4.6.</strong></p>
<p><code>Let</code> expressions are
derived expressions, because</p>
<p><code>(let ((&lt;</code><em><code>var</code><del><code>1</code></del></em><code>&gt; &lt;</code><em><code>exp</code><del><code>1</code></del></em><code>&gt;) ... (&lt;</code><em><code>var</code>~</em><code>n</code><em>~</em><code>&gt; &lt;</code><em><code>exp</code>~</em><code>n</code><em>~</em>`&gt;))</p>
<p>&lt;<code>*</code>body<code>*</code>&gt;)`</p>
<p>is equivalent to</p>
<p><code>((lambda (&lt;</code><em><code>var</code><del><code>1</code></del></em><code>&gt; ... &lt;</code><em><code>var</code>~</em><code>n</code><em>~</em>`&gt;)</p>
<p>&lt;<code>*</code>body<code>*</code>&gt;)</p>
<p>&lt;<code>*</code>exp<code>~</code>1<code>~*</code>&gt;</p>
<p><img src="book-Z-G-D-18.gif" alt="" /></p>
<p>&lt;<code>*</code>exp<code>~*</code>n<code>*~*</code>&gt;)`</p>
<p>Implement a syntactic transformation <code>let-&gt;combination</code> that reduces
evaluating <code>let</code> expressions to evaluating combinations of the type
shown above, and add the appropriate clause to <code>eval</code> to handle <code>let</code>
expressions.</p>
<p><strong>Exercise
4.7.</strong></p>
<p><code>Let*</code> is similar
to <code>let</code>, except that the bindings of the <code>let</code> variables are performed
sequentially from left to right, and each binding is made in an
environment in which all of the preceding bindings are visible. For
example</p>
<pre><code class="language-scheme editable">(let* ((x 3)
       (y (+ x 2))
       (z (+ x y 5)))
  (* x z))
</code></pre>
<p>returns 39. Explain how a <code>let*</code> expression can be rewritten as a set of
nested <code>let</code> expressions, and write a procedure <code>let*-&gt;nested-lets</code> that
performs this transformation. If we have already implemented <code>let</code>
(exercise
<a href="book-Z-H-26.html#%_thm_4.6">4.6</a>) and we want to extend the
evaluator to handle <code>let*</code>, is it sufficient to add a clause to <code>eval</code>
whose action is</p>
<p><code>(eval (let*-&gt;nested-lets exp) env)</code></p>
<p>or must we explicitly expand <code>let*</code> in terms of non-derived expressions?</p>
<p><strong>Exercise
4.8.</strong></p>
<p>''Named
<code>let</code>'' is a variant of <code>let</code> that has the form</p>
<p><code>(let &lt;</code><em><code>var</code></em><code>&gt; &lt;</code><em><code>bindings</code></em><code>&gt; &lt;</code><em><code>body</code></em><code>&gt;)</code></p>
<p>The &lt;<em>bindings</em>&gt; and &lt;<em>body</em>&gt; are just as in ordinary <code>let</code>, except
that &lt;<em>var</em>&gt; is bound within &lt;<em>body</em>&gt; to a procedure whose body is
&lt;<em>body</em>&gt; and whose parameters are the variables in the &lt;<em>bindings</em>&gt;.
Thus, one can repeatedly execute the &lt;<em>body</em>&gt; by invoking the
procedure named &lt;<em>var</em>&gt;. For example, the iterative Fibonacci
procedure (section
<a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a>) can be
rewritten using named <code>let</code> as follows:</p>
<pre><code class="language-scheme editable">(define (fib n)
  (let fib-iter ((a 1)
                 (b 0)
                 (count n))
    (if (= count 0)
        b
        (fib-iter (+ a b) a (- count 1)))))
</code></pre>
<p>Modify <code>let-&gt;combination</code> of exercise
<a href="book-Z-H-26.html#%_thm_4.6">4.6</a>
to also support named <code>let</code>.</p>
<p><strong>Exercise 4.9.</strong></p>
<p>Many
languages support a variety of iteration constructs, such as <code>do</code>,
<code>for</code>, <code>while</code>, and <code>until</code>. In Scheme, iterative processes can be
expressed in terms of ordinary procedure calls, so special iteration
constructs provide no essential gain in computational power. On the
other hand, such constructs are often convenient. Design some iteration
constructs, give examples of their use, and show how to implement them
as derived expressions.</p>
<p><strong>Exercise 4.10.</strong></p>
<p>By
using data abstraction, we were able to write an <code>eval</code> procedure that
is independent of the particular syntax of the language to be evaluated.
To illustrate this, design and implement a new syntax for Scheme by
modifying the procedures in this section, without changing <code>eval</code> or
<code>apply</code>.</p>
<h3 id="413"><a class="header" href="#413">[4.1.3</a></h3>
<p>Evaluator Data Structures](book-Z-H-4.html#%<em>toc</em>%_sec_4.1.3)</p>
<p>In addition to defining the external syntax of expressions, the
evaluator implementation must also define the data structures that the
evaluator manipulates internally, as part of the execution of a program,
such as the representation of procedures and environments and the
representation of true and false.</p>
<h4 id="testing-of-predicates"><a class="header" href="#testing-of-predicates"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_541">Testing of predicates</a></a></h4>
<p>For conditionals, we accept anything to be true that is
not the explicit <code>false</code> object.</p>
<pre><code class="language-scheme editable">(define (true? x)
  (not (eq? x false)))
(define (false? x)
  (eq? x false))
</code></pre>
<h4 id="representing-procedures"><a class="header" href="#representing-procedures"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_542">Representing procedures</a></a></h4>
<p>To handle primitives, we assume that we have available
the following procedures:</p>
<ul>
<li><code>(apply-primitive-procedure &lt;</code><em><code>proc</code></em><code>&gt; &lt;</code><em><code>args</code></em><code>&gt;)</code>
applies the given primitive procedure to the argument values in the
list &lt;<em>args</em>&gt; and returns the result of the application.</li>
<li><code>(primitive-procedure? &lt;</code><em><code>proc</code></em><code>&gt;)</code>
tests whether &lt;<em>proc</em>&gt; is a primitive procedure.</li>
</ul>
<p>These mechanisms for handling primitives are further described in
section
<a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>.</p>
<p>Compound procedures are constructed from parameters, procedure bodies,
and environments using the constructor <code>make-procedure</code>:</p>
<pre><code class="language-scheme editable">(define (make-procedure parameters body env)
  (list 'procedure parameters body env))
(define (compound-procedure? p)
  (tagged-list? p 'procedure))
(define (procedure-parameters p) (cadr p))
(define (procedure-body p) (caddr p))
(define (procedure-environment p) (cadddr p))
</code></pre>
<h4 id="operations-on-environments"><a class="header" href="#operations-on-environments"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_543">Operations on Environments</a></a></h4>
<p>The evaluator needs operations for manipulating
environments. As explained in section
<a href="book-Z-H-21.html#%_sec_3.2">3.2</a>,
an environment is a sequence of frames, where each frame is a table of
bindings that associate variables with their corresponding values. We
use the following operations for manipulating environments:</p>
<ul>
<li></li>
<li><code>(lookup-variable-value &lt;</code><em><code>var</code></em><code>&gt; &lt;</code><em><code>env</code></em><code>&gt;)</code>
returns the value that is bound to the symbol &lt;<em>var</em>&gt; in the
environment &lt;<em>env</em>&gt;, or signals an error if the variable is unbound.</li>
<li><code>(extend-environment &lt;</code><em><code>variables</code></em><code>&gt; &lt;</code><em><code>values</code></em><code>&gt; &lt;</code><em><code>base-env</code></em><code>&gt;)</code>
returns a new environment, consisting of a new frame in which the
symbols in the list &lt;<em>variables</em>&gt; are bound to the corresponding
elements in the list &lt;<em>values</em>&gt;, where the enclosing environment is
the environment &lt;<em>base-env</em>&gt;.</li>
<li><code>(define-variable! &lt;</code><em><code>var</code></em><code>&gt; &lt;</code><em><code>value</code></em><code>&gt; &lt;</code><em><code>env</code></em><code>&gt;)</code>
adds to the first frame in the environment &lt;<em>env</em>&gt; a new binding
that associates the variable &lt;<em>var</em>&gt; with the value &lt;<em>value</em>&gt;.</li>
<li><code>(set-variable-value! &lt;</code><em><code>var</code></em><code>&gt; &lt;</code><em><code>value</code></em><code>&gt; &lt;</code><em><code>env</code></em><code>&gt;)</code>
changes the binding of the variable &lt;<em>var</em>&gt; in the environment
&lt;<em>env</em>&gt; so that the variable is now bound to the value &lt;<em>value</em>&gt;,
or signals an error if the variable is unbound.</li>
</ul>
<p>To implement these operations we represent an environment
as a list of frames. The enclosing environment of an environment is the
<code>cdr</code> of the list. The empty environment is simply the empty list.</p>
<pre><code class="language-scheme editable">(define (enclosing-environment env) (cdr env))
(define (first-frame env) (car env))
(define the-empty-environment '())
</code></pre>
<p>Each frame of an environment is represented as a pair of lists: a list
of the variables bound in that frame and a list of the associated
values.<a href="book-Z-H-26.html#footnote_Temp_544">^[14]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (make-frame variables values)
  (cons variables values))
(define (frame-variables frame) (car frame))
(define (frame-values frame) (cdr frame))
(define (add-binding-to-frame! var val frame)
  (set-car! frame (cons var (car frame)))
  (set-cdr! frame (cons val (cdr frame))))
</code></pre>
<p>To extend an environment by a new frame that associates variables with
values, we make a frame consisting of the list of variables and the list
of values, and we adjoin this to the environment. We signal an error if
the number of variables does not match the number of values.</p>
<pre><code class="language-scheme editable">(define (extend-environment vars vals base-env)
  (if (= (length vars) (length vals))
      (cons (make-frame vars vals) base-env)
      (if (&lt; (length vars) (length vals))
          (error "Too many arguments supplied" vars vals)
          (error "Too few arguments supplied" vars vals))))
</code></pre>
<p>To look up a variable in an environment, we scan the list of variables
in the first frame. If we find the desired variable, we return the
corresponding element in the list of values. If we do not find the
variable in the current frame, we search the enclosing environment, and
so on. If we reach the empty environment, we signal an ''unbound
variable'' error.</p>
<pre><code class="language-scheme editable">(define (lookup-variable-value var env)
  (define (env-loop env)
    (define (scan vars vals)
      (cond ((null? vars)
             (env-loop (enclosing-environment env)))
            ((eq? var (car vars))
             (car vals))
            (else (scan (cdr vars) (cdr vals)))))
    (if (eq? env the-empty-environment)
        (error "Unbound variable" var)
        (let ((frame (first-frame env)))
          (scan (frame-variables frame)
                (frame-values frame)))))
  (env-loop env))
</code></pre>
<p>To set a variable to a new value in a specified environment, we scan for
the variable, just as in <code>lookup-variable-value</code>, and change the
corresponding value when we find it.</p>
<pre><code class="language-scheme editable">(define (set-variable-value! var val env)
  (define (env-loop env)
    (define (scan vars vals)
      (cond ((null? vars)
             (env-loop (enclosing-environment env)))
            ((eq? var (car vars))
             (set-car! vals val))
            (else (scan (cdr vars) (cdr vals)))))
    (if (eq? env the-empty-environment)
        (error "Unbound variable -- SET!" var)
        (let ((frame (first-frame env)))
          (scan (frame-variables frame)
                (frame-values frame)))))
  (env-loop env))
</code></pre>
<p>To define a variable, we search the first frame for a binding for the
variable, and change the binding if it exists (just as in
<code>set-variable-value!</code>). If no such binding exists, we adjoin one to the
first frame.</p>
<pre><code class="language-scheme editable">(define (define-variable! var val env)
  (let ((frame (first-frame env)))
    (define (scan vars vals)
      (cond ((null? vars)
             (add-binding-to-frame! var val frame))
            ((eq? var (car vars))
             (set-car! vals val))
            (else (scan (cdr vars) (cdr vals)))))
    (scan (frame-variables frame)
          (frame-values frame))))
</code></pre>
<p>The method described here is only one of many plausible
ways to represent environments. Since we used data abstraction to
isolate the rest of the evaluator from the detailed choice of
representation, we could change the environment representation if we
wanted to. (See exercise
<a href="book-Z-H-26.html#%_thm_4.11">4.11</a>.) In a
production-quality Lisp system, the speed of the evaluator's
environment operations -- especially that of variable lookup -- has a
major impact on the performance of the system. The representation
described here, although conceptually simple, is not efficient and would
not ordinarily be used in a production
system.<a href="book-Z-H-26.html#footnote_Temp_545">^[15]{.small}^</a></p>
<p><strong>Exercise 4.11.</strong></p>
<p>Instead of representing a frame as a
pair of lists, we can represent a frame as a list of bindings, where
each binding is a name-value pair. Rewrite the environment operations to
use this alternative representation.</p>
<p><strong>Exercise 4.12.</strong></p>
<p>The procedures
<code>set-variable-value!</code>, <code>define-variable!</code>, and <code>lookup-variable-value</code>
can be expressed in terms of more abstract procedures for traversing the
environment structure. Define abstractions that capture the common
patterns and redefine the three procedures in terms of these
abstractions.</p>
<p><strong>Exercise 4.13.</strong></p>
<p>Scheme allows us to create new
bindings for variables by means of <code>define</code>, but provides no way to get
rid of bindings. Implement for the evaluator a special form
<code>make-unbound!</code> that removes the binding of a given symbol from the
environment in which the <code>make-unbound!</code> expression is evaluated. This
problem is not completely specified. For example, should we remove only
the binding in the first frame of the environment? Complete the
specification and justify any choices you make.</p>
<h3 id="414"><a class="header" href="#414">[4.1.4</a></h3>
<p>Running the Evaluator as a Program](book-Z-H-4.html#%<em>toc</em>%_sec_4.1.4)</p>
<p>Given the evaluator, we have in our hands a description
(expressed in Lisp) of the process by which Lisp expressions are
evaluated. One advantage of expressing the evaluator as a program is
that we can run the program. This gives us, running within Lisp, a
working model of how Lisp itself evaluates expressions. This can serve
as a framework for experimenting with evaluation rules, as we shall do
later in this chapter.</p>
<p>Our evaluator program reduces expressions ultimately to
the application of primitive procedures. Therefore, all that we need to
run the evaluator is to create a mechanism that calls on the underlying
Lisp system to model the application of primitive procedures.</p>
<p>There must be a binding for each primitive procedure name, so that when
<code>eval</code> evaluates the operator of an application of a primitive, it will
find an object to pass to <code>apply</code>. We thus set up a
global environment that associates unique
objects with the names of the primitive procedures that can appear in
the expressions we will be evaluating. The global environment also
includes bindings for the symbols <code>true</code> and <code>false</code>, so
that they can be used as variables in expressions to be evaluated.</p>
<pre><code class="language-scheme editable">(define (setup-environment)
  (let ((initial-env
         (extend-environment (primitive-procedure-names)
                             (primitive-procedure-objects)
                             the-empty-environment)))
    (define-variable! 'true true initial-env)
    (define-variable! 'false false initial-env)
    initial-env))
(define the-global-environment (setup-environment))
</code></pre>
<p>It does not matter how we represent the primitive procedure objects, so
long as <code>apply</code> can identify and apply them by using the procedures
<code>primitive-procedure?</code> and <code>apply-primitive-procedure</code>. We have chosen
to represent a primitive procedure as a list beginning with the symbol
<code>primitive</code> and containing a procedure in the underlying Lisp that
implements that primitive.</p>
<pre><code class="language-scheme editable">(define (primitive-procedure? proc)
  (tagged-list? proc 'primitive))

(define (primitive-implementation proc) (cadr proc))
</code></pre>
<p><code>Setup-environment</code> will get the primitive names and implementation
procedures from a
list:<a href="book-Z-H-26.html#footnote_Temp_549">^[16]{.small}^</a></p>
<pre><code class="language-scheme editable">(define primitive-procedures
  (list (list 'car car)
        (list 'cdr cdr)
        (list 'cons cons)
        (list 'null? null?)
        &lt;more primitives&gt;
        ))
(define (primitive-procedure-names)
  (map car
       primitive-procedures))

(define (primitive-procedure-objects)
  (map (lambda (proc) (list 'primitive (cadr proc)))
       primitive-procedures))
</code></pre>
<p>To apply a primitive procedure, we simply apply the implementation
procedure to the arguments, using the underlying Lisp
system:<a href="book-Z-H-26.html#footnote_Temp_550">^[17]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (apply-primitive-procedure proc args)
  (apply-in-underlying-scheme
   (primitive-implementation proc) args))
</code></pre>
<p>For convenience in running the
metacircular evaluator, we provide a <em>driver loop</em> that models the
read-eval-print loop of the underlying Lisp system. It prints a
<em>prompt</em>, reads an input expression, evaluates this
expression in the global environment, and prints the result. We precede
each printed result by an <em>output prompt</em> so as to distinguish the value
of the expression from other output that may be
printed.<a href="book-Z-H-26.html#footnote_Temp_551">^[18]{.small}^</a></p>
<pre><code class="language-scheme editable">(define input-prompt ";;; M-Eval input:")
(define output-prompt ";;; M-Eval value:")
(define (driver-loop)
  (prompt-for-input input-prompt)
  (let ((input (read)))
    (let ((output (eval input the-global-environment)))
      (announce-output output-prompt)
      (user-print output))))
(define (prompt-for-input string)
  (newline) (newline) (display string) (newline))

(define (announce-output string)
  (newline) (display string) (newline))
</code></pre>
<p>We use a special printing procedure, <code>user-print</code>, to avoid printing the
environment part of a compound procedure, which may be a very long list
(or may even contain cycles).</p>
<pre><code class="language-scheme editable">(define (user-print object)
  (if (compound-procedure? object)
      (display (list 'compound-procedure
                   (procedure-parameters object)
                   (procedure-body object)
                   '&lt;procedure-env&gt;))
      (display object)))
</code></pre>
<p>Now all we need to do to run the evaluator is to initialize the global
environment and start the driver loop. Here is a sample interaction:</p>
<pre><code class="language-scheme editable">(define the-global-environment (setup-environment))
(driver-loop)
</code></pre>
<p><em><code>;;; M-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(define (append x y)
  (if (null? x)
      y
      (cons (car x)
            (append (cdr x) y))))
</code></pre>
<p><em><code>;;; M-Eval value:</code></em>
<em><code>ok</code></em>
<em><code>;;; M-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(append '(a b c) '(d e f))
</code></pre>
<p><em><code>;;; M-Eval value:</code></em>
<em><code>(a b c d e f)</code></em></p>
<p><strong>Exercise 4.14.</strong></p>
<p>Eva Lu Ator and Louis Reasoner are
each experimenting with the metacircular evaluator. Eva types in the
definition of <code>map</code>, and runs some test programs that use it. They work
fine. Louis, in contrast, has installed the system version of <code>map</code> as a
primitive for the metacircular evaluator. When he tries it, things go
terribly wrong. Explain why Louis's <code>map</code> fails even though Eva's
works.</p>
<h3 id="415"><a class="header" href="#415">[4.1.5</a></h3>
<p>Data as Programs](book-Z-H-4.html#%<em>toc</em>%_sec_4.1.5)</p>
<p>In thinking about a Lisp program that
evaluates Lisp expressions, an analogy might be helpful. One operational
view of the meaning of a program is that a program is a
description of an abstract (perhaps infinitely large) machine. For
example, consider the familiar program to compute factorials:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (if (= n 1)
      1
      (* (factorial (- n 1)) n)))
</code></pre>
<p>We may regard this program as the description of a
machine containing parts that decrement, multiply, and test for
equality, together with a two-position switch and another factorial
machine. (The factorial machine is infinite because it contains another
factorial machine within it.) Figure
<a href="book-Z-H-26.html#%_fig_4.2">4.2</a>
is a flow diagram for the factorial machine, showing how the parts are
wired together.</p>
<p><img src="ch4-Z-G-2.gif" alt="" /></p>
<p><strong>Figure 4.2:</strong></p>
<p>The factorial program, viewed as an abstract machine.</p>
<p>In a similar way, we can regard the evaluator as a very
special machine that takes as input a description of a machine. Given
this input, the evaluator configures itself to emulate the machine
described. For example, if we feed our evaluator the definition of
<code>factorial</code>, as shown in figure
<a href="book-Z-H-26.html#%_fig_4.3">4.3</a>, the
evaluator will be able to compute factorials.</p>
<p><img src="ch4-Z-G-3.gif" alt="" /></p>
<p><strong>Figure 4.3:</strong></p>
<p>The evaluator emulating a factorial machine.</p>
<p>From this perspective, our evaluator is
seen to be a <em>universal machine</em>. It mimics other machines when these
are described as Lisp
programs.<a href="book-Z-H-26.html#footnote_Temp_553">^[19]{.small}^</a>
This is striking. Try to imagine an analogous evaluator for electrical
circuits. This would be a circuit that takes as input a signal encoding
the plans for some other circuit, such as a filter. Given this input,
the circuit evaluator would then behave like a filter with the same
description. Such a universal electrical circuit is almost unimaginably
complex. It is remarkable that the program evaluator is a rather simple
program.<a href="book-Z-H-26.html#footnote_Temp_554">^[20]{.small}^</a></p>
<p>Another striking aspect of the evaluator is that it acts as a bridge
between the data objects that are manipulated by our programming
language and the programming language itself. Imagine that the evaluator
program (implemented in Lisp) is running, and that a user is typing
expressions to the evaluator and observing the results. From the
perspective of the user, an input expression such as <code>(* x x)</code> is an
expression in the programming language, which the evaluator should
execute. From the perspective of the evaluator, however, the expression
is simply a list (in this case, a list of three symbols: <code>*</code>, <code>x</code>, and
<code>x</code>) that is to be manipulated according to a well-defined set of rules.</p>
<p>That the user's programs are the evaluator's data need not be a source
of confusion. In fact, it is sometimes convenient to ignore this
distinction, and to give the user the ability to explicitly evaluate a
data object as a Lisp expression, by making <code>eval</code> available for use in
programs. Many Lisp dialects provide a
primitive <code>eval</code> procedure that takes as
arguments an expression and an environment and evaluates the expression
relative to the
environment.<a href="book-Z-H-26.html#footnote_Temp_555">^[21]{.small}^</a>
Thus,</p>
<pre><code class="language-scheme editable">(eval '(* 5 5) user-initial-environment)
</code></pre>
<p>and</p>
<pre><code class="language-scheme editable">(eval (cons '* (list 5 5)) user-initial-environment)
</code></pre>
<p>will both return
25.<a href="book-Z-H-26.html#footnote_Temp_556">^[22]{.small}^</a></p>
<p><strong>Exercise 4.15.</strong></p>
<p>Given a one-argument
procedure <code>p</code> and an object <code>a</code>, <code>p</code> is said to ''halt'' on <code>a</code> if
evaluating the expression <code>(p a)</code> returns a value (as opposed to
terminating with an error message or running forever). Show that it is
impossible to write a procedure <code>halts?</code> that correctly determines
whether <code>p</code> halts on <code>a</code> for any procedure <code>p</code> and object <code>a</code>. Use the
following reasoning: If you had such a procedure <code>halts?</code>, you could
implement the following program:</p>
<pre><code class="language-scheme editable">(define (run-forever) (run-forever))

(define (try p)
  (if (halts? p p)
      (run-forever)
      'halted))
</code></pre>
<p>Now consider evaluating the expression <code>(try try)</code> and show that any
possible outcome (either halting or running forever) violates the
intended behavior of
<code>halts?</code>.<a href="book-Z-H-26.html#footnote_Temp_558">^[23]{.small}^</a></p>
<h3 id="416"><a class="header" href="#416">[4.1.6</a></h3>
<p>Internal Definitions](book-Z-H-4.html#%<em>toc</em>%_sec_4.1.6)</p>
<p>Our environment model of
evaluation and our metacircular evaluator execute definitions in
sequence, extending the environment frame one definition at a time. This
is particularly convenient for interactive program development, in which
the programmer needs to freely mix the application of procedures with
the definition of new procedures. However, if we think carefully about
the internal definitions used to implement block structure (introduced
in section
<a href="book-Z-H-10.html#%_sec_1.1.8">1.1.8</a>), we will find that
name-by-name extension of the environment may not be the best way to
define local variables.</p>
<p>Consider a procedure with internal definitions, such as</p>
<pre><code class="language-scheme editable">(define (f x)
  (define (even? n)
    (if (= n 0)
        true
        (odd? (- n 1))))
  (define (odd? n)
    (if (= n 0)
        false
        (even? (- n 1))))
  &lt;rest of body of f&gt;)
</code></pre>
<p>Our intention here is that the name <code>odd?</code> in the body of the procedure
<code>even?</code> should refer to the procedure <code>odd?</code> that is defined after
<code>even?</code>. The scope of the name <code>odd?</code> is the entire body of <code>f</code>, not
just the portion of the body of <code>f</code> starting at the point where the
<code>define</code> for <code>odd?</code> occurs. Indeed, when we consider that <code>odd?</code> is
itself defined in terms of <code>even?</code> -- so that <code>even?</code> and <code>odd?</code> are
mutually recursive procedures -- we see that the only satisfactory
interpretation of the two <code>define</code>s is to regard them as if the names
<code>even?</code> and <code>odd?</code> were being added to the environment simultaneously.
More generally, in block structure, the scope of a local name is the
entire procedure body in which the <code>define</code> is evaluated.</p>
<p>As it happens, our interpreter will evaluate calls to <code>f</code> correctly, but
for an ''accidental'' reason: Since the definitions of the internal
procedures come first, no calls to these procedures will be evaluated
until all of them have been defined. Hence, <code>odd?</code> will have been
defined by the time <code>even?</code> is executed. In fact, our sequential
evaluation mechanism will give the same result as a mechanism that
directly implements simultaneous definition for any procedure in which
the internal definitions come first in a body and
evaluation of the value expressions for the defined variables doesn't
actually use any of the defined variables. (For an example of a
procedure that doesn't obey these restrictions, so that sequential
definition isn't equivalent to simultaneous definition, see
exercise
<a href="book-Z-H-26.html#%_thm_4.19">4.19</a>.)<a href="book-Z-H-26.html#footnote_Temp_559">^[24]{.small}^</a></p>
<p>There is, however, a simple way to treat definitions so that internally
defined names have truly simultaneous scope -- just create all local
variables that will be in the current environment before evaluating any
of the value expressions. One way to do this is by a syntax
transformation on <code>lambda</code> expressions. Before evaluating the body of a
<code>lambda</code> expression, we ''scan out''
and eliminate all the internal definitions in the body. The internally
defined variables will be created with a <code>let</code> and then set to their
values by assignment. For example, the procedure</p>
<p><code>(lambda &lt;</code><em><code>vars</code></em>`&gt;</p>
<p>(define
u
&lt;<code>*</code>e1<code>*</code>&gt;)</p>
<p>(define
v
&lt;<code>*</code>e2<code>*</code>&gt;)</p>
<p>&lt;<code>*</code>e3<code>*</code>&gt;)`</p>
<p>would be transformed into</p>
<p><code>(lambda &lt;</code><em><code>vars</code></em>`&gt;</p>
<p>(let
((u
'<em>unassigned</em>)</p>
<p>(v
'<em>unassigned</em>))</p>
<p>(set!
u
&lt;<code>*</code>e1<code>*</code>&gt;)</p>
<p>(set!
v
&lt;<code>*</code>e2<code>*</code>&gt;)</p>
<p>&lt;<code>*</code>e3<code>*</code>&gt;))`</p>
<p>where <code>*unassigned*</code> is a special symbol that causes looking up a
variable to signal an error if an attempt is made to use the value of
the not-yet-assigned variable.</p>
<p>An alternative strategy for scanning out internal definitions is shown
in exercise
<a href="book-Z-H-26.html#%_thm_4.18">4.18</a>. Unlike the
transformation shown above, this enforces the restriction that the
defined variables' values can be evaluated without using any of the
variables'
values.<a href="book-Z-H-26.html#footnote_Temp_560">^[25]{.small}^</a></p>
<p><strong>Exercise 4.16.</strong></p>
<p>In this exercise we implement the
method just described for interpreting internal definitions. We assume
that the evaluator supports <code>let</code> (see
exercise
<a href="book-Z-H-26.html#%_thm_4.6">4.6</a>).</p>
<p>a.</p>
<p>Change <code>lookup-variable-value</code>
(section
<a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a>) to signal an error if
the value it finds is the symbol <code>*unassigned*</code>.</p>
<p>b.</p>
<p>Write a procedure <code>scan-out-defines</code> that takes a
procedure body and returns an equivalent one that has no internal
definitions, by making the transformation described above.</p>
<p>c.</p>
<p>Install <code>scan-out-defines</code> in the interpreter, either in
<code>make-procedure</code> or in <code>procedure-body</code> (see
section
<a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a>). Which place is better?
Why?</p>
<p><strong>Exercise 4.17.</strong></p>
<p>Draw diagrams of the environment in
effect when evaluating the expression &lt;<em>e3</em>&gt; in the procedure in the
text, comparing how this will be structured when definitions are
interpreted sequentially with how it will be structured if definitions
are scanned out as described. Why is there an extra frame in the
transformed program? Explain why this difference in environment
structure can never make a difference in the behavior of a correct
program. Design a way to make the interpreter implement the
''simultaneous'' scope rule for internal definitions without
constructing the extra frame.</p>
<p><strong>Exercise 4.18.</strong></p>
<p>Consider an alternative strategy for
scanning out definitions that translates the example in the text to</p>
<p><code>(lambda &lt;</code><em><code>vars</code></em>`&gt;</p>
<p>(let
((u
'<em>unassigned</em>)</p>
<p>(v
'<em>unassigned</em>))</p>
<p>(let
((a
&lt;<code>*</code>e1<code>*</code>&gt;)</p>
<p>(b
&lt;<code>*</code>e2<code>*</code>&gt;))</p>
<p>(set!
u
a)</p>
<p>(set!
v
b))</p>
<p>&lt;<code>*</code>e3<code>*</code>&gt;))`</p>
<p>Here <code>a</code> and <code>b</code> are meant to represent new variable names, created by
the interpreter, that do not appear in the user's program. Consider the
<code>solve</code> procedure from section
<a href="book-Z-H-24.html#%_sec_3.5.4">3.5.4</a>:</p>
<pre><code class="language-scheme editable">(define (solve f y0 dt)
  (define y (integral (delay dy) y0 dt))
  (define dy (stream-map f y))
  y)
</code></pre>
<p>Will this procedure work if internal definitions are scanned out as
shown in this exercise? What if they are scanned out as shown in the
text? Explain.</p>
<p><strong>Exercise 4.19.</strong></p>
<p>Ben Bitdiddle, Alyssa P. Hacker, and
Eva Lu Ator are arguing about the desired result of evaluating the
expression</p>
<pre><code class="language-scheme editable">(let ((a 1))
  (define (f x)
    (define b (+ a x))
    (define a 5)
    (+ a b))
  (f 10))
</code></pre>
<p>Ben asserts that the result should be obtained using the sequential rule
for <code>define</code>: <code>b</code> is defined to be 11, then <code>a</code> is defined to be 5, so
the result is 16. Alyssa objects that mutual recursion requires the
simultaneous scope rule for internal procedure definitions, and that it
is unreasonable to treat procedure names differently from other names.
Thus, she argues for the mechanism implemented in
exercise
<a href="book-Z-H-26.html#%_thm_4.16">4.16</a>. This would lead to <code>a</code>
being unassigned at the time that the value for <code>b</code> is to be computed.
Hence, in Alyssa's view the procedure should produce an error. Eva has
a third opinion. She says that if the definitions of <code>a</code> and <code>b</code> are
truly meant to be simultaneous, then the value 5 for <code>a</code> should be used
in evaluating <code>b</code>. Hence, in Eva's view <code>a</code> should be 5, <code>b</code> should be
15, and the result should be 20. Which (if any) of these viewpoints do
you support? Can you devise a way to implement internal definitions so
that they behave as Eva
prefers?<a href="book-Z-H-26.html#footnote_Temp_565">^[26]{.small}^</a></p>
<p><strong>Exercise
4.20.</strong></p>
<p>Because internal definitions look
sequential but are actually simultaneous, some people prefer to avoid
them entirely, and use the special form <code>letrec</code> instead. <code>Letrec</code> looks
like <code>let</code>, so it is not surprising that the variables it binds are
bound simultaneously and have the same scope as each other. The sample
procedure <code>f</code> above can be written without internal definitions, but
with exactly the same meaning, as</p>
<pre><code class="language-scheme editable">(define (f x)
  (letrec ((even?
            (lambda (n)
              (if (= n 0)
                  true
                  (odd? (- n 1)))))
           (odd?
            (lambda (n)
              (if (= n 0)
                  false
                  (even? (- n 1))))))
    &lt;rest of body of f&gt;))
</code></pre>
<p><code>Letrec</code> expressions, which have the form</p>
<p><code>(letrec ((&lt;</code><em><code>var</code><del><code>1</code></del></em><code>&gt; &lt;</code><em><code>exp</code><del><code>1</code></del></em><code>&gt;) ... (&lt;</code><em><code>var</code>~</em><code>n</code><em>~</em><code>&gt; &lt;</code><em><code>exp</code>~</em><code>n</code><em>~</em>`&gt;))</p>
<p>&lt;<code>*</code>body<code>*</code>&gt;)`</p>
<p>are a variation on <code>let</code> in which the expressions &lt;<em>exp~<em>k</em>~</em>&gt; that
provide the initial values for the variables &lt;<em>var~<em>k</em>~</em>&gt; are
evaluated in an environment that includes all the <code>letrec</code> bindings.
This permits recursion in the bindings, such as the mutual recursion of
<code>even?</code> and <code>odd?</code> in the example above, or the
evaluation of 10 factorial with</p>
<pre><code class="language-scheme editable">(letrec ((fact
          (lambda (n)
            (if (= n 1)
                1
                (* n (fact (- n 1)))))))
  (fact 10))
</code></pre>
<p>a. Implement <code>letrec</code> as a derived expression, by transforming a
<code>letrec</code> expression into a <code>let</code> expression as shown in the text above
or in exercise
<a href="book-Z-H-26.html#%_thm_4.18">4.18</a>. That is, the
<code>letrec</code> variables should be created with a <code>let</code> and then be assigned
their values with <code>set!</code>.</p>
<p>b. Louis Reasoner is confused by all this fuss about internal
definitions. The way he sees it, if you don't like to use <code>define</code>
inside a procedure, you can just use <code>let</code>. Illustrate what is loose
about his reasoning by drawing an environment diagram that shows the
environment in which the &lt;<em>rest of body of <code>f</code></em>&gt; is evaluated during
evaluation of the expression <code>(f 5)</code>, with <code>f</code> defined as in this
exercise. Draw an environment diagram for the same evaluation, but with
<code>let</code> in place of <code>letrec</code> in the definition of <code>f</code>.</p>
<p><strong>Exercise 4.21.</strong></p>
<p>Amazingly, Louis's
intuition in exercise
<a href="book-Z-H-26.html#%_thm_4.20">4.20</a> is correct. It
is indeed possible to specify recursive procedures without using
<code>letrec</code> (or even <code>define</code>), although the method for accomplishing this
is much more subtle than Louis imagined. The following expression
computes 10 factorial by applying a recursive factorial
procedure:<a href="book-Z-H-26.html#footnote_Temp_568">^[27]{.small}^</a></p>
<pre><code class="language-scheme editable">((lambda (n)
   ((lambda (fact)
      (fact fact n))
    (lambda (ft k)
      (if (= k 1)
          1
          (* k (ft ft (- k 1)))))))
 10)
</code></pre>
<p>a. Check (by evaluating the expression) that this really does compute
factorials. Devise an analogous expression for computing Fibonacci
numbers.</p>
<p>b. Consider the following procedure, which includes mutually recursive
internal definitions:</p>
<pre><code class="language-scheme editable">(define (f x)
  (define (even? n)
    (if (= n 0)
        true
        (odd? (- n 1))))
  (define (odd? n)
    (if (= n 0)
        false
        (even? (- n 1))))
  (even? x))
</code></pre>
<p>Fill in the missing expressions to complete an alternative definition of
<code>f</code>, which uses neither internal definitions nor <code>letrec</code>:</p>
<pre><code class="language-scheme editable">(define (f x)
  ((lambda (even? odd?)
     (even? even? odd? x))
   (lambda (ev? od? n)
     (if (= n 0) true (od? &lt;??&gt; &lt;??&gt; &lt;??&gt;)))
   (lambda (ev? od? n)
     (if (= n 0) false (ev? &lt;??&gt; &lt;??&gt; &lt;??&gt;)))))
</code></pre>
<h3 id="417"><a class="header" href="#417">[4.1.7</a></h3>
<p>Separating Syntactic Analysis from Execution](book-Z-H-4.html#%<em>toc</em>%_sec_4.1.7)</p>
<p>The evaluator implemented above is simple,
but it is very inefficient, because the syntactic analysis of
expressions is interleaved with their execution. Thus if a program is
executed many times, its syntax is analyzed many times. Consider, for
example, evaluating <code>(factorial 4)</code> using the following definition of
<code>factorial</code>:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (if (= n 1)
      1
      (* (factorial (- n 1)) n)))
</code></pre>
<p>Each time <code>factorial</code> is called, the evaluator must determine that the
body is an <code>if</code> expression and extract the predicate. Only then can it
evaluate the predicate and dispatch on its value. Each time it evaluates
the expression <code>(* (factorial (- n 1)) n)</code>, or the subexpressions
<code>(factorial (- n 1))</code> and <code>(- n 1)</code>, the evaluator must perform the case
analysis in <code>eval</code> to determine that the expression is an application,
and must extract its operator and operands. This analysis is expensive.
Performing it repeatedly is wasteful.</p>
<p>We can transform the evaluator to be significantly more efficient by
arranging things so that syntactic analysis is performed only
once.<a href="book-Z-H-26.html#footnote_Temp_569">^[28]{.small}^</a>
We split <code>eval</code>, which takes an expression and an environment, into two
parts. The procedure <code>analyze</code> takes only the expression. It performs
the syntactic analysis and returns a new procedure, the
<em>execution procedure</em>, that encapsulates the work to be
done in executing the analyzed expression. The execution procedure takes
an environment as its argument and completes the evaluation. This saves
work because <code>analyze</code> will be called only once on an expression, while
the execution procedure may be called many times.</p>
<p>With the separation into analysis and execution, <code>eval</code> now becomes</p>
<pre><code class="language-scheme editable">(define (eval exp env)
  ((analyze exp) env))
</code></pre>
<p>The result of calling <code>analyze</code> is the execution procedure to be applied
to the environment. The <code>analyze</code> procedure is the same case analysis as
performed by the original <code>eval</code> of
section
<a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>, except that the
procedures to which we dispatch perform only analysis, not full
evaluation:</p>
<pre><code class="language-scheme editable">(define (analyze exp)
  (cond ((self-evaluating? exp) 
         (analyze-self-evaluating exp))
        ((quoted? exp) (analyze-quoted exp))
        ((variable? exp) (analyze-variable exp))
        ((assignment? exp) (analyze-assignment exp))
        ((definition? exp) (analyze-definition exp))
        ((if? exp) (analyze-if exp))
        ((lambda? exp) (analyze-lambda exp))
        ((begin? exp) (analyze-sequence (begin-actions exp)))
        ((cond? exp) (analyze (cond-&gt;if exp)))
        ((application? exp) (analyze-application exp))
        (else
         (error "Unknown expression type -- ANALYZE" exp))))
</code></pre>
<p>Here is the simplest syntactic analysis procedure, which handles
self-evaluating expressions. It returns an execution procedure that
ignores its environment argument and just returns the expression:</p>
<pre><code class="language-scheme editable">(define (analyze-self-evaluating exp)
  (lambda (env) exp))
</code></pre>
<p>For a quoted expression, we can gain a little efficiency by extracting
the text of the quotation only once, in the analysis phase, rather than
in the execution phase.</p>
<pre><code class="language-scheme editable">(define (analyze-quoted exp)
  (let ((qval (text-of-quotation exp)))
    (lambda (env) qval)))
</code></pre>
<p>Looking up a variable value must still be done in the execution phase,
since this depends upon knowing the
environment.<a href="book-Z-H-26.html#footnote_Temp_570">^[29]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (analyze-variable exp)
  (lambda (env) (lookup-variable-value exp env)))
</code></pre>
<p><code>Analyze-assignment</code> also must defer actually setting the variable until
the execution, when the environment has been supplied. However, the fact
that the <code>assignment-value</code> expression can be analyzed (recursively)
during analysis is a major gain in efficiency, because the
<code>assignment-value</code> expression will now be analyzed only once. The same
holds true for definitions.</p>
<pre><code class="language-scheme editable">(define (analyze-assignment exp)
  (let ((var (assignment-variable exp))
        (vproc (analyze (assignment-value exp))))
    (lambda (env)
      (set-variable-value! var (vproc env) env)
      'ok)))
(define (analyze-definition exp)
  (let ((var (definition-variable exp))
        (vproc (analyze (definition-value exp))))
    (lambda (env)
      (define-variable! var (vproc env) env)
      'ok)))
</code></pre>
<p>For <code>if</code> expressions, we extract and analyze the predicate, consequent,
and alternative at analysis time.</p>
<pre><code class="language-scheme editable">(define (analyze-if exp)
  (let ((pproc (analyze (if-predicate exp)))
        (cproc (analyze (if-consequent exp)))
        (aproc (analyze (if-alternative exp))))
    (lambda (env)
      (if (true? (pproc env))
          (cproc env)
          (aproc env)))))
</code></pre>
<p>Analyzing a <code>lambda</code> expression also achieves a major gain in
efficiency: We analyze the <code>lambda</code> body only once, even though
procedures resulting from evaluation of the <code>lambda</code> may be applied many
times.</p>
<pre><code class="language-scheme editable">(define (analyze-lambda exp)
  (let ((vars (lambda-parameters exp))
        (bproc (analyze-sequence (lambda-body exp))))
    (lambda (env) (make-procedure vars bproc env))))
</code></pre>
<p>Analysis of a sequence of expressions (as in a <code>begin</code> or the body of a
<code>lambda</code> expression) is more
involved.<a href="book-Z-H-26.html#footnote_Temp_571">^[30]{.small}^</a>
Each expression in the sequence is analyzed, yielding an execution
procedure. These execution procedures are combined to produce an
execution procedure that takes an environment as argument and
sequentially calls each individual execution procedure with the
environment as argument.</p>
<pre><code class="language-scheme editable">(define (analyze-sequence exps)
  (define (sequentially proc1 proc2)
    (lambda (env) (proc1 env) (proc2 env)))
  (define (loop first-proc rest-procs)
    (if (null? rest-procs)
        first-proc
        (loop (sequentially first-proc (car rest-procs))
              (cdr rest-procs))))
  (let ((procs (map analyze exps)))
    (if (null? procs)
        (error "Empty sequence -- ANALYZE"))
    (loop (car procs) (cdr procs))))
</code></pre>
<p>To analyze an application, we analyze the operator and operands and
construct an execution procedure that calls the operator execution
procedure (to obtain the actual procedure to be applied) and the operand
execution procedures (to obtain the actual arguments). We then pass
these to <code>execute-application</code>, which is the analog of <code>apply</code> in
section
<a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>. <code>Execute-application</code>
differs from <code>apply</code> in that the procedure body for a compound procedure
has already been analyzed, so there is no need to do further analysis.
Instead, we just call the execution procedure for the body on the
extended environment.</p>
<pre><code class="language-scheme editable">(define (analyze-application exp)
  (let ((fproc (analyze (operator exp)))
        (aprocs (map analyze (operands exp))))
    (lambda (env)
      (execute-application (fproc env)
                           (map (lambda (aproc) (aproc env))
                                aprocs)))))
(define (execute-application proc args)
  (cond ((primitive-procedure? proc)
         (apply-primitive-procedure proc args))
        ((compound-procedure? proc)
         ((procedure-body proc)
          (extend-environment (procedure-parameters proc)
                              args
                              (procedure-environment proc))))
        (else
         (error
          "Unknown procedure type -- EXECUTE-APPLICATION"
          proc))))
</code></pre>
<p>Our new evaluator uses the same data structures, syntax procedures, and
run-time support procedures as in
sections
<a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a>,</p>
<p><a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a>,
and
<a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>.</p>
<p><strong>Exercise 4.22.</strong></p>
<p>Extend the evaluator
in this section to support the special form <code>let</code>. (See
exercise
<a href="book-Z-H-26.html#%_thm_4.6">4.6</a>.)</p>
<p><strong>Exercise 4.23.</strong></p>
<p>Alyssa P. Hacker
doesn't understand why <code>analyze-sequence</code> needs to be so complicated.
All the other analysis procedures are straightforward transformations of
the corresponding evaluation procedures (or <code>eval</code> clauses) in
section
<a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>. She expected
<code>analyze-sequence</code> to look like this:</p>
<pre><code class="language-scheme editable">(define (analyze-sequence exps)
  (define (execute-sequence procs env)
    (cond ((null? (cdr procs)) ((car procs) env))
          (else ((car procs) env)
                (execute-sequence (cdr procs) env))))
  (let ((procs (map analyze exps)))
    (if (null? procs)
        (error "Empty sequence -- ANALYZE"))
    (lambda (env) (execute-sequence procs env))))
</code></pre>
<p>Eva Lu Ator explains to Alyssa that the version in the text does more of
the work of evaluating a sequence at analysis time. Alyssa's
sequence-execution procedure, rather than having the calls to the
individual execution procedures built in, loops through the procedures
in order to call them: In effect, although the individual expressions in
the sequence have been analyzed, the sequence itself has not been.</p>
<p>Compare the two versions of <code>analyze-sequence</code>. For example, consider
the common case (typical of procedure bodies) where the sequence has
just one expression. What work will the execution procedure produced by
Alyssa's program do? What about the execution procedure produced by the
program in the text above? How do the two versions compare for a
sequence with two expressions?</p>
<p><strong>Exercise 4.24.</strong></p>
<p>Design and carry out some
experiments to compare the speed of the original metacircular evaluator
with the version in this section. Use your results to estimate the
fraction of time that is spent in analysis versus execution for various
procedures.</p>
<hr />
<p><a href="book-Z-H-26.html#call_footnote_Temp_510">^[3]{.small}^</a>
Even so, there will remain important aspects of the evaluation process
that are not elucidated by our evaluator. The most important of these
are the detailed mechanisms by which procedures call other procedures
and return values to their callers. We will address these issues in
chapter
5, where we take a closer look at the evaluation process by
implementing the evaluator as a simple register machine.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_511">^[4]{.small}^</a>
If we grant ourselves the ability to apply primitives,
then what remains for us to implement in the evaluator?
The job of the evaluator is not to specify the primitives of the
language, but rather to provide the connective tissue -- the means of
combination and the means of abstraction -- that binds a collection of
primitives to form a language. Specifically:</p>
<ul>
<li>The evaluator enables us to deal with nested expressions. For example,
although simply applying primitives would suffice for evaluating the
expression <code>(+ 1 6)</code>, it is not adequate for handling <code>(+ 1 (* 2 3))</code>.
As far as the primitive procedure <code>+</code> is concerned, its arguments must
be numbers, and it would choke if we passed it the expression
<code>(* 2 3)</code> as an argument. One important role of the evaluator is to
choreograph procedure composition so that <code>(* 2 3)</code> is reduced to 6
before being passed as an argument to <code>+</code>.</li>
<li>The evaluator allows us to use variables. For example, the primitive
procedure for addition has no way to deal with expressions such as
<code>(+ x 1)</code>. We need an evaluator to keep track of variables and obtain
their values before invoking the primitive procedures.</li>
<li>The evaluator allows us to define compound procedures. This involves
keeping track of procedure definitions, knowing how to use these
definitions in evaluating expressions, and providing a mechanism that
enables procedures to accept arguments.</li>
<li>The evaluator provides the special forms, which must be evaluated
differently from procedure calls.</li>
</ul>
<p><a href="book-Z-H-26.html#call_footnote_Temp_518">^[5]{.small}^</a>
We could have simplified the <code>application?</code> clause in <code>eval</code> by using
<code>map</code> (and stipulating that <code>operands</code> returns a list) rather than
writing an explicit <code>list-of-values</code> procedure. We chose not to use
<code>map</code> here to emphasize the fact that the
evaluator can be implemented without any
use of higher-order procedures (and thus could be written in a language
that doesn't have higher-order procedures), even though the language
that it supports will include higher-order procedures.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_520">^[6]{.small}^</a>
In this case, the language being implemented and the implementation
language are the same. Contemplation of the meaning of
<code>true?</code> here yields expansion of consciousness without
the abuse of substance.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_523">^[7]{.small}^</a>
This implementation of <code>define</code> ignores a subtle issue in the handling
of internal definitions, although it works correctly in most cases. We
will see what the problem is and how to solve it in
section
<a href="book-Z-H-26.html#%_sec_4.1.6">4.1.6</a>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_524">^[8]{.small}^</a>
As we said when we introduced <code>define</code> and <code>set!</code>, these values are
implementation-dependent in Scheme -- that is, the implementor can
choose what value to return.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_526">^[9]{.small}^</a>
As mentioned in section
<a href="book-Z-H-16.html#%_sec_2.3.1">2.3.1</a>, the
evaluator sees a quoted expression as a list beginning with <code>quote</code>,
even if the expression is typed with the quotation mark. For example,
the expression <code>'a</code> would be seen by the evaluator as <code>(quote a)</code>. See
exercise
<a href="book-Z-H-16.html#%_thm_2.55">2.55</a>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_527">^[10]{.small}^</a>
The value of an <code>if</code> expression when the predicate is false and there is
no alternative is unspecified in Scheme; we have chosen here to make it
false. We will support the use of the variables <code>true</code> and <code>false</code> in
expressions to be evaluated by binding them in the global environment.
See section
<a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_528">^[11]{.small}^</a>
These selectors for a list of expressions -- and the corresponding ones
for a list of operands -- are not intended as a data abstraction. They
are introduced as mnemonic names for the basic list operations in order
to make it easier to understand the explicit-control evaluator in
section
<a href="book-Z-H-34.html#%_sec_5.4">5.4</a>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_530">^[12]{.small}^</a>
The value of a <code>cond</code> expression when all the predicates are false and
there is no <code>else</code> clause is unspecified in Scheme; we have chosen here
to make it false.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_531">^[13]{.small}^</a>
Practical Lisp systems provide a mechanism that allows a user to add new
derived expressions and specify their implementation as syntactic
transformations without modifying the evaluator. Such a user-defined
transformation is called a <em>macro</em>. Although it is easy
to add an elementary mechanism for defining macros, the resulting
language has subtle name-conflict problems. There has been much research
on mechanisms for macro definition that do not cause these difficulties.
See, for
example, Kohlbecker 1986, Clinger and Rees 1991, and Hanson 1991.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_544">^[14]{.small}^</a>
Frames are not really a data abstraction in the following code:
<code>Set-variable-value!</code> and <code>define-variable!</code> use <code>set-car!</code> to directly
modify the values in a frame. The purpose of the frame procedures is to
make the environment-manipulation procedures easy to read.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_545">^[15]{.small}^</a>
The drawback of this representation (as well as the variant in
exercise
<a href="book-Z-H-26.html#%_thm_4.11">4.11</a>) is that the evaluator may
have to search through many frames in order to find the binding for a
given variable. (Such an approach is
referred to as <em>deep binding</em>.) One way to avoid this inefficiency is to
make use of a strategy called <em>lexical addressing</em>, which will be
discussed in section
<a href="book-Z-H-35.html#%_sec_5.5.6">5.5.6</a>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_549">^[16]{.small}^</a>
Any procedure defined in the underlying Lisp can be used as a primitive
for the metacircular evaluator. The name of a primitive installed in the
evaluator need not be the same as the name of its implementation in the
underlying Lisp; the names are the same here because the metacircular
evaluator implements Scheme itself. Thus, for example, we could put
<code>(list 'first car)</code> or <code>(list 'square (lambda (x) (* x x)))</code> in the list
of <code>primitive-procedures</code>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_550">^[17]{.small}^</a>
<code>Apply-in-underlying-scheme</code> is the <code>apply</code> procedure we have used in
earlier chapters. The metacircular evaluator's <code>apply</code> procedure
(section
<a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>) models the working of
this primitive. Having two different things called <code>apply</code> leads to a
technical problem in running the metacircular evaluator, because
defining the metacircular evaluator's <code>apply</code> will mask the definition
of the primitive. One way around this is to rename the metacircular
<code>apply</code> to avoid conflict with the name of the primitive procedure. We
have assumed instead that we have saved a reference to the underlying
<code>apply</code> by doing</p>
<p><code>(define apply-in-underlying-scheme apply)</code></p>
<p>before defining the metacircular <code>apply</code>. This allows us to access the
original version of <code>apply</code> under a different name.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_551">^[18]{.small}^</a>
The primitive procedure <code>read</code> waits for
input from the user, and returns the next complete expression that is
typed. For example, if the user types <code>(+ 23 x)</code>, <code>read</code> returns a
three-element list containing the symbol <code>+</code>, the number 23, and the
symbol <code>x</code>. If the user types <code>'x</code>, <code>read</code>
returns a two-element list containing the symbol <code>quote</code> and the symbol
<code>x</code>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_553">^[19]{.small}^</a>
The fact that the machines are described in Lisp is inessential. If we
give our evaluator a Lisp program that behaves as an evaluator for some
other language, say C, the Lisp evaluator will emulate the C evaluator,
which in turn can emulate any machine described as a C program.
Similarly, writing a Lisp evaluator in C produces a C program that can
execute any Lisp program. The deep idea here is that any evaluator can
emulate any other. Thus, the notion of ''what can in principle be
computed'' (ignoring practicalities of time and memory required) is
independent of the language or the computer, and instead reflects an
underlying notion of <em>computability</em>. This was first
demonstrated in a clear way by Alan M. Turing
(1912-1954), whose 1936 paper laid the foundations for theoretical
computer science. In the paper, Turing presented a simple
computational model -- now known as a <em>Turing machine</em>
-- and argued that any ''effective process'' can be formulated as a
program for such a machine. (This argument is known as the
<em>Church-Turing thesis</em>.) Turing then implemented a
universal machine, i.e., a Turing machine that behaves as an evaluator
for Turing-machine programs. He used this framework to demonstrate that
there are well-posed problems that cannot be computed by Turing machines
(see exercise
<a href="book-Z-H-26.html#%_thm_4.15">4.15</a>), and so by
implication cannot be formulated as ''effective processes.'' Turing
went on to make fundamental contributions to practical computer science
as well. For example, he invented the idea of structuring
programs using general-purpose subroutines. See Hodges
1983 for a biography of Turing.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_554">^[20]{.small}^</a>
Some people find it counterintuitive that an evaluator, which is
implemented by a relatively simple procedure, can emulate programs that
are more complex than the evaluator itself. The existence of a universal
evaluator machine is a deep and wonderful property of computation.
<em>Recursion theory</em>, a branch of mathematical logic, is
concerned with logical limits of computation. Douglas
Hofstadter's beautiful book <em>Gödel, Escher, Bach</em> (1979) explores some
of these ideas.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_555">^[21]{.small}^</a>
Warning: This <code>eval</code> primitive is not identical to the
<code>eval</code> procedure we implemented in
section
<a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>, because it uses <em>actual</em>
Scheme environments rather than the sample environment structures we
built in section
<a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a>. These actual
environments cannot be manipulated by the user as ordinary lists; they
must be accessed via <code>eval</code> or other special operations.
Similarly, the <code>apply</code> primitive we saw earlier is not
identical to the metacircular <code>apply</code>, because it uses actual Scheme
procedures rather than the procedure objects we constructed in
sections
<a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a>
and
<a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_556">^[22]{.small}^</a>
The MIT
implementation
of Scheme includes <code>eval</code>, as well as a symbol
<code>user-initial-environment</code> that is bound to the initial environment in
which the user's input expressions are evaluated.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_558">^[23]{.small}^</a>
Although we stipulated that <code>halts?</code> is given a procedure object, notice
that this reasoning still applies even if <code>halts?</code> can gain access to
the procedure's text and its environment.
This is
Turing's celebrated <em>Halting Theorem</em>, which gave the first clear
example of a <em>non-computable</em> problem, i.e., a well-posed task that
cannot be carried out as a computational procedure.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_559">^[24]{.small}^</a>
Wanting programs to not depend on this evaluation mechanism is the
reason for the ''management is not responsible'' remark in
footnote
<a href="book-Z-H-10.html#footnote_Temp_45">28</a> of chapter</p>
<ol>
<li>By
insisting that internal definitions come first and do not use each other
while the definitions are being evaluated, the IEEE standard for Scheme
leaves implementors some choice in the mechanism used to evaluate these
definitions. The choice of one evaluation rule rather than another here
may seem like a small issue, affecting only the interpretation of
''badly formed'' programs. However, we will see in
section
<a href="book-Z-H-35.html#%_sec_5.5.6">5.5.6</a> that moving to a model of
simultaneous scoping for internal definitions avoids some nasty
difficulties that would otherwise arise in implementing a compiler.</li>
</ol>
<p><a href="book-Z-H-26.html#call_footnote_Temp_560">^[25]{.small}^</a>
The IEEE standard for Scheme allows for different implementation
strategies by specifying that it is up to the programmer to obey this
restriction, not up to the implementation to enforce it. Some Scheme
implementations, including MIT Scheme, use the
transformation shown above. Thus, some programs that don't obey this
restriction will in fact run in such implementations.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_565">^[26]{.small}^</a>
The MIT implementors of Scheme support Alyssa on the following grounds:
Eva is in principle correct -- the definitions should be regarded as
simultaneous. But it seems difficult to implement a general, efficient
mechanism that does what Eva requires. In the absence of such a
mechanism, it is better to generate an error in the difficult cases of
simultaneous definitions (Alyssa's notion) than to produce an incorrect
answer (as Ben would have it).</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_568">^[27]{.small}^</a>
This example illustrates a programming trick for formulating recursive
procedures without using <code>define</code>. The most general trick
of this sort is the <em>Y</em> <em>operator</em>, which can be used to give a ''pure
<img src="book-Z-G-D-6.gif" alt="" />-calculus'' implementation of
recursion. (See Stoy 1977 for details on
the lambda calculus, and Gabriel 1988 for an exposition of the <em>Y</em>
operator in Scheme.)</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_569">^[28]{.small}^</a>
This technique is an integral part of the compilation process, which we
shall discuss in chapter
5. Jonathan Rees wrote a Scheme
interpreter
like this in about 1982 for the T project (Rees and Adams 1982). Marc
Feeley (1986) (see also Feeley and Lapalme 1987) independently invented
this technique in his master's thesis.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_570">^[29]{.small}^</a>
There is, however, an important part of the variable search that <em>can</em>
be done as part of the syntactic analysis. As we will show in
section
<a href="book-Z-H-35.html#%_sec_5.5.6">5.5.6</a>, one can determine the
position in the environment structure where the value of the variable
will be found, thus obviating the need to scan the environment for the
entry that matches the variable.</p>
<p><a href="book-Z-H-26.html#call_footnote_Temp_571">^[30]{.small}^</a>
See exercise
<a href="book-Z-H-26.html#%_thm_4.23">4.23</a> for some insight into
the processing of sequences.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="42--variations-on-a-scheme----lazy-evaluation"><a class="header" href="#42--variations-on-a-scheme----lazy-evaluation"><a href="book-Z-H-4.html#%_toc_%_sec_4.2">4.2  Variations on a Scheme -- Lazy Evaluation</a></a></h2>
<p>Now that we
have an evaluator expressed as a Lisp program, we can experiment with
alternative choices in language design simply by modifying the
evaluator. Indeed, new languages are often invented by first writing an
evaluator that embeds the new language within an existing high-level
language. For example, if we wish to discuss some aspect of a proposed
modification to Lisp with another member of the Lisp community, we can
supply an evaluator that embodies the change. The recipient can then
experiment with the new evaluator and send back comments as further
modifications. Not only does the high-level implementation base make it
easier to test and debug the evaluator; in addition, the embedding
enables the designer to
snarf<a href="book-Z-H-27.html#footnote_Temp_575">^[31]{.small}^</a>
features from the underlying language, just as our embedded Lisp
evaluator uses primitives and control structure from the underlying
Lisp. Only later (if ever) need the designer go to the trouble of
building a complete implementation in a low-level language or in
hardware. In this section and the next we explore some variations on
Scheme that provide significant additional expressive power.</p>
<h3 id="421--normal-order-and-applicative-order"><a class="header" href="#421--normal-order-and-applicative-order"><a href="book-Z-H-4.html#%_toc_%_sec_4.2.1">4.2.1  Normal Order and Applicative Order</a></a></h3>
<p>In
section <a href="book-Z-H-10.html#%_sec_1.1">1.1</a>, where we began our discussion
of models of evaluation, we noted that Scheme is an <em>applicative-order</em>
language, namely, that all the arguments to Scheme procedures are
evaluated when the procedure is applied. In contrast, <em>normal-order</em>
languages delay evaluation of procedure arguments until the actual
argument values are needed. Delaying evaluation of procedure arguments
until the last possible moment (e.g., until they are required by a
primitive operation) is called <em>lazy
evaluation</em>.<a href="book-Z-H-27.html#footnote_Temp_576">^[32]{.small}^</a>
Consider the procedure</p>
<pre><code class="language-scheme editable">(define (try a b)
  (if (= a 0) 1 b))
</code></pre>
<p>Evaluating <code>(try 0 (/ 1 0))</code> generates an error in Scheme. With lazy
evaluation, there would be no error. Evaluating the expression would
return 1, because the argument <code>(/ 1 0)</code> would never be evaluated.</p>
<p>An example that exploits lazy evaluation is the definition of a
procedure <code>unless</code></p>
<pre><code class="language-scheme editable">(define (unless condition usual-value exceptional-value)
  (if condition exceptional-value usual-value))
</code></pre>
<p>that can be used in expressions such as</p>
<pre><code class="language-scheme editable">(unless (= b 0)
        (/ a b)
        (begin (display "exception: returning 0")
               0))
</code></pre>
<p>This won't work in an applicative-order language because both the usual
value and the exceptional value will be evaluated before <code>unless</code> is
called (compare exercise <a href="book-Z-H-10.html#%_thm_1.6">1.6</a>). An
advantage of lazy evaluation is that some procedures, such as <code>unless</code>,
can do useful computation even if evaluation of some of their arguments
would produce errors or would not terminate.</p>
<p>If the body of a procedure is entered before an argument has been
evaluated we say that the procedure is <em>non-strict</em> in
that argument. If the argument is evaluated before the body of the
procedure is entered we say that the procedure is
<em>strict</em> in that
argument.<a href="book-Z-H-27.html#footnote_Temp_577">^[33]{.small}^</a>
In a purely applicative-order language, all procedures are strict in
each argument. In a purely normal-order language, all compound
procedures are non-strict in each argument, and primitive procedures may
be either strict or non-strict. There are also languages (see
exercise <a href="book-Z-H-27.html#%_thm_4.31">4.31</a>) that give programmers
detailed control over the strictness of the procedures they define.</p>
<p>A striking example of a procedure that can usefully be made non-strict
is <code>cons</code> (or, in general, almost any constructor for data structures).
One can do useful computation, combining elements to form data
structures and operating on the resulting data structures, even if the
values of the elements are not known. It makes perfect sense, for
instance, to compute the length of a list without knowing the values of
the individual elements in the list. We will exploit this idea in
section <a href="book-Z-H-27.html#%_sec_4.2.3">4.2.3</a> to implement the streams
of chapter 3 as lists formed of non-strict <code>cons</code> pairs.</p>
<p><strong>Exercise 4.25.</strong>  Suppose that (in ordinary
applicative-order Scheme) we define <code>unless</code> as shown above and then
define <code>factorial</code> in terms of <code>unless</code> as</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (unless (= n 1)
          (* n (factorial (- n 1)))
          1))
</code></pre>
<p>What happens if we attempt to evaluate <code>(factorial 5)</code>? Will our
definitions work in a normal-order language?</p>
<p><strong>Exercise 4.26.</strong>  Ben
Bitdiddle and Alyssa P. Hacker disagree over the importance of lazy
evaluation for implementing things such as <code>unless</code>. Ben points out that
it's possible to implement <code>unless</code> in applicative order as a special
form. Alyssa counters that, if one did that, <code>unless</code> would be merely
syntax, not a procedure that could be used in conjunction with
higher-order procedures. Fill in the details on both sides of the
argument. Show how to implement <code>unless</code> as a derived expression (like
<code>cond</code> or <code>let</code>), and give an example of a situation where it might be
useful to have <code>unless</code> available as a procedure, rather than as a
special form.</p>
<h3 id="422--an-interpreter-with-lazy-evaluation"><a class="header" href="#422--an-interpreter-with-lazy-evaluation"><a href="book-Z-H-4.html#%_toc_%_sec_4.2.2">4.2.2  An Interpreter with Lazy Evaluation</a></a></h3>
<p>In this section we will implement a normal-order language that is the
same as Scheme except that compound procedures are non-strict in each
argument. Primitive procedures will still be strict. It is not difficult
to modify the evaluator of section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>
so that the language it interprets behaves this way. Almost all the
required changes center around procedure application.</p>
<p>The basic idea is that, when applying a procedure, the interpreter must
determine which arguments are to be evaluated and which are to be
delayed. The delayed arguments are not evaluated; instead, they are
transformed into objects called
<em>thunk</em>s.<a href="book-Z-H-27.html#footnote_Temp_580">^[34]{.small}^</a>
The thunk must contain the information required to produce the value of
the argument when it is needed, as if it had been evaluated at the time
of the application. Thus, the thunk must contain the argument expression
and the environment in which the procedure application is being
evaluated.</p>
<p>The process of evaluating the expression
in a thunk is called
<em>forcing</em>.<a href="book-Z-H-27.html#footnote_Temp_581">^[35]{.small}^</a>
In general, a thunk will be forced only when its value is needed: when
it is passed to a primitive procedure that will use the value of the
thunk; when it is the value of a predicate of a conditional; and when it
is the value of an operator that is about to be applied as a procedure.
One design choice we have available is whether or not to
<em>memoize</em> thunks, as we did with delayed objects in
section <a href="book-Z-H-24.html#%_sec_3.5.1">3.5.1</a>. With memoization, the
first time a thunk is forced, it stores the value that is computed.
Subsequent forcings simply return the stored value without repeating the
computation. We'll make our interpreter memoize, because this is more
efficient for many applications. There are tricky considerations here,
however.<a href="book-Z-H-27.html#footnote_Temp_582">^[36]{.small}^</a></p>
<h4 id="modifying-the-evaluator"><a class="header" href="#modifying-the-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_583">Modifying the evaluator</a></a></h4>
<p>The main difference between the lazy evaluator and the one in
section <a href="book-Z-H-26.html#%_sec_4.1">4.1</a> is in the handling of
procedure applications in <code>eval</code> and <code>apply</code>.</p>
<p>The <code>application?</code> clause of <code>eval</code> becomes</p>
<pre><code class="language-scheme editable">((application? exp)
 (apply (actual-value (operator exp) env)
        (operands exp)
        env))
</code></pre>
<p>This is almost the same as the <code>application?</code> clause of <code>eval</code> in
section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>. For lazy evaluation,
however, we call <code>apply</code> with the operand expressions, rather than the
arguments produced by evaluating them. Since we will need the
environment to construct thunks if the arguments are to be delayed, we
must pass this as well. We still evaluate the operator, because <code>apply</code>
needs the actual procedure to be applied in order to dispatch on its
type (primitive versus compound) and apply it.</p>
<p>Whenever we need the actual value of an expression, we use</p>
<pre><code class="language-scheme editable">(define (actual-value exp env)
  (force-it (eval exp env)))
</code></pre>
<p>instead of just <code>eval</code>, so that if the expression's value is a thunk,
it will be forced.</p>
<p>Our new version of <code>apply</code> is also almost the same as the version in
section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>. The difference is that
<code>eval</code> has passed in unevaluated operand expressions: For primitive
procedures (which are strict), we evaluate all the arguments before
applying the primitive; for compound procedures (which are non-strict)
we delay all the arguments before applying the procedure.</p>
<pre><code class="language-scheme editable">(define (apply procedure arguments env)
  (cond ((primitive-procedure? procedure)
         (apply-primitive-procedure
          procedure
          (list-of-arg-values arguments env)))  ; changed
        ((compound-procedure? procedure)
         (eval-sequence
          (procedure-body procedure)
          (extend-environment
           (procedure-parameters procedure)
           (list-of-delayed-args arguments env) ; changed
           (procedure-environment procedure))))
        (else
         (error
          "Unknown procedure type -- APPLY" procedure))))
</code></pre>
<p>The procedures that process the arguments are just like <code>list-of-values</code>
from section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>, except that
<code>list-of-delayed-args</code> delays the arguments instead of evaluating them,
and <code>list-of-arg-values</code> uses <code>actual-value</code> instead of <code>eval</code>:</p>
<pre><code class="language-scheme editable">(define (list-of-arg-values exps env)
  (if (no-operands? exps)
      '()
      (cons (actual-value (first-operand exps) env)
            (list-of-arg-values (rest-operands exps)
                                env))))
(define (list-of-delayed-args exps env)
  (if (no-operands? exps)
      '()
      (cons (delay-it (first-operand exps) env)
            (list-of-delayed-args (rest-operands exps)
                                  env))))
</code></pre>
<p>The other place we must change the evaluator is in the handling of <code>if</code>,
where we must use <code>actual-value</code> instead of <code>eval</code> to get the value of
the predicate expression before testing whether it is true or false:</p>
<pre><code class="language-scheme editable">(define (eval-if exp env)
  (if (true? (actual-value (if-predicate exp) env))
      (eval (if-consequent exp) env)
      (eval (if-alternative exp) env)))
</code></pre>
<p>Finally, we must change the <code>driver-loop</code> procedure
(section <a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>) to use <code>actual-value</code>
instead of <code>eval</code>, so that if a delayed value is propagated back to the
read-eval-print loop, it will be forced before being printed. We also
change the prompts to indicate that this is the lazy evaluator:</p>
<pre><code class="language-scheme editable">(define input-prompt ";;; L-Eval input:")
(define output-prompt ";;; L-Eval value:")
(define (driver-loop)
  (prompt-for-input input-prompt)
  (let ((input (read)))
    (let ((output
           (actual-value input the-global-environment)))
      (announce-output output-prompt)
      (user-print output)))
  (driver-loop))
</code></pre>
<p>With these changes made, we can start the evaluator and test it. The
successful evaluation of the <code>try</code> expression discussed in
section <a href="book-Z-H-27.html#%_sec_4.2.1">4.2.1</a> indicates that the
interpreter is performing lazy evaluation:</p>
<pre><code class="language-scheme editable">(define the-global-environment (setup-environment))
(driver-loop)
</code></pre>
<p><em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(define (try a b)
  (if (= a 0) 1 b))
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<em><code>ok</code></em>
<em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(try 0 (/ 1 0))
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<em><code>1</code></em></p>
<h4 id="representing-thunks"><a class="header" href="#representing-thunks"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_584">Representing thunks</a></a></h4>
<p>Our evaluator must arrange to create thunks when
procedures are applied to arguments and to force these thunks later. A
thunk must package an expression together with the environment, so that
the argument can be produced later. To force the thunk, we simply
extract the expression and environment from the thunk and evaluate the
expression in the environment. We use <code>actual-value</code> rather than <code>eval</code>
so that in case the value of the expression is itself a thunk, we will
force that, and so on, until we reach something that is not a thunk:</p>
<pre><code class="language-scheme editable">(define (force-it obj)
  (if (thunk? obj)
      (actual-value (thunk-exp obj) (thunk-env obj))
      obj))
</code></pre>
<p>One easy way to package an expression with an environment is to make a
list containing the expression and the environment. Thus, we create a
thunk as follows:</p>
<pre><code class="language-scheme editable">(define (delay-it exp env)
  (list 'thunk exp env))

(define (thunk? obj)
  (tagged-list? obj 'thunk))

(define (thunk-exp thunk) (cadr thunk))

(define (thunk-env thunk) (caddr thunk))
</code></pre>
<p>Actually, what we want for our interpreter is not quite this, but rather
thunks that have been memoized. When a thunk is forced, we will turn it
into an evaluated thunk by replacing the stored expression with its
value and changing the <code>thunk</code> tag so that it can be recognized as
already
evaluated.<a href="book-Z-H-27.html#footnote_Temp_585">^[37]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (evaluated-thunk? obj)
  (tagged-list? obj 'evaluated-thunk))

(define (thunk-value evaluated-thunk) (cadr evaluated-thunk))
(define (force-it obj)
  (cond ((thunk? obj)
         (let ((result (actual-value
                        (thunk-exp obj)
                        (thunk-env obj))))
           (set-car! obj 'evaluated-thunk)
           (set-car! (cdr obj) result)  ; replace exp with its value
           (set-cdr! (cdr obj) '())     ; forget unneeded env
           result))
        ((evaluated-thunk? obj)
         (thunk-value obj))
        (else obj)))
</code></pre>
<p>Notice that the same <code>delay-it</code> procedure works both with and without
memoization.</p>
<p><strong>Exercise 4.27.</strong>  Suppose we type in the following
definitions to the lazy evaluator:</p>
<pre><code class="language-scheme editable">(define count 0)
(define (id x)
  (set! count (+ count 1))
  x)
</code></pre>
<p>Give the missing values in the following sequence of interactions, and
explain your
answers.<a href="book-Z-H-27.html#footnote_Temp_587">^[38]{.small}^</a></p>
<pre><code class="language-scheme editable">(define w (id (id 10)))
</code></pre>
<p><em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">count
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<code>&lt;</code><em><code>response</code></em><code>&gt;</code>
<em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">w
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<code>&lt;</code><em><code>response</code></em><code>&gt;</code>
<em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">count
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<code>&lt;</code><em><code>response</code></em><code>&gt;</code></p>
<p><strong>Exercise 4.28.</strong>  <code>Eval</code> uses <code>actual-value</code> rather
than <code>eval</code> to evaluate the operator before passing it to <code>apply</code>, in
order to force the value of the operator. Give an example that
demonstrates the need for this forcing.</p>
<p><strong>Exercise 4.29.</strong>  Exhibit a program that you would
expect to run much more slowly without memoization than with
memoization. Also, consider the following interaction, where the <code>id</code>
procedure is defined as in exercise <a href="book-Z-H-27.html#%_thm_4.27">4.27</a>
and <code>count</code> starts at 0:</p>
<pre><code class="language-scheme editable">(define (square x)
  (* x x))
</code></pre>
<p><em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(square (id 10))
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<code>&lt;</code><em><code>response</code></em><code>&gt;</code>
<em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">count
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<code>&lt;</code><em><code>response</code></em><code>&gt;</code></p>
<p>Give the responses both when the evaluator memoizes and when it does
not.</p>
<p><strong>Exercise 4.30.</strong>  Cy D. Fect, a reformed C programmer,
is worried that some side effects may never take place, because the lazy
evaluator doesn't force the expressions in a sequence. Since the value
of an expression in a sequence other than the last one is not used (the
expression is there only for its effect, such as assigning to a variable
or printing), there can be no subsequent use of this value (e.g., as an
argument to a primitive procedure) that will cause it to be forced. Cy
thus thinks that when evaluating sequences, we must force all
expressions in the sequence except the final one. He proposes to modify
<code>eval-sequence</code> from section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a> to
use <code>actual-value</code> rather than <code>eval</code>:</p>
<pre><code class="language-scheme editable">(define (eval-sequence exps env)
  (cond ((last-exp? exps) (eval (first-exp exps) env))
        (else (actual-value (first-exp exps) env)
              (eval-sequence (rest-exps exps) env))))
</code></pre>
<p>a. Ben Bitdiddle thinks Cy is wrong. He shows Cy the <code>for-each</code>
procedure described in exercise <a href="book-Z-H-15.html#%_thm_2.23">2.23</a>,
which gives an important example of a sequence with side effects:</p>
<pre><code class="language-scheme editable">(define (for-each proc items)
  (if (null? items)
      'done
      (begin (proc (car items))
             (for-each proc (cdr items)))))
</code></pre>
<p>He claims that the evaluator in the text (with the original
<code>eval-sequence</code>) handles this correctly:</p>
<p><em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(for-each (lambda (x) (newline) (display x))
          (list 57 321 88))
</code></pre>
<p><em><code>57</code></em>
<em><code>321</code></em>
<em><code>88</code></em>
<em><code>;;; L-Eval value:</code></em>
<em><code>done</code></em></p>
<p>Explain why Ben is right about the behavior of <code>for-each</code>.</p>
<p>b. Cy agrees that Ben is right about the <code>for-each</code> example, but says
that that's not the kind of program he was thinking about when he
proposed his change to <code>eval-sequence</code>. He defines the following two
procedures in the lazy evaluator:</p>
<pre><code class="language-scheme editable">(define (p1 x)
  (set! x (cons x '(2)))
  x)

(define (p2 x)
  (define (p e)
    e
    x)
  (p (set! x (cons x '(2)))))
</code></pre>
<p>What are the values of <code>(p1 1)</code> and <code>(p2 1)</code> with the original
<code>eval-sequence</code>? What would the values be with Cy's proposed change to
<code>eval-sequence</code>?</p>
<p>c. Cy also points out that changing <code>eval-sequence</code> as he proposes does
not affect the behavior of the example in part a. Explain why this is
true.</p>
<p>d. How do you think sequences ought to be treated in the lazy
evaluator? Do you like Cy's approach, the approach in the text, or some
other approach?</p>
<p><strong>Exercise 4.31.</strong>  The approach taken in
this section is somewhat unpleasant, because it makes an incompatible
change to Scheme. It might be nicer to implement lazy evaluation as an
<em>upward-compatible extension</em>, that is, so that ordinary Scheme programs
will work as before. We can do this by extending the syntax of procedure
declarations to let the user control whether or not arguments are to be
delayed. While we're at it, we may as well also give the user the
choice between delaying with and without memoization. For example, the
definition</p>
<pre><code class="language-scheme editable">(define (f a (b lazy) c (d lazy-memo))
  ...)
</code></pre>
<p>would define <code>f</code> to be a procedure of four arguments, where the first
and third arguments are evaluated when the procedure is called, the
second argument is delayed, and the fourth argument is both delayed and
memoized. Thus, ordinary procedure definitions will produce the same
behavior as ordinary Scheme, while adding the <code>lazy-memo</code> declaration to
each parameter of every compound procedure will produce the behavior of
the lazy evaluator defined in this section. Design and implement the
changes required to produce such an extension to Scheme. You will have
to implement new syntax procedures to handle the new syntax for
<code>define</code>. You must also arrange for <code>eval</code> or <code>apply</code> to determine when
arguments are to be delayed, and to force or delay arguments
accordingly, and you must arrange for forcing to memoize or not, as
appropriate.</p>
<h3 id="423--streams-as-lazy-lists"><a class="header" href="#423--streams-as-lazy-lists"><a href="book-Z-H-4.html#%_toc_%_sec_4.2.3">4.2.3  Streams as Lazy Lists</a></a></h3>
<p>In
section <a href="book-Z-H-24.html#%_sec_3.5.1">3.5.1</a>, we showed how to
implement streams as delayed lists. We introduced special forms <code>delay</code>
and <code>cons-stream</code>, which allowed us to construct a ''promise'' to
compute the <code>cdr</code> of a stream, without actually fulfilling that promise
until later. We could use this general technique of introducing special
forms whenever we need more control over the evaluation process, but
this is awkward. For one thing, a special form is not a first-class
object like a procedure, so we cannot use it together with higher-order
procedures.<a href="book-Z-H-27.html#footnote_Temp_592">^[39]{.small}^</a>
Additionally, we were forced to create streams as a new kind of data
object similar but not identical to lists, and this required us to
reimplement many ordinary list operations (<code>map</code>, <code>append</code>, and so on)
for use with streams.</p>
<p>With lazy evaluation, streams and lists can be identical, so there is no
need for special forms or for separate list and stream operations. All
we need to do is to arrange matters so that <code>cons</code> is non-strict. One
way to accomplish this is to extend the lazy evaluator to allow for
non-strict primitives, and to implement <code>cons</code> as one of these. An
easier way is to recall (section <a href="book-Z-H-14.html#%_sec_2.1.3">2.1.3</a>)
that there is no fundamental need to implement <code>cons</code> as a primitive at
all. Instead, we can represent pairs as
procedures:<a href="book-Z-H-27.html#footnote_Temp_593">^[40]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (cons x y)
  (lambda (m) (m x y)))
(define (car z)
  (z (lambda (p q) p)))
(define (cdr z)
  (z (lambda (p q) q)))
</code></pre>
<p>In terms of these basic operations, the standard definitions of the list
operations will work with infinite lists (streams) as well as finite
ones, and the stream operations can be implemented as list operations.
Here are some examples:</p>
<pre><code class="language-scheme editable">(define (list-ref items n)
  (if (= n 0)
      (car items)
      (list-ref (cdr items) (- n 1))))
(define (map proc items)
  (if (null? items)
      '()
      (cons (proc (car items))
            (map proc (cdr items)))))
(define (scale-list items factor)
  (map (lambda (x) (* x factor))
       items))
(define (add-lists list1 list2)
  (cond ((null? list1) list2)
        ((null? list2) list1)
        (else (cons (+ (car list1) (car list2))
                    (add-lists (cdr list1) (cdr list2))))))
(define ones (cons 1 ones))
(define integers (cons 1 (add-lists ones integers)))
</code></pre>
<p><em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(list-ref integers 17)
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<em><code>18</code></em></p>
<p>Note that these lazy lists are even lazier than the streams of
chapter 3: The <code>car</code> of the list, as well as the <code>cdr</code>, is
delayed.<a href="book-Z-H-27.html#footnote_Temp_594">^[41]{.small}^</a>
In fact, even accessing the <code>car</code> or <code>cdr</code> of a lazy pair need not force
the value of a list element. The value will be forced only when it is
really needed -- e.g., for use as the argument of a primitive, or to be
printed as an answer.</p>
<p>Lazy pairs also help with the problem that arose with streams in
section <a href="book-Z-H-24.html#%_sec_3.5.4">3.5.4</a>, where we found that
formulating stream models of systems with loops may require us to
sprinkle our programs with explicit
<code>delay</code> operations, beyond the ones supplied by <code>cons-stream</code>. With lazy
evaluation, all arguments to procedures are delayed uniformly. For
instance, we can implement procedures to integrate lists and solve
differential equations as we originally intended in
section <a href="book-Z-H-24.html#%_sec_3.5.4">3.5.4</a>:</p>
<pre><code class="language-scheme editable">(define (integral integrand initial-value dt)
  (define int
    (cons initial-value
          (add-lists (scale-list integrand dt)
                     int)))
  int)
(define (solve f y0 dt)
  (define y (integral dy y0 dt))
  (define dy (map f y))
  y)
</code></pre>
<p><em><code>;;; L-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(list-ref (solve (lambda (x) x) 1 0.001) 1000)
</code></pre>
<p><em><code>;;; L-Eval value:</code></em>
<em><code>2.716924</code></em></p>
<p><strong>Exercise 4.32.</strong>  Give some examples that illustrate
the difference between the streams of chapter 3 and the ''lazier''
lazy lists described in this section. How can you take advantage of this
extra laziness?</p>
<p><strong>Exercise 4.33.</strong>  Ben Bitdiddle tests the lazy list
implementation given above by evaluating the expression</p>
<pre><code class="language-scheme editable">(car '(a b c))
</code></pre>
<p>To his surprise, this produces an error. After some thought, he realizes
that the ''lists'' obtained by reading in quoted expressions are
different from the lists manipulated by the new definitions of <code>cons</code>,
<code>car</code>, and <code>cdr</code>. Modify the evaluator's treatment of quoted
expressions so that quoted lists typed at the driver loop will produce
true lazy lists.</p>
<p><strong>Exercise 4.34.</strong>  Modify the driver loop for the
evaluator so that lazy pairs and lists will print in some reasonable
way. (What are you going to do about infinite lists?) You may also need
to modify the representation of lazy pairs so that the evaluator can
identify them in order to print them.</p>
<hr />
<p>^[31]{.small}^](book-Z-H-27.html#call_footnote_Temp_575)
Snarf: ''To grab, especially a large document or
file for the purpose of
using it either with or without the owner's permission.'' Snarf down:
''To snarf, sometimes with the connotation of absorbing, processing,
or understanding.'' (These definitions were snarfed from Steele et al.
1983. See also Raymond 1993.)</p>
<p>^[32]{.small}^](book-Z-H-27.html#call_footnote_Temp_576)
The difference between the ''lazy'' terminology and the
''normal-order'' terminology is somewhat fuzzy. Generally,
''lazy'' refers to the mechanisms of particular evaluators, while
''normal-order'' refers to the semantics of languages, independent
of any particular evaluation strategy. But this is not a hard-and-fast
distinction, and the two terminologies are often used interchangeably.</p>
<p>^[33]{.small}^](book-Z-H-27.html#call_footnote_Temp_577)
The ''strict'' versus ''non-strict'' terminology means
essentially the same thing as ''applicative-order'' versus
''normal-order,'' except that it refers to individual procedures and
arguments rather than to the language as a whole. At a conference on
programming languages you might hear someone say, ''The normal-order
language Hassle has certain strict primitives. Other
procedures take their arguments by lazy evaluation.''</p>
<p>^[34]{.small}^](book-Z-H-27.html#call_footnote_Temp_580)
The word <em>thunk</em> was invented by an informal
working group that was
discussing the implementation of call-by-name in Algol 60. They observed
that most of the analysis of (''thinking about'') the expression
could be done at compile time; thus, at run time, the expression would
already have been ''thunk'' about (Ingerman et al. 1960).</p>
<p>^[35]{.small}^](book-Z-H-27.html#call_footnote_Temp_581)
This is analogous to the use of <code>force</code> on the delayed
objects that were introduced in chapter 3 to represent streams. The
critical difference between what we are doing here and what we did in
chapter 3 is that we are building delaying and forcing into the
evaluator, and thus making this uniform and automatic throughout the
language.</p>
<p>^[36]{.small}^](book-Z-H-27.html#call_footnote_Temp_582)
Lazy evaluation combined with memoization is sometimes
referred to as <em>call-by-need</em> argument passing, in
contrast to <em>call-by-name</em> argument passing.
(Call-by-name, introduced in Algol 60, is
similar to non-memoized lazy evaluation.) As language designers, we can
build our evaluator to memoize, not to memoize, or leave this an option
for programmers (exercise <a href="book-Z-H-27.html#%_thm_4.31">4.31</a>). As you
might expect from chapter 3, these choices raise issues that become both
subtle and confusing in the presence of assignments. (See
exercises <a href="book-Z-H-27.html#%_thm_4.27">4.27</a>
and <a href="book-Z-H-27.html#%_thm_4.29">4.29</a>.) An excellent
article by Clinger (1982) attempts to clarify the multiple dimensions of
confusion that arise here.</p>
<p>^[37]{.small}^](book-Z-H-27.html#call_footnote_Temp_585)
Notice that we also erase the <code>env</code> from the thunk once the
expression's value has been computed. This makes no difference in the
values returned by the interpreter. It does help save space, however,
because removing the reference from the thunk to the <code>env</code> once it is no
longer needed allows this structure to be
<em>garbage-collected</em> and its space
recycled, as we will discuss in
section <a href="book-Z-H-33.html#%_sec_5.3">5.3</a>.</p>
<p>Similarly, we could have allowed unneeded environments in the memoized
delayed objects of section <a href="book-Z-H-24.html#%_sec_3.5.1">3.5.1</a> to be
garbage-collected, by having <code>memo-proc</code> do something like
<code>(set! proc '())</code> to discard the procedure <code>proc</code> (which includes the
environment in which the <code>delay</code> was evaluated) after storing its value.</p>
<p>^[38]{.small}^](book-Z-H-27.html#call_footnote_Temp_587)
This exercise demonstrates that the interaction between lazy evaluation
and side effects can be very confusing. This is just what you might
expect from the discussion in chapter 3.</p>
<p>^[39]{.small}^](book-Z-H-27.html#call_footnote_Temp_592)
This is precisely the issue with the <code>unless</code> procedure, as in
exercise <a href="book-Z-H-27.html#%_thm_4.26">4.26</a>.</p>
<p>^[40]{.small}^](book-Z-H-27.html#call_footnote_Temp_593)
This is the procedural representation described in
exercise <a href="book-Z-H-14.html#%_thm_2.4">2.4</a>. Essentially any procedural
representation (e.g., a message-passing implementation) would do as
well. Notice that we can install these definitions in the lazy evaluator
simply by typing them at the driver loop. If we had originally included
<code>cons</code>, <code>car</code>, and <code>cdr</code> as primitives in the global environment, they
will be redefined. (Also see
exercises <a href="book-Z-H-27.html#%_thm_4.33">4.33</a>
and <a href="book-Z-H-27.html#%_thm_4.34">4.34</a>.)</p>
<p>^[41]{.small}^](book-Z-H-27.html#call_footnote_Temp_594)
This permits us to create delayed versions of more general kinds of
list structures, not just sequences. Hughes 1990
discusses some applications of ''lazy
trees.''</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="43--variations-on-a-scheme----nondeterministic-computing"><a class="header" href="#43--variations-on-a-scheme----nondeterministic-computing"><a href="book-Z-H-4.html#%_toc_%_sec_4.3">4.3  Variations on a Scheme -- Nondeterministic Computing</a></a></h2>
<p>In this section, we extend the Scheme
evaluator to support a programming paradigm called <em>nondeterministic
computing</em> by building into the evaluator a facility to support
automatic search. This is a much more profound change to the language
than the introduction of lazy evaluation in
section <a href="book-Z-H-27.html#%_sec_4.2">4.2</a>.</p>
<p>Nondeterministic computing, like stream processing, is
useful for ''generate and test'' applications. Consider the task of
starting with two lists of positive integers and finding a pair of
integers -- one from the first list and one from the second list --
whose sum is prime. We saw how to handle this with finite sequence
operations in section <a href="book-Z-H-15.html#%_sec_2.2.3">2.2.3</a> and with
infinite streams in section <a href="book-Z-H-24.html#%_sec_3.5.3">3.5.3</a>. Our
approach was to generate the sequence of all possible pairs and filter
these to select the pairs whose sum is prime. Whether we actually
generate the entire sequence of pairs first as in chapter 2, or
interleave the generating and filtering as in chapter 3, is immaterial
to the essential image of how the computation is organized.</p>
<p>The nondeterministic approach evokes a different image.
Imagine simply that we choose (in some way) a number from the first list
and a number from the second list and require (using some mechanism)
that their sum be prime. This is expressed by following procedure:</p>
<pre><code class="language-scheme editable">(define (prime-sum-pair list1 list2)
  (let ((a (an-element-of list1))
        (b (an-element-of list2)))
    (require (prime? (+ a b)))
    (list a b)))
</code></pre>
<p>It might seem as if this procedure merely restates the problem, rather
than specifying a way to solve it. Nevertheless, this is a legitimate
nondeterministic
program.<a href="book-Z-H-28.html#footnote_Temp_598">^[42]{.small}^</a></p>
<p>The key idea here is that expressions in a nondeterministic language can
have more than one possible value. For instance, <code>an-element-of</code> might
return any element of the given list. Our nondeterministic program
evaluator will work by automatically choosing a possible value and
keeping track of the choice. If a subsequent requirement is not met, the
evaluator will try a different choice, and it will keep trying new
choices until the evaluation succeeds, or until we run out of choices.
Just as the lazy evaluator freed the programmer from the details of how
values are delayed and forced, the nondeterministic program evaluator
will free the programmer from the details of how choices are made.</p>
<p>It is instructive to contrast the different images of
time evoked by nondeterministic evaluation and stream processing. Stream
processing uses lazy evaluation to decouple the time when the stream of
possible answers is assembled from the time when the actual stream
elements are produced. The evaluator supports the illusion that all the
possible answers are laid out before us in a timeless sequence. With
nondeterministic evaluation, an expression represents the exploration of
a set of possible worlds, each determined by a set of choices. Some of
the possible worlds lead to dead ends, while others have useful values.
The nondeterministic program evaluator supports the illusion that time
branches, and that our programs have different possible execution
histories. When we reach a dead end, we can revisit a previous choice
point and proceed along a different branch.</p>
<p>The nondeterministic program evaluator implemented below is called the
<code>amb</code> evaluator because it is based on a new special form called <code>amb</code>.
We can type the above definition of <code>prime-sum-pair</code> at the <code>amb</code>
evaluator driver loop (along with definitions of <code>prime?</code>,
<code>an-element-of</code>, and <code>require</code>) and run the procedure as follows:</p>
<p><em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(prime-sum-pair '(1 3 5 8) '(20 35 110))
</code></pre>
<p><em><code>;;; Starting a new problem</code></em>
<em><code>;;; Amb-Eval value:</code></em>
<em><code>(3 20)</code></em></p>
<p>The value returned was obtained after the evaluator repeatedly chose
elements from each of the lists, until a successful choice was made.</p>
<p>Section <a href="book-Z-H-28.html#%_sec_4.3.1">4.3.1</a> introduces <code>amb</code> and
explains how it supports nondeterminism through the evaluator's
automatic search mechanism. Section
<a href="book-Z-H-28.html#%_sec_4.3.2">4.3.2</a> presents examples of
nondeterministic programs, and
section <a href="book-Z-H-28.html#%_sec_4.3.3">4.3.3</a> gives the details of how
to implement the <code>amb</code> evaluator by modifying the ordinary Scheme
evaluator.</p>
<h3 id="431--amb-and-search"><a class="header" href="#431--amb-and-search"><a href="book-Z-H-4.html#%_toc_%_sec_4.3.1">4.3.1  Amb and Search</a></a></h3>
<p>To extend Scheme to support nondeterminism, we introduce
a new special form called
<code>amb</code>.<a href="book-Z-H-28.html#footnote_Temp_599">^[43]{.small}^</a>
The expression
<code>(amb &lt;</code><strong><code>e</code><em><del><code>1</code></del></em><code>&gt; &lt;</code></strong><code>e</code><em><del><code>2</code></del></em><code>&gt; ... &lt;</code>**<code>e</code><em>~</em><code>n</code><em>~</em><code>&gt;)</code>
returns the value of one of the <em>n</em> expressions &lt;*<em>e</em><del><em>i</em></del>*&gt;
''ambiguously.'' For example, the expression</p>
<pre><code class="language-scheme editable">(list (amb 1 2 3) (amb 'a 'b))
</code></pre>
<p>can have six possible values:</p>
<hr />
<p><code>(1 a) </code>   <code>(1 b) </code>   <code>(2 a) </code>   <code>(2 b) </code>   <code>(3 a) </code>   <code>(3 b) </code></p>
<hr />
<p><code>Amb</code> with a single choice produces an ordinary (single) value.</p>
<p><code>Amb</code> with no choices -- the expression <code>(amb)</code> -- is
an expression with no acceptable values. Operationally, we can think of
<code>(amb)</code> as an expression that when evaluated causes the computation to
''fail'': The computation aborts and no value is produced. Using
this idea, we can express the requirement that a particular predicate
expression <code>p</code> must be true as follows:</p>
<pre><code class="language-scheme editable">(define (require p)
  (if (not p) (amb)))
</code></pre>
<p>With <code>amb</code> and <code>require</code>, we can implement the <code>an-element-of</code> procedure
used above:</p>
<pre><code class="language-scheme editable">(define (an-element-of items)
  (require (not (null? items)))
  (amb (car items) (an-element-of (cdr items))))
</code></pre>
<p><code>An-element-of</code> fails if the list is empty. Otherwise it ambiguously
returns either the first element of the list or an element chosen from
the rest of the list.</p>
<p>We can also express infinite ranges of choices. The following procedure
potentially returns any integer greater than or equal to some given <em>n</em>:</p>
<pre><code class="language-scheme editable">(define (an-integer-starting-from n)
  (amb n (an-integer-starting-from (+ n 1))))
</code></pre>
<p>This is like the stream procedure <code>integers-starting-from</code> described in
section <a href="book-Z-H-24.html#%_sec_3.5.2">3.5.2</a>, but with an important
difference: The stream procedure returns an object that represents the
sequence of all integers beginning with <em>n</em>, whereas the <code>amb</code> procedure
returns a single
integer.<a href="book-Z-H-28.html#footnote_Temp_600">^[44]{.small}^</a></p>
<p>Abstractly, we can imagine that evaluating an <code>amb</code>
expression causes time to split into branches, where the computation
continues on each branch with one of the possible values of the
expression. We say that <code>amb</code> represents a
<em>nondeterministic choice point</em>. If we had a machine with
a sufficient number of processors that could be dynamically allocated,
we could implement the search in a straightforward way. Execution would
proceed as in a sequential machine, until an <code>amb</code> expression is
encountered. At this point, more processors would be allocated and
initialized to continue all of the parallel executions implied by the
choice. Each processor would proceed sequentially as if it were the only
choice, until it either terminates by encountering a failure, or it
further subdivides, or it
finishes.<a href="book-Z-H-28.html#footnote_Temp_601">^[45]{.small}^</a></p>
<p>On the other hand, if we have a machine that can execute
only one process (or a few concurrent processes), we must consider the
alternatives sequentially. One could imagine modifying an evaluator to
pick at random a branch to follow whenever it encounters a choice point.
Random choice, however, can easily lead to failing values. We might try
running the evaluator over and over, making random choices and hoping to
find a non-failing value, but it is better to
<em>systematically search</em> all possible
execution paths. The <code>amb</code> evaluator that we will develop and work with
in this section implements a systematic search as follows: When the
evaluator encounters an application of <code>amb</code>, it initially selects the
first alternative. This selection may itself lead to a further choice.
The evaluator will always initially choose the first alternative at each
choice point. If a choice results in a failure, then the evaluator
automagically<a href="book-Z-H-28.html#footnote_Temp_602">^[46]{.small}^</a>
<em>backtracks</em> to the most recent choice point and tries
the next alternative. If it runs out of alternatives at any choice
point, the evaluator will back up to the previous choice point and
resume from there. This process leads to a search strategy known as
<em>depth-first search</em> or
<em>chronological
backtracking</em>.<a href="book-Z-H-28.html#footnote_Temp_603">^[47]{.small}^</a></p>
<h4 id="driver-loop"><a class="header" href="#driver-loop"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_604">Driver loop</a></a></h4>
<p>The driver loop for the <code>amb</code> evaluator has some unusual
properties. It reads an expression and prints the value of the first
non-failing execution, as in the <code>prime-sum-pair</code> example shown above.
If we want to see the value of the next successful execution, we can ask
the interpreter to backtrack and attempt to generate a second
non-failing execution. This is signaled by typing the symbol
<code>try-again</code>. If any expression except <code>try-again</code> is
given, the interpreter will start a new problem, discarding the
unexplored alternatives in the previous problem. Here is a sample
interaction:</p>
<p><em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(prime-sum-pair '(1 3 5 8) '(20 35 110))
</code></pre>
<p><em><code>;;; Starting a new problem</code></em>
<em><code>;;; Amb-Eval value:</code></em>
<em><code>(3 20)</code></em>
<em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">try-again
</code></pre>
<p><em><code>;;; Amb-Eval value:</code></em>
<em><code>(3 110)</code></em>
<em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">try-again
</code></pre>
<p><em><code>;;; Amb-Eval value:</code></em>
<em><code>(8 35)</code></em>
<em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">try-again
</code></pre>
<p><em><code>;;; There are no more values of</code></em>
<em><code>(prime-sum-pair (quote (1 3 5 8)) (quote (20 35 110)))</code></em>
<em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(prime-sum-pair '(19 27 30) '(11 36 58))
</code></pre>
<p><em><code>;;; Starting a new problem</code></em>
<em><code>;;; Amb-Eval value:</code></em>
<em><code>(30 11)</code></em></p>
<p><strong>Exercise 4.35.</strong>  Write
a procedure <code>an-integer-between</code> that returns an integer between two
given bounds. This can be used to implement a procedure that finds
Pythagorean triples, i.e., triples of integers (<em>i</em>,<em>j</em>,<em>k</em>) between the
given bounds such that <em>i</em> [&lt;]{.underline} <em>j</em> and <em>i</em>^2^ + <em>j</em>^2^ =
<em>k</em>^2^, as follows:</p>
<pre><code class="language-scheme editable">(define (a-pythagorean-triple-between low high)
  (let ((i (an-integer-between low high)))
    (let ((j (an-integer-between i high)))
      (let ((k (an-integer-between j high)))
        (require (= (+ (* i i) (* j j)) (* k k)))
        (list i j k)))))
</code></pre>
<p><strong>Exercise
4.36.</strong>  Exercise <a href="book-Z-H-24.html#%_thm_3.69">3.69</a>
discussed how to generate the stream of <em>all</em> Pythagorean triples, with
no upper bound on the size of the integers to be searched. Explain why
simply replacing <code>an-integer-between</code> by <code>an-integer-starting-from</code> in
the procedure in exercise <a href="book-Z-H-28.html#%_thm_4.35">4.35</a> is not an
adequate way to generate arbitrary Pythagorean triples. Write a
procedure that actually will accomplish this. (That is, write a
procedure for which repeatedly typing <code>try-again</code> would in principle
eventually generate all Pythagorean triples.)</p>
<p><strong>Exercise 4.37.</strong>  Ben
Bitdiddle claims that the following method for generating Pythagorean
triples is more efficient than the one in
exercise <a href="book-Z-H-28.html#%_thm_4.35">4.35</a>. Is he correct? (Hint:
Consider the number of possibilities that must be explored.)</p>
<pre><code class="language-scheme editable">(define (a-pythagorean-triple-between low high)
  (let ((i (an-integer-between low high))
        (hsq (* high high)))
    (let ((j (an-integer-between i high)))
      (let ((ksq (+ (* i i) (* j j))))
        (require (&gt;= hsq ksq))
        (let ((k (sqrt ksq)))
          (require (integer? k))
          (list i j k))))))
</code></pre>
<h3 id="432--examples-of-nondeterministic-programs"><a class="header" href="#432--examples-of-nondeterministic-programs"><a href="book-Z-H-4.html#%_toc_%_sec_4.3.2">4.3.2  Examples of Nondeterministic Programs</a></a></h3>
<p>Section <a href="book-Z-H-28.html#%_sec_4.3.3">4.3.3</a> describes the
implementation of the <code>amb</code> evaluator. First, however, we give some
examples of how it can be used. The advantage of nondeterministic
programming is that we can suppress the details of how search is carried
out, thereby expressing our programs at a higher level of
abstraction.</p>
<h4 id="logic-puzzles"><a class="header" href="#logic-puzzles"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_608">Logic Puzzles</a></a></h4>
<p>The
following puzzle (taken from Dinesman 1968) is typical of a large class
of simple logic puzzles:</p>
<blockquote>
<p>Baker, Cooper, Fletcher, Miller, and Smith live on different floors of
an apartment house that contains only five floors. Baker does not live
on the top floor. Cooper does not live on the bottom floor. Fletcher
does not live on either the top or the bottom floor. Miller lives on a
higher floor than does Cooper. Smith does not live on a floor adjacent
to Fletcher's. Fletcher does not live on a floor adjacent to
Cooper's. Where does everyone live?</p>
</blockquote>
<p>We can determine who lives on each floor in a straightforward way by
enumerating all the possibilities and imposing the given
restrictions:<a href="book-Z-H-28.html#footnote_Temp_609">^[48]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (multiple-dwelling)
  (let ((baker (amb 1 2 3 4 5))
        (cooper (amb 1 2 3 4 5))
        (fletcher (amb 1 2 3 4 5))
        (miller (amb 1 2 3 4 5))
        (smith (amb 1 2 3 4 5)))
    (require
     (distinct? (list baker cooper fletcher miller smith)))
    (require (not (= baker 5)))
    (require (not (= cooper 1)))
    (require (not (= fletcher 5)))
    (require (not (= fletcher 1)))
    (require (&gt; miller cooper))
    (require (not (= (abs (- smith fletcher)) 1)))
    (require (not (= (abs (- fletcher cooper)) 1)))
    (list (list 'baker baker)
          (list 'cooper cooper)
          (list 'fletcher fletcher)
          (list 'miller miller)
          (list 'smith smith))))
</code></pre>
<p>Evaluating the expression <code>(multiple-dwelling)</code> produces the result</p>
<p><code>((baker 3) (cooper 2) (fletcher 4) (miller 5) (smith 1))</code></p>
<p>Although this simple procedure works, it is very slow.
Exercises <a href="book-Z-H-28.html#%_thm_4.39">4.39</a>
and <a href="book-Z-H-28.html#%_thm_4.40">4.40</a> discuss some possible
improvements.</p>
<p><strong>Exercise 4.38.</strong>  Modify the multiple-dwelling
procedure to omit the requirement that Smith and Fletcher do not live on
adjacent floors. How many solutions are there to this modified puzzle?</p>
<p><strong>Exercise 4.39.</strong>  Does the order of the restrictions
in the multiple-dwelling procedure affect the answer? Does it affect the
time to find an answer? If you think it matters, demonstrate a faster
program obtained from the given one by reordering the restrictions. If
you think it does not matter, argue your case.</p>
<p><strong>Exercise 4.40.</strong>  In the multiple dwelling problem,
how many sets of assignments are there of people to floors, both before
and after the requirement that floor assignments be distinct? It is very
inefficient to generate all possible assignments of people to floors and
then leave it to backtracking to eliminate them. For example, most of
the restrictions depend on only one or two of the person-floor
variables, and can thus be imposed before floors have been selected for
all the people. Write and demonstrate a much more efficient
nondeterministic procedure that solves this problem based upon
generating only those possibilities that are not already ruled out by
previous restrictions. (Hint: This will require a nest of <code>let</code>
expressions.)</p>
<p><strong>Exercise 4.41.</strong>  Write an ordinary
Scheme program to solve the multiple dwelling puzzle.</p>
<p><strong>Exercise 4.42.</strong>  Solve the following
''Liars'' puzzle (from Phillips 1934):</p>
<blockquote>
<p>Five schoolgirls sat for an examination. Their parents -- so they
thought -- showed an undue degree of interest in the result. They
therefore agreed that, in writing home about the examination, each
girl should make one true statement and one untrue one. The following
are the relevant passages from their letters:</p>
<ul>
<li>Betty: ''Kitty was second in the examination. I was only
third.''</li>
<li>Ethel: ''You'll be glad to hear that I was on top. Joan was
second.''</li>
<li>Joan: ''I was third, and poor old Ethel was bottom.''</li>
<li>Kitty: ''I came out second. Mary was only fourth.''</li>
<li>Mary: ''I was fourth. Top place was taken by Betty.''</li>
</ul>
<p>What in fact was the order in which the five girls were placed?</p>
</blockquote>
<p><strong>Exercise 4.43.</strong>  Use the <code>amb</code> evaluator to solve the
following
puzzle:<a href="book-Z-H-28.html#footnote_Temp_616">^[49]{.small}^</a></p>
<blockquote>
<p>Mary Ann Moore's father has a yacht and so has each of his four
friends: Colonel Downing, Mr. Hall, Sir Barnacle Hood, and Dr. Parker.
Each of the five also has one daughter and each has named his yacht
after a daughter of one of the others. Sir Barnacle's yacht is the
Gabrielle, Mr. Moore owns the Lorna; Mr. Hall the Rosalind. The
Melissa, owned by Colonel Downing, is named after Sir Barnacle's
daughter. Gabrielle's father owns the yacht that is named after Dr.
Parker's daughter. Who is Lorna's father?</p>
</blockquote>
<p>Try to write the program so that it runs efficiently (see
exercise <a href="book-Z-H-28.html#%_thm_4.40">4.40</a>). Also determine how many
solutions there are if we are not told that Mary Ann's last name is
Moore.</p>
<p><strong>Exercise
4.44.</strong>  Exercise <a href="book-Z-H-15.html#%_thm_2.42">2.42</a>
described the ''eight-queens puzzle'' of placing queens on a
chessboard so that no two attack each other. Write a nondeterministic
program to solve this puzzle.</p>
<h4 id="parsing-natural-language"><a class="header" href="#parsing-natural-language"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_618">Parsing natural language</a></a></h4>
<p>Programs designed to accept natural
language as input usually start by attempting to <em>parse</em> the input, that
is, to match the input against some grammatical structure. For example,
we might try to recognize simple sentences consisting of an article
followed by a noun followed by a verb, such as ''The cat eats.'' To
accomplish such an analysis, we must be able to identify the parts of
speech of individual words. We could start with some lists that classify
various
words:<a href="book-Z-H-28.html#footnote_Temp_619">^[50]{.small}^</a></p>
<pre><code class="language-scheme editable">(define nouns '(noun student professor cat class))
(define verbs '(verb studies lectures eats sleeps))
(define articles '(article the a))
</code></pre>
<p>We also need a <em>grammar</em>, that is, a set of rules
describing how grammatical elements are composed from simpler elements.
A very simple grammar might stipulate that a sentence always consists of
two pieces -- a noun phrase followed by a verb -- and that a noun
phrase consists of an article followed by a noun. With this grammar, the
sentence ''The cat eats'' is parsed as follows:</p>
<p><code>(sentence (noun-phrase (article the) (noun cat))</code>
<code>          (verb eats))</code></p>
<p>We can generate such a parse with a simple program that has separate
procedures for each of the grammatical rules. To parse a sentence, we
identify its two constituent pieces and return a list of these two
elements, tagged with the symbol <code>sentence</code>:</p>
<pre><code class="language-scheme editable">(define (parse-sentence)
  (list 'sentence
        (parse-noun-phrase)
        (parse-word verbs)))
</code></pre>
<p>A noun phrase, similarly, is parsed by finding an article followed by a
noun:</p>
<pre><code class="language-scheme editable">(define (parse-noun-phrase)
  (list 'noun-phrase
        (parse-word articles)
        (parse-word nouns)))
</code></pre>
<p>At the lowest level, parsing boils down to repeatedly checking that the
next unparsed word is a member of the list of words for the required
part of speech. To implement this, we maintain a global variable
<code>*unparsed*</code>, which is the input that has not yet been parsed. Each time
we check a word, we require that <code>*unparsed*</code> must be non-empty and that
it should begin with a word from the designated list. If so, we remove
that word from <code>*unparsed*</code> and return the word together with its part
of speech (which is found at the head of the
list):<a href="book-Z-H-28.html#footnote_Temp_620">^[51]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (parse-word word-list)
  (require (not (null? *unparsed*)))
  (require (memq (car *unparsed*) (cdr word-list)))
  (let ((found-word (car *unparsed*)))
    (set! *unparsed* (cdr *unparsed*))
    (list (car word-list) found-word)))
</code></pre>
<p>To start the parsing, all we need to do is set <code>*unparsed*</code> to be the
entire input, try to parse a sentence, and check that nothing is left
over:</p>
<pre><code class="language-scheme editable">(define *unparsed* '())
(define (parse input)
  (set! *unparsed* input)
  (let ((sent (parse-sentence)))
    (require (null? *unparsed*))
    sent))
</code></pre>
<p>We can now try the parser and verify that it works for our simple test
sentence:</p>
<p><em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(parse '(the cat eats))
</code></pre>
<p><em><code>;;; Starting a new problem</code></em>
<em><code>;;; Amb-Eval value:</code></em>
<em><code>(sentence (noun-phrase (article the) (noun cat)) (verb eats))</code></em></p>
<p>The <code>amb</code> evaluator is useful here because it is convenient to express
the parsing constraints with the aid of <code>require</code>. Automatic search and
backtracking really pay off, however, when we consider more complex
grammars where there are choices for how the units can be decomposed.</p>
<p>Let's add to our grammar a list of prepositions:</p>
<pre><code class="language-scheme editable">(define prepositions '(prep for to in by with))
</code></pre>
<p>and define a prepositional phrase (e.g., ''for the cat'') to be a
preposition followed by a noun phrase:</p>
<pre><code class="language-scheme editable">(define (parse-prepositional-phrase)
  (list 'prep-phrase
        (parse-word prepositions)
        (parse-noun-phrase)))
</code></pre>
<p>Now we can define a sentence to be a noun phrase followed by a verb
phrase, where a verb phrase can be either a verb or a verb phrase
extended by a prepositional
phrase:<a href="book-Z-H-28.html#footnote_Temp_621">^[52]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (parse-sentence)
  (list 'sentence
        (parse-noun-phrase)
        (parse-verb-phrase)))
(define (parse-verb-phrase)
  (define (maybe-extend verb-phrase)
    (amb verb-phrase
         (maybe-extend (list 'verb-phrase
                             verb-phrase
                             (parse-prepositional-phrase)))))
  (maybe-extend (parse-word verbs)))
</code></pre>
<p>While we're at it, we can also elaborate the definition of noun phrases
to permit such things as ''a cat in the class.'' What we used to
call a noun phrase, we'll now call a simple noun phrase, and a noun
phrase will now be either a simple noun phrase or a noun phrase extended
by a prepositional phrase:</p>
<pre><code class="language-scheme editable">(define (parse-simple-noun-phrase)
  (list 'simple-noun-phrase
        (parse-word articles)
        (parse-word nouns)))
(define (parse-noun-phrase)
  (define (maybe-extend noun-phrase)
    (amb noun-phrase
         (maybe-extend (list 'noun-phrase
                             noun-phrase
                             (parse-prepositional-phrase)))))
  (maybe-extend (parse-simple-noun-phrase)))
</code></pre>
<p>Our new grammar lets us parse more complex sentences. For example</p>
<pre><code class="language-scheme editable">(parse '(the student with the cat sleeps in the class))
</code></pre>
<p>produces</p>
<p><code>(sentence</code>
<code> (noun-phrase</code>
<code>  (simple-noun-phrase (article the) (noun student))</code>
<code>  (prep-phrase (prep with)</code>
<code>               (simple-noun-phrase</code>
<code>                (article the) (noun cat))))</code>
<code> (verb-phrase</code>
<code>  (verb sleeps)</code>
<code>  (prep-phrase (prep in)</code>
<code>               (simple-noun-phrase</code>
<code>                (article the) (noun class)))))</code></p>
<p>Observe that a given input may have more than one legal parse. In the
sentence ''The professor lectures to the student with the cat,'' it
may be that the professor is lecturing with the cat, or that the student
has the cat. Our nondeterministic program finds both possibilities:</p>
<pre><code class="language-scheme editable">(parse '(the professor lectures to the student with the cat))
</code></pre>
<p>produces</p>
<p><code>(sentence</code>
<code> (simple-noun-phrase (article the) (noun professor))</code>
<code> (verb-phrase</code>
<code>  (verb-phrase</code>
<code>   (verb lectures)</code>
<code>   (prep-phrase (prep to)</code>
<code>                (simple-noun-phrase</code>
<code>                 (article the) (noun student))))</code>
<code>  (prep-phrase (prep with)</code>
<code>               (simple-noun-phrase</code>
<code>                (article the) (noun cat)))))</code></p>
<p>Asking the evaluator to try again yields</p>
<p><code>(sentence</code>
<code> (simple-noun-phrase (article the) (noun professor))</code>
<code> (verb-phrase</code>
<code>  (verb lectures)</code>
<code>  (prep-phrase (prep to)</code>
<code>               (noun-phrase</code>
<code>                (simple-noun-phrase</code>
<code>                 (article the) (noun student))</code>
<code>                (prep-phrase (prep with)</code>
<code>                             (simple-noun-phrase</code>
<code>                              (article the) (noun cat)))))))</code></p>
<p><strong>Exercise 4.45.</strong>  With the grammar given above, the
following sentence can be parsed in five different ways: ''The
professor lectures to the student in the class with the cat.'' Give
the five parses and explain the differences in shades of meaning among
them.</p>
<p><strong>Exercise 4.46.</strong>  The evaluators in
sections <a href="book-Z-H-26.html#%_sec_4.1">4.1</a> and
<a href="book-Z-H-27.html#%_sec_4.2">4.2</a> do not determine what order operands
are evaluated in. We will see that the <code>amb</code> evaluator evaluates them
from left to right. Explain why our parsing program wouldn't work if
the operands were evaluated in some other order.</p>
<p><strong>Exercise 4.47.</strong>  Louis Reasoner suggests that, since
a verb phrase is either a verb or a verb phrase followed by a
prepositional phrase, it would be much more straightforward to define
the procedure <code>parse-verb-phrase</code> as follows (and similarly for noun
phrases):</p>
<pre><code class="language-scheme editable">(define (parse-verb-phrase)
  (amb (parse-word verbs)
       (list 'verb-phrase
             (parse-verb-phrase)
             (parse-prepositional-phrase))))
</code></pre>
<p>Does this work? Does the program's behavior change if we interchange
the order of expressions in the <code>amb</code>?</p>
<p><strong>Exercise 4.48.</strong>  Extend the grammar given above to
handle more complex sentences. For example, you could extend noun
phrases and verb phrases to include adjectives and adverbs, or you could
handle compound
sentences.<a href="book-Z-H-28.html#footnote_Temp_626">^[53]{.small}^</a></p>
<p><strong>Exercise 4.49.</strong>  Alyssa P. Hacker is
more interested in generating interesting sentences than in parsing
them. She reasons that by simply changing the procedure <code>parse-word</code> so
that it ignores the ''input sentence'' and instead always succeeds
and generates an appropriate word, we can use the programs we had built
for parsing to do generation instead. Implement Alyssa's idea, and show
the first half-dozen or so sentences
generated.<a href="book-Z-H-28.html#footnote_Temp_628">^[54]{.small}^</a></p>
<h3 id="433--implementing-the-amb-evaluator"><a class="header" href="#433--implementing-the-amb-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_4.3.3">4.3.3  Implementing the <code>Amb</code> Evaluator</a></a></h3>
<p>The evaluation of an ordinary Scheme expression may
return a value, may never terminate, or may signal an error. In
nondeterministic Scheme the evaluation of an expression may in addition
result in the discovery of a dead end, in which case evaluation must
backtrack to a previous choice point. The interpretation of
nondeterministic Scheme is complicated by this extra case.</p>
<p>We will construct the <code>amb</code> evaluator for
nondeterministic Scheme by modifying the analyzing evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>.<a href="book-Z-H-28.html#footnote_Temp_629">^[55]{.small}^</a>
As in the analyzing evaluator, evaluation of an expression is
accomplished by calling an execution procedure produced
by analysis of that expression. The difference between the
interpretation of ordinary Scheme and the interpretation of
nondeterministic Scheme will be entirely in the execution procedures.</p>
<h4 id="execution-procedures-and-continuations"><a class="header" href="#execution-procedures-and-continuations"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_630">Execution procedures and continuations</a></a></h4>
<p>Recall that the execution procedures for
the ordinary evaluator take one argument: the environment of execution.
In contrast, the execution procedures in the <code>amb</code> evaluator take three
arguments: the environment, and two procedures called <em>continuation
procedures</em>. The evaluation of an expression will finish by calling one
of these two continuations: If the evaluation results in a value, the
<em>success continuation</em> is called with that value; if the
evaluation results in the discovery of a dead end, the
<em>failure continuation</em> is called. Constructing and
calling appropriate continuations is the mechanism by which the
nondeterministic evaluator implements backtracking.</p>
<p>It is the job of the success continuation to receive a value and proceed
with the computation. Along with that value, the success continuation is
passed another failure continuation, which is to be called subsequently
if the use of that value leads to a dead end.</p>
<p>It is the job of the failure continuation to try another branch of the
nondeterministic process. The essence of the nondeterministic language
is in the fact that expressions may represent choices among
alternatives. The evaluation of such an expression must proceed with one
of the indicated alternative choices, even though it is not known in
advance which choices will lead to acceptable results. To deal with
this, the evaluator picks one of the alternatives and passes this value
to the success continuation. Together with this value, the evaluator
constructs and passes along a failure continuation that can be called
later to choose a different alternative.</p>
<p>A failure is triggered during evaluation (that is, a failure
continuation is called) when a user program explicitly rejects the
current line of attack (for example, a call to <code>require</code> may result in
execution of <code>(amb)</code>, an expression that always fails -- see
section <a href="book-Z-H-28.html#%_sec_4.3.1">4.3.1</a>). The failure continuation
in hand at that point will cause the most recent choice point to choose
another alternative. If there are no more alternatives to be considered
at that choice point, a failure at an earlier choice point is triggered,
and so on. Failure continuations are also invoked by the driver loop in
response to a <code>try-again</code> request, to find another value of the
expression.</p>
<p>In addition, if a side-effect operation (such as assignment to a
variable) occurs on a branch of the process resulting from a choice, it
may be necessary, when the process finds a dead end, to undo the side
effect before making a new choice. This is accomplished by having the
side-effect operation produce a failure continuation that undoes the
side effect and propagates the failure.</p>
<p>In summary, failure continuations are constructed by</p>
<ul>
<li><code>amb</code> expressions -- to provide a mechanism to make alternative
choices if the current choice made by the <code>amb</code> expression leads to a
dead end;</li>
<li>the top-level driver -- to provide a mechanism to report failure when
the choices are exhausted;</li>
<li>assignments -- to intercept failures and undo assignments during
backtracking.</li>
</ul>
<p>Failures are initiated only when a dead end is encountered. This occurs</p>
<ul>
<li>if the user program executes <code>(amb)</code>;</li>
<li>if the user types <code>try-again</code> at the top-level driver.</li>
</ul>
<p>Failure continuations are also called during processing of a failure:</p>
<ul>
<li>When the failure continuation created by an assignment finishes
undoing a side effect, it calls the failure continuation it
intercepted, in order to propagate the failure back to the choice
point that led to this assignment or to the top level.</li>
<li>When the failure continuation for an <code>amb</code> runs out of choices, it
calls the failure continuation that was originally given to the <code>amb</code>,
in order to propagate the failure back to the previous choice point or
to the top level.</li>
</ul>
<h4 id="structure-of-the-evaluator"><a class="header" href="#structure-of-the-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_631">Structure of the evaluator</a></a></h4>
<p>The syntax- and data-representation procedures for the
<code>amb</code> evaluator, and also the basic <code>analyze</code> procedure, are identical
to those in the evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>, except for the fact that
we need additional syntax procedures to recognize the <code>amb</code> special
form:<a href="book-Z-H-28.html#footnote_Temp_632">^[56]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (amb? exp) (tagged-list? exp 'amb))
(define (amb-choices exp) (cdr exp))
</code></pre>
<p>We must also add to the dispatch in <code>analyze</code> a clause that will
recognize this special form and generate an appropriate execution
procedure:</p>
<p><code>((amb? exp) (analyze-amb exp))</code></p>
<p>The top-level procedure <code>ambeval</code> (similar to the version of <code>eval</code>
given in section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>) analyzes the
given expression and applies the resulting execution procedure to the
given environment, together with two given continuations:</p>
<pre><code class="language-scheme editable">(define (ambeval exp env succeed fail)
  ((analyze exp) env succeed fail))
</code></pre>
<p>A success continuation is a
procedure of two arguments: the value just obtained and another failure
continuation to be used if that value leads to a subsequent failure. A
failure continuation is a procedure of no arguments. So
the general form of an execution procedure is</p>
<p><code>(lambda (env succeed fail)</code>
<code>  ;; succeed is (lambda (value fail) ...)</code>
<code>  ;; fail is (lambda () ...)</code>
<code>  ...)</code></p>
<p>For example, executing</p>
<p><code>(ambeval &lt;</code><em><code>exp</code></em><code>&gt;</code>
<code>         the-global-environment</code>
<code>         (lambda (value fail) value)</code>
<code>         (lambda () 'failed))</code></p>
<p>will attempt to evaluate the given expression and will return either the
expression's value (if the evaluation succeeds) or the symbol <code>failed</code>
(if the evaluation fails). The call to <code>ambeval</code> in the driver loop
shown below uses much more complicated continuation procedures, which
continue the loop and support the <code>try-again</code> request.</p>
<p>Most of the complexity of the <code>amb</code> evaluator results from the mechanics
of passing the continuations around as the execution procedures call
each other. In going through the following code, you should compare each
of the execution procedures with the corresponding procedure for the
ordinary evaluator given in
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>.</p>
<h4 id="simple-expressions"><a class="header" href="#simple-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_633">Simple expressions</a></a></h4>
<p>The execution procedures for the simplest kinds of expressions are
essentially the same as those for the ordinary evaluator, except for the
need to manage the continuations. The execution procedures simply
succeed with the value of the expression, passing along the failure
continuation that was passed to them.</p>
<pre><code class="language-scheme editable">(define (analyze-self-evaluating exp)
  (lambda (env succeed fail)
    (succeed exp fail)))
(define (analyze-quoted exp)
  (let ((qval (text-of-quotation exp)))
    (lambda (env succeed fail)
      (succeed qval fail))))
(define (analyze-variable exp)
  (lambda (env succeed fail)
    (succeed (lookup-variable-value exp env)
             fail)))
(define (analyze-lambda exp)
  (let ((vars (lambda-parameters exp))
        (bproc (analyze-sequence (lambda-body exp))))
    (lambda (env succeed fail)
      (succeed (make-procedure vars bproc env)
               fail))))
</code></pre>
<p>Notice that looking up a variable always
''succeeds.'' If <code>lookup-variable-value</code> fails to find the variable,
it signals an error, as usual. Such a ''failure'' indicates a
program bug -- a reference to an unbound variable; it is not an
indication that we should try another nondeterministic choice instead of
the one that is currently being tried.</p>
<h4 id="conditionals-and-sequences"><a class="header" href="#conditionals-and-sequences"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_634">Conditionals and sequences</a></a></h4>
<p>Conditionals are also handled in a similar way as in the ordinary
evaluator. The execution procedure generated by <code>analyze-if</code> invokes the
predicate execution procedure <code>pproc</code> with a success continuation that
checks whether the predicate value is true and goes on to execute either
the consequent or the alternative. If the execution of <code>pproc</code> fails,
the original failure continuation for the <code>if</code> expression is called.</p>
<pre><code class="language-scheme editable">(define (analyze-if exp)
  (let ((pproc (analyze (if-predicate exp)))
        (cproc (analyze (if-consequent exp)))
        (aproc (analyze (if-alternative exp))))
    (lambda (env succeed fail)
      (pproc env
             ;; success continuation for evaluating the predicate
             ;; to obtain pred-value
             (lambda (pred-value fail2)
               (if (true? pred-value)
                   (cproc env succeed fail2)
                   (aproc env succeed fail2)))
             ;; failure continuation for evaluating the predicate
             fail))))
</code></pre>
<p>Sequences are also handled in the same way as in the previous evaluator,
except for the machinations in the subprocedure <code>sequentially</code> that are
required for passing the continuations. Namely, to sequentially execute
<code>a</code> and then <code>b</code>, we call <code>a</code> with a success continuation that calls
<code>b</code>.</p>
<pre><code class="language-scheme editable">(define (analyze-sequence exps)
  (define (sequentially a b)
    (lambda (env succeed fail)
      (a env
         ; success continuation for calling a
         (lambda (a-value fail2)
           (b env succeed fail2))
         ; failure continuation for calling a
         fail)))
  (define (loop first-proc rest-procs)
    (if (null? rest-procs)
        first-proc
        (loop (sequentially first-proc (car rest-procs))
              (cdr rest-procs))))
  (let ((procs (map analyze exps)))
    (if (null? procs)
        (error "Empty sequence -- ANALYZE"))
    (loop (car procs) (cdr procs))))
</code></pre>
<h4 id="definitions-and-assignments"><a class="header" href="#definitions-and-assignments"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_635">Definitions and assignments</a></a></h4>
<p>Definitions are another case where we must go to some trouble to manage
the continuations, because it is necessary to evaluate the
definition-value expression before actually defining the new variable.
To accomplish this, the definition-value execution procedure <code>vproc</code> is
called with the environment, a success continuation, and the failure
continuation. If the execution of <code>vproc</code> succeeds, obtaining a value
<code>val</code> for the defined variable, the variable is defined and the success
is propagated:</p>
<pre><code class="language-scheme editable">(define (analyze-definition exp)
  (let ((var (definition-variable exp))
        (vproc (analyze (definition-value exp))))
    (lambda (env succeed fail)
      (vproc env              
             (lambda (val fail2)
               (define-variable! var val env)
               (succeed 'ok fail2))
             fail))))
</code></pre>
<p>Assignments are more interesting. This is the first place
where we really use the continuations, rather than just passing them
around. The execution procedure for assignments starts out like the one
for definitions. It first attempts to obtain the new value to be
assigned to the variable. If this evaluation of <code>vproc</code> fails, the
assignment fails.</p>
<p>If <code>vproc</code> succeeds, however, and we go on to make the assignment, we
must consider the possibility that this branch of the computation might
later fail, which will require us to backtrack out of the assignment.
Thus, we must arrange to undo the assignment as part of the backtracking
process.<a href="book-Z-H-28.html#footnote_Temp_636">^[57]{.small}^</a></p>
<p>This is accomplished by giving <code>vproc</code> a success continuation (marked
with the comment ''<em>1</em>'' below) that saves the old value of the
variable before assigning the new value to the variable and proceeding
from the assignment. The failure continuation that is passed along with
the value of the assignment (marked with the comment ''<em>2</em>''
below) restores the old value of the variable before continuing the
failure. That is, a successful assignment provides a failure
continuation that will intercept a subsequent failure; whatever failure
would otherwise have called <code>fail2</code> calls this procedure instead, to
undo the assignment before actually calling <code>fail2</code>.</p>
<pre><code class="language-scheme editable">(define (analyze-assignment exp)
  (let ((var (assignment-variable exp))
        (vproc (analyze (assignment-value exp))))
    (lambda (env succeed fail)
      (vproc env
             (lambda (val fail2)         ; *1*
               (let ((old-value
                      (lookup-variable-value var env))) 
                 (set-variable-value! var val env)
                 (succeed 'ok
                          (lambda ()    ; *2*
                            (set-variable-value! var
                                                 old-value
                                                 env)
                            (fail2)))))
             fail))))
</code></pre>
<h4 id="procedure-applications"><a class="header" href="#procedure-applications"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_637">Procedure applications</a></a></h4>
<p>The execution procedure for applications contains no new ideas except
for the technical complexity of managing the continuations. This
complexity arises in <code>analyze-application</code>, due to the need to keep
track of the success and failure continuations as we evaluate the
operands. We use a procedure <code>get-args</code> to evaluate the list of
operands, rather than a simple <code>map</code> as in the ordinary evaluator.</p>
<pre><code class="language-scheme editable">(define (analyze-application exp)
  (let ((fproc (analyze (operator exp)))
        (aprocs (map analyze (operands exp))))
    (lambda (env succeed fail)
      (fproc env
             (lambda (proc fail2)
               (get-args aprocs
                         env
                         (lambda (args fail3)
                           (execute-application
                            proc args succeed fail3))
                         fail2))
             fail))))
</code></pre>
<p>In <code>get-args</code>, notice how <code>cdr</code>ing down the list of <code>aproc</code> execution
procedures and <code>cons</code>ing up the resulting list of <code>args</code> is accomplished
by calling each <code>aproc</code> in the list with a success continuation that
recursively calls <code>get-args</code>. Each of these recursive calls to
<code>get-args</code> has a success continuation whose value is the <code>cons</code> of the
newly obtained argument onto the list of accumulated arguments:</p>
<pre><code class="language-scheme editable">(define (get-args aprocs env succeed fail)
  (if (null? aprocs)
      (succeed '() fail)
      ((car aprocs) env
                    ; success continuation for this aproc
                    (lambda (arg fail2)
                      (get-args (cdr aprocs)
                                env
                                ;; success continuation for recursive
                                ;; call to get-args
                                (lambda (args fail3)
                                  (succeed (cons arg args)
                                           fail3))
                                fail2))
                    fail)))
</code></pre>
<p>The actual procedure application, which is performed by
<code>execute-application</code>, is accomplished in the same way as for the
ordinary evaluator, except for the need to manage the continuations.</p>
<pre><code class="language-scheme editable">(define (execute-application proc args succeed fail)
  (cond ((primitive-procedure? proc)
         (succeed (apply-primitive-procedure proc args)
                  fail))
        ((compound-procedure? proc)
         ((procedure-body proc)
          (extend-environment (procedure-parameters proc)
                              args
                              (procedure-environment proc))
          succeed
          fail))
        (else
         (error
          "Unknown procedure type -- EXECUTE-APPLICATION"
          proc))))
</code></pre>
<h4 id="evaluating-amb-expressions"><a class="header" href="#evaluating-amb-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_638">Evaluating <code>amb</code> expressions</a></a></h4>
<p>The <code>amb</code> special form is the key element in the
nondeterministic language. Here we see the essence of the interpretation
process and the reason for keeping track of the continuations. The
execution procedure for <code>amb</code> defines a loop <code>try-next</code> that cycles
through the execution procedures for all the possible values of the
<code>amb</code> expression. Each execution procedure is called with a failure
continuation that will try the next one. When there are no more
alternatives to try, the entire <code>amb</code> expression fails.</p>
<pre><code class="language-scheme editable">(define (analyze-amb exp)
  (let ((cprocs (map analyze (amb-choices exp))))
    (lambda (env succeed fail)
      (define (try-next choices)
        (if (null? choices)
            (fail)
            ((car choices) env
                           succeed
                           (lambda ()
                             (try-next (cdr choices))))))
      (try-next cprocs))))
</code></pre>
<h4 id="driver-loop-1"><a class="header" href="#driver-loop-1"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_639">Driver loop</a></a></h4>
<p>The driver loop for the <code>amb</code> evaluator
is complex, due to the mechanism that permits the user to try again in
evaluating an expression. The driver uses a procedure called
<code>internal-loop</code>, which takes as argument a procedure <code>try-again</code>. The
intent is that calling <code>try-again</code> should go on to the next untried
alternative in the nondeterministic evaluation. <code>Internal-loop</code> either
calls <code>try-again</code> in response to the user typing <code>try-again</code> at the
driver loop, or else starts a new evaluation by calling <code>ambeval</code>.</p>
<p>The failure continuation for this call to <code>ambeval</code> informs the user
that there are no more values and re-invokes the driver loop.</p>
<p>The success continuation for the call to <code>ambeval</code> is more subtle. We
print the obtained value and then invoke the internal loop again with a
<code>try-again</code> procedure that will be able to try the next alternative.
This <code>next-alternative</code> procedure is the second argument that was passed
to the success continuation. Ordinarily, we think of this second
argument as a failure continuation to be used if the current evaluation
branch later fails. In this case, however, we have completed a
successful evaluation, so we can invoke the ''failure'' alternative
branch in order to search for additional successful evaluations.</p>
<pre><code class="language-scheme editable">(define input-prompt ";;; Amb-Eval input:")
(define output-prompt ";;; Amb-Eval value:")
(define (driver-loop)
  (define (internal-loop try-again)
    (prompt-for-input input-prompt)
    (let ((input (read)))
      (if (eq? input 'try-again)
          (try-again)
          (begin
            (newline)
            (display ";;; Starting a new problem ")
            (ambeval input
                     the-global-environment
                     ;; ambeval success
                     (lambda (val next-alternative)
                       (announce-output output-prompt)
                       (user-print val)
                       (internal-loop next-alternative))
                     ;; ambeval failure
                     (lambda ()
                       (announce-output
                        ";;; There are no more values of")
                       (user-print input)
                       (driver-loop)))))))
  (internal-loop
   (lambda ()
     (newline)
     (display ";;; There is no current problem")
     (driver-loop))))
</code></pre>
<p>The initial call to <code>internal-loop</code> uses a <code>try-again</code> procedure that
complains that there is no current problem and restarts the driver loop.
This is the behavior that will happen if the user types <code>try-again</code> when
there is no evaluation in progress.</p>
<p><strong>Exercise 4.50.</strong>  Implement a new special form <code>ramb</code>
that is like <code>amb</code> except that it searches alternatives in a random
order, rather than from left to right. Show how this can help with
Alyssa's problem in exercise <a href="book-Z-H-28.html#%_thm_4.49">4.49</a>.</p>
<p><strong>Exercise 4.51.</strong>  Implement a new kind of assignment
called <code>permanent-set!</code> that is not undone upon failure. For example, we
can choose two distinct elements from a list and count the number of
trials required to make a successful choice as follows:</p>
<pre><code class="language-scheme editable">(define count 0)
(let ((x (an-element-of '(a b c)))
      (y (an-element-of '(a b c))))
  (permanent-set! count (+ count 1))
  (require (not (eq? x y)))
  (list x y count))
</code></pre>
<p><em><code>;;; Starting a new problem</code></em>
<em><code>;;; Amb-Eval value:</code></em>
<em><code>(a b 2)</code></em>
<em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">try-again
</code></pre>
<p><em><code>;;; Amb-Eval value:</code></em>
<em><code>(a c 3)</code></em></p>
<p>What values would have been displayed if we had used <code>set!</code> here rather
than <code>permanent-set!</code> ?</p>
<p><strong>Exercise 4.52.</strong>  Implement a new construct called
<code>if-fail</code> that permits the user to catch the failure of an expression.
<code>If-fail</code> takes two expressions. It evaluates the first expression as
usual and returns as usual if the evaluation succeeds. If the evaluation
fails, however, the value of the second expression is returned, as in
the following example:</p>
<p><em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(if-fail (let ((x (an-element-of '(1 3 5))))
           (require (even? x))
           x)
         'all-odd)
</code></pre>
<p><em><code>;;; Starting a new problem</code></em>
<em><code>;;; Amb-Eval value:</code></em>
<em><code>all-odd</code></em>
<em><code>;;; Amb-Eval input:</code></em></p>
<pre><code class="language-scheme editable">(if-fail (let ((x (an-element-of '(1 3 5 8))))
           (require (even? x))
           x)
         'all-odd)
</code></pre>
<p><em><code>;;; Starting a new problem</code></em>
<em><code>;;; Amb-Eval value:</code></em>
<em><code>8</code></em></p>
<p><strong>Exercise 4.53.</strong>  With <code>permanent-set!</code> as described
in exercise <a href="book-Z-H-28.html#%_thm_4.51">4.51</a> and <code>if-fail</code> as in
exercise <a href="book-Z-H-28.html#%_thm_4.52">4.52</a>, what will be the result of
evaluating</p>
<pre><code class="language-scheme editable">(let ((pairs '()))
  (if-fail (let ((p (prime-sum-pair '(1 3 5 8) '(20 35 110))))
             (permanent-set! pairs (cons p pairs))
             (amb))
           pairs))
</code></pre>
<p><strong>Exercise 4.54.</strong>  If we had not
realized that <code>require</code> could be implemented as an ordinary procedure
that uses <code>amb</code>, to be defined by the user as part of a nondeterministic
program, we would have had to implement it as a special form. This would
require syntax procedures</p>
<pre><code class="language-scheme editable">(define (require? exp) (tagged-list? exp 'require))

(define (require-predicate exp) (cadr exp))
</code></pre>
<p>and a new clause in the dispatch in <code>analyze</code></p>
<p><code>((require? exp) (analyze-require exp))</code></p>
<p>as well the procedure <code>analyze-require</code> that handles <code>require</code>
expressions. Complete the following definition of <code>analyze-require</code>.</p>
<pre><code class="language-scheme editable">(define (analyze-require exp)
  (let ((pproc (analyze (require-predicate exp))))
    (lambda (env succeed fail)
      (pproc env
             (lambda (pred-value fail2)
               (if &lt;*??*&gt;
                   &lt;*??*&gt;
                   (succeed 'ok fail2)))
             fail))))
</code></pre>
<p>)</p>
<hr />
<p>)</p>
<p>)
^[42]{.small}^](book-Z-H-28.html#call_footnote_Temp_598)
We assume that we have previously defined a procedure <code>prime?</code> that
tests whether numbers are prime. Even with <code>prime?</code> defined, the
<code>prime-sum-pair</code> procedure may look suspiciously like the unhelpful
''pseudo-Lisp'' attempt to define the square-root function, which we
described at the beginning of
section <a href="book-Z-H-10.html#%_sec_1.1.7">1.1.7</a>. In fact, a square-root
procedure along those lines can actually be formulated as a
nondeterministic program. By incorporating a search mechanism into the
evaluator, we are eroding the distinction
between purely declarative descriptions and imperative specifications of
how to compute answers. We'll go even farther in this direction in
section <a href="book-Z-H-29.html#%_sec_4.4">4.4</a>.</p>
<p>^[43]{.small}^](book-Z-H-28.html#call_footnote_Temp_599)
The idea of <code>amb</code> for nondeterministic programming was
first described in 1961 by John McCarthy (see McCarthy
1967).</p>
<p>^[44]{.small}^](book-Z-H-28.html#call_footnote_Temp_600)
In actuality, the distinction between nondeterministically returning a
single choice and returning all choices depends somewhat on our point of
view. From the perspective of the code that uses the value, the
nondeterministic choice returns a single value. From the perspective of
the programmer designing the code, the nondeterministic choice
potentially returns all possible values, and the computation branches so
that each value is investigated separately.</p>
<p>^[45]{.small}^](book-Z-H-28.html#call_footnote_Temp_601)
One might object that this is a hopelessly inefficient mechanism. It
might require millions of processors to solve some easily stated problem
this way, and most of the time most of those processors would be idle.
This objection should be taken in the context of history. Memory used to
be considered just such an expensive commodity. In 1964 a
megabyte of RAM cost about $400,000. Now every personal computer has
many megabytes of RAM, and most of the time most of that RAM is unused.
It is hard to underestimate the cost of mass-produced electronics.</p>
<p>^[46]{.small}^](book-Z-H-28.html#call_footnote_Temp_602)
Automagically: ''Automatically, but in a way which, for some reason
(typically because it is too complicated, or too ugly, or perhaps even
too trivial), the speaker doesn't feel like explaining.'' (Steele
1983, Raymond 1993)</p>
<p>^[47]{.small}^](book-Z-H-28.html#call_footnote_Temp_603)
The integration of automatic search strategies into
programming languages has had a long and checkered history. The first
suggestions that nondeterministic algorithms might be elegantly encoded
in a programming language with search and automatic backtracking came
from Robert Floyd (1967). Carl Hewitt
(1969) invented a programming language called Planner
that explicitly supported automatic chronological backtracking,
providing for a built-in depth-first search strategy.
Sussman, Winograd, and
Charniak (1971) implemented a subset of this language, called
MicroPlanner, which was used to support work in problem
solving and robot planning. Similar ideas, arising from logic and
theorem proving, led to the genesis in Edinburgh and Marseille of the
elegant language Prolog (which we will discuss in
section <a href="book-Z-H-29.html#%_sec_4.4">4.4</a>). After sufficient frustration
with automatic search, McDermott and
Sussman (1972) developed a language called Conniver,
which included mechanisms for placing the search strategy under
programmer control. This proved unwieldy, however, and
Sussman and Stallman (1975) found a more
tractable approach while investigating methods of symbolic analysis for
electrical circuits. They developed a non-chronological backtracking
scheme that was based on tracing out the logical dependencies connecting
facts, a technique that has come to be known as
<em>dependency-directed backtracking</em>. Although their method
was complex, it produced reasonably efficient programs because it did
little redundant search. Doyle (1979) and
McAllester (1978, 1980) generalized and clarified the methods of
Stallman and Sussman, developing a new paradigm for formulating search
that is now called <em>truth maintenance</em>. Modern
problem-solving systems all use some form of truth-maintenance system as
a substrate. See Forbus and deKleer 1993
for a discussion of elegant ways to build truth-maintenance systems and
applications using truth maintenance.
Zabih, McAllester, and
Chapman 1987 describes a nondeterministic extension to Scheme that is
based on <code>amb</code>; it is similar to the interpreter described in this
section, but more sophisticated, because it uses dependency-directed
backtracking rather than chronological backtracking.
Winston 1992 gives an introduction to both kinds of backtracking.</p>
<p>^[48]{.small}^](book-Z-H-28.html#call_footnote_Temp_609)
Our program uses the following procedure to determine if the elements of
a list are distinct:</p>
<pre><code class="language-scheme editable">(define (distinct? items)
  (cond ((null? items) true)
        ((null? (cdr items)) true)
        ((member (car items) (cdr items)) false)
        (else (distinct? (cdr items)))))
</code></pre>
<p><code>Member</code> is like <code>memq</code> except that it uses <code>equal?</code>
instead of <code>eq?</code> to test for equality.</p>
<p>^[49]{.small}^](book-Z-H-28.html#call_footnote_Temp_616)
This is taken from a booklet called ''Problematical Recreations,''
published in the 1960s by Litton Industries, where it is attributed to
the <em>Kansas State Engineer</em>.</p>
<p>^[50]{.small}^](book-Z-H-28.html#call_footnote_Temp_619)
Here we use the convention that the first element of each list
designates the part of speech for the rest of the words in the list.</p>
<p>^[51]{.small}^](book-Z-H-28.html#call_footnote_Temp_620)
Notice that <code>parse-word</code> uses <code>set!</code> to modify the unparsed input list.
For this to work, our <code>amb</code> evaluator must undo the effects of <code>set!</code>
operations when it backtracks.</p>
<p>^[52]{.small}^](book-Z-H-28.html#call_footnote_Temp_621)
Observe that this definition is recursive -- a verb may be followed by
any number of prepositional phrases.</p>
<p>^[53]{.small}^](book-Z-H-28.html#call_footnote_Temp_626)
This kind of grammar can become arbitrarily complex, but it
is only a toy as far as real language understanding is
concerned. Real natural-language understanding by computer requires an
elaborate mixture of syntactic analysis and interpretation of meaning.
On the other hand, even toy parsers can be useful in supporting flexible
command languages for programs such as information-retrieval systems.
Winston 1992 discusses computational approaches to real
language understanding and also the applications of simple grammars to
command languages.</p>
<p>^[54]{.small}^](book-Z-H-28.html#call_footnote_Temp_628)
Although Alyssa's idea works just fine (and is surprisingly simple),
the sentences that it generates are a bit boring -- they don't sample
the possible sentences of this language in a very interesting way. In
fact, the grammar is highly recursive in many places, and Alyssa's
technique ''falls into'' one of these recursions and gets stuck. See
exercise <a href="book-Z-H-28.html#%_thm_4.50">4.50</a> for a way to deal with
this.</p>
<p>^[55]{.small}^](book-Z-H-28.html#call_footnote_Temp_629)
We chose to implement the lazy evaluator in
section <a href="book-Z-H-27.html#%_sec_4.2">4.2</a> as a modification of the
ordinary metacircular evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>. In contrast, we will base
the <code>amb</code> evaluator on the analyzing evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>, because the execution
procedures in that evaluator provide a convenient framework for
implementing backtracking.</p>
<p>^[56]{.small}^](book-Z-H-28.html#call_footnote_Temp_632)
We assume that the evaluator supports <code>let</code> (see
exercise <a href="book-Z-H-26.html#%_thm_4.22">4.22</a>), which we have used in our
nondeterministic programs.</p>
<p>^[57]{.small}^](book-Z-H-28.html#call_footnote_Temp_636)
We didn't worry about undoing definitions, since we can
assume that internal definitions are scanned out
(section <a href="book-Z-H-26.html#%_sec_4.1.6">4.1.6</a>).</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="44--logic-programming"><a class="header" href="#44--logic-programming"><a href="book-Z-H-4.html#%_toc_%_sec_4.4">4.4  Logic Programming</a></a></h2>
<p>In chapter 1
we stressed that computer science deals with imperative (how to)
knowledge, whereas mathematics deals with declarative (what is)
knowledge. Indeed, programming languages require that the programmer
express knowledge in a form that indicates the step-by-step methods for
solving particular problems. On the other hand, high-level languages
provide, as part of the language implementation, a substantial amount of
methodological knowledge that frees the user from concern with numerous
details of how a specified computation will progress.</p>
<p>Most programming languages, including Lisp, are organized around
computing the values of mathematical functions. Expression-oriented
languages (such as Lisp, Fortran, and Algol) capitalize on the
'pun' that an expression that describes the value of a function
may also be interpreted as a means of computing that value. Because of
this, most programming languages are strongly biased toward
unidirectional computations (computations with well-defined inputs and
outputs). There are, however, radically different programming languages
that relax this bias. We saw one such example in
section <a href="book-Z-H-22.html#%_sec_3.3.5">3.3.5</a>, where the objects of
computation were arithmetic constraints. In a constraint system the
direction and the order of computation are not so well specified; in
carrying out a computation the system must therefore provide more
detailed 'how to' knowledge than would be the case with an
ordinary arithmetic computation. This does not mean, however, that the
user is released altogether from the responsibility of providing
imperative knowledge. There are many constraint networks that implement
the same set of constraints, and the user must choose from the set of
mathematically equivalent networks a suitable network to specify a
particular computation.</p>
<p>The nondeterministic program evaluator of
section <a href="book-Z-H-28.html#%_sec_4.3">4.3</a> also moves away from the view
that programming is about constructing algorithms for computing
unidirectional functions. In a nondeterministic language, expressions
can have more than one value, and, as a result, the computation is
dealing with relations rather than with single-valued
functions. Logic programming extends this idea by combining a relational
vision of programming with a powerful kind of symbolic pattern matching
called
<em>unification</em>.<a href="book-Z-H-29.html#footnote_Temp_645">^[58]{.small}^</a></p>
<p>This approach, when it works, can be a
very powerful way to write programs. Part of the power comes from the
fact that a single 'what is' fact can be used to solve a number of
different problems that would have different 'how to' components.
As an example, consider the <code>append</code> operation, which
takes two lists as arguments and combines their elements to form a
single list. In a procedural language such as Lisp, we could define
<code>append</code> in terms of the basic list constructor <code>cons</code>, as we did in
section <a href="book-Z-H-15.html#%_sec_2.2.1">2.2.1</a>:</p>
<pre><code class="language-scheme editable">(define (append x y)
  (if (null? x)
      y
      (cons (car x) (append (cdr x) y))))
</code></pre>
<p>This procedure can be regarded as a translation into Lisp of the
following two rules, the first of which covers the case where the first
list is empty and the second of which handles the case of a nonempty
list, which is a <code>cons</code> of two parts:</p>
<ul>
<li>For any list <code>y</code>, the empty list and <code>y</code> <code>append</code> to form <code>y</code>.</li>
<li>For any <code>u</code>, <code>v</code>, <code>y</code>, and <code>z</code>, <code>(cons u v)</code> and <code>y</code> <code>append</code> to form
<code>(cons u z)</code> if <code>v</code> and <code>y</code> <code>append</code> to form
<code>z</code>.<a href="book-Z-H-29.html#footnote_Temp_646">^[59]{.small}^</a></li>
</ul>
<p>Using the <code>append</code> procedure, we can answer questions such as</p>
<blockquote>
<p>Find the <code>append</code> of <code>(a b)</code> and <code>(c d)</code>.</p>
</blockquote>
<p>But the same two rules are also sufficient for answering the following
sorts of questions, which the procedure can't answer:</p>
<blockquote>
<p>Find a list <code>y</code> that <code>append</code>s with <code>(a b)</code> to produce <code>(a b c d)</code>.</p>
<p>Find all <code>x</code> and <code>y</code> that <code>append</code> to form <code>(a b c d)</code>.</p>
</blockquote>
<p>In a logic programming language, the
programmer writes an <code>append</code> 'procedure' by stating the two rules
about <code>append</code> given above. 'How to' knowledge is provided
automatically by the interpreter to allow this single pair of rules to
be used to answer all three types of questions about
<code>append</code>.<a href="book-Z-H-29.html#footnote_Temp_647">^[60]{.small}^</a></p>
<p>Contemporary logic programming languages (including the one we implement
here) have substantial deficiencies, in that their general 'how
to' methods can lead them into spurious infinite loops or other
undesirable behavior. Logic programming is an active field of research
in computer
science.<a href="book-Z-H-29.html#footnote_Temp_648">^[61]{.small}^</a></p>
<p>Earlier in this chapter we explored the technology of implementing
interpreters and described the elements that are essential to an
interpreter for a Lisp-like language (indeed, to an interpreter for any
conventional language). Now we will apply these ideas to discuss an
interpreter for a logic programming language. We call this
language the <em>query language</em>, because it is very useful
for retrieving information from data bases by formulating
<em>queries</em>, or questions, expressed in the language. Even
though the query language is very different from Lisp, we will find it
convenient to describe the language in terms of the same general
framework we have been using all along: as a collection of primitive
elements, together with means of combination that enable us to combine
simple elements to create more complex elements and means of abstraction
that enable us to regard complex elements as single conceptual units. An
interpreter for a logic programming language is considerably more
complex than an interpreter for a language like Lisp. Nevertheless, we
will see that our query-language interpreter contains
many of the same elements found in the interpreter of
section <a href="book-Z-H-26.html#%_sec_4.1">4.1</a>. In particular, there will be
an 'eval' part that classifies expressions according to type and
an 'apply' part that implements the language's abstraction
mechanism (procedures in the case of Lisp, and <em>rules</em> in the case of
logic programming). Also, a central role is played in the implementation
by a frame data structure, which determines the correspondence between
symbols and their associated values. One additional interesting aspect
of our query-language implementation is that we make substantial use of
streams, which were introduced in chapter 3.</p>
<h3 id="441--deductive-information-retrieval"><a class="header" href="#441--deductive-information-retrieval"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.1">4.4.1  Deductive Information Retrieval</a></a></h3>
<p>Logic programming excels in providing
interfaces to data bases for information retrieval. The query language
we shall implement in this chapter is designed to be used in this way.</p>
<p>In order to illustrate what the query system does, we will show how it
can be used to manage the data base of personnel records for
Microshaft, a thriving high-technology company in the
Boston area. The language provides pattern-directed access to personnel
information and can also take advantage of general rules in order to
make logical deductions.</p>
<h4 id="a-sample-data-base"><a class="header" href="#a-sample-data-base"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_649">A sample data base</a></a></h4>
<p>The personnel data base
for Microshaft contains <em>assertions</em> about company personnel. Here is
the information about Ben Bitdiddle, the resident computer wizard:</p>
<pre><code class="language-scheme editable">(address (Bitdiddle Ben) (Slumerville (Ridge Road) 10))
(job (Bitdiddle Ben) (computer wizard))
(salary (Bitdiddle Ben) 60000)
</code></pre>
<p>Each assertion is a list (in this case a triple) whose elements can
themselves be lists.</p>
<p>As resident wizard, Ben is in charge of the company's computer
division, and he supervises two programmers and one technician. Here is
the information about them:</p>
<pre><code class="language-scheme editable">(address (Hacker Alyssa P) (Cambridge (Mass Ave) 78))
(job (Hacker Alyssa P) (computer programmer))
(salary (Hacker Alyssa P) 40000)
(supervisor (Hacker Alyssa P) (Bitdiddle Ben))
(address (Fect Cy D) (Cambridge (Ames Street) 3))
(job (Fect Cy D) (computer programmer))
(salary (Fect Cy D) 35000)
(supervisor (Fect Cy D) (Bitdiddle Ben))
(address (Tweakit Lem E) (Boston (Bay State Road) 22))
(job (Tweakit Lem E) (computer technician))
(salary (Tweakit Lem E) 25000)
(supervisor (Tweakit Lem E) (Bitdiddle Ben))
</code></pre>
<p>There is also a programmer trainee, who is supervised by Alyssa:</p>
<pre><code class="language-scheme editable">(address (Reasoner Louis) (Slumerville (Pine Tree Road) 80))
(job (Reasoner Louis) (computer programmer trainee))
(salary (Reasoner Louis) 30000)
(supervisor (Reasoner Louis) (Hacker Alyssa P))
</code></pre>
<p>All of these people are in the computer division, as indicated by the
word <code>computer</code> as the first item in their job descriptions.</p>
<p>Ben is a high-level employee. His supervisor is the company's big wheel
himself:</p>
<pre><code class="language-scheme editable">(supervisor (Bitdiddle Ben) (Warbucks Oliver))
(address (Warbucks Oliver) (Swellesley (Top Heap Road)))
(job (Warbucks Oliver) (administration big wheel))
(salary (Warbucks Oliver) 150000)
</code></pre>
<p>Besides the computer division supervised by Ben, the company has an
accounting division, consisting of a chief accountant and his assistant:</p>
<pre><code class="language-scheme editable">(address (Scrooge Eben) (Weston (Shady Lane) 10))
(job (Scrooge Eben) (accounting chief accountant))
(salary (Scrooge Eben) 75000)
(supervisor (Scrooge Eben) (Warbucks Oliver))
(address (Cratchet Robert) (Allston (N Harvard Street) 16))
(job (Cratchet Robert) (accounting scrivener))
(salary (Cratchet Robert) 18000)
(supervisor (Cratchet Robert) (Scrooge Eben))
</code></pre>
<p>There is also a secretary for the big wheel:</p>
<pre><code class="language-scheme editable">(address (Aull DeWitt) (Slumerville (Onion Square) 5))
(job (Aull DeWitt) (administration secretary))
(salary (Aull DeWitt) 25000)
(supervisor (Aull DeWitt) (Warbucks Oliver))
</code></pre>
<p>The data base also contains assertions about which kinds of jobs can be
done by people holding other kinds of jobs. For instance, a computer
wizard can do the jobs of both a computer programmer and a computer
technician:</p>
<pre><code class="language-scheme editable">(can-do-job (computer wizard) (computer programmer))
(can-do-job (computer wizard) (computer technician))
</code></pre>
<p>A computer programmer could fill in for a trainee:</p>
<pre><code class="language-scheme editable">(can-do-job (computer programmer)
            (computer programmer trainee))
</code></pre>
<p>Also, as is well known,</p>
<pre><code class="language-scheme editable">(can-do-job (administration secretary)
            (administration big wheel))
</code></pre>
<h4 id="simple-queries"><a class="header" href="#simple-queries"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_650">Simple queries</a></a></h4>
<p>The query language allows users to retrieve information
from the data base by posing queries in response to the system's
prompt. For example, to find all computer programmers one can say</p>
<p><em><code>;;; Query input:</code></em></p>
<pre><code class="language-scheme editable">(job ?x (computer programmer))
</code></pre>
<p>The system will respond with the following items:</p>
<p><em><code>;;; Query results:</code></em></p>
<pre><code class="language-scheme editable">(job (Hacker Alyssa P) (computer programmer))
(job (Fect Cy D) (computer programmer))
</code></pre>
<p>The input query specifies that we are looking for entries
in the data base that match a certain <em>pattern</em>. In this example, the
pattern specifies entries consisting of three items, of which the first
is the literal symbol <code>job</code>, the second can be anything, and the third
is the literal list <code>(computer programmer)</code>. The 'anything' that
can be the second item in the matching list is specified by a
<em>pattern variable</em>, <code>?x</code>. The general form of a pattern
variable is a symbol, taken to be the name of the variable, preceded by
a question mark. We will see below why it is useful to specify names for
pattern variables rather than just putting <code>?</code> into patterns to
represent 'anything.' The system responds to a simple query by
showing all entries in the data base that match the specified pattern.</p>
<p>A pattern can have more than one variable. For example, the query</p>
<pre><code class="language-scheme editable">(address ?x ?y)
</code></pre>
<p>will list all the employees' addresses.</p>
<p>A pattern can have no variables, in which case the query simply
determines whether that pattern is an entry in the data base. If so,
there will be one match; if not, there will be no matches.</p>
<p>The same pattern variable can appear more than once in a query,
specifying that the same 'anything' must appear in each position.
This is why variables have names. For example,</p>
<pre><code class="language-scheme editable">(supervisor ?x ?x)
</code></pre>
<p>finds all people who supervise themselves (though there are no such
assertions in our sample data base).</p>
<p>The query</p>
<pre><code class="language-scheme editable">(job ?x (computer ?type))
</code></pre>
<p>matches all job entries whose third item is a two-element list whose
first item is <code>computer</code>:</p>
<pre><code class="language-scheme editable">(job (Bitdiddle Ben) (computer wizard))
(job (Hacker Alyssa P) (computer programmer))
(job (Fect Cy D) (computer programmer))
(job (Tweakit Lem E) (computer technician))
</code></pre>
<p>This same pattern does <em>not</em> match</p>
<pre><code class="language-scheme editable">(job (Reasoner Louis) (computer programmer trainee))
</code></pre>
<p>because the third item in the entry is a list of three elements, and the
pattern's third item specifies that there should be two elements. If we
wanted to change the pattern so that the third item could be any list
beginning with <code>computer</code>, we could
specify<a href="book-Z-H-29.html#footnote_Temp_651">^[62]{.small}^</a></p>
<pre><code class="language-scheme editable">(job ?x (computer . ?type))
</code></pre>
<p>For example,</p>
<pre><code class="language-scheme editable">(computer . ?type)
</code></pre>
<p>matches the data</p>
<pre><code class="language-scheme editable">(computer programmer trainee)
</code></pre>
<p>with <code>?type</code> as the list <code>(programmer trainee)</code>. It also matches the
data</p>
<pre><code class="language-scheme editable">(computer programmer)
</code></pre>
<p>with <code>?type</code> as the list <code>(programmer)</code>, and matches the data</p>
<pre><code class="language-scheme editable">(computer)
</code></pre>
<p>with <code>?type</code> as the empty list <code>()</code>.</p>
<p>We can describe the query language's processing of simple queries as
follows:</p>
<ul>
<li>The system finds all assignments to variables in the query
pattern that <em>satisfy</em> the pattern -- that is, all
sets of values for the variables such that if the pattern variables
are <em>instantiated with</em> (replaced by) the values, the
result is in the data base.</li>
<li>The system responds to the query by listing all instantiations of the
query pattern with the variable assignments that satisfy it.</li>
</ul>
<p>Note that if the pattern has no variables, the query reduces to a
determination of whether that pattern is in the data base. If so, the
empty assignment, which assigns no values to variables, satisfies that
pattern for that data base.</p>
<p><strong>Exercise 4.55.</strong>  Give simple queries that retrieve
the following information from the data base:</p>
<p>a. all people supervised by Ben Bitdiddle;</p>
<p>b. the names and jobs of all people in the accounting division;</p>
<p>c. the names and addresses of all people who live in Slumerville.</p>
<h4 id="compound-queries"><a class="header" href="#compound-queries"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_653">Compound queries</a></a></h4>
<p>Simple queries form the primitive operations of the
query language. In order to form compound operations, the query language
provides means of combination. One thing that makes the query language a
logic programming language is that the means of combination mirror the
means of combination used in forming logical expressions: <code>and</code>, <code>or</code>,
and <code>not</code>. (Here <code>and</code>, <code>or</code>, and <code>not</code> are not the Lisp primitives, but
rather operations built into the query language.)</p>
<p>We can use <code>and</code> as follows to find the addresses of all
the computer programmers:</p>
<pre><code class="language-scheme editable">(and (job ?person (computer programmer))
     (address ?person ?where))
</code></pre>
<p>The resulting output is</p>
<pre><code class="language-scheme editable">(and (job (Hacker Alyssa P) (computer programmer))
     (address (Hacker Alyssa P) (Cambridge (Mass Ave) 78)))
(and (job (Fect Cy D) (computer programmer))
     (address (Fect Cy D) (Cambridge (Ames Street) 3)))
</code></pre>
<p>In general,</p>
<p><code>(and &lt;</code><em><code>query</code><del><code>1</code></del></em><code>&gt; &lt;</code><em><code>query</code><del><code>2</code></del></em><code>&gt; ... &lt;</code><em><code>query</code>~</em><code>n</code><em>~</em><code>&gt;)</code></p>
<p>is satisfied by all sets of values for the pattern variables that
simultaneously satisfy &lt;<em>query~1~</em>&gt; <code>...</code> &lt;<em>query~<em>n</em>~</em>&gt;.</p>
<p>As for simple queries, the system processes a compound query by finding
all assignments to the pattern variables that satisfy the query, then
displaying instantiations of the query with those values.</p>
<p>Another means of constructing compound queries is through
<code>or</code>. For example,</p>
<pre><code class="language-scheme editable">(or (supervisor ?x (Bitdiddle Ben))
    (supervisor ?x (Hacker Alyssa P)))
</code></pre>
<p>will find all employees supervised by Ben Bitdiddle or Alyssa P. Hacker:</p>
<pre><code class="language-scheme editable">(or (supervisor (Hacker Alyssa P) (Bitdiddle Ben))
    (supervisor (Hacker Alyssa P) (Hacker Alyssa P)))
(or (supervisor (Fect Cy D) (Bitdiddle Ben))
    (supervisor (Fect Cy D) (Hacker Alyssa P)))
(or (supervisor (Tweakit Lem E) (Bitdiddle Ben))
    (supervisor (Tweakit Lem E) (Hacker Alyssa P)))
(or (supervisor (Reasoner Louis) (Bitdiddle Ben))
    (supervisor (Reasoner Louis) (Hacker Alyssa P)))
</code></pre>
<p>In general,</p>
<p><code>(or &lt;</code><em><code>query</code><del><code>1</code></del></em><code>&gt; &lt;</code><em><code>query</code><del><code>2</code></del></em><code>&gt; ... &lt;</code><em><code>query</code>~</em><code>n</code><em>~</em><code>&gt;)</code></p>
<p>is satisfied by all sets of values for the pattern variables that
satisfy at least one of &lt;<em>query~1~</em>&gt; <code>...</code> &lt;<em>query~<em>n</em>~</em>&gt;.</p>
<p>Compound queries can also be formed with <code>not</code>. For
example,</p>
<pre><code class="language-scheme editable">(and (supervisor ?x (Bitdiddle Ben))
     (not (job ?x (computer programmer))))
</code></pre>
<p>finds all people supervised by Ben Bitdiddle who are not computer
programmers. In general,</p>
<p><code>(not &lt;</code><em><code>query</code><del><code>1</code></del></em><code>&gt;)</code></p>
<p>is satisfied by all assignments to the pattern variables that do not
satisfy
&lt;<em>query~1~</em>&gt;.<a href="book-Z-H-29.html#footnote_Temp_654">^[63]{.small}^</a></p>
<p>The final combining form is called <code>lisp-value</code>. When
<code>lisp-value</code> is the first element of a pattern, it specifies that the
next element is a Lisp predicate to be applied to the rest of the
(instantiated) elements as arguments. In general,</p>
<p><code>(lisp-value &lt;</code><em><code>predicate</code></em><code>&gt; &lt;</code><em><code>arg</code><del><code>1</code></del></em><code>&gt; ... &lt;</code><em><code>arg</code>~</em><code>n</code><em>~</em><code>&gt;)</code></p>
<p>will be satisfied by assignments to the pattern variables for which the
&lt;<em>predicate</em>&gt; applied to the instantiated &lt;<em>arg~1~</em>&gt; <code>...</code>
&lt;<em>arg~<em>n</em>~</em>&gt; is true. For example, to find all people whose salary is
greater than $30,000 we could
write<a href="book-Z-H-29.html#footnote_Temp_655">^[64]{.small}^</a></p>
<pre><code class="language-scheme editable">(and (salary ?person ?amount)
     (lisp-value &gt; ?amount 30000))
</code></pre>
<p><strong>Exercise 4.56.</strong>  Formulate compound queries that
retrieve the following information:</p>
<p>a. the names of all people who are supervised by Ben Bitdiddle,
together with their addresses;</p>
<p>b. all people whose salary is less than Ben Bitdiddle's, together with
their salary and Ben Bitdiddle's salary;</p>
<p>c. all people who are supervised by someone who is not in the computer
division, together with the supervisor's name and job.</p>
<h4 id="rules"><a class="header" href="#rules"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_657">Rules</a></a></h4>
<p>In addition to primitive queries and
compound queries, the query language provides means for abstracting
queries. These are given by <em>rules</em>. The rule</p>
<pre><code class="language-scheme editable">(rule (lives-near ?person-1 ?person-2)
      (and (address ?person-1 (?town . ?rest-1))
           (address ?person-2 (?town . ?rest-2))
           (not (same ?person-1 ?person-2))))
</code></pre>
<p>specifies that two people live near each other if they live in the same
town. The final <code>not</code> clause prevents the rule from saying that all
people live near themselves. The <code>same</code> relation is defined by a very
simple
rule:<a href="book-Z-H-29.html#footnote_Temp_658">^[65]{.small}^</a></p>
<pre><code class="language-scheme editable">(rule (same ?x ?x))
</code></pre>
<p>The following rule declares that a person is a 'wheel' in an
organization if he supervises someone who is in turn a supervisor:</p>
<pre><code class="language-scheme editable">(rule (wheel ?person)
      (and (supervisor ?middle-manager ?person)
           (supervisor ?x ?middle-manager)))
</code></pre>
<p>The general form of a rule is</p>
<p><code>(rule &lt;</code><em><code>conclusion</code></em><code>&gt; &lt;</code><em><code>body</code></em><code>&gt;)</code></p>
<p>where &lt;<em>conclusion</em>&gt; is a pattern and &lt;<em>body</em>&gt; is any
query.<a href="book-Z-H-29.html#footnote_Temp_659">^[66]{.small}^</a>
We can think of a rule as representing a large (even infinite) set of
assertions, namely all instantiations of the rule conclusion with
variable assignments that satisfy the rule body. When we described
simple queries (patterns), we said that an assignment to variables
satisfies a pattern if the instantiated pattern is in the data base. But
the pattern needn't be explicitly in the data base as an assertion. It
can be an implicit assertion implied by a rule. For
example, the query</p>
<pre><code class="language-scheme editable">(lives-near ?x (Bitdiddle Ben))
</code></pre>
<p>results in</p>
<pre><code class="language-scheme editable">(lives-near (Reasoner Louis) (Bitdiddle Ben))
(lives-near (Aull DeWitt) (Bitdiddle Ben))
</code></pre>
<p>To find all computer programmers who live near Ben Bitdiddle, we can ask</p>
<pre><code class="language-scheme editable">(and (job ?x (computer programmer))
     (lives-near ?x (Bitdiddle Ben)))
</code></pre>
<p>As in the case of compound procedures, rules can be used
as parts of other rules (as we saw with the <code>lives-near</code> rule above) or
even be defined recursively. For instance, the rule</p>
<pre><code class="language-scheme editable">(rule (outranked-by ?staff-person ?boss)
      (or (supervisor ?staff-person ?boss)
          (and (supervisor ?staff-person ?middle-manager)
               (outranked-by ?middle-manager ?boss))))
</code></pre>
<p>says that a staff person is outranked by a boss in the organization if
the boss is the person's supervisor or (recursively) if the person's
supervisor is outranked by the boss.</p>
<p><strong>Exercise 4.57.</strong>  Define a rule that says that person
1 can replace person 2 if either person 1 does the same job as person 2
or someone who does person 1's job can also do person 2's job, and if
person 1 and person 2 are not the same person. Using your rule, give
queries that find the following:</p>
<p>a. all people who can replace Cy D. Fect;</p>
<p>b. all people who can replace someone who is being paid more than they
are, together with the two salaries.</p>
<p><strong>Exercise 4.58.</strong>  Define a rule that says that a
person is a 'big shot' in a division if the person works in the
division but does not have a supervisor who works in the division.</p>
<p><strong>Exercise 4.59.</strong>  Ben Bitdiddle has missed one meeting
too many. Fearing that his habit of forgetting meetings could cost him
his job, Ben decides to do something about it. He adds all the weekly
meetings of the firm to the Microshaft data base by asserting the
following:</p>
<pre><code class="language-scheme editable">(meeting accounting (Monday 9am))
(meeting administration (Monday 10am))
(meeting computer (Wednesday 3pm))
(meeting administration (Friday 1pm))
</code></pre>
<p>Each of the above assertions is for a meeting of an entire division. Ben
also adds an entry for the company-wide meeting that spans all the
divisions. All of the company's employees attend this meeting.</p>
<pre><code class="language-scheme editable">(meeting whole-company (Wednesday 4pm))
</code></pre>
<p>a. On Friday morning, Ben wants to query the data base for all the
meetings that occur that day. What query should he use?</p>
<p>b. Alyssa P. Hacker is unimpressed. She thinks it would be much more
useful to be able to ask for her meetings by specifying her name. So she
designs a rule that says that a person's meetings include all
<code>whole-company</code> meetings plus all meetings of that person's division.
Fill in the body of Alyssa's rule.</p>
<pre><code class="language-scheme editable">(rule (meeting-time ?person ?day-and-time)
      &lt;rule-body&gt;)
</code></pre>
<p>c. Alyssa arrives at work on Wednesday morning and wonders what
meetings she has to attend that day. Having defined the above rule, what
query should she make to find this out?</p>
<p><strong>Exercise 4.60.</strong>  By giving the query</p>
<pre><code class="language-scheme editable">(lives-near ?person (Hacker Alyssa P))
</code></pre>
<p>Alyssa P. Hacker is able to find people who live near her, with whom she
can ride to work. On the other hand, when she tries to find all pairs of
people who live near each other by querying</p>
<pre><code class="language-scheme editable">(lives-near ?person-1 ?person-2)
</code></pre>
<p>she notices that each pair of people who live near each other is listed
twice; for example,</p>
<pre><code class="language-scheme editable">(lives-near (Hacker Alyssa P) (Fect Cy D))
(lives-near (Fect Cy D) (Hacker Alyssa P))
</code></pre>
<p>Why does this happen? Is there a way to find a list of people who live
near each other, in which each pair appears only once? Explain.</p>
<h4 id="logic-as-programs"><a class="header" href="#logic-as-programs"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_664">Logic as programs</a></a></h4>
<p>We can regard a rule as a kind of logical implication:
<em>If</em> an assignment of values to pattern variables satisfies the body,
<em>then</em> it satisfies the conclusion. Consequently, we can regard the
query language as having the ability to perform <em>logical deductions</em>
based upon the rules. As an example, consider the <code>append</code> operation
described at the beginning of section <a href="book-Z-H-29.html#%_sec_4.4">4.4</a>.
As we said, <code>append</code> can be characterized by the following two rules:</p>
<ul>
<li>For any list <code>y</code>, the empty list and <code>y</code> <code>append</code> to form <code>y</code>.</li>
<li>For any <code>u</code>, <code>v</code>, <code>y</code>, and <code>z</code>, <code>(cons u v)</code> and <code>y</code> <code>append</code> to form
<code>(cons u z)</code> if <code>v</code> and <code>y</code> <code>append</code> to form <code>z</code>.</li>
</ul>
<p>To express this in our query language, we define two rules for a
relation</p>
<p><code>(append-to-form x y z)</code></p>
<p>which we can interpret to mean '<code>x</code> and <code>y</code> <code>append</code> to form <code>z</code>':</p>
<pre><code class="language-scheme editable">(rule (append-to-form () ?y ?y))
(rule (append-to-form (?u . ?v) ?y (?u . ?z))
      (append-to-form ?v ?y ?z))
</code></pre>
<p>The first rule has no body, which means that the
conclusion holds for any value of <code>?y</code>. Note how the second rule makes
use of dotted-tail notation to name the <code>car</code> and <code>cdr</code>
of a list.</p>
<p>Given these two rules, we can formulate queries that compute the
<code>append</code> of two lists:</p>
<p><em><code>;;; Query input:</code></em></p>
<pre><code class="language-scheme editable">(append-to-form (a b) (c d) ?z)
</code></pre>
<p><em><code>;;; Query results:</code></em></p>
<pre><code class="language-scheme editable">(append-to-form (a b) (c d) (a b c d))
</code></pre>
<p>What is more striking, we can use the same rules to ask the question
'Which list, when <code>append</code>ed to <code>(a b)</code>, yields <code>(a b c d)</code>?' This
is done as follows:</p>
<p><em><code>;;; Query input:</code></em></p>
<pre><code class="language-scheme editable">(append-to-form (a b) ?y (a b c d))
</code></pre>
<p><em><code>;;; Query results:</code></em></p>
<pre><code class="language-scheme editable">(append-to-form (a b) (c d) (a b c d))
</code></pre>
<p>We can also ask for all pairs of lists that <code>append</code> to form
<code>(a b c d)</code>:</p>
<p><em><code>;;; Query input:</code></em></p>
<pre><code class="language-scheme editable">(append-to-form ?x ?y (a b c d))
</code></pre>
<p><em><code>;;; Query results:</code></em></p>
<pre><code class="language-scheme editable">(append-to-form () (a b c d) (a b c d))
(append-to-form (a) (b c d) (a b c d))
(append-to-form (a b) (c d) (a b c d))
(append-to-form (a b c) (d) (a b c d))
(append-to-form (a b c d) () (a b c d))
</code></pre>
<p>The query system may seem to exhibit quite a bit of intelligence in
using the rules to deduce the answers to the queries above. Actually, as
we will see in the next section, the system is following a
well-determined algorithm in unraveling the rules. Unfortunately,
although the system works impressively in the <code>append</code> case, the general
methods may break down in more complex cases, as we will see in
section <a href="book-Z-H-29.html#%_sec_4.4.3">4.4.3</a>.</p>
<p><strong>Exercise 4.61.</strong>  The following rules implement a
<code>next-to</code> relation that finds adjacent elements of a list:</p>
<pre><code class="language-scheme editable">(rule (?x next-to ?y in (?x ?y . ?u)))

(rule (?x next-to ?y in (?v . ?z))
      (?x next-to ?y in ?z))
</code></pre>
<p>What will the response be to the following queries?</p>
<pre><code class="language-scheme editable">(?x next-to ?y in (1 (2 3) 4))

(?x next-to 1 in (2 1 3 1))
</code></pre>
<p><strong>Exercise 4.62.</strong>  Define rules to
implement the <code>last-pair</code> operation of
exercise <a href="book-Z-H-15.html#%_thm_2.17">2.17</a>, which returns a list
containing the last element of a nonempty list. Check your rules on
queries such as <code>(last-pair (3) ?x)</code>, <code>(last-pair (1 2 3) ?x)</code>, and
<code>(last-pair (2 ?x) (3))</code>. Do your rules work correctly on queries such
as <code>(last-pair ?x (3))</code> ?</p>
<p><strong>Exercise 4.63.</strong>  The
following data base (see Genesis 4) traces the genealogy of the
descendants of Ada back to Adam, by way of Cain:</p>
<pre><code class="language-scheme editable">(son Adam Cain)
(son Cain Enoch)
(son Enoch Irad)
(son Irad Mehujael)
(son Mehujael Methushael)
(son Methushael Lamech)
(wife Lamech Ada)
(son Ada Jabal)
(son Ada Jubal)
</code></pre>
<p>Formulate rules such as 'If <em>S</em> is the son of <em>F</em>, and <em>F</em> is the son
of <em>G</em>, then <em>S</em> is the grandson of <em>G</em>' and 'If <em>W</em> is the wife
of <em>M</em>, and <em>S</em> is the son of <em>W</em>, then <em>S</em> is the son of <em>M</em>' (which
was supposedly more true in biblical times than today) that will enable
the query system to find the grandson of Cain; the sons of Lamech; the
grandsons of Methushael. (See
exercise <a href="book-Z-H-29.html#%_thm_4.69">4.69</a> for some rules to deduce
more complicated relationships.)</p>
<h3 id="442--how-the-query-system-works"><a class="header" href="#442--how-the-query-system-works"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.2">4.4.2  How the Query System Works</a></a></h3>
<p>In section <a href="book-Z-H-29.html#%_sec_4.4.4">4.4.4</a> we will
present a complete implementation of the query interpreter as a collection
of procedures. In this section we give an overview that explains the
general structure of the system independent of low-level implementation
details. After describing the implementation of the interpreter, we will
be in a position to understand some of its limitations and some of the
subtle ways in which the query language's logical operations differ
from the operations of mathematical logic.</p>
<p>It should be apparent that the query evaluator must perform some kind of
search in order to match queries against facts and rules in the data
base. One way to do this would be to implement the query system as a
nondeterministic program, using the <code>amb</code> evaluator of
section <a href="book-Z-H-28.html#%_sec_4.3">4.3</a> (see
exercise <a href="book-Z-H-29.html#%_thm_4.78">4.78</a>). Another possibility is to
manage the search with the aid of streams. Our implementation follows
this second approach.</p>
<p>The query system is organized around two central operations called
<em>pattern matching</em> and <em>unification</em>. We first describe pattern matching
and explain how this operation, together with the organization of
information in terms of streams of frames, enables us to implement both
simple and compound queries. We next discuss unification, a
generalization of pattern matching needed to implement rules. Finally,
we show how the entire query interpreter fits together through a
procedure that classifies expressions in a manner analogous to the way
<code>eval</code> classifies expressions for the interpreter described in
section <a href="book-Z-H-26.html#%_sec_4.1">4.1</a>.</p>
<h4 id="pattern-matching"><a class="header" href="#pattern-matching"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_668">Pattern matching</a></a></h4>
<p>A <em>pattern matcher</em> is a program that
tests whether some datum fits a specified pattern. For example, the data
list <code>((a b) c (a b))</code> matches the pattern <code>(?x c ?x)</code> with the pattern
variable <code>?x</code> bound to <code>(a b)</code>. The same data list matches the pattern
<code>(?x ?y ?z)</code> with <code>?x</code> and <code>?z</code> both bound to <code>(a b)</code> and <code>?y</code> bound to
<code>c</code>. It also matches the pattern <code>((?x ?y) c (?x ?y))</code> with <code>?x</code> bound
to <code>a</code> and <code>?y</code> bound to <code>b</code>. However, it does not match the pattern
<code>(?x a ?y)</code>, since that pattern specifies a list whose second element is
the symbol <code>a</code>.</p>
<p>The pattern matcher used by the query
system takes as inputs a pattern, a datum, and a <em>frame</em> that specifies
bindings for various pattern variables. It checks whether the datum
matches the pattern in a way that is consistent with the bindings
already in the frame. If so, it returns the given frame augmented by any
bindings that may have been determined by the match. Otherwise, it
indicates that the match has failed.</p>
<p>For example, using the pattern <code>(?x ?y ?x)</code> to match <code>(a b a)</code> given an
empty frame will return a frame specifying that <code>?x</code> is bound to <code>a</code> and
<code>?y</code> is bound to <code>b</code>. Trying the match with the same pattern, the same
datum, and a frame specifying that <code>?y</code> is bound to <code>a</code> will fail.
Trying the match with the same pattern, the same datum, and a frame in
which <code>?y</code> is bound to <code>b</code> and <code>?x</code> is unbound will return the given
frame augmented by a binding of <code>?x</code> to <code>a</code>.</p>
<p>The pattern matcher is all the mechanism that is needed
to process simple queries that don't involve rules. For instance, to
process the query</p>
<pre><code class="language-scheme editable">(job ?x (computer programmer))
</code></pre>
<p>we scan through all assertions in the data base and select those that
match the pattern with respect to an initially empty frame. For each
match we find, we use the frame returned by the match to instantiate the
pattern with a value for <code>?x</code>.</p>
<h4 id="streams-of-frames"><a class="header" href="#streams-of-frames"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_669">Streams of frames</a></a></h4>
<p>The testing of patterns against frames is
organized through the use of streams. Given a single frame, the matching
process runs through the data-base entries one by one. For each
data-base entry, the matcher generates either a special symbol
indicating that the match has failed or an extension to the frame. The
results for all the data-base entries are collected into a stream, which
is passed through a filter to weed out the failures. The result is a
stream of all the frames that extend the given frame via a match to some
assertion in the data
base.<a href="book-Z-H-29.html#footnote_Temp_670">^[67]{.small}^</a></p>
<p>In our system, a query takes an input stream of frames and performs the
above matching operation for every frame in the stream, as indicated in
figure <a href="book-Z-H-29.html#%_fig_4.4">4.4</a>. That is, for each frame in the
input stream, the query generates a new stream consisting of all
extensions to that frame by matches to assertions in the data base. All
these streams are then combined to form one huge stream, which contains
all possible extensions of every frame in the input stream. This stream
is the output of the query.</p>
<p><img src="ch4-Z-G-4.gif" alt="" /></p>
<p><strong>Figure 4.4:</strong>  A query processes a stream of frames.</p>
<p>To answer a simple query, we use the query with an input
stream consisting of a single empty frame. The resulting output stream
contains all extensions to the empty frame (that is, all answers to our
query). This stream of frames is then used to generate a stream of
copies of the original query pattern with the variables instantiated by
the values in each frame, and this is the stream that is finally
printed.</p>
<h4 id="compound-queries-1"><a class="header" href="#compound-queries-1"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_671">Compound queries</a></a></h4>
<p>The real elegance of the stream-of-frames implementation
is evident when we deal with compound queries. The processing of
compound queries makes use of the ability of our matcher to demand that
a match be consistent with a specified frame. For
example, to handle the <code>and</code> of two queries, such as</p>
<pre><code class="language-scheme editable">(and (can-do-job ?x (computer programmer trainee))
     (job ?person ?x))
</code></pre>
<p>(informally, 'Find all people who can do the job of a computer
programmer trainee'), we first find all entries that match the
pattern</p>
<pre><code class="language-scheme editable">(can-do-job ?x (computer programmer trainee))
</code></pre>
<p>This produces a stream of frames, each of which contains a binding for
<code>?x</code>. Then for each frame in the stream we find all entries that match</p>
<pre><code class="language-scheme editable">(job ?person ?x)
</code></pre>
<p>in a way that is consistent with the given binding for <code>?x</code>. Each such
match will produce a frame containing bindings for <code>?x</code> and <code>?person</code>.
The <code>and</code> of two queries can be viewed as a series combination of the
two component queries, as shown in
figure <a href="book-Z-H-29.html#%_fig_4.5">4.5</a>. The frames that pass through
the first query filter are filtered and further extended by the second
query.</p>
<p><img src="ch4-Z-G-5.gif" alt="" /></p>
<p><strong>Figure 4.5:</strong>  The <code>and</code> combination of two queries is produced by
operating on the stream of frames in series.</p>
<p>Figure <a href="book-Z-H-29.html#%_fig_4.6">4.6</a> shows the
analogous method for computing the <code>or</code> of two queries as a parallel
combination of the two component queries. The input stream of frames is
extended separately by each query. The two resulting streams are then
merged to produce the final output stream.</p>
<p><img src="ch4-Z-G-6.gif" alt="" /></p>
<p><strong>Figure 4.6:</strong>  The <code>or</code> combination of two queries is produced by
operating on the stream of frames in parallel and merging the results.</p>
<p>Even from this high-level description, it is apparent
that the processing of compound queries can be slow. For example, since
a query may produce more than one output frame for each input frame, and
each query in an <code>and</code> gets its input frames from the previous query, an
<code>and</code> query could, in the worst case, have to perform a number of
matches that is exponential in the number of queries (see
exercise <a href="book-Z-H-29.html#%_thm_4.76">4.76</a>).<a href="book-Z-H-29.html#footnote_Temp_672">^[68]{.small}^</a>
Though systems for handling only simple queries are quite practical,
dealing with complex queries is extremely
difficult.<a href="book-Z-H-29.html#footnote_Temp_673">^[69]{.small}^</a></p>
<p>From the stream-of-frames viewpoint, the <code>not</code> of some
query acts as a filter that removes all frames for which the query can
be satisfied. For instance, given the pattern</p>
<pre><code class="language-scheme editable">(not (job ?x (computer programmer)))
</code></pre>
<p>we attempt, for each frame in the input stream, to produce extension
frames that satisfy <code>(job ?x (computer programmer))</code>. We remove from the
input stream all frames for which such extensions exist. The result is a
stream consisting of only those frames in which the binding for <code>?x</code>
does not satisfy <code>(job ?x (computer programmer))</code>. For example, in
processing the query</p>
<pre><code class="language-scheme editable">(and (supervisor ?x ?y)
     (not (job ?x (computer programmer))))
</code></pre>
<p>the first clause will generate frames with bindings for <code>?x</code> and <code>?y</code>.
The <code>not</code> clause will then filter these by removing all frames in which
the binding for <code>?x</code> satisfies the restriction that <code>?x</code> is a computer
programmer.<a href="book-Z-H-29.html#footnote_Temp_674">^[70]{.small}^</a></p>
<p>The <code>lisp-value</code> special form is implemented as a similar
filter on frame streams. We use each frame in the stream to instantiate
any variables in the pattern, then apply the Lisp predicate. We remove
from the input stream all frames for which the predicate fails.</p>
<h4 id="unification"><a class="header" href="#unification"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_675">Unification</a></a></h4>
<p>In order to handle rules in the query
language, we must be able to find the rules whose conclusions match a
given query pattern. Rule conclusions are like assertions except that
they can contain variables, so we will need a generalization of pattern
matching -- called <em>unification</em> -- in which both the 'pattern'
and the 'datum' may contain variables.</p>
<p>A unifier takes two patterns, each containing constants and variables,
and determines whether it is possible to assign values to the variables
that will make the two patterns equal. If so, it returns a frame
containing these bindings. For example, unifying <code>(?x a ?y)</code> and
<code>(?y ?z a)</code> will specify a frame in which <code>?x</code>, <code>?y</code>, and <code>?z</code> must all
be bound to <code>a</code>. On the other hand, unifying <code>(?x ?y a)</code> and <code>(?x b ?y)</code>
will fail, because there is no value for <code>?y</code> that can make the two
patterns equal. (For the second elements of the patterns to be equal,
<code>?y</code> would have to be <code>b</code>; however, for the third elements to be equal,
<code>?y</code> would have to be <code>a</code>.) The unifier used in the query system, like
the pattern matcher, takes a frame as input and performs unifications
that are consistent with this frame.</p>
<p>The unification algorithm is the most technically difficult part of the
query system. With complex patterns, performing unification may seem to
require deduction. To unify <code>(?x ?x)</code> and <code>((a ?y c) (a b ?z))</code>, for
example, the algorithm must infer that <code>?x</code> should be <code>(a b c)</code>, <code>?y</code>
should be <code>b</code>, and <code>?z</code> should be <code>c</code>. We may think of this process as
solving a set of equations among the pattern components. In general,
these are simultaneous equations, which may require substantial
manipulation to
solve.<a href="book-Z-H-29.html#footnote_Temp_676">^[71]{.small}^</a>
For example, unifying <code>(?x ?x)</code> and <code>((a ?y c) (a b ?z))</code> may be thought
of as specifying the simultaneous equations</p>
<p><code>?x  =  (a ?y c)</code>
<code>?x  =  (a b ?z)</code></p>
<p>These equations imply that</p>
<p><code>(a ?y c)  =  (a b ?z)</code></p>
<p>which in turn implies that</p>
<p><code>a  =  a, ?y  =  b, c  =  ?z,</code></p>
<p>and hence that</p>
<p><code>?x  =  (a b c)</code></p>
<p>In a successful pattern match, all pattern
variables become bound, and the values to which they are bound contain
only constants. This is also true of all the examples of unification we
have seen so far. In general, however, a successful unification may not
completely determine the variable values; some variables may remain
unbound and others may be bound to values that contain variables.</p>
<p>Consider the unification of <code>(?x a)</code> and <code>((b ?y) ?z)</code>. We can deduce
that <code>?x = (b ?y)</code> and <code>a = ?z</code>, but we cannot further solve for <code>?x</code>
or <code>?y</code>. The unification doesn't fail, since it is certainly possible
to make the two patterns equal by assigning values to <code>?x</code> and <code>?y</code>.
Since this match in no way restricts the values <code>?y</code> can take on, no
binding for <code>?y</code> is put into the result frame. The match does, however,
restrict the value of <code>?x</code>. Whatever value <code>?y</code> has, <code>?x</code> must be
<code>(b ?y)</code>. A binding of <code>?x</code> to the pattern <code>(b ?y)</code> is thus put into the
frame. If a value for <code>?y</code> is later determined and added to the frame
(by a pattern match or unification that is required to be consistent
with this frame), the previously bound <code>?x</code> will refer to this
value.<a href="book-Z-H-29.html#footnote_Temp_677">^[72]{.small}^</a></p>
<h4 id="applying-rules"><a class="header" href="#applying-rules"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_678">Applying rules</a></a></h4>
<p>Unification is the key to the component of the query
system that makes inferences from rules. To see how this is
accomplished, consider processing a query that involves applying a rule,
such as</p>
<pre><code class="language-scheme editable">(lives-near ?x (Hacker Alyssa P))
</code></pre>
<p>To process this query, we first use the ordinary pattern-match procedure
described above to see if there are any assertions in the data base that
match this pattern. (There will not be any in this case, since our data
base includes no direct assertions about who lives near whom.) The next
step is to attempt to unify the query pattern with the conclusion of
each rule. We find that the pattern unifies with the conclusion of the
rule</p>
<pre><code class="language-scheme editable">(rule (lives-near ?person-1 ?person-2)
      (and (address ?person-1 (?town . ?rest-1))
           (address ?person-2 (?town . ?rest-2))
           (not (same ?person-1 ?person-2))))
</code></pre>
<p>resulting in a frame specifying that <code>?person-2</code> is bound to
<code>(Hacker Alyssa P)</code> and that <code>?x</code> should be bound to (have the same
value as) <code>?person-1</code>. Now, relative to this frame, we evaluate the
compound query given by the body of the rule. Successful matches will
extend this frame by providing a binding for <code>?person-1</code>, and
consequently a value for <code>?x</code>, which we can use to instantiate the
original query pattern.</p>
<p>In general, the query evaluator uses the following method to apply a
rule when trying to establish a query pattern in a frame that specifies
bindings for some of the pattern variables:</p>
<ul>
<li>Unify the query with the conclusion of the rule to form, if
successful, an extension of the original frame.</li>
<li>Relative to the extended frame, evaluate the query formed by the body
of the rule.</li>
</ul>
<p>Notice how similar this is to the method for applying a
procedure in the <code>eval</code>/<code>apply</code> evaluator for Lisp:</p>
<ul>
<li></li>
<li>Bind the procedure's parameters to its arguments to form a frame that
extends the original procedure environment.</li>
<li>Relative to the extended environment, evaluate the expression formed
by the body of the procedure.</li>
</ul>
<p>The similarity between the two evaluators should come as no surprise.
Just as procedure definitions are the means of abstraction in Lisp, rule
definitions are the means of abstraction in the query language. In each
case, we unwind the abstraction by creating appropriate bindings and
evaluating the rule or procedure body relative to these.</p>
<h4 id="simple-queries-1"><a class="header" href="#simple-queries-1"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_679">Simple queries</a></a></h4>
<p>We saw earlier in this section how to evaluate simple
queries in the absence of rules. Now that we have seen how to apply
rules, we can describe how to evaluate simple queries by using both
rules and assertions.</p>
<p>Given the query pattern and a stream of frames, we produce, for each
frame in the input stream, two streams:</p>
<ul>
<li>a stream of extended frames obtained by matching the pattern against
all assertions in the data base (using the pattern matcher), and</li>
<li>a stream of extended frames obtained by applying all possible rules
(using the
unifier).<a href="book-Z-H-29.html#footnote_Temp_680">^[73]{.small}^</a></li>
</ul>
<p>Appending these two streams produces a stream that consists of all the
ways that the given pattern can be satisfied consistent with the
original frame. These streams (one for each frame in the input stream)
are now all combined to form one large stream, which therefore consists
of all the ways that any of the frames in the original input stream can
be extended to produce a match with the given pattern.</p>
<h4 id="the-query-evaluator-and-the-driver-loop"><a class="header" href="#the-query-evaluator-and-the-driver-loop"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_681">The query evaluator and the driver loop</a></a></h4>
<p>Despite the complexity of the underlying matching
operations, the system is organized much like an evaluator for any
language. The procedure that coordinates the matching operations is
called <code>qeval</code>, and it plays a role
analogous to that of the <code>eval</code> procedure for Lisp. <code>Qeval</code> takes as
inputs a query and a stream of frames. Its output is a stream of frames,
corresponding to successful matches to the query pattern, that extend
some frame in the input stream, as indicated in
figure <a href="book-Z-H-29.html#%_fig_4.4">4.4</a>. Like <code>eval</code>, <code>qeval</code>
classifies the different types of expressions (queries) and dispatches
to an appropriate procedure for each. There is a procedure for each
special form (<code>and</code>, <code>or</code>, <code>not</code>, and <code>lisp-value</code>) and one for simple
queries.</p>
<p>The driver loop, which is analogous to the
<code>driver-loop</code> procedure for the other evaluators in this chapter, reads
queries from the terminal. For each query, it calls <code>qeval</code> with the
query and a stream that consists of a single empty frame. This will
produce the stream of all possible matches (all possible extensions to
the empty frame). For each frame in the resulting stream, it
instantiates the original query using the values of the variables found
in the frame. This stream of instantiated queries is then
printed.<a href="book-Z-H-29.html#footnote_Temp_682">^[74]{.small}^</a></p>
<p>The driver also checks for the special
command <code>assert!</code>, which signals that the input is not a query but
rather an assertion or rule to be added to the data base. For instance,</p>
<pre><code class="language-scheme editable">(assert! (job (Bitdiddle Ben) (computer wizard)))
(assert! (rule (wheel ?person)
               (and (supervisor ?middle-manager ?person)
                    (supervisor ?x ?middle-manager))))
</code></pre>
<h3 id="443--is-logic-programming-mathematical-logic"><a class="header" href="#443--is-logic-programming-mathematical-logic"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.3">4.4.3  Is Logic Programming Mathematical Logic?</a></a></h3>
<p>The means of combination used in the
query language may at first seem identical to the operations <code>and</code>,
<code>or</code>, and <code>not</code> of mathematical logic, and the application of
query-language rules is in fact accomplished through a legitimate method
of
inference.<a href="book-Z-H-29.html#footnote_Temp_683">^[75]{.small}^</a>
This identification of the query language with mathematical logic is not
really valid, though, because the query language provides a
<em>control structure</em> that interprets the logical
statements procedurally. We can often take advantage of this control
structure. For example, to find all of the supervisors of programmers we
could formulate a query in either of two logically equivalent forms:</p>
<pre><code class="language-scheme editable">(and (job ?x (computer programmer))
     (supervisor ?x ?y))
</code></pre>
<p>or</p>
<pre><code class="language-scheme editable">(and (supervisor ?x ?y)
     (job ?x (computer programmer)))
</code></pre>
<p>If a company has many more supervisors than programmers
(the usual case), it is better to use the first form rather than the
second because the data base must be scanned for each intermediate
result (frame) produced by the first clause of the <code>and</code>.</p>
<p>The aim of logic programming is to provide
the programmer with techniques for decomposing a computational problem
into two separate problems: 'what' is to be computed, and
'how' this should be computed. This is accomplished by selecting a
subset of the statements of mathematical logic that is powerful enough
to be able to describe anything one might want to compute, yet weak
enough to have a controllable procedural interpretation. The intention
here is that, on the one hand, a program specified in a logic
programming language should be an effective program that can be carried
out by a computer. Control ('how' to compute) is effected by using
the order of evaluation of the language. We should be able to arrange
the order of clauses and the order of subgoals within each clause so
that the computation is done in an order deemed to be effective and
efficient. At the same time, we should be able to view the result of the
computation ('what' to compute) as a simple consequence of the
laws of logic.</p>
<p>Our query language can be regarded as just such a procedurally
interpretable subset of mathematical logic. An assertion represents a
simple fact (an atomic proposition). A rule represents the implication
that the rule conclusion holds for those cases where the rule body
holds. A rule has a natural procedural interpretation: To establish the
conclusion of the rule, establish the body of the rule. Rules,
therefore, specify computations. However, because rules can also be
regarded as statements of mathematical logic, we can justify any
'inference' accomplished by a logic program by asserting that the
same result could be obtained by working entirely within mathematical
logic.<a href="book-Z-H-29.html#footnote_Temp_684">^[76]{.small}^</a></p>
<h4 id="infinite-loops"><a class="header" href="#infinite-loops"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_685">Infinite loops</a></a></h4>
<p>A consequence of the procedural interpretation of logic
programs is that it is possible to construct hopelessly inefficient
programs for solving certain problems. An extreme case of inefficiency
occurs when the system falls into infinite loops in making deductions.
As a simple example, suppose we are setting up a data base of famous
marriages, including</p>
<pre><code class="language-scheme editable">(assert! (married Minnie Mickey))
</code></pre>
<p>If we now ask</p>
<pre><code class="language-scheme editable">(married Mickey ?who)
</code></pre>
<p>we will get no response, because the system doesn't know that if <em>A</em> is
married to <em>B</em>, then <em>B</em> is married to <em>A</em>. So we assert the rule</p>
<pre><code class="language-scheme editable">(assert! (rule (married ?x ?y)
               (married ?y ?x)))
</code></pre>
<p>and again query</p>
<pre><code class="language-scheme editable">(married Mickey ?who)
</code></pre>
<p>Unfortunately, this will drive the system into an infinite loop, as
follows:</p>
<ul>
<li>The system finds that the <code>married</code> rule is applicable; that is, the
rule conclusion <code>(married ?x ?y)</code> successfully unifies with the query
pattern <code>(married Mickey ?who)</code> to produce a frame in which <code>?x</code> is
bound to <code>Mickey</code> and <code>?y</code> is bound to <code>?who</code>. So the interpreter
proceeds to evaluate the rule body <code>(married ?y ?x)</code> in this frame --
in effect, to process the query <code>(married ?who Mickey)</code>.</li>
<li>One answer appears directly as an assertion in the data base:
<code>(married Minnie Mickey)</code>.</li>
<li>The <code>married</code> rule is also applicable, so the interpreter again
evaluates the rule body, which this time is equivalent to
<code>(married Mickey ?who)</code>.</li>
</ul>
<p>The system is now in an infinite loop. Indeed, whether the system will
find the simple answer <code>(married Minnie Mickey)</code> before it goes into the
loop depends on implementation details concerning the order in which the
system checks the items in the data base. This is a very simple example
of the kinds of loops that can occur. Collections of interrelated rules
can lead to loops that are much harder to anticipate, and the appearance
of a loop can depend on the order of clauses in an <code>and</code> (see
exercise <a href="book-Z-H-29.html#%_thm_4.64">4.64</a>) or on low-level details
concerning the order in which the system processes
queries.<a href="book-Z-H-29.html#footnote_Temp_686">^[77]{.small}^</a></p>
<h4 id="problems-with-not"><a class="header" href="#problems-with-not"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_687">Problems with <code>not</code></a></a></h4>
<p>Another quirk in the query system
concerns <code>not</code>. Given the data base of
section <a href="book-Z-H-29.html#%_sec_4.4.1">4.4.1</a>, consider the following
two queries:</p>
<pre><code class="language-scheme editable">(and (supervisor ?x ?y)
     (not (job ?x (computer programmer))))
(and (not (job ?x (computer programmer)))
     (supervisor ?x ?y))
</code></pre>
<p>These two queries do not produce the same result. The first query begins
by finding all entries in the data base that match <code>(supervisor ?x ?y)</code>,
and then filters the resulting frames by removing the ones in which the
value of <code>?x</code> satisfies <code>(job ?x (computer programmer))</code>. The second
query begins by filtering the incoming frames to remove those that can
satisfy <code>(job ?x (computer programmer))</code>. Since the only incoming frame
is empty, it checks the data base to see if there are any patterns that
satisfy <code>(job ?x (computer programmer))</code>. Since there generally are
entries of this form, the <code>not</code> clause filters out the empty frame and
returns an empty stream of frames. Consequently, the entire compound
query returns an empty stream.</p>
<p>The trouble is that our implementation of <code>not</code> really is meant to serve
as a filter on values for the variables. If a <code>not</code> clause is processed
with a frame in which some of the variables remain unbound (as does <code>?x</code>
in the example above), the system will produce unexpected results.
Similar problems occur with the use of <code>lisp-value</code> --
the Lisp predicate can't work if some of its arguments are unbound. See
exercise <a href="book-Z-H-29.html#%_thm_4.77">4.77</a>.</p>
<p>There is also a much more serious way in which the <code>not</code> of the query
language differs from the <code>not</code> of mathematical logic. In logic, we
interpret the statement 'not <em>P</em>' to mean that <em>P</em> is not true. In
the query system, however, 'not <em>P</em>' means that <em>P</em> is not
deducible from the knowledge in the data base. For example, given the
personnel data base of section <a href="book-Z-H-29.html#%_sec_4.4.1">4.4.1</a>,
the system would happily deduce all sorts of <code>not</code> statements, such as
that Ben Bitdiddle is not a baseball fan, that it is not raining
outside, and that 2 + 2 is not
4.<a href="book-Z-H-29.html#footnote_Temp_688">^[78]{.small}^</a>
In other words, the <code>not</code> of logic programming languages reflects the
so-called <em>closed world assumption</em> that all relevant
information has been included in the data
base.<a href="book-Z-H-29.html#footnote_Temp_689">^[79]{.small}^</a></p>
<p><strong>Exercise 4.64.</strong>  Louis Reasoner
mistakenly deletes the <code>outranked-by</code> rule
(section <a href="book-Z-H-29.html#%_sec_4.4.1">4.4.1</a>) from the data base. When
he realizes this, he quickly reinstalls it. Unfortunately, he makes a
slight change in the rule, and types it in as</p>
<pre><code class="language-scheme editable">(rule (outranked-by ?staff-person ?boss)
      (or (supervisor ?staff-person ?boss)
          (and (outranked-by ?middle-manager ?boss)
               (supervisor ?staff-person ?middle-manager))))
</code></pre>
<p>Just after Louis types this information into the system, DeWitt Aull
comes by to find out who outranks Ben Bitdiddle. He issues the query</p>
<pre><code class="language-scheme editable">(outranked-by (Bitdiddle Ben) ?who)
</code></pre>
<p>After answering, the system goes into an infinite loop. Explain why.</p>
<p><strong>Exercise 4.65.</strong>  Cy D. Fect, looking
forward to the day when he will rise in the organization, gives a query
to find all the wheels (using the <code>wheel</code> rule of
section <a href="book-Z-H-29.html#%_sec_4.4.1">4.4.1</a>):</p>
<pre><code class="language-scheme editable">(wheel ?who)
</code></pre>
<p>To his surprise, the system responds</p>
<p><em><code>;;; Query results:</code></em></p>
<pre><code class="language-scheme editable">(wheel (Warbucks Oliver))
(wheel (Bitdiddle Ben))
(wheel (Warbucks Oliver))
(wheel (Warbucks Oliver))
(wheel (Warbucks Oliver))
</code></pre>
<p>Why is Oliver Warbucks listed four times?</p>
<p><strong>Exercise 4.66.</strong>  Ben has been
generalizing the query system to provide statistics about the company.
For example, to find the total salaries of all the computer programmers
one will be able to say</p>
<p><code>(sum ?amount</code>
<code>     (and (job ?x (computer programmer))</code>
<code>          (salary ?x ?amount)))</code></p>
<p>In general, Ben's new system allows expressions of the form</p>
<p><code>(accumulation-function &lt;</code><em><code>variable</code></em><code>&gt;</code>
<code>                       &lt;</code><em><code>query pattern</code></em><code>&gt;)</code></p>
<p>where <code>accumulation-function</code> can be things like <code>sum</code>, <code>average</code>, or
<code>maximum</code>. Ben reasons that it should be a cinch to implement this. He
will simply feed the query pattern to <code>qeval</code>. This will produce a
stream of frames. He will then pass this stream through a mapping
function that extracts the value of the designated variable from each
frame in the stream and feed the resulting stream of values to the
accumulation function. Just as Ben completes the implementation and is
about to try it out, Cy walks by, still puzzling over the <code>wheel</code> query
result in exercise <a href="book-Z-H-29.html#%_thm_4.65">4.65</a>. When Cy shows
Ben the system's response, Ben groans, 'Oh, no, my simple
accumulation scheme won't work!'</p>
<p>What has Ben just realized? Outline a method he can use to salvage the
situation.</p>
<p><strong>Exercise 4.67.</strong>  Devise
a way to install a loop detector in the query system so as to avoid the
kinds of simple loops illustrated in the text and in
exercise <a href="book-Z-H-29.html#%_thm_4.64">4.64</a>. The general idea is that
the system should maintain some sort of history of its current chain of
deductions and should not begin processing a query that it is already
working on. Describe what kind of information (patterns and frames) is
included in this history, and how the check should be made. (After you
study the details of the query-system implementation in
section <a href="book-Z-H-29.html#%_sec_4.4.4">4.4.4</a>, you may want to modify
the system to include your loop detector.)</p>
<p><strong>Exercise 4.68.</strong>  Define rules to
implement the <code>reverse</code> operation of
exercise <a href="book-Z-H-15.html#%_thm_2.18">2.18</a>, which returns a list
containing the same elements as a given list in reverse order. (Hint:
Use <code>append-to-form</code>.) Can your rules answer both <code>(reverse (1 2 3) ?x)</code>
and <code>(reverse ?x (1 2 3))</code> ?</p>
<p><strong>Exercise 4.69.</strong>  Beginning with the data base and the
rules you formulated in exercise <a href="book-Z-H-29.html#%_thm_4.63">4.63</a>,
devise a rule for adding 'greats' to a grandson relationship. This
should enable the system to deduce that Irad is the great-grandson of
Adam, or that Jabal and Jubal are the
great-great-great-great-great-grandsons of Adam. (Hint: Represent the
fact about Irad, for example, as <code>((great grandson) Adam Irad)</code>. Write
rules that determine if a list ends in the word <code>grandson</code>. Use this to
express a rule that allows one to derive the relationship
<code>((great . ?rel) ?x ?y)</code>, where <code>?rel</code> is a list ending in <code>grandson</code>.)
Check your rules on queries such as <code>((great grandson) ?g ?ggs)</code> and
<code>(?relationship Adam Irad)</code>.</p>
<h3 id="444--implementing-the-query-system"><a class="header" href="#444--implementing-the-query-system"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4">4.4.4  Implementing the Query System</a></a></h3>
<p>Section <a href="book-Z-H-29.html#%_sec_4.4.2">4.4.2</a> described how the query
system works. Now we fill in the details by presenting a complete
implementation of the system.</p>
<h4 id="4441--the-driver-loop-and-instantiation"><a class="header" href="#4441--the-driver-loop-and-instantiation"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.1">4.4.4.1  The Driver Loop and Instantiation</a></a></h4>
<p>The driver loop for the query system
repeatedly reads input expressions. If the expression is a rule or
assertion to be added to the data base, then the information is added.
Otherwise the expression is assumed to be a query. The driver passes
this query to the evaluator <code>qeval</code> together with an initial frame
stream consisting of a single empty frame. The result of the evaluation
is a stream of frames generated by satisfying the query with variable
values found in the data base. These frames are used to form a new
stream consisting of copies of the original query in which the variables
are instantiated with values supplied by the stream of frames, and this
final stream is printed at the terminal:</p>
<pre><code class="language-scheme editable">(define input-prompt ";;; Query input:")
(define output-prompt ";;; Query results:")
(define (query-driver-loop)
  (prompt-for-input input-prompt)
  (let ((q (query-syntax-process (read))))
    (cond ((assertion-to-be-added? q)
           (add-rule-or-assertion! (add-assertion-body q))
           (newline)
           (display "Assertion added to data base.")
           (query-driver-loop))
          (else
           (newline)
           (display output-prompt)
           (display-stream
            (stream-map
             (lambda (frame)
               (instantiate q
                            frame
                            (lambda (v f)
                              (contract-question-mark v))))
             (qeval q (singleton-stream '())))))
           (query-driver-loop)))))
</code></pre>
<p>Here, as in the other evaluators in this chapter, we use
an abstract syntax for the expressions of the query language. The
implementation of the expression syntax, including the predicate
<code>assertion-to-be-added?</code> and the selector <code>add-assertion-body</code>, is given
in section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>.
<code>Add-rule-or-assertion!</code> is defined in
section <a href="book-Z-H-29.html#%_sec_4.4.4.5">4.4.4.5</a>.</p>
<p>Before doing any processing on an input expression, the driver loop
transforms it syntactically into a form that makes the processing more
efficient. This involves changing the
representation of pattern variables. When
the query is instantiated, any variables that remain unbound are
transformed back to the input representation before being printed. These
transformations are performed by the two procedures
<code>query-syntax-process</code> and <code>contract-question-mark</code> (section
<a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>).</p>
<p>To instantiate an expression, we copy it, replacing any
variables in the expression by their values in a given frame. The values
are themselves instantiated, since they could contain variables (for
example, if <code>?x</code> in <code>exp</code> is bound to <code>?y</code> as the result of unification
and <code>?y</code> is in turn bound to 5). The action to take if a variable cannot
be instantiated is given by a procedural argument to <code>instantiate</code>.</p>
<pre><code class="language-scheme editable">(define (instantiate exp frame unbound-var-handler)
  (define (copy exp)
    (cond ((var? exp)
           (let ((binding (binding-in-frame exp frame)))
             (if binding
                 (copy (binding-value binding))
                 (unbound-var-handler exp frame))))
          ((pair? exp)
           (cons (copy (car exp)) (copy (cdr exp))))
          (else exp)))
  (copy exp))
</code></pre>
<p>The procedures that manipulate bindings are defined in
section <a href="book-Z-H-29.html#%_sec_4.4.4.8">4.4.4.8</a>.</p>
<h4 id="4442--the-evaluator"><a class="header" href="#4442--the-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.2">4.4.4.2  The Evaluator</a></a></h4>
<p>The <code>qeval</code> procedure, called by the <code>query-driver-loop</code>,
is the basic evaluator of the query system. It takes as inputs a query
and a stream of frames, and it returns a stream of extended frames. It
identifies special forms by a data-directed dispatch
using <code>get</code> and <code>put</code>, just as we did in implementing generic operations
in chapter 2. Any query that is not identified as a special form is
assumed to be a simple query, to be processed by <code>simple-query</code>.</p>
<pre><code class="language-scheme editable">(define (qeval query frame-stream)
  (let ((qproc (get (type query) 'qeval)))
    (if qproc
        (qproc (contents query) frame-stream)
        (simple-query query frame-stream))))
</code></pre>
<p><code>Type</code> and <code>contents</code>, defined in
section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>, implement the
abstract syntax of the special forms.</p>
<h4 id="simple-queries-2"><a class="header" href="#simple-queries-2"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_696">Simple queries</a></a></h4>
<p>The <code>simple-query</code> procedure handles simple queries. It
takes as arguments a simple query (a pattern) together with a stream of
frames, and it returns the stream formed by extending each frame by all
data-base matches of the query.</p>
<pre><code class="language-scheme editable">(define (simple-query query-pattern frame-stream)
  (stream-flatmap
   (lambda (frame)
     (stream-append-delayed
      (find-assertions query-pattern frame)
      (delay (apply-rules query-pattern frame))))
   frame-stream))
</code></pre>
<p>For each frame in the input stream, we use <code>find-assertions</code>
(section <a href="book-Z-H-29.html#%_sec_4.4.4.3">4.4.4.3</a>) to match the pattern
against all assertions in the data base, producing a stream of extended
frames, and we use <code>apply-rules</code>
(section <a href="book-Z-H-29.html#%_sec_4.4.4.4">4.4.4.4</a>) to apply all
possible rules, producing another stream of extended frames. These two
streams are combined (using <code>stream-append-delayed</code>,
section <a href="book-Z-H-29.html#%_sec_4.4.4.6">4.4.4.6</a>) to make a stream of
all the ways that the given pattern can be satisfied consistent with the
original frame (see exercise <a href="book-Z-H-29.html#%_thm_4.71">4.71</a>). The
streams for the individual input frames are combined using
<code>stream-flatmap</code> (section <a href="book-Z-H-29.html#%_sec_4.4.4.6">4.4.4.6</a>) to
form one large stream of all the ways that any of the frames in the
original input stream can be extended to produce a match with the given
pattern.</p>
<h4 id="compound-queries-2"><a class="header" href="#compound-queries-2"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_697">Compound queries</a></a></h4>
<p><code>And</code> queries are handled as illustrated
in figure <a href="book-Z-H-29.html#%_fig_4.5">4.5</a> by the <code>conjoin</code> procedure.
<code>Conjoin</code> takes as inputs the conjuncts and the frame stream and returns
the stream of extended frames. First, <code>conjoin</code> processes the stream of
frames to find the stream of all possible frame extensions that satisfy
the first query in the conjunction. Then, using this as the new frame
stream, it recursively applies <code>conjoin</code> to the rest of the queries.</p>
<pre><code class="language-scheme editable">(define (conjoin conjuncts frame-stream)
  (if (empty-conjunction? conjuncts)
      frame-stream
      (conjoin (rest-conjuncts conjuncts)
               (qeval (first-conjunct conjuncts)
                      frame-stream))))
</code></pre>
<p>The expression</p>
<p><code>(put 'and 'qeval conjoin)</code></p>
<p>sets up <code>qeval</code> to dispatch to <code>conjoin</code> when an <code>and</code> form is
encountered.</p>
<p><code>Or</code> queries are handled similarly, as shown in
figure <a href="book-Z-H-29.html#%_fig_4.6">4.6</a>. The output streams for the
various disjuncts of the <code>or</code> are computed separately and merged using
the <code>interleave-delayed</code> procedure from
section <a href="book-Z-H-29.html#%_sec_4.4.4.6">4.4.4.6</a>. (See
exercises <a href="book-Z-H-29.html#%_thm_4.71">4.71</a>
and <a href="book-Z-H-29.html#%_thm_4.72">4.72</a>.)</p>
<pre><code class="language-scheme editable">(define (disjoin disjuncts frame-stream)
  (if (empty-disjunction? disjuncts)
      the-empty-stream
      (interleave-delayed
       (qeval (first-disjunct disjuncts) frame-stream)
       (delay (disjoin (rest-disjuncts disjuncts)
                       frame-stream)))))
(put 'or 'qeval disjoin)
</code></pre>
<p>The predicates and selectors for the syntax of conjuncts and disjuncts
are given in section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>.</p>
<h4 id="filters"><a class="header" href="#filters"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_698">Filters</a></a></h4>
<p><code>Not</code> is handled by the method outlined in
section <a href="book-Z-H-29.html#%_sec_4.4.2">4.4.2</a>. We attempt to extend each
frame in the input stream to satisfy the query being negated, and we
include a given frame in the output stream only if it cannot be
extended.</p>
<pre><code class="language-scheme editable">(define (negate operands frame-stream)
  (stream-flatmap
   (lambda (frame)
     (if (stream-null? (qeval (negated-query operands)
                              (singleton-stream frame)))
         (singleton-stream frame)
         the-empty-stream))
   frame-stream))
(put 'not 'qeval negate)
</code></pre>
<p><code>Lisp-value</code> is a filter similar to <code>not</code>. Each frame in
the stream is used to instantiate the variables in the pattern, the
indicated predicate is applied, and the frames for which the predicate
returns false are filtered out of the input stream. An error results if
there are unbound pattern variables.</p>
<pre><code class="language-scheme editable">(define (lisp-value call frame-stream)
  (stream-flatmap
   (lambda (frame)
     (if (execute
          (instantiate
           call
           frame
           (lambda (v f)
             (error "Unknown pat var -- LISP-VALUE" v))))
         (singleton-stream frame)
         the-empty-stream))
   frame-stream))
(put 'lisp-value 'qeval lisp-value)
</code></pre>
<p><code>Execute</code>, which applies the predicate to the arguments, must <code>eval</code> the
predicate expression to get the procedure to apply. However, it must not
evaluate the arguments, since they are already the actual arguments, not
expressions whose evaluation (in Lisp) will produce the arguments. Note
that <code>execute</code> is implemented using <code>eval</code> and <code>apply</code>
from the underlying Lisp system.</p>
<pre><code class="language-scheme editable">(define (execute exp)
  (apply (eval (predicate exp) user-initial-environment)
         (args exp)))
</code></pre>
<p>The <code>always-true</code> special form provides for a query that is always
satisfied. It ignores its contents (normally empty) and simply passes
through all the frames in the input stream. <code>Always-true</code> is used by the
<code>rule-body</code> selector (section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>)
to provide bodies for rules that were defined without
bodies (that is, rules whose conclusions are always satisfied).</p>
<pre><code class="language-scheme editable">(define (always-true ignore frame-stream) frame-stream)
(put 'always-true 'qeval always-true)
</code></pre>
<p>The selectors that define the syntax of <code>not</code> and <code>lisp-value</code> are given
in section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>.</p>
<h4 id="4443--finding-assertions-by-pattern-matching"><a class="header" href="#4443--finding-assertions-by-pattern-matching"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.3">4.4.4.3  Finding Assertions by Pattern Matching</a></a></h4>
<p><code>Find-assertions</code>, called by
<code>simple-query</code> (section <a href="book-Z-H-29.html#%_sec_4.4.4.2">4.4.4.2</a>),
takes as input a pattern and a frame. It returns a stream of frames,
each extending the given one by a data-base match of the given pattern.
It uses <code>fetch-assertions</code>
(section <a href="book-Z-H-29.html#%_sec_4.4.4.5">4.4.4.5</a>) to get a stream of
all the assertions in the data base that should be checked for a match
against the pattern and the frame. The reason for <code>fetch-assertions</code>
here is that we can often apply simple tests that will eliminate many of
the entries in the data base from the pool of candidates for a
successful match. The system would still work if we eliminated
<code>fetch-assertions</code> and simply checked a stream of all assertions in the
data base, but the computation would be less efficient because we would
need to make many more calls to the matcher.</p>
<pre><code class="language-scheme editable">(define (find-assertions pattern frame)
  (stream-flatmap (lambda (datum)
                    (check-an-assertion datum pattern frame))
                  (fetch-assertions pattern frame)))
</code></pre>
<p><code>Check-an-assertion</code> takes as arguments a pattern, a data object
(assertion), and a frame and returns either a one-element stream
containing the extended frame or <code>the-empty-stream</code> if the match fails.</p>
<pre><code class="language-scheme editable">(define (check-an-assertion assertion query-pat query-frame)
  (let ((match-result
         (pattern-match query-pat assertion query-frame)))
    (if (eq? match-result 'failed)
        the-empty-stream
        (singleton-stream match-result))))
</code></pre>
<p>The basic pattern matcher returns either the symbol <code>failed</code> or an
extension of the given frame. The basic idea of the matcher is to check
the pattern against the data, element by element, accumulating bindings
for the pattern variables. If the pattern and the data object are the
same, the match succeeds and we return the frame of bindings accumulated
so far. Otherwise, if the pattern is a variable we extend the current
frame by binding the variable to the data, so long as this is consistent
with the bindings already in the frame. If the pattern and the data are
both pairs, we (recursively) match the <code>car</code> of the pattern against the
<code>car</code> of the data to produce a frame; in this frame we then match the
<code>cdr</code> of the pattern against the <code>cdr</code> of the data. If none of these
cases are applicable, the match fails and we return the symbol <code>failed</code>.</p>
<pre><code class="language-scheme editable">(define (pattern-match pat dat frame)
  (cond ((eq? frame 'failed) 'failed)
        ((equal? pat dat) frame)
        ((var? pat) (extend-if-consistent pat dat frame))
        ((and (pair? pat) (pair? dat))
         (pattern-match (cdr pat)
                        (cdr dat)
                        (pattern-match (car pat)
                                       (car dat)
                                       frame)))
        (else 'failed)))
</code></pre>
<p>Here is the procedure that extends a frame by adding a new binding, if
this is consistent with the bindings already in the frame:</p>
<pre><code class="language-scheme editable">(define (extend-if-consistent var dat frame)
  (let ((binding (binding-in-frame var frame)))
    (if binding
        (pattern-match (binding-value binding) dat frame)
        (extend var dat frame))))
</code></pre>
<p>If there is no binding for the variable in the frame, we simply add the
binding of the variable to the data. Otherwise we match, in the frame,
the data against the value of the variable in the frame. If the stored
value contains only constants, as it must if it was stored during
pattern matching by <code>extend-if-consistent</code>, then the match simply tests
whether the stored and new values are the same. If so, it returns the
unmodified frame; if not, it returns a failure indication. The stored
value may, however, contain pattern variables if it was stored during
unification (see section <a href="book-Z-H-29.html#%_sec_4.4.4.4">4.4.4.4</a>). The
recursive match of the stored pattern against the new data will add or
check bindings for the variables in this pattern. For example, suppose
we have a frame in which <code>?x</code> is bound to <code>(f ?y)</code> and <code>?y</code> is unbound,
and we wish to augment this frame by a binding of <code>?x</code> to <code>(f b)</code>. We
look up <code>?x</code> and find that it is bound to <code>(f ?y)</code>. This leads us to
match <code>(f ?y)</code> against the proposed new value <code>(f b)</code> in the same frame.
Eventually this match extends the frame by adding a binding of <code>?y</code> to
<code>b</code>. <code>?X</code> remains bound to <code>(f ?y)</code>. We never modify a stored binding
and we never store more than one binding for a given variable.</p>
<p>The procedures used by <code>extend-if-consistent</code> to manipulate bindings are
defined in section <a href="book-Z-H-29.html#%_sec_4.4.4.8">4.4.4.8</a>.</p>
<h4 id="patterns-with-dotted-tails"><a class="header" href="#patterns-with-dotted-tails"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_699">Patterns with dotted tails</a></a></h4>
<p>If a pattern contains a dot followed by a pattern
variable, the pattern variable matches the rest of the data list (rather
than the next element of the data list), just as one would expect with
the dotted-tail notation described in
exercise <a href="book-Z-H-15.html#%_thm_2.20">2.20</a>. Although the pattern
matcher we have just implemented doesn't look for dots, it does behave
as we want. This is because the Lisp <code>read</code> primitive, which is used by
<code>query-driver-loop</code> to read the query and represent it as a list
structure, treats dots in a special way.</p>
<p>When <code>read</code> sees a dot, instead of making
the next item be the next element of a list (the <code>car</code> of a <code>cons</code> whose
<code>cdr</code> will be the rest of the list) it makes the next item be the <code>cdr</code>
of the list structure. For example, the list structure produced by
<code>read</code> for the pattern <code>(computer ?type)</code> could be constructed by
evaluating the expression <code>(cons 'computer (cons '?type '()))</code>, and that
for <code>(computer . ?type)</code> could be constructed by evaluating the
expression <code>(cons 'computer '?type)</code>.</p>
<p>Thus, as <code>pattern-match</code> recursively compares <code>car</code>s and <code>cdr</code>s of a
data list and a pattern that had a dot, it eventually matches the
variable after the dot (which is a <code>cdr</code> of the pattern) against a
sublist of the data list, binding the variable to that list. For
example, matching the pattern <code>(computer . ?type)</code> against
<code>(computer programmer trainee)</code> will match <code>?type</code> against the list
<code>(programmer trainee)</code>.</p>
<h4 id="4444--rules-and-unification"><a class="header" href="#4444--rules-and-unification"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.4">4.4.4.4  Rules and Unification</a></a></h4>
<p><code>Apply-rules</code> is the rule analog of <code>find-assertions</code>
(section <a href="book-Z-H-29.html#%_sec_4.4.4.3">4.4.4.3</a>). It takes as input a
pattern and a frame, and it forms a stream of extension frames by
applying rules from the data base. <code>Stream-flatmap</code> maps <code>apply-a-rule</code>
down the stream of possibly applicable rules (selected by <code>fetch-rules</code>,
section <a href="book-Z-H-29.html#%_sec_4.4.4.5">4.4.4.5</a>) and combines the
resulting streams of frames.</p>
<pre><code class="language-scheme editable">(define (apply-rules pattern frame)
  (stream-flatmap (lambda (rule)
                    (apply-a-rule rule pattern frame))
                  (fetch-rules pattern frame)))
</code></pre>
<p><code>Apply-a-rule</code> applies rules using the method outlined in section
<a href="book-Z-H-29.html#%_sec_4.4.2">4.4.2</a>. It first augments its argument
frame by unifying the rule conclusion with the pattern in the given
frame. If this succeeds, it evaluates the rule body in this new frame.</p>
<p>Before any of this happens, however, the program renames all the
variables in the rule with unique new names. The reason for this is to
prevent the variables for different rule applications from becoming
confused with each other. For instance, if two rules both use a variable
named <code>?x</code>, then each one may add a binding for <code>?x</code> to the frame when
it is applied. These two <code>?x</code>'s have nothing to do with each other, and
we should not be fooled into thinking that the two bindings must be
consistent. Rather than rename variables, we could devise a more clever
environment structure; however, the renaming approach we have chosen
here is the most straightforward, even if not the most efficient. (See
exercise <a href="book-Z-H-29.html#%_thm_4.79">4.79</a>.) Here is the
<code>apply-a-rule</code> procedure:</p>
<pre><code class="language-scheme editable">(define (apply-a-rule rule query-pattern query-frame)
  (let ((clean-rule (rename-variables-in rule)))
    (let ((unify-result
           (unify-match query-pattern
                        (conclusion clean-rule)
                        query-frame)))
      (if (eq? unify-result 'failed)
          the-empty-stream
          (qeval (rule-body clean-rule)
                 (singleton-stream unify-result))))))
</code></pre>
<p>The selectors <code>rule-body</code> and <code>conclusion</code> that extract parts of a rule
are defined in section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>.</p>
<p>We generate unique variable names by associating a unique identifier
(such as a number) with each rule application and combining this
identifier with the original variable names. For example, if the
rule-application identifier is 7, we might change each <code>?x</code> in the rule
to <code>?x-7</code> and each <code>?y</code> in the rule to <code>?y-7</code>. (<code>Make-new-variable</code> and
<code>new-rule-application-id</code> are included with the syntax procedures in
section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>.)</p>
<pre><code class="language-scheme editable">(define (rename-variables-in rule)
  (let ((rule-application-id (new-rule-application-id)))
    (define (tree-walk exp)
      (cond ((var? exp)
             (make-new-variable exp rule-application-id))
            ((pair? exp)
             (cons (tree-walk (car exp))
                   (tree-walk (cdr exp))))
            (else exp)))
    (tree-walk rule)))
</code></pre>
<p>The unification algorithm is implemented
as a procedure that takes as inputs two patterns and a frame and returns
either the extended frame or the symbol <code>failed</code>. The unifier is like
the pattern matcher except that it is symmetrical -- variables are
allowed on both sides of the match. <code>Unify-match</code> is basically the same
as <code>pattern-match</code>, except that there is extra code (marked
'***' below) to handle the case where the object on the right
side of the match is a variable.</p>
<pre><code class="language-scheme editable">(define (unify-match p1 p2 frame)
  (cond ((eq? frame 'failed) 'failed)
        ((equal? p1 p2) frame)
        ((var? p1) (extend-if-possible p1 p2 frame))
        ((var? p2) (extend-if-possible p2 p1 frame))  ; ***
        ((and (pair? p1) (pair? p2))
         (unify-match (cdr p1)
                      (cdr p2)
                      (unify-match (car p1)
                                   (car p2)
                                   frame)))
        (else 'failed)))
</code></pre>
<p>In unification, as in one-sided pattern matching, we want to accept a
proposed extension of the frame only if it is consistent with existing
bindings. The procedure <code>extend-if-possible</code> used in unification is the
same as the <code>extend-if-consistent</code> used in pattern matching except for
two special checks, marked '***' in the program below. In the
first case, if the variable we are trying to match is not bound, but the
value we are trying to match it with is itself a (different) variable,
it is necessary to check to see if the value is bound, and if so, to
match its value. If both parties to the match are unbound, we may bind
either to the other.</p>
<p>The second check deals with attempts to bind a variable to a pattern
that includes that variable. Such a situation can occur whenever a
variable is repeated in both patterns. Consider, for example, unifying
the two patterns <code>(?x ?x)</code> and <code>(?y &lt;</code><em><code>expression involving ?y</code></em><code>&gt;)</code>
in a frame where both <code>?x</code> and <code>?y</code> are unbound. First <code>?x</code> is matched
against <code>?y</code>, making a binding of <code>?x</code> to <code>?y</code>. Next, the same <code>?x</code> is
matched against the given expression involving <code>?y</code>. Since <code>?x</code> is
already bound to <code>?y</code>, this results in matching <code>?y</code> against the
expression. If we think of the unifier as finding a set of values for
the pattern variables that make the patterns the same, then these
patterns imply instructions to find a <code>?y</code> such that <code>?y</code> is equal to
the expression involving <code>?y</code>. There is no general method for solving
such equations, so we reject such bindings; these cases are recognized
by the predicate
<code>depends-on?</code>.<a href="book-Z-H-29.html#footnote_Temp_700">^[80]{.small}^</a>
On the other hand, we do not want to reject attempts to bind a variable
to itself. For example, consider unifying <code>(?x ?x)</code> and <code>(?y ?y)</code>. The
second attempt to bind <code>?x</code> to <code>?y</code> matches <code>?y</code> (the stored value of
<code>?x</code>) against <code>?y</code> (the new value of <code>?x</code>). This is taken care of by the
<code>equal?</code> clause of <code>unify-match</code>.</p>
<pre><code class="language-scheme editable">(define (extend-if-possible var val frame)
  (let ((binding (binding-in-frame var frame)))
    (cond (binding
           (unify-match
            (binding-value binding) val frame))
          ((var? val)                      ; ***
           (let ((binding (binding-in-frame val frame)))
             (if binding
                 (unify-match
                  var (binding-value binding) frame)
                 (extend var val frame))))
          ((depends-on? val var frame)     ; ***
           'failed)
          (else (extend var val frame)))))
</code></pre>
<p><code>Depends-on?</code> is a predicate that tests whether an expression proposed
to be the value of a pattern variable depends on the variable. This must
be done relative to the current frame because the expression may contain
occurrences of a variable that already has a value that depends on our
test variable. The structure of <code>depends-on?</code> is a simple recursive tree
walk in which we substitute for the values of variables whenever
necessary.</p>
<pre><code class="language-scheme editable">(define (depends-on? exp var frame)
  (define (tree-walk e)
    (cond ((var? e)
           (if (equal? var e)
               true
               (let ((b (binding-in-frame e frame)))
                 (if b
                     (tree-walk (binding-value b))
                     false))))
          ((pair? e)
           (or (tree-walk (car e))
               (tree-walk (cdr e))))
          (else false)))
  (tree-walk exp))
</code></pre>
<h4 id="4445--maintaining-the-data-base"><a class="header" href="#4445--maintaining-the-data-base"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.5">4.4.4.5  Maintaining the Data Base</a></a></h4>
<p>One important problem in
designing logic programming languages is that of arranging things so
that as few irrelevant data-base entries as possible will be examined in
checking a given pattern. In our system, in addition to storing all
assertions in one big stream, we store all assertions whose <code>car</code>s are
constant symbols in separate streams, in a table indexed by the symbol.
To fetch an assertion that may match a pattern, we first check to see if
the <code>car</code> of the pattern is a constant symbol. If so, we return (to be
tested using the matcher) all the stored assertions that have the same
<code>car</code>. If the pattern's <code>car</code> is not a constant symbol, we return all
the stored assertions. Cleverer methods could also take advantage of
information in the frame, or try also to optimize the case where the
<code>car</code> of the pattern is not a constant symbol. We avoid building our
criteria for indexing (using the <code>car</code>, handling only the case of
constant symbols) into the program; instead we call on predicates and
selectors that embody our criteria.</p>
<pre><code class="language-scheme editable">(define THE-ASSERTIONS the-empty-stream)
(define (fetch-assertions pattern frame)
  (if (use-index? pattern)
      (get-indexed-assertions pattern)
      (get-all-assertions)))
(define (get-all-assertions) THE-ASSERTIONS)
(define (get-indexed-assertions pattern)
  (get-stream (index-key-of pattern) 'assertion-stream))
</code></pre>
<p><code>Get-stream</code> looks up a stream in the table and returns an empty stream
if nothing is stored there.</p>
<pre><code class="language-scheme editable">(define (get-stream key1 key2)
  (let ((s (get key1 key2)))
    (if s s the-empty-stream)))
</code></pre>
<p>Rules are stored similarly, using the <code>car</code> of the rule conclusion. Rule
conclusions are arbitrary patterns, however, so they differ from
assertions in that they can contain variables. A pattern whose <code>car</code> is
a constant symbol can match rules whose conclusions start with a
variable as well as rules whose conclusions have the same <code>car</code>. Thus,
when fetching rules that might match a pattern whose <code>car</code> is a constant
symbol we fetch all rules whose conclusions start with a variable as
well as those whose conclusions have the same <code>car</code> as the pattern. For
this purpose we store all rules whose conclusions start with a variable
in a separate stream in our table, indexed by the symbol <code>?</code>.</p>
<pre><code class="language-scheme editable">(define THE-RULES the-empty-stream)
(define (fetch-rules pattern frame)
  (if (use-index? pattern)
      (get-indexed-rules pattern)
      (get-all-rules)))
(define (get-all-rules) THE-RULES)
(define (get-indexed-rules pattern)
  (stream-append
   (get-stream (index-key-of pattern) 'rule-stream)
   (get-stream '? 'rule-stream)))
</code></pre>
<p><code>Add-rule-or-assertion!</code> is used by <code>query-driver-loop</code> to add
assertions and rules to the data base. Each item is stored in the index,
if appropriate, and in a stream of all assertions or rules in the data
base.</p>
<pre><code class="language-scheme editable">(define (add-rule-or-assertion! assertion)
  (if (rule? assertion)
      (add-rule! assertion)
      (add-assertion! assertion)))
(define (add-assertion! assertion)
  (store-assertion-in-index assertion)
  (let ((old-assertions THE-ASSERTIONS))
    (set! THE-ASSERTIONS
          (cons-stream assertion old-assertions)))
  'ok))
(define (add-rule! rule)
  (store-rule-in-index rule)
  (let ((old-rules THE-RULES))
    (set! THE-RULES (cons-stream rule old-rules)))
  'ok))
</code></pre>
<p>To actually store an assertion or a rule, we check to see if it can be
indexed. If so, we store it in the appropriate stream.</p>
<pre><code class="language-scheme editable">(define (store-assertion-in-index assertion)
  (if (indexable? assertion)
      (let ((key (index-key-of assertion)))
        (let ((current-assertion-stream
               (get-stream key 'assertion-stream)))
          (put key
               'assertion-stream
               (cons-stream assertion
                            current-assertion-stream))))))
(define (store-rule-in-index rule)
  (let ((pattern (conclusion rule)))
    (if (indexable? pattern)
        (let ((key (index-key-of pattern)))
          (let ((current-rule-stream
                 (get-stream key 'rule-stream)))
            (put key
                 'rule-stream
                 (cons-stream rule
                              current-rule-stream)))))))
</code></pre>
<p>The following procedures define how the data-base index is used. A
pattern (an assertion or a rule conclusion) will be stored in the table
if it starts with a variable or a constant symbol.</p>
<pre><code class="language-scheme editable">(define (indexable? pat)
  (let ((key (index-key-of pat)))
    (or (symbol? key) (var? key))))
(define (index-key-of pat)
  (let ((key (car pat)))
    (if (var? key) '? key)))
(define (use-index? pat)
  (let ((key (car pat)))
    (symbol? key)))
</code></pre>
<h4 id="4446--stream-operations"><a class="header" href="#4446--stream-operations"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.6">4.4.4.6  Stream Operations</a></a></h4>
<p>The query evaluator uses the following stream operations,
which are adaptations of the stream procedures in chapter 3.</p>
<p><code>Singleton-stream</code> makes a stream containing one element:</p>
<pre><code class="language-scheme editable">(define (singleton-stream x)
  (cons-stream x the-empty-stream))
</code></pre>
<p><code>Stream-flatmap</code> is a version of <code>flatmap</code> (see
exercise <a href="book-Z-H-15.html#%_thm_2.28">2.28</a>) that is modified to work
with streams. It takes a procedure <code>proc</code> and a stream <code>s</code> and returns
the stream formed by concatenating the streams that result from applying
<code>proc</code> to each element of <code>s</code>.</p>
<pre><code class="language-scheme editable">(define (stream-flatmap proc s)
  (if (stream-null? s)
      the-empty-stream
      (interleave-delayed
       (proc (stream-car s))
       (delay (stream-flatmap proc (stream-cdr s))))))
</code></pre>
<p><code>Interleave-delayed</code> is like the <code>interleave</code> procedure of
section <a href="book-Z-H-24.html#%_sec_3.5.3">3.5.3</a>, except that the second
stream argument is delayed. This is the appropriate way to combine
streams in the query system, because the second stream may not yet be
needed. If we do not delay the second stream, we might do a lot of
superfluous computation. For example, if the first stream is infinite,
we would never get to the second stream at all.</p>
<pre><code class="language-scheme editable">(define (interleave-delayed s1 delayed-s2)
  (if (stream-null? s1)
      (force delayed-s2)
      (cons-stream
       (stream-car s1)
       (interleave-delayed (force delayed-s2)
                           (delay (stream-cdr s1))))))
</code></pre>
<p><code>Stream-append-delayed</code> is like <code>stream-append</code>
(section <a href="book-Z-H-24.html#%_sec_3.5.3">3.5.3</a>), but it takes a delayed
second stream, for the same reason as <code>interleave-delayed</code>.</p>
<pre><code class="language-scheme editable">(define (stream-append-delayed s1 delayed-s2)
  (if (stream-null? s1)
      (force delayed-s2)
      (cons-stream
       (stream-car s1)
       (stream-append-delayed (stream-cdr s1) delayed-s2))))
</code></pre>
<h4 id="4447--query-syntax-procedures"><a class="header" href="#4447--query-syntax-procedures"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.7">4.4.4.7  Query Syntax Procedures</a></a></h4>
<p>The following procedures define the syntax of queries,
assertions, and rules. They are used by the evaluator and the driver
loop.</p>
<p><code>Type</code> and <code>contents</code> are used by <code>qeval</code> to get the type and contents of
a query. The type is the <code>car</code> of the query.</p>
<pre><code class="language-scheme editable">(define (type exp) (if (pair? exp) (car exp) 'simple))
(define (contents exp) (if (pair? exp) (cdr exp) exp))
</code></pre>
<p><code>Assertion-to-be-added?</code> and <code>add-assertion-body</code> are used by the driver
loop to identify and extract the body of an <code>assert!</code> expression.</p>
<pre><code class="language-scheme editable">(define (assertion-to-be-added? exp)
  (tagged-list? exp 'assert!))
(define (add-assertion-body exp) (cadr exp))
</code></pre>
<p><code>Empty-conjunction?</code>, <code>first-conjunct</code>, and <code>rest-conjuncts</code> are used by
<code>conjoin</code> to manipulate <code>and</code> queries.</p>
<pre><code class="language-scheme editable">(define (empty-conjunction? exps) (null? exps))
(define (first-conjunct exps) (car exps))
(define (rest-conjuncts exps) (cdr exps))
</code></pre>
<p><code>Empty-disjunction?</code>, <code>first-disjunct</code>, and <code>rest-disjuncts</code> are used by
<code>disjoin</code> to manipulate <code>or</code> queries.</p>
<pre><code class="language-scheme editable">(define (empty-disjunction? exps) (null? exps))
(define (first-disjunct exps) (car exps))
(define (rest-disjuncts exps) (cdr exps))
</code></pre>
<p><code>Negated-query</code> is used by <code>negate</code> to get the query to be negated from a
<code>not</code> query.</p>
<pre><code class="language-scheme editable">(define (negated-query exps) (car exps))
</code></pre>
<p><code>Predicate</code> and <code>args</code> are used by <code>execute</code> to get the parts of a
<code>lisp-value</code> query.</p>
<pre><code class="language-scheme editable">(define (predicate exps) (car exps))
(define (args exps) (cdr exps))
</code></pre>
<p><code>Rule?</code>, <code>conclusion</code>, and <code>rule-body</code> are used to manipulate rules.</p>
<pre><code class="language-scheme editable">(define (rule? exp) (tagged-list? exp 'rule))
(define (conclusion rule) (cadr rule))
(define (rule-body rule)
  (if (null? (cddr rule))
      '(always-true)
      (caddr rule)))
</code></pre>
<p>The query system uses a special internal
representation for pattern variables in order to distinguish them from
ordinary symbols. When the driver reads a query, it scans the query and
replaces all the symbols that start with <code>?</code> with internal variables,
which are lists beginning with the symbol <code>?</code>. For example, <code>?x</code> is
represented as <code>(? x)</code>. The procedure <code>var?</code> tests whether an expression
is such a variable. The procedure <code>variable-name</code> returns the symbol.</p>
<pre><code class="language-scheme editable">(define (var? exp) (tagged-list? exp '?))
(define (variable-name var) (cadr var))
</code></pre>
<p><code>Query-syntax-process</code> transforms a query read from the terminal into
the internal form with variables represented as lists. It also checks
for <code>assert!</code> so that the driver loop can tell whether the input is an
assertion or a query.</p>
<pre><code class="language-scheme editable">(define (query-syntax-process exp)
  (if (tagged-list? exp 'assert!)
      (cons 'assert! (cons (cadr exp) '())))
      (map-over-symbols expand-question-mark exp)))
</code></pre>
<p><code>Map-over-symbols</code> is a tree walk that is like <code>instantiate</code> except that
it operates on symbols rather than variables.</p>
<pre><code class="language-scheme editable">(define (map-over-symbols proc exp)
  (cond ((pair? exp)
         (cons (map-over-symbols proc (car exp))
               (map-over-symbols proc (cdr exp))))
        ((symbol? exp) (proc exp))
        (else exp)))
</code></pre>
<p><code>Expand-question-mark</code> does the actual transformation of each variable.</p>
<pre><code class="language-scheme editable">(define (expand-question-mark symbol)
  (let ((chars (symbol-&gt;list symbol)))
    (if (eq? (car chars) #\?)
        (list '? (list-&gt;symbol (cdr chars)))
        symbol)))
</code></pre>
<p><code>Contract-question-mark</code> is used by the driver loop to transform the
internal representation of a variable back to the <code>?</code>-prefix form for
printing.</p>
<pre><code class="language-scheme editable">(define (contract-question-mark symbol)
  (list-&gt;symbol
   (cons #\?
         (symbol-&gt;list (variable-name symbol)))))
</code></pre>
<p><code>Make-new-variable</code> and <code>new-rule-application-id</code> are used by
<code>apply-a-rule</code> (section <a href="book-Z-H-29.html#%_sec_4.4.4.4">4.4.4.4</a>) to
generate new variables for each rule application.</p>
<pre><code class="language-scheme editable">(define (make-new-variable var id)
  (list '? (string-&gt;symbol
           (string-append (symbol-&gt;string (variable-name var))
                          "-"
                          (number-&gt;string id)))))
(define *rule-counter* 0)
(define (new-rule-application-id)
  (set! *rule-counter* (+ *rule-counter* 1))
  *rule-counter*)
</code></pre>
<h4 id="4448--frames-and-bindings"><a class="header" href="#4448--frames-and-bindings"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.4.8">4.4.4.8  Frames and Bindings</a></a></h4>
<p>A frame is a list of bindings. A binding is a <code>cons</code> of a
variable and a value.</p>
<pre><code class="language-scheme editable">(define (make-binding variable value) (cons variable value))
(define (binding-variable binding) (car binding))
(define (binding-value binding) (cdr binding))
(define (binding-in-frame variable frame)
  (assoc variable frame))
(define (extend variable value frame)
  (cons (make-binding variable value) frame))
</code></pre>
<p><code>Assoc</code> is the primitive that retrieves the binding of a variable in a
frame. It returns the binding if it finds one, and false otherwise.</p>
<pre><code class="language-scheme editable">(define (assoc variable frame)
  (cond ((null? frame) false)
        ((equal? variable (binding-variable (car frame)))
         (car frame))
        (else (assoc variable (cdr frame)))))
</code></pre>
<h3 id="445--exercises"><a class="header" href="#445--exercises"><a href="book-Z-H-4.html#%_toc_%_sec_4.4.5">4.4.5  Exercises</a></a></h3>
<p><strong>Exercise 4.70.</strong>  The <code>unify-match</code> procedure is passed a frame in which to look up and store bindings. Thus, <code>unify-match</code> can be called with a frame that already contains bindings. The procedure <code>extend-if-possible</code> must be careful, when extending the frame, to distinguish between the case where a variable is unbound and the case where it is bound to a value that happens to be another variable. The following examples, which use the representation of variables described in section <a href="book-Z-H-29.html#%_sec_4.4.4.7">4.4.4.7</a>, illustrate this difference. Suppose that the query system is working with the two patterns <code>(?x a)</code> and <code>(?y b)</code> and a frame in which <code>?y</code> is bound to <code>?x</code>:</p>
<p><code>(unify-match '(? x a) '(? y b) (list (make-binding '(? y) '(? x))))</code></p>
<p>First, <code>unify-match</code> is called on the <code>cdr</code>s of the patterns, <code>(a)</code> and <code>(b)</code>. This fails. Now suppose the frame is empty:</p>
<p><code>(unify-match '(? x a) '(? y b) '())</code></p>
<p>In this case, <code>unify-match</code> is called on the <code>cdr</code>s, and this fails. Finally, suppose the frame has a binding for <code>?y</code> but not for <code>?x</code>:</p>
<p><code>(unify-match '(? x a) '(? y b) (list (make-binding '(? y) 'c)))</code></p>
<p>This time, the <code>cdr</code> match succeeds, and then the <code>car</code> match is tried. <code>?X</code> is unbound, so it is bound to <code>?y</code>'s value, <code>c</code>. The resulting frame is <code>((? x) . c) ((? y) . c)</code>. In each case, we have simplified the situation by ignoring the fact that the system creates new variable names for each rule application.</p>
<p>For each of the following examples, give the result of the match and explain it.</p>
<p><code>a. (unify-match '(? x ?x) '((a ?y c) (a b ?z)) '())</code></p>
<p><code>b. (unify-match '(? x ?x) '((a ?y c) (a b ?z))</code>
<code>               (list (make-binding '(? y) 'b)))</code></p>
<p><code>c. (unify-match '(? x (a ?y)) '(?x (a b)) '())</code></p>
<p><strong>Exercise 4.71.</strong>  The <code>simple-query</code> procedure forms a stream of frames by appending the stream of frames from the assertions with the stream of frames from the rules. A different implementation would be to interleave the two streams. Would this be a better design? Would it be a worse design? Present arguments for both sides.</p>
<p><strong>Exercise 4.72.</strong>  The <code>disjoin</code> procedure is implemented with <code>interleave-delayed</code>. Explain why <code>stream-append-delayed</code> would not be appropriate here.</p>
<p><strong>Exercise 4.73.</strong>  The <code>conjoin</code> procedure is implemented as a cascade of <code>qeval</code>s. This is not the only way to compute the conjunction of a set of queries. Another way is to process the queries in parallel and to combine the resulting streams of frames. Devise a procedure that implements this parallel method. Can you find any reason to prefer the parallel method over the serial one, or vice versa?</p>
<p><strong>Exercise 4.74.</strong>  The <code>negate</code> procedure in section <a href="book-Z-H-29.html#%_sec_4.4.4.2">4.4.4.2</a> has a bug. Consider a query such as</p>
<p><code>(and (job ?x (computer programmer))</code>
<code>     (not (supervisor ?x (Bitdiddle Ben))))</code></p>
<p>This should find all the computer programmers who are not supervised by Ben Bitdiddle. The <code>and</code> will first find all computer programmers and produce a stream of frames, each containing a binding for <code>?x</code>. Then <code>negate</code> will be called on the pattern <code>(supervisor ?x (Bitdiddle Ben))</code> and this stream of frames. For each frame in the stream, <code>negate</code> will check to see if the pattern can be satisfied given the binding for <code>?x</code> in that frame. The bug is that <code>negate</code> will check for this by calling <code>qeval</code> with the pattern and a stream containing only the single frame. This is incorrect, because it will not be possible to satisfy the pattern by using a rule if that rule requires further extending the frame to bind other variables.</p>
<p>To see the problem, suppose we have the rule</p>
<p><code>(rule (supervisor ?x ?y) (and ...))</code></p>
<p>and we are checking the <code>not</code> clause with a frame in which <code>?x</code> is bound to Alyssa Hacker. <code>Negate</code> will try to see if <code>(supervisor (Hacker Alyssa P) (Bitdiddle Ben))</code> can be satisfied. It will try to do this by unifying <code>(supervisor ?x ?y)</code> with <code>(supervisor (Hacker Alyssa P) (Bitdiddle Ben))</code>, which will bind <code>?y</code> to Ben Bitdiddle and then try to satisfy the body of the <code>supervisor</code> rule. If the body of the <code>supervisor</code> rule requires binding other variables, <code>negate</code> will not be able to do this, because it is processing the stream of frames with <code>singleton-stream</code>. Thus <code>negate</code> will report that the pattern cannot be satisfied, which is wrong.</p>
<p>Fix this bug in <code>negate</code>. You will have to change <code>qeval</code> so that it can produce a stream of all possible extensions to a given frame, rather than a stream of all extensions to any frame in a given stream of frames. You can do this by having <code>qeval</code> take a single frame as argument rather than a stream of frames. Then <code>stream-flatmap</code> in <code>simple-query</code> will no longer be redundant.</p>
<p><strong>Exercise 4.75.</strong>  The <code>lisp-value</code> special form is vulnerable to the same bug described in exercise <a href="book-Z-H-29.html#%_thm_4.75">4.74</a>. Fix this bug.</p>
<p><strong>Exercise 4.76.</strong>  Suppose we have a data base of students in a small school:</p>
<p><code>(student (Adams Alyssa P) (address ...) (telephone ...))</code>
<code>(student (Bitdiddle Ben) (address ...) (telephone ...))</code>
<code>...</code>
<code>(class (CS101) (lecturer ...) (time ...))</code>
<code>...</code>
<code>(enrolled (Adams Alyssa P) (CS101))</code>
<code>(enrolled (Bitdiddle Ben) (CS101))</code>
<code>(enrolled (Bitdiddle Ben) (CS205))</code>
<code>...</code></p>
<p>Now suppose we want to find all the students who are enrolled in two different classes. The following query finds all pairs of a student and two classes and then checks if the classes are different:</p>
<p><code>(and (enrolled ?student ?class-1)</code>
<code>     (enrolled ?student ?class-2)</code>
<code>     (lisp-value not (equal? ?class-1 ?class-2)))</code></p>
<p>This is grossly inefficient, because for each student it will check every pair of classes the student is enrolled in. For example, if Ben Bitdiddle is enrolled in ten classes, this query will check 100 pairs of classes for him.</p>
<p>Write a new special form <code>unique-query</code> that will do this job more efficiently. The following query should generate only one answer for each student:</p>
<p><code>(unique-query (and (enrolled ?student ?class-1)</code>
<code>                   (enrolled ?student ?class-2)))</code></p>
<p>To implement this, you will have to change <code>qeval</code> to take an additional argument, a list of the variables that are required to be unique. <code>Qeval</code> will pass this list to the procedures that handle the special forms. For example, <code>conjoin</code> will have to be changed to check if any of the variables in the list become bound by satisfying the first conjunct. If so, these variables must be removed from the list before the rest of the conjuncts are processed.</p>
<p><strong>Exercise 4.77.</strong>  The query system has a serious bug in that <code>lisp-value</code> and <code>not</code> may not work correctly if the patterns being tested contain variables that are not bound in the input frame stream. For example, if the frame stream passed to <code>negate</code> has a frame in which <code>?x</code> is unbound, and the pattern to be checked is <code>(job ?x (computer programmer))</code>, then <code>negate</code> will report that the pattern can be satisfied, because there is an assertion <code>(job (Fect Cy D) (computer programmer))</code> in the data base. This is incorrect. The <code>not</code> should act as a filter, to remove only those frames in which the given pattern is satisfied. An unbound variable can never cause a pattern to be satisfied. For example, a frame in which <code>?x</code> is unbound could be extended to bind <code>?x</code> to <code>(Hacker Alyssa P)</code>. But it could also be extended to bind <code>?x</code> to <code>(Bitdiddle Ben)</code>. The <code>not</code> should let the frame pass only if there is no way to extend it that satisfies the pattern. Fix this bug in <code>negate</code> and <code>lisp-value</code>. You will have to change the way that frames are created. Up to now, a frame has been a list of bindings. You will have to add to this a list of all the variables that are mentioned in the query but are not yet bound.</p>
<p><strong>Exercise 4.78.</strong>  Implement the query language as a nondeterministic program to be run with the <code>amb</code> evaluator of section <a href="book-Z-H-28.html#%_sec_4.3">4.3</a>. In this approach, the query evaluator will not have to deal with streams of frames. Instead, a query will be transformed into a nondeterministic expression with <code>amb</code>s. Evaluating this expression with the <code>amb</code> evaluator will cause the system to search for a satisfying assignment. For example, the query</p>
<p><code>(and (job ?x (computer programmer))</code>
<code>     (supervisor ?x ?y))</code></p>
<p>can be restated as follows: Find a <code>?x</code> and a <code>?y</code> such that <code>?x</code> has the job of computer programmer and <code>?y</code> is the supervisor of <code>?x</code>. In our nondeterministic language, this can be expressed as</p>
<p><code>(let ((x (an-element-of &lt;</code><em><code>list-of-people</code></em><code>&gt;))</code>
<code>      (y (an-element-of &lt;</code><em><code>list-of-people</code></em><code>&gt;)))</code>
<code> (require (is-in-db?</code>(job ,x (computer programmer))))<code> </code>  (require (is-in-db? <code>(supervisor ,x ,y)))</code>
<code>  (list x y))</code></p>
<p>where <code>is-in-db?</code> checks if a pattern is in the data base and <code>&lt;</code><em><code>list-of-people</code></em><code>&gt;</code> is a list of all the people in the data base. The backquote notation used here is the <code>quasiquote</code> syntax described in section <a href="book-Z-H-17.html#%_sec_2.4.1">2.4.1</a>.</p>
<p>Complete this sketch of an implementation of the query language. You must implement <code>is-in-db?</code> to check against both assertions and rules. <code>Is-in-db?</code> for a rule will require a unifier. You will also have to implement the various special forms. Think carefully about how to handle <code>not</code>.</p>
<p><strong>Exercise 4.79.</strong>  When we apply a rule, we rename the variables of the rule with a unique new name. A less straightforward implementation of rules would not do this renaming. Instead, it would require the unifier to distinguish between variables in the query and variables in the rule. That is, if <code>?x</code> appeared in both the query and the rule, these would be two different variables. Modify the unification algorithm to keep track of the variables in the two patterns being unified. You will have to augment the frame with information to distinguish the variables of the two patterns.</p>
<hr />
<p><a href="book-Z-H-29.html#call_footnote_Temp_645">^[58]{.small}^</a>
Logic programming is a major field of computer science research. The language we implement in this section is a version of
Prolog
(an acronym for <em>Pro</em>gramming in <em>Log</em>ic), which was developed in the
1970s by Alain Colmerauer and his colleagues at the University of
Marseille. The logic-programming methodology is based on the work of
Robert Kowalski at the University of Edinburgh and on earlier work in
automated theorem proving. See Kowalski 1979 for a discussion of the
logic-programming approach to computer science. The language we
implement in this section is a very simple version of Prolog. There are
many introductory texts on Prolog, for example, Clocksin and Mellish
1981. The computer language Planner, developed by Carl Hewitt (1969),
was an ancestor of Prolog. Planner was a rather cumbersome language,
and a subset of Planner, called Micro-Planner (Sussman, Winograd, and
Charniak 1971), was used in implementing the SHRDLU program described in
Winograd 1973.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_646">^[59]{.small}^</a>
These rules can be stated more formally as follows: Let <code>append(x,y,z)</code>
be the relation that is true if list <code>z</code> is the result of appending
list <code>y</code> to list <code>x</code>. Then <code>append</code> is defined by</p>
<ul>
<li><code>append(nil, y, y)</code> is true for any list <code>y</code>.</li>
<li><code>append((u . v), y, (u . z))</code> is true if <code>append(v, y, z)</code> is true.</li>
</ul>
<p><a href="book-Z-H-29.html#call_footnote_Temp_647">^[60]{.small}^</a>
This is not quite true. The Lisp <code>append</code> procedure can also be used to
answer questions of the third type, by means of the nondeterministic
evaluator of section <a href="book-Z-H-28.html#%_sec_4.3">4.3</a>. For example, to
find all pairs <code>(?x, ?y)</code> that append to form <code>(a b c d)</code>, we could
evaluate</p>
<p><code>(let ((x (a-list)) (y (a-list)))</code>
<code>  (require (equal? (append x y) '(a b c d)))</code>
<code>  (list x y))</code></p>
<p>where <code>a-list</code> is a procedure that nondeterministically generates lists.
This is, however, a hopelessly inefficient way to solve the problem.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_648">^[61]{.small}^</a>
One reason for the great interest in logic programming is its connection
to the goal of developing expert systems. See, for example, Davis 1982.
Another reason is the hope that logic programming will provide a handle
on the problem of programming parallel computers. See, for example,
Shapiro 1989.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_651">^[62]{.small}^</a>
This is the dotted-tail notation introduced in
exercise <a href="book-Z-H-15.html#%_thm_2.20">2.20</a>. We will see in
section <a href="book-Z-H-29.html#%_sec_4.4.4.3">4.4.4.3</a> how the query system
handles this.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_654">^[63]{.small}^</a>
This interpretation of <code>not</code> is not the only one, or even the most
reasonable one. Many people feel that a <code>not</code> query should be satisfied
only if the variables in the subquery can be instantiated in some way
that satisfies the subquery, and there is some assignment of values to
the other variables in the main query that satisfies the main query.
The problem of giving a clean definition of <code>not</code> in logic programming
is a delicate one. We will return to this in
section <a href="book-Z-H-29.html#%_sec_4.4.3">4.4.3</a>.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_655">^[64]{.small}^</a>
We assume here that we have defined a Lisp procedure <code>&gt;</code> that can be
applied to two arguments.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_658">^[65]{.small}^</a>
This rule is not completely correct, because it does not specify that
the two people must be different. We will see how to fix this below.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_659">^[66]{.small}^</a>
In Prolog, the conclusion is written first, separated from the body by
the symbol <code>:-</code> (which is meant to be reminiscent of a backward-facing
implication sign). The <code>and</code> connective is indicated by commas. Thus,
the <code>lives-near</code> rule would be written in Prolog as</p>
<p><code>lives_near(Person1, Person2) :-</code>
<code>  address(Person1, Town, _),</code>
<code>  address(Person2, Town, _),</code>
<code>  not(Person1 = Person2).</code></p>
<p>In this expression, <code>Person1</code>, <code>Person2</code>, and <code>Town</code> are variables. The
underscore <code>_</code> indicates an anonymous variable, i.e., a variable that is
not used elsewhere in the rule. We have chosen to use Lisp syntax for
our query language to make it blend with the rest of the book.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_670">^[67]{.small}^</a>
This stream-of-frames data structure was first described by
Eugene Charniak (see Charniak,
Riesbeck, and McDermott 1980).</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_672">^[68]{.small}^</a>
This worst-case estimate assumes that the number of matches of each
query to each frame is a constant that is greater than 1 and is
independent of the frame. For example, if each query generates two
matches for each input frame, then <em>n</em> queries in series will generate
2^<em>n</em>^ output frames for each input frame.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_673">^[69]{.small}^</a>
One of the key ideas in the evolution of data-base systems has been the
development of query-optimization techniques. See Ullman 1988 for an
introduction to this area.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_674">^[70]{.small}^</a>
This implementation of <code>not</code> is technically called 'negation as
failure.' A query <code>(not q)</code> is considered to be satisfied if the query
<code>q</code> fails. As we will see in section <a href="book-Z-H-29.html#%_sec_4.4.3">4.4.3</a>,
this leads to some strange behavior.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_676">^[71]{.small}^</a>
The unification algorithm we present in this chapter is a version of an
algorithm developed by J. A. Robinson (1965). The problem of devising
efficient unification algorithms is an active area of research.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_677">^[72]{.small}^</a>
This is an example of how a pattern can be used to represent a set of
values that is not yet determined. Such a pattern is often called a
<em>partially instantiated</em> data object.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_680">^[73]{.small}^</a>
In a practical data-base system, we would use indexing to avoid
scanning the entire list of rules. See
section <a href="book-Z-H-29.html#%_sec_4.4.4.5">4.4.4.5</a>.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_682">^[74]{.small}^</a>
In a real logic programming system, the user would be able to ask for
more than one answer to a query. This could be accomplished by having
the driver loop, like the <code>amb</code> driver loop of
section <a href="book-Z-H-28.html#%_sec_4.3.3">4.3.3</a>, respond to a <code>try-again</code>
request by looking for more elements in the stream of answers. The
stream of frames is a perfect tool for implementing this feature.
Instead of processing the whole stream of frames at once, the driver
would process only one frame at a time, and the <code>try-again</code> command
would cause the driver to process the next frame in the stream.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_683">^[75]{.small}^</a>
The method of inference is a slight variant of a method called
<em>resolution</em>, which was developed by the logician J. A. Robinson
(1965).</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_684">^[76]{.small}^</a>
This is not to say that the query language is a general-purpose theorem
prover. As we will see, the query language is organized in such a way
that its inferences are chained in a simple fashion. This makes the
language an effective programming system, but it also severely limits
the kinds of deductions it can make. A general theorem prover might try
to prove a statement by, for example, showing that the negation of the
statement leads to a contradiction. Such a proof by contradiction is a
very powerful inference method, but it is also very expensive to
compute. Any programming language that included such a method as its
central element would be hopelessly inefficient.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_686">^[77]{.small}^</a>
Most Prolog implementations provide some mechanism for programmers to
control the search. One common mechanism is called <code>cut</code>. <code>Cut</code> allows
the programmer to prune the search tree, which can be useful for
expressing things like 'if you have found one answer, don't bother
searching for any others.'</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_688">^[78]{.small}^</a>
This is not quite true. The system will not deduce that 2 + 2 is not 4,
because <code>lisp-value</code> forms are handled specially. The predicate in a
<code>lisp-value</code> form is a Lisp procedure, so it is evaluated by the
underlying Lisp system. The query system has no information about the
behavior of Lisp procedures, so it cannot make deductions about them.</p>
<p><a href="book-Z-H-29.html#call_footnote_Temp_689">^[79]{.small}^</a>
This is also called <em>negation as failure</em>. See
footnote <a href="book-Z-H-29.html#footnote_Temp_674">70</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="section" class="chapter"><a class="header" href="#section"></a></h1>
<p><a href="book-Z-H-4.html#%_toc_%_chap_5">Chapter 5</a></p>
<p><a href="book-Z-H-4.html#%_toc_%_chap_5">Computing with Register Machines</a></p>
<div class="info">
My aim is to show that the heavenly machine is not a kind of divine, 
live being, but a kind of clockwork (and he who believes that a clock
has soul attributes the maker\'s glory to the work), insofar as
nearly all the manifold motions are caused by a most simple and
material force, just as all motions of the clock are caused by a
single weight.
Johannes Kepler (letter to Herwart von Hohenburg,1605)
</div>
<p>We began this book by studying processes and by describing processes in
terms of procedures written in Lisp. To explain the meanings of these
procedures, we used a succession of models of evaluation: the
substitution model of chapter 1, the environment model of chapter 3, and
the metacircular evaluator of chapter 4. Our examination of the
metacircular evaluator, in particular, dispelled much of the mystery of
how Lisp-like languages are interpreted. But even the metacircular
evaluator leaves important questions unanswered, because it fails to
elucidate the mechanisms of control in a Lisp system. For instance, the
evaluator does not explain how the evaluation of a subexpression manages
to return a value to the expression that uses this value, nor does the
evaluator explain how some recursive procedures generate iterative
processes (that is, are evaluated using constant space) whereas other
recursive procedures generate recursive processes. These questions
remain unanswered because the metacircular evaluator is itself a Lisp
program and hence inherits the control structure of the underlying Lisp
system. In order to provide a more complete description of the control
structure of the Lisp evaluator, we must work at a more primitive level
than Lisp itself.</p>
<p>In this chapter we will describe processes in terms of the step-by-step
operation of a traditional computer. Such a computer, or
<em>register machine</em>, sequentially executes <em>instructions</em>
that manipulate the contents of a fixed set of storage elements called
<em>registers</em>. A typical register-machine instruction
applies a primitive operation to the contents of some registers and
assigns the result to another register. Our descriptions of processes
executed by register machines will look very much like
``machine-language'' programs for traditional computers. However,
instead of focusing on the machine language of any particular computer,
we will examine several Lisp procedures and design a specific register
machine to execute each procedure. Thus, we will approach our task from
the perspective of a hardware architect rather than that of a
machine-language computer programmer. In designing register machines, we
will develop mechanisms for implementing important programming
constructs such as recursion. We will also present a language for
describing designs for register machines. In
section <a href="book-Z-H-32.html#%_sec_5.2">5.2</a> we will implement a Lisp
program that uses these descriptions to simulate the machines we design.</p>
<p>Most of the primitive operations of our register machines are very
simple. For example, an operation might add the numbers fetched from two
registers, producing a result to be stored into a third register. Such
an operation can be performed by easily described hardware. In order to
deal with list structure, however, we will also use the memory
operations <code>car</code>, <code>cdr</code>, and <code>cons</code>, which require an elaborate
storage-allocation mechanism. In
section <a href="book-Z-H-33.html#%_sec_5.3">5.3</a> we study their implementation
in terms of more elementary operations.</p>
<p>In section <a href="book-Z-H-34.html#%_sec_5.4">5.4</a>, after we have accumulated
experience formulating simple procedures as register machines, we will
design a machine that carries out the algorithm described by the
metacircular evaluator of section <a href="book-Z-H-26.html#%_sec_4.1">4.1</a>.
This will fill in the gap in our understanding of how Scheme expressions
are interpreted, by providing an explicit model for the mechanisms of
control in the evaluator. In section <a href="book-Z-H-35.html#%_sec_5.5">5.5</a>
we will study a simple compiler that translates Scheme programs into
sequences of instructions that can be executed directly with the
registers and operations of the evaluator register machine.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="51-designing-register-machines"><a class="header" href="#51-designing-register-machines"><a href="book-Z-H-4.html#%_toc_%_sec_5.1">5.1 Designing Register Machines</a></a></h2>
<p>To design a register machine, we must design its <em>data paths</em> (registers
and operations) and the <em>controller</em> that sequences these operations. To
illustrate the design of a simple register machine, let us examine
Euclid's Algorithm, which is used to compute the
greatest common divisor (GCD) of two integers. As we saw in
section
<a href="book-Z-H-11.html#%_sec_1.2.5">1.2.5</a>, Euclid's
Algorithm can be carried out by an iterative process, as specified by
the following procedure:</p>
<pre><code class="language-scheme editable">(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
</code></pre>
<p>A machine to carry out this algorithm must keep track of two numbers,
<em>a</em> and <em>b</em>, so let us assume that these numbers are stored in two
registers with those names. The basic operations required are testing
whether the contents of register <code>b</code> is zero and computing the remainder
of the contents of register <code>a</code> divided by the contents of register <code>b</code>.
The remainder operation is a complex process, but assume for the moment
that we have a primitive device that computes remainders. On each cycle
of the GCD algorithm, the contents of register <code>a</code> must be replaced by
the contents of register <code>b</code>, and the contents of <code>b</code> must be replaced
by the remainder of the old contents of <code>a</code> divided by the old contents
of <code>b</code>. It would be convenient if these replacements could be done
simultaneously, but in our model of register machines we will assume
that only one register can be assigned a new value at each step. To
accomplish the replacements, our machine will use a third
''temporary'' register, which we call <code>t</code>. (First the remainder will
be placed in <code>t</code>, then the contents of <code>b</code> will be placed in <code>a</code>, and
finally the remainder stored in <code>t</code> will be placed in <code>b</code>.)</p>
<p>We can illustrate the registers and
operations required for this machine by using the data-path diagram
shown in figure
<a href="book-Z-H-31.html#%_fig_5.1">5.1</a>. In this diagram, the
registers (<code>a</code>, <code>b</code>, and <code>t</code>) are represented by rectangles. Each way to
assign a value to a register is indicated by an arrow with an <code>X</code> behind
the head, pointing from the source of data to the register. We can think
of the <code>X</code> as a button that, when pushed, allows the value at the source
to ''flow'' into the designated register. The label next to each
button is the name we will use to refer to the button. The names are
arbitrary, and can be chosen to have mnemonic value (for example, <code>a&lt;-b</code>
denotes pushing the button that assigns the contents of register <code>b</code> to
register <code>a</code>). The source of data for a register can be another register
(as in the <code>a&lt;-b</code> assignment), an operation result (as in the <code>t&lt;-r</code>
assignment), or a constant (a built-in value that cannot be changed,
represented in a data-path diagram by a triangle containing the
constant).</p>
<p>An operation that computes a value from constants and the contents of
registers is represented in a data-path diagram by a trapezoid
containing a name for the operation. For example, the box marked <code>rem</code>
in figure
<a href="book-Z-H-31.html#%_fig_5.1">5.1</a> represents an operation that
computes the remainder of the contents of the registers <code>a</code> and <code>b</code> to
which it is attached. Arrows (without buttons) point from the input
registers and constants to the box, and arrows connect the operation's
output value to registers. A test is represented by a circle containing
a name for the test. For example, our GCD machine has an operation that
tests whether the contents of register <code>b</code> is zero. A test also has
arrows from its input registers and
constants, but it has no output arrows; its value is used by the
controller rather than by the data paths. Overall, the data-path diagram
shows the registers and operations that are required for the machine and
how they must be connected. If we view the arrows as wires and the <code>X</code>
buttons as switches, the data-path diagram is very like the wiring
diagram for a machine that could be constructed from electrical
components.</p>
<p><img src="ch5-Z-G-1.gif" alt="" /></p>
<p><strong>Figure 5.1:</strong>
Data paths for a GCD machine.</p>
<p>In order for the data paths to actually
compute GCDs, the buttons must be pushed in the correct sequence. We
will describe this sequence in terms of a controller diagram, as
illustrated in figure
<a href="book-Z-H-31.html#%_fig_5.2">5.2</a>. The elements of
the controller diagram indicate how the data-path components should be
operated. The rectangular boxes in the controller diagram identify
data-path buttons to be pushed, and the arrows describe the sequencing
from one step to the next. The diamond in the diagram represents a
decision. One of the two sequencing arrows will be followed, depending
on the value of the data-path test identified in the diamond. We can
interpret the controller in terms of a physical analogy: Think of the
diagram as a maze in which a marble is rolling. When the marble rolls
into a box, it pushes the data-path button that is named by the box.
When the marble rolls into a decision node (such as the test for <code>b</code> =
0), it leaves the node on the path determined by the result of the
indicated test. Taken together, the data paths and the controller
completely describe a machine for computing GCDs. We start the
controller (the rolling marble) at the place marked <code>start</code>, after
placing numbers in registers <code>a</code> and <code>b</code>. When the controller reaches
<code>done</code>, we will find the value of the GCD in register <code>a</code>.</p>
<p><img src="ch5-Z-G-2.gif" alt="" /></p>
<p><strong>Figure 5.2:</strong>
Controller for a GCD machine.</p>
<p><strong>Exercise 5.1.</strong>
Design a register
machine to compute factorials using the iterative algorithm specified by
the following procedure. Draw data-path and controller diagrams for this
machine.</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (define (iter product counter)
    (if (&gt; counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
</code></pre>
<h3 id="511"><a class="header" href="#511">[5.1.1</a></h3>
<p>A Language for Describing Register Machines](book-Z-H-4.html#%<em>toc</em>%_sec_5.1.1)</p>
<p>Data-path and controller diagrams are adequate for
representing simple machines such as GCD, but they are unwieldy for
describing large machines such as a Lisp interpreter. To make it
possible to deal with complex machines, we will create a language that
presents, in textual form, all the information given by the data-path
and controller diagrams. We will start with a notation that directly
mirrors the diagrams.</p>
<p>We define the data paths of a machine by describing the registers and
the operations. To describe a register, we give it a name and specify
the buttons that control assignment to it. We give each of these buttons
a name and specify the source of the data that enters the register under
the button's control. (The source is a register, a constant, or an
operation.) To describe an operation, we give it a name and specify its
inputs (registers or constants).</p>
<p>We define the controller of a machine as a sequence of
<em>instructions</em> together with
<em>labels</em> that identify <em>entry points</em> in
the sequence. An instruction is one of the following:</p>
<ul>
<li>
<p>The name of a data-path button to push to assign a value to a
register. (This corresponds to a box in the controller diagram.)</p>
</li>
<li>
<p>A <code>test</code> instruction, that performs a specified test.</p>
</li>
<li>
<p>A conditional branch (<code>branch</code> instruction) to a location indicated by
a controller label, based on the result of the previous test. (The
test and branch together correspond to a diamond in the controller
diagram.) If the test is false, the controller should continue with
the next instruction in the sequence. Otherwise, the controller should
continue with the instruction after the label.</p>
</li>
<li>
<p>An unconditional branch (<code>goto</code> instruction) naming a controller label
at which to continue execution.</p>
</li>
</ul>
<p>The machine starts at the beginning of the controller instruction
sequence and stops when execution reaches the end of the sequence.
Except when a branch changes the flow of control, instructions are
executed in the order in which they are listed.</p>
<pre><code class="language-scheme editable">(data-paths
 (registers
  ((name a)
   (buttons ((name a&lt;-b) (source (register b)))))
  ((name b)
   (buttons ((name b&lt;-t) (source (register t)))))
  ((name t)
   (buttons ((name t&lt;-r) (source (operation rem))))))

 (operations
  ((name rem)
   (inputs (register a) (register b)))
  ((name =)
   (inputs (register b) (constant 0)))))

(controller
 test-b                           `*`; label`*`
   (test =)                       `*`; test`*`
   (branch (label gcd-done))      `*`; conditional branch`*`
   (t&lt;-r)                         `*`; button push`*`
   (a&lt;-b)                         `*`; button push`*`
   (b&lt;-t)                         `*`; button push`*`
   (goto (label test-b))          `*`; unconditional branch`*`
 gcd-done)                        `*`; label`*`
</code></pre>
<p><strong>Figure 5.3:</strong>
A specification of the GCD machine.</p>
<p>Figure
<a href="book-Z-H-31.html#%_fig_5.3">5.3</a> shows the GCD machine described
in this way. This example only hints at the generality of these
descriptions, since the GCD machine is a very simple case: Each register
has only one button, and each button and test is used only once in the
controller.</p>
<p>Unfortunately, it is difficult to read such a description. In order to
understand the controller instructions we must constantly refer back to
the definitions of the button names and the operation names, and to
understand what the buttons do we may have to refer to the definitions
of the operation names. We will thus transform our notation to combine
the information from the data-path and controller descriptions so that
we see it all together.</p>
<p>To obtain this form of description, we will replace the arbitrary button
and operation names by the definitions of their behavior. That is,
instead of saying (in the controller) ''Push button <code>t&lt;-r</code>'' and
separately saying (in the data paths) ''Button <code>t&lt;-r</code> assigns the
value of the <code>rem</code> operation to register <code>t</code>'' and ''The <code>rem</code>
operation's inputs are the contents of registers
<code>a</code>
and <code>b</code>,'' we will say (in the controller) ''Push the button that
assigns to register <code>t</code> the value of the <code>rem</code> operation on the contents
of registers <code>a</code> and <code>b</code>.'' Similarly, instead of saying (in the
controller) ''Perform the <code>=</code> test'' and separately saying (in the
data paths) ''The <code>=</code> test operates on the contents of register <code>b</code>
and the constant 0,'' we will say ''Perform the <code>=</code> test on the
contents of register <code>b</code> and the constant
0.'' We will omit the data-path description, leaving only the
controller sequence. Thus, the GCD machine is described as follows:</p>
<pre><code class="language-scheme editable">(controller
  test-b
    (test (op =) (reg b) (const 0))
    (branch (label gcd-done))
    (assign t (op rem) (reg a) (reg b))
    (assign a (reg b))
    (assign b (reg t))
    (goto (label test-b))
  gcd-done)
</code></pre>
<p>This form of description is easier to read than the kind illustrated in
figure
<a href="book-Z-H-31.html#%_fig_5.3">5.3</a>, but it also has disadvantages:</p>
<ul>
<li></li>
<li>It is more verbose for large machines, because complete descriptions
of the data-path elements are repeated whenever the elements are
mentioned in the controller instruction sequence. (This is not a
problem in the GCD example, because each operation and button is used
only once.) Moreover, repeating the data-path descriptions obscures
the actual data-path structure of the machine; it is not obvious for a
large machine how many registers, operations, and buttons there are
and how they are interconnected.</li>
<li>Because the controller instructions in a machine definition look like
Lisp expressions, it is easy to forget that they are not arbitrary
Lisp expressions. They can notate only legal machine operations. For
example, operations can operate directly only on constants and the
contents of registers, not on the results of other operations.</li>
</ul>
<p>In spite of these disadvantages, we will use this register-machine
language throughout this chapter, because we will be more concerned with
understanding controllers than with understanding the elements and
connections in data paths. We should keep in mind, however, that
data-path design is crucial in designing real machines.</p>
<p><strong>Exercise 5.2.</strong>
Use the
register-machine language to describe the iterative factorial machine of
exercise
<a href="book-Z-H-31.html#%_thm_5.1">5.1</a>.</p>
<h4 id="actions"><a class="header" href="#actions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_714">Actions</a></a></h4>
<p>Let us modify the GCD machine so that we
can type in the numbers whose GCD we want and get the answer printed at
our terminal. We will not discuss how to make a machine that can read
and print, but will assume (as we do when we use <code>read</code> and <code>display</code> in
Scheme) that they are available as primitive
operations.<a href="book-Z-H-31.html#footnote_Temp_715">^[1]{.small}^</a></p>
<p><code>Read</code> is like the operations we have been using in that
it produces a value that can be stored in a register. But <code>read</code> does
not take inputs from any registers; its value depends on something that
happens outside the parts of the machine we are designing. We will allow
our machine's operations to have such behavior, and thus will draw and
notate the use of <code>read</code> just as we do any other operation that computes
a value.</p>
<p><code>Print</code>, on the other hand, differs from the operations
we have been using in a fundamental way: It does not produce an output
value to be stored in a register. Though it has an effect, this effect
is not on a part of the machine we are designing. We will refer to this
kind of operation as an <em>action</em>. We will represent an action in a
data-path diagram just as we represent an operation that computes a
value -- as a trapezoid that contains the name of the action. Arrows
point to the action box from any inputs (registers or constants). We
also associate a button with the action. Pushing the button makes the
action happen. To make a controller push an action
button we use a new kind of instruction
called <code>perform</code>. Thus, the action of printing the contents of register
<code>a</code> is represented in a controller sequence by the instruction:</p>
<pre><code class="language-scheme editable">(perform (op print) (reg a))
</code></pre>
<p>Figure
<a href="book-Z-H-31.html#%_fig_5.4">5.4</a> shows the data paths and
controller for the new GCD machine. Instead of having the machine stop
after printing the answer, we have made it start over, so that it
repeatedly reads a pair of numbers, computes their GCD, and prints the
result. This structure is like the driver loops we used in the
interpreters of chapter
4.</p>
<p><img src="ch5-Z-G-3.gif" alt="" /></p>
<pre><code class="language-scheme editable"> (controller
  gcd-loop
    (assign a (op read))
    (assign b (op read))
  test-b
    (test (op =) (reg b) (const 0))
    (branch (label gcd-done))
    (assign t (op rem) (reg a) (reg b))
    (assign a (reg b))
    (assign b (reg t))
    (goto (label test-b))
  gcd-done
    (perform (op print) (reg a))
    (goto (label gcd-loop)))
</code></pre>
<p><strong>Figure 5.4:</strong>
A GCD machine that reads inputs and prints results.</p>
<h3 id="512"><a class="header" href="#512">[5.1.2</a></h3>
<p>Abstraction in Machine Design](book-Z-H-4.html#%<em>toc</em>%_sec_5.1.2)</p>
<p>We will often define a machine to include
''primitive'' operations that are actually very complex. For
example, in sections
<a href="book-Z-H-34.html#%_sec_5.4">5.4</a> and
<a href="book-Z-H-35.html#%_sec_5.5">5.5</a> we will treat Scheme's environment
manipulations as primitive. Such abstraction is valuable because it
allows us to ignore the details of parts of a machine so that we can
concentrate on other aspects of the design. The fact that we have swept
a lot of complexity under the rug, however, does not mean that a machine
design is unrealistic. We can always replace the complex
''primitives'' by simpler primitive operations.</p>
<p>Consider the GCD machine. The machine has an instruction that computes
the remainder of the contents of registers <code>a</code> and <code>b</code> and assigns the
result to register <code>t</code>. If we want to construct the GCD machine without
using a primitive remainder operation, we must specify how to compute
remainders in terms of simpler operations, such as subtraction. Indeed,
we can write a Scheme procedure that finds remainders in this way:</p>
<pre><code class="language-scheme editable">(define (remainder n d)
  (if (&lt; n d)
      n
      (remainder (- n d) d)))
</code></pre>
<p>We can thus replace the remainder operation in the GCD machine's data
paths with a subtraction operation and a comparison test.
Figure
<a href="book-Z-H-31.html#%_fig_5.5">5.5</a> shows the data paths and
controller for the elaborated machine. The instruction</p>
<p><img src="ch5-Z-G-4.gif" alt="" /></p>
<p><strong>Figure 5.5:</strong>
Data paths and controller for the elaborated GCD
machine.</p>
<pre><code class="language-scheme editable">(assign t (op rem) (reg a) (reg b))
</code></pre>
<p>in the GCD controller definition is replaced by a sequence of
instructions that contains a loop, as shown in
figure
<a href="book-Z-H-31.html#%_fig_5.6">5.6</a>.</p>
<pre><code class="language-scheme editable">
(controller
 test-b
   (test (op =) (reg b) (const 0))
   (branch (label gcd-done))
   (assign t (reg a))
 rem-loop
   (test (op &lt;) (reg t) (reg b))
   (branch (label rem-done))
   (assign t (op -) (reg t) (reg b))
   (goto (label rem-loop))
 rem-done
   (assign a (reg b))
   (assign b (reg t))
   (goto (label test-b))
 gcd-done)
</code></pre>
<p><strong>Figure 5.6:</strong>
Controller instruction sequence for the GCD machine in
figure
<a href="book-Z-H-31.html#%_fig_5.5">5.5</a>.</p>
<p><strong>Exercise 5.3.</strong>
Design a machine to
compute square roots using Newton's method, as described in
section
<a href="book-Z-H-10.html#%_sec_1.1.7">1.1.7</a>:</p>
<pre><code class="language-scheme editable">(define (sqrt x)
  (define (good-enough? guess)
    (&lt; (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
        guess
        (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))
</code></pre>
<p>Begin by assuming that <code>good-enough?</code> and <code>improve</code> operations are
available as primitives. Then show how to expand these in terms of
arithmetic operations. Describe each version of the <code>sqrt</code> machine
design by drawing a data-path diagram and writing a controller
definition in the register-machine language.</p>
<h3 id="513"><a class="header" href="#513">[5.1.3</a></h3>
<p>Subroutines](book-Z-H-4.html#%<em>toc</em>%_sec_5.1.3)</p>
<p>When designing a machine to perform a
computation, we would often prefer to arrange for components to be
shared by different parts of the computation rather than duplicate the
components. Consider a machine that includes two GCD computations --
one that finds the GCD of the contents of registers <code>a</code> and <code>b</code> and one
that finds the GCD of the contents of registers <code>c</code> and <code>d</code>. We might
start by assuming we have a primitive <code>gcd</code> operation, then expand the
two instances of <code>gcd</code> in terms of more primitive operations.
Figure
<a href="book-Z-H-31.html#%_fig_5.7">5.7</a> shows just the GCD portions of
the resulting machine's data paths, without showing how they connect to
the rest of the machine. The figure also shows the corresponding
portions of the machine's controller sequence.</p>
<p><img src="ch5-Z-G-5.gif" alt="" /></p>
<p>gcd-1</p>
<pre><code class="language-scheme editable"> (test (op =) (reg b) (const 0))
 (branch (label after-gcd-1))
 (assign t (op rem) (reg a) (reg b))
 (assign a (reg b))
 (assign b (reg t))
 (goto (label gcd-1))
</code></pre>
<p>after-gcd-1
<code>![](book-Z-G-D-18.gif)</code>
gcd-2</p>
<pre><code class="language-scheme editable"> (test (op =) (reg d) (const 0))
 (branch (label after-gcd-2))
 (assign s (op rem) (reg c) (reg d))
 (assign c (reg d))
 (assign d (reg s))
 (goto (label gcd-2))
</code></pre>
<p>after-gcd-2</p>
<p><strong>Figure 5.7:</strong>
Portions of the data paths and controller sequence for
a machine with two GCD computations.</p>
<p>This machine has two remainder operation boxes and two boxes for testing
equality. If the duplicated components are complicated, as is the
remainder box, this will not be an economical way to build the machine.
We can avoid duplicating the data-path components by using the same
components for both GCD computations, provided that doing so will not
affect the rest of the larger machine's computation. If the values in
registers <code>a</code> and <code>b</code> are not needed by the time the controller gets to
<code>gcd-2</code> (or if these values can be moved to other registers for
safekeeping), we can change the machine so that it uses registers <code>a</code>
and <code>b</code>, rather than registers <code>c</code> and <code>d</code>, in computing the second GCD
as well as the first. If we do this, we obtain the controller sequence
shown in figure
<a href="book-Z-H-31.html#%_fig_5.8">5.8</a>.</p>
<p>We have removed the duplicate data-path components (so that the data
paths are again as in figure
<a href="book-Z-H-31.html#%_fig_5.1">5.1</a>), but the
controller now has two GCD sequences that differ only in their
entry-point labels. It would be better to replace these two sequences by
branches to a single sequence -- a <code>gcd</code> <em>subroutine</em> -- at the end of
which we branch back to the correct place in the main instruction
sequence. We can accomplish this as follows: Before branching to <code>gcd</code>,
we place a distinguishing value (such as 0 or</p>
<ol>
<li>into a special
register, <code>continue</code>. At the end of the <code>gcd</code> subroutine
we return either to <code>after-gcd-1</code> or to <code>after-gcd-2</code>, depending on the
value of the <code>continue</code> register.
Figure
<a href="book-Z-H-31.html#%_fig_5.9">5.9</a> shows the relevant portion of
the resulting controller sequence, which includes only a single copy of
the <code>gcd</code> instructions.</li>
</ol>
<p>gcd-1</p>
<pre><code class="language-scheme editable"> (test (op =) (reg b) (const 0))
 (branch (label after-gcd-1))
 (assign t (op rem) (reg a) (reg b))
 (assign a (reg b))
 (assign b (reg t))
 (goto (label gcd-1))
</code></pre>
<p>after-gcd-1<code>   </code><img src="book-Z-G-D-18.gif" alt="" />
gcd-2</p>
<pre><code class="language-scheme editable"> (test (op =) (reg b) (const 0))
 (branch (label after-gcd-2))
 (assign t (op rem) (reg a) (reg b))
 (assign a (reg b))
 (assign b (reg t))
 (goto (label gcd-2))
</code></pre>
<p>after-gcd-2</p>
<p><strong>Figure 5.8:</strong>
Portions of the controller sequence for a machine that
uses the same data-path components for two different GCD computations.</p>
<p>gcd
(test (op =) (reg b) (const 0))
(branch (label gcd-done))
(assign t (op rem) (reg a) (reg b))
(assign a (reg b))
(assign b (reg t))
(goto (label gcd))
gcd-done
(test (op =) (reg continue) (const 0))<br />
(branch (label after-gcd-1))
(goto (label after-gcd-2))
<code>  </code><img src="book-Z-G-D-18.gif" alt="" />
<em><code>;; Before branching to ``gcd`` from the first place where</code></em>
<em><code>;; it is needed, we place 0 in the ``continue`` register</code></em>
(assign continue (const 0))
(goto (label gcd))
after-gcd-1
<code>![](book-Z-G-D-18.gif) *</code>;; Before the second use of <code>gcd</code>, we place 1 in the <code>continue</code> register`*
(assign continue (const 1))
(goto (label gcd))
after-gcd-2</p>
<p><strong>Figure 5.9:</strong>
Using a <code>continue</code> register to avoid the duplicate
controller sequence in figure
<a href="book-Z-H-31.html#%_fig_5.8">5.8</a>.</p>
<p>gcd</p>
<pre><code class="language-scheme editable"> (test (op =) (reg b) (const 0))
 (branch (label gcd-done))
 (assign t (op rem) (reg a) (reg b))
 (assign a (reg b))
 (assign b (reg t))
 (goto (label gcd))
</code></pre>
<p>gcd-done</p>
<pre><code class="language-scheme editable"> (goto (reg continue))
</code></pre>
<p><code>![](book-Z-G-D-18.gif) *</code>;; Before calling <code>gcd</code>, we assign to <code>continue`* *`;; the label to which </code>gcd`` should return.`*</p>
<pre><code class="language-scheme editable"> (assign continue (label after-gcd-1))
 (goto (label gcd))
</code></pre>
<p>after-gcd-1
<code>![](book-Z-G-D-18.gif) *</code>;; Here is the second call to <code>gcd</code>, with a different continuation.`*</p>
<pre><code class="language-scheme editable"> (assign continue (label after-gcd-2))
 (goto (label gcd))
</code></pre>
<p>after-gcd-2</p>
<p><strong>Figure 5.10:</strong>
Assigning labels to the <code>continue</code> register simplifies
and generalizes the strategy shown in
figure
<a href="book-Z-H-31.html#%_fig_5.9">5.9</a>.</p>
<p>This is a reasonable approach for handling small problems, but it would
be awkward if there were many instances of GCD computations in the
controller sequence. To decide where to continue executing after the
<code>gcd</code> subroutine, we would need tests in the data paths and branch
instructions in the controller for all the places that use <code>gcd</code>. A more
powerful method for implementing subroutines is to have the <code>continue</code>
register hold the label of the entry point in the controller sequence at
which execution should continue when the subroutine is finished.
Implementing this strategy requires a new kind of connection between the
data paths and the controller of a register machine: There must be a way
to assign to a register a label in the controller sequence in such a way
that this value can be fetched from the register and used to continue
execution at the designated entry point.</p>
<p>To reflect this ability, we will extend
the <code>assign</code> instruction of the register-machine language to allow a
register to be assigned as value a label from the controller sequence
(as a special kind of constant). We will also extend the <code>goto</code>
instruction to allow execution to continue at the entry point described
by the contents of a register rather than only at an entry point
described by a constant label. Using these new constructs we can
terminate the <code>gcd</code> subroutine with a branch to the location stored in
the <code>continue</code> register. This leads to the controller sequence shown in
figure
<a href="book-Z-H-31.html#%_fig_5.10">5.10</a>.</p>
<p>A machine with more than one subroutine could use multiple continuation
registers (e.g., <code>gcd-continue</code>, <code>factorial-continue</code>) or we could have
all subroutines share a single <code>continue</code> register. Sharing is more
economical, but we must be careful if we have a subroutine (<code>sub1</code>)
that calls another subroutine (<code>sub2</code>). Unless <code>sub1</code> saves the contents
of <code>continue</code> in some other register before setting up <code>continue</code> for the
call to <code>sub2</code>, <code>sub1</code> will not know where to go when it is finished.
The mechanism developed in the next section to handle recursion also
provides a better solution to this problem of nested subroutine calls.</p>
<h3 id="514"><a class="header" href="#514">[5.1.4</a></h3>
<p>Using a Stack to Implement Recursion](book-Z-H-4.html#%<em>toc</em>%_sec_5.1.4)</p>
<p>With the
ideas illustrated so far, we can implement any iterative process by
specifying a register machine that has a register corresponding to each
state variable of the process. The machine repeatedly executes a
controller loop, changing the contents of the registers, until some
termination condition is satisfied. At each point in the controller
sequence, the state of the machine (representing the state of the
iterative process) is completely determined by the contents of the
registers (the values of the state variables).</p>
<p>Implementing recursive
processes, however, requires an additional mechanism. Consider the
following recursive method for computing factorials, which we first
examined in section
<a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a>:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (if (= n 1)
      1
      (* (factorial (- n 1)) n)))
</code></pre>
<p>As we see from the procedure, computing <em>n</em>! requires computing (<em>n</em> -
1)!. Our GCD machine, modeled on the procedure</p>
<pre><code class="language-scheme editable">(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
</code></pre>
<p>similarly had to compute another GCD. But there is an important
difference between the <code>gcd</code> procedure, which reduces the original
computation to a new GCD computation, and <code>factorial</code>, which requires
computing another factorial as a subproblem. In GCD, the answer to the
new GCD computation is the answer to the original problem. To compute
the next GCD, we simply place the new arguments in the input registers
of the GCD machine and reuse the machine's data paths by executing the
same controller sequence. When the machine is finished solving the final
GCD problem, it has completed the entire computation.</p>
<p>In the case of factorial (or any recursive process) the answer to the
new factorial subproblem is not the answer to the original problem. The
value obtained for (<em>n</em> - 1)! must be multiplied by <em>n</em> to get the final
answer. If we try to imitate the GCD design, and solve the factorial
subproblem by decrementing the <code>n</code> register and rerunning the factorial
machine, we will no longer have available the old value of <code>n</code> by which
to multiply the result. We thus need a second factorial machine to work
on the subproblem. This second factorial computation itself has a
factorial subproblem, which requires a third factorial machine, and so
on. Since each factorial machine contains another factorial machine
within it, the total machine contains an infinite nest of similar
machines and hence cannot be constructed from a fixed, finite number of
parts.</p>
<p>Nevertheless, we can implement the factorial process as a register
machine if we can arrange to use the same components for each nested
instance of the machine. Specifically, the machine that computes <em>n</em>!
should use the same components to work on the subproblem of computing
(<em>n</em> - 1)!, on the subproblem for (<em>n</em> - 2)!, and so on. This is
plausible because, although the factorial process dictates that an
unbounded number of copies of the same machine are needed to perform a
computation, only one of these copies needs to be active at any given
time. When the machine encounters a recursive subproblem, it can suspend
work on the main problem, reuse the same physical parts to work on the
subproblem, then continue the suspended computation.</p>
<p>In the subproblem, the contents of the registers will be different than
they were in the main problem. (In this case the <code>n</code> register is
decremented.) In order to be able to continue the suspended computation,
the machine must save the contents of any registers that will be needed
after the subproblem is solved so that these can be restored to continue
the suspended computation. In the case of factorial, we will save the
old value of <code>n</code>, to be restored when we are finished computing the
factorial of the decremented <code>n</code>
register.<a href="book-Z-H-31.html#footnote_Temp_717">^[2]{.small}^</a></p>
<p>Since there is no <em>a priori</em> limit on the depth of nested recursive
calls, we may need to save an arbitrary number of register values. These
values must be restored in the reverse of the order in which they were
saved, since in a nest of recursions the last subproblem to be entered
is the first to be finished. This dictates the use of a <em>stack</em>, or
''last in, first out'' data structure, to save register values. We
can extend the register-machine language to include a stack by adding
two kinds of instructions: Values are placed
on the stack
using a <code>save</code> instruction and restored from the stack using a <code>restore</code>
instruction. After a sequence of values has been <code>save</code>d on the stack, a
sequence of <code>restore</code>s will retrieve these values in reverse
order.<a href="book-Z-H-31.html#footnote_Temp_718">^[3]{.small}^</a></p>
<p>With the aid of the stack, we can reuse a single copy of the factorial
machine's data paths for each factorial subproblem. There is a similar
design issue in reusing the controller sequence that operates the data
paths. To reexecute the factorial computation, the controller cannot
simply loop back to the beginning, as with an iterative process, because
after solving the (<em>n</em> - 1)! subproblem the machine must still multiply
the result by <em>n</em>. The controller must suspend its computation of <em>n</em>!,
solve the (<em>n</em> - 1)! subproblem, then continue its computation of <em>n</em>!.
This view of the factorial computation suggests the use of the
subroutine mechanism described in
section
<a href="book-Z-H-31.html#%_sec_5.1.3">5.1.3</a>, which has the controller
use a <code>continue</code> register to transfer to the part of the
sequence that solves a subproblem and then continue where it left off on
the main problem. We can thus make a factorial subroutine that returns
to the entry point stored in the <code>continue</code> register. Around each
subroutine call, we save and restore <code>continue</code> just as we do the <code>n</code>
register, since each ''level'' of the factorial computation will use
the same <code>continue</code> register. That is, the factorial subroutine must put
a new value in <code>continue</code> when it calls itself for a subproblem, but it
will need the old value in order to return to the place that called it
to solve a subproblem.</p>
<p>Figure
<a href="book-Z-H-31.html#%_fig_5.11">5.11</a> shows the data paths and
controller for a machine that implements the recursive <code>factorial</code>
procedure. The machine has a stack and three registers, called <code>n</code>,
<code>val</code>, and <code>continue</code>. To simplify the data-path diagram, we have not
named the register-assignment buttons, only the stack-operation buttons
(<code>sc</code> and <code>sn</code> to save registers, <code>rc</code> and <code>rn</code> to restore registers).
To operate the machine, we put in register <code>n</code> the number whose
factorial we wish to compute and start the machine. When the machine
reaches <code>fact-done</code>, the computation is finished and the answer will be
found in the <code>val</code> register. In the controller sequence, <code>n</code> and
<code>continue</code> are saved before each recursive call and restored upon return
from the call. Returning from a call is accomplished by branching to the
location stored in <code>continue</code>. <code>Continue</code> is initialized when the
machine starts so that the last return will go to <code>fact-done</code>. The <code>val</code>
register, which holds the result of the factorial computation, is not
saved before the recursive call, because the old contents of <code>val</code> is
not useful after the subroutine returns. Only the new value, which is
the value produced by the subcomputation, is needed. Although in
principle the factorial computation requires an infinite machine, the
machine in figure
<a href="book-Z-H-31.html#%_fig_5.11">5.11</a> is actually finite
except for the stack, which is potentially unbounded. Any particular
physical implementation of a stack, however, will be of finite size, and
this will limit the depth of recursive calls that can be handled by the
machine. This implementation of factorial illustrates the general
strategy for realizing recursive algorithms as ordinary register
machines augmented by stacks. When a recursive subproblem is
encountered, we save on the stack the registers whose current values
will be required after the subproblem is solved, solve the recursive
subproblem, then restore the saved registers and continue execution on
the main problem. The <code>continue</code> register must always be saved. Whether
there are other registers that need to be saved depends on the
particular machine, since not all recursive computations need the
original values of registers that are modified during solution of the
subproblem (see exercise
<a href="book-Z-H-31.html#%_thm_5.4">5.4</a>).</p>
<h4 id="a-double-recursion"><a class="header" href="#a-double-recursion"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_719">A double recursion</a></a></h4>
<p>Let us examine a more complex recursive process, the
tree-recursive computation of the Fibonacci numbers, which we introduced
in section
<a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a>:</p>
<pre><code class="language-scheme editable">(define (fib n)
  (if (&lt; n 2)
      n
      (+ (fib (- n 1)) (fib (- n 2)))))
</code></pre>
<p>Just as with factorial, we can implement the recursive Fibonacci
computation as a register machine with registers <code>n</code>, <code>val</code>, and
<code>continue</code>. The machine is more complex than the one for factorial,
because there are two places in the controller sequence where we need to
perform recursive calls -- once to compute Fib(<em>n</em> - 1) and once to
compute Fib(<em>n</em> - 2). To set up for each of these calls, we save the
registers whose values will be needed later, set the <code>n</code> register to the
number whose Fib we need to compute recursively (<em>n</em> - 1 or <em>n</em> - 2),
and assign to <code>continue</code> the entry point in the main sequence to which
to return (<code>afterfib-n-1</code> or <code>afterfib-n-2</code>, respectively). We then go
to <code>fib-loop</code>. When we return from the recursive call, the answer is in
<code>val</code>.
Figure
<a href="book-Z-H-31.html#%_fig_5.12">5.12</a> shows the controller
sequence for this machine.</p>
<p><img src="ch5-Z-G-6.gif" alt="" /></p>
<p>(controller
(assign continue (label fact-done))     <code>*</code>; set up final return address<code>*  fact-loop    (test (op =) (reg n) (const 1))    (branch (label base-case))    </code><em><code>;; Set up for the recursive call by saving ``n`` and ``continue``.</code></em><code>    </code><em><code>;; Set up ``continue`` so that the computation will continue</code></em>
<code>*</code>;; at <code>after-fact</code> when the subroutine returns.<code>*    (save continue)    (save n)    (assign n (op -) (reg n) (const 1))    (assign continue (label after-fact))    (goto (label fact-loop))  after-fact    (restore n)    (restore continue)    (assign val (op *) (reg n) (reg val))   </code><em><code>; ``val`` now contains</code></em><code> </code><em><code>n</code></em><code>(</code><em><code>n</code></em><code> - 1)!</code>
(goto (reg continue))                   <code>*</code>; return to caller<code>*  base-case    (assign val (const 1))                  </code><em><code>; base case:</code></em><code> 1! = 1</code>
(goto (reg continue))                   <code>*</code>; return to caller`*
fact-done)</p>
<p><strong>Figure 5.11:</strong>
A recursive factorial machine.</p>
<pre><code class="language-scheme editable">(controller
   (assign continue (label fib-done))
</code></pre>
<p>fib-loop</p>
<pre><code class="language-scheme editable">   (test (op &lt;) (reg n) (const 2))
   (branch (label immediate-answer))
   `*`;; set up to compute `*`Fib`*`(`*`n`*` - 1)`*
   (save continue)
   (assign continue (label afterfib-n-1))
   (save n)                           `*`; save old value of ``n`*
   (assign n (op -) (reg n) (const 1))`*`; clobber ``n`` to `*`n`*` - 1`*
   (goto (label fib-loop))
</code></pre>
<p>afterfib-n-1                         <code>*</code>; upon return, <code>val</code> contains <code>*</code>Fib<code>*</code>(<code>*</code>n<code>*</code> - 1)`*</p>
<pre><code class="language-scheme editable">   (restore n)
   (restore continue)
   `*`;; set up to compute `*`Fib`*`(`*`n`*` - 2)`*
   (assign n (op -) (reg n) (const 2))
   (save continue)
   (assign continue (label afterfib-n-2))
   (save val)                         `*`; save `*`Fib`*`(`*`n`*` - 1)`*
   (goto (label fib-loop))
</code></pre>
<p>afterfib-n-2                         <code>*</code>; upon return, <code>val</code> contains <code>*</code>Fib<code>*</code>(<code>*</code>n<code>*</code> - 2)`*</p>
<pre><code class="language-scheme editable">   (assign n (reg val))               `*`; ``n`` now contains `*`Fib`*`(`*`n`*` - 2)`*
   (restore val)                      `*`; ``val`` now contains `*`Fib`*`(`*`n`*` - 1)`*
   (restore continue)
   (assign val                        `*`;  `*`Fib`*`(`*`n`*` - 1) +  `*`Fib`*`(`*`n`*` - 2)`*
           (op +) (reg val) (reg n)) 
   (goto (reg continue))              `*`; return to caller, answer is in ``val`*
 immediate-answer
   (assign val (reg n))               `*`; base case:  `*`Fib`*`(`*`n`*`) = `*`n`**`
   (goto (reg continue))
 fib-done)
</code></pre>
<p><strong>Figure 5.12:</strong>
Controller for a machine to compute Fibonacci numbers.</p>
<p><strong>Exercise 5.4.</strong>
Specify register machines that
implement each of the following procedures. For each machine, write a
controller instruction sequence and draw a diagram showing the data
paths.</p>
<p>a. Recursive exponentiation:</p>
<pre><code class="language-scheme editable">(define (expt b n)
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))
</code></pre>
<p>b. Iterative exponentiation:</p>
<pre><code class="language-scheme editable">(define (expt b n)
  (define (expt-iter counter product)
    (if (= counter 0)
        product
        (expt-iter (- counter 1) (* b product))))
  (expt-iter n 1))
</code></pre>
<p><strong>Exercise 5.5.</strong>
Hand-simulate the factorial and
Fibonacci machines, using some nontrivial input (requiring execution of
at least one recursive call). Show the contents of the stack at each
significant point in the execution.</p>
<p><strong>Exercise 5.6.</strong>
Ben Bitdiddle observes that the
Fibonacci machine's controller sequence has an extra <code>save</code> and an
extra <code>restore</code>, which can be removed to make a faster machine. Where
are these instructions?</p>
<h3 id="515"><a class="header" href="#515">[5.1.5</a></h3>
<p>Instruction Summary](book-Z-H-4.html#%<em>toc</em>%_sec_5.1.5)</p>
<p>A controller instruction
in our register-machine language has one of the following forms, where
each &lt;<em>input~<em>i</em>~</em>&gt; is either <code>(reg &lt;</code><em><code>register-name</code></em><code>&gt;)</code> or
<code>(const &lt;</code><em><code>constant-value</code></em><code>&gt;)</code>.</p>
<p>These instructions were introduced in
section
<a href="book-Z-H-31.html#%_sec_5.1.1">5.1.1</a>:</p>
<p><code>(assign &lt;</code><em><code>register-name</code></em><code>&gt; (reg &lt;</code><em><code>register-name</code></em><code>&gt;))</code></p>
<p><code>(assign &lt;</code><em><code>register-name</code></em><code>&gt; (const &lt;</code><em><code>constant-value</code></em><code>&gt;))</code></p>
<p><code>(assign &lt;</code><em><code>register-name</code></em><code>&gt; (op &lt;</code><em><code>operation-name</code></em><code>&gt;) &lt;</code><em><code>input</code><del><code>1</code></del></em>&gt; ... &lt;<code>*</code>input<code>~*</code>n<code>*</code>&gt;)`</p>
<p><code>(perform (op &lt;</code><em><code>operation-name</code></em><code>&gt;) &lt;</code><em><code>input</code><del><code>1</code></del></em>&gt; ... &lt;<code>*</code>input<code>~*</code>n<code>*</code>&gt;)`</p>
<p><code>(test (op &lt;</code><em><code>operation-name</code></em><code>&gt;) &lt;</code><em><code>input</code><del><code>1</code></del></em>&gt; ... &lt;<code>*</code>input<code>~*</code>n<code>*</code>&gt;)`</p>
<p><code>(branch (label &lt;</code><em><code>label-name</code></em><code>&gt;))</code></p>
<p><code>(goto (label &lt;</code><em><code>label-name</code></em><code>&gt;))</code></p>
<p>The use of registers to hold labels was introduced in
section
<a href="book-Z-H-31.html#%_sec_5.1.3">5.1.3</a>:</p>
<p><code>(assign &lt;</code><em><code>register-name</code></em><code>&gt; (label &lt;</code><em><code>label-name</code></em><code>&gt;))</code></p>
<p><code>(goto (reg &lt;</code><em><code>register-name</code></em><code>&gt;))</code></p>
<p>Instructions to use the stack were introduced in
section
<a href="book-Z-H-31.html#%_sec_5.1.4">5.1.4</a>:</p>
<p><code>(save &lt;</code><em><code>register-name</code></em><code>&gt;)</code></p>
<p><code>(restore &lt;</code><em><code>register-name</code></em><code>&gt;)</code></p>
<p>The only kind of
&lt;<em>constant-value</em>&gt; we have seen so far is a number, but later we will
use strings, symbols, and lists. For example, <code>(const "abc")</code> is the
string <code>"abc"</code>, <code>(const abc)</code> is the symbol <code>abc</code>, <code>(const (a b c))</code> is
the list <code>(a b c)</code>, and <code>(const ())</code> is the empty list.</p>
<hr />
<p>^[1]{.small}^](book-Z-H-31.html#call_footnote_Temp_715)
This assumption glosses over a great deal of complexity. Usually a large
portion of the implementation of a Lisp system is dedicated to making
reading and printing work.</p>
<p>^[2]{.small}^](book-Z-H-31.html#call_footnote_Temp_717)
One might argue that we don't need to save the old <code>n</code>; after we
decrement it and solve the subproblem, we could simply increment it to
recover the old value. Although this strategy works for factorial, it
cannot work in general, since the old value of a register cannot always
be computed from the new one.</p>
<p>^[3]{.small}^](book-Z-H-31.html#call_footnote_Temp_718)
In section
<a href="book-Z-H-33.html#%_sec_5.3">5.3</a> we will see how to
implement a stack in terms of more primitive operations.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="52--a-register-machine-simulator"><a class="header" href="#52--a-register-machine-simulator"><a href="book-Z-H-4.html#%_toc_%_sec_5.2">5.2  A Register-Machine Simulator</a></a></h2>
<p>In order to gain a good understanding of
the design of register machines, we must test the machines we design to
see if they perform as expected. One way to test a design is to
hand-simulate the operation of the controller, as in
exercise <a href="book-Z-H-31.html#%_thm_5.5">5.5</a>. But this is extremely
tedious for all but the simplest machines. In this section we construct
a simulator for machines described in the register-machine language. The
simulator is a Scheme program with four interface procedures. The first
uses a description of a register machine to construct a model of the
machine (a data structure whose parts correspond to the parts of the
machine to be simulated), and the other three allow us to simulate thev
machine by manipulating the model:</p>
<blockquote>
<pre><code class="language-scheme editable">(make-machine &lt;`*`register-names`*`&gt; &lt;`*`operations`*`&gt; &lt;`*`controller`*`&gt;)
</code></pre>
<p>constructs and returns a model of the machine with the given
registers, operations, and controller.</p>
<pre><code class="language-scheme editable">(set-register-contents! &lt;`*`machine-model`*`&gt; &lt;`*`register-name`*`&gt; &lt;`*`value`*`&gt;)
</code></pre>
<p>stores a value in a simulated register in the given machine.</p>
<pre><code class="language-scheme editable">(get-register-contents &lt;`*`machine-model`*`&gt; &lt;`*`register-name`*`&gt;)
</code></pre>
<p>returns the contents of a simulated register in the given machine.</p>
<pre><code class="language-scheme editable">(start &lt;`*`machine`*`&gt;)
</code></pre>
<p>simulates the execution of the given machine, starting from the
beginning of the controller sequence and stopping when it reaches the
end of the sequence.</p>
</blockquote>
<p>As an example of how these procedures are used, we can define
<code>gcd-machine</code> to be a model of the GCD machine of
section <a href="book-Z-H-31.html#%_sec_5.1.1">5.1.1</a> as follows:</p>
<pre><code class="language-scheme editable">(define gcd-machine
  (make-machine
   '(a b t)
   (list (list 'rem remainder) (list '= =))
   '(test-b
       (test (op =) (reg b) (const 0))
       (branch (label gcd-done))
       (assign t (op rem) (reg a) (reg b))
       (assign a (reg b))
       (assign b (reg t))
       (goto (label test-b))
     gcd-done)))
</code></pre>
<p>The first argument to <code>make-machine</code> is a list of register names. The
next argument is a table (a list of two-element lists) that pairs each
operation name with a Scheme procedure that implements the operation
(that is, produces the same output value given the same input values).
The last argument specifies the controller as a list of labels and
machine instructions, as in section <a href="book-Z-H-31.html#%_sec_5.1">5.1</a>.</p>
<p>To compute GCDs with this machine, we set the input registers, start the
machine, and examine the result when the simulation terminates:</p>
<pre><code class="language-scheme editable">(set-register-contents! gcd-machine 'a 206)
</code></pre>
<p><em><code>done</code></em></p>
<pre><code class="language-scheme editable">(set-register-contents! gcd-machine 'b 40)
</code></pre>
<p><em><code>done</code></em></p>
<pre><code class="language-scheme editable">(start gcd-machine)
</code></pre>
<p><em><code>done</code></em></p>
<pre><code class="language-scheme editable">(get-register-contents gcd-machine 'a)
</code></pre>
<p><em><code>2</code></em></p>
<p>This computation will run much more slowly than a <code>gcd</code> procedure
written in Scheme, because we will simulate low-level machine
instructions, such as <code>assign</code>, by much more complex operations.</p>
<p><strong>Exercise 5.7.</strong>  Use the simulator to test the machines
you designed in exercise <a href="book-Z-H-31.html#%_thm_5.4">5.4</a>.</p>
<h3 id="521--the-machine-model"><a class="header" href="#521--the-machine-model"><a href="book-Z-H-4.html#%_toc_%_sec_5.2.1">5.2.1  The Machine Model</a></a></h3>
<p>The machine model generated by <code>make-machine</code> is represented as a
procedure with local state using the message-passing techniques
developed in chapter 3. To build this model, <code>make-machine</code> begins by
calling the procedure <code>make-new-machine</code> to construct the parts of the
machine model that are common to all register machines. This basic
machine model constructed by <code>make-new-machine</code> is essentially a
container for some registers and a stack, together with an execution
mechanism that processes the controller instructions one by one.</p>
<p><code>Make-machine</code> then extends this basic model (by sending it messages) to
include the registers, operations, and controller of the particular
machine being defined. First it allocates a register in the new machine
for each of the supplied register names and installs the designated
operations in the machine. Then it uses an <em>assembler</em>
(described below in section <a href="book-Z-H-32.html#%_sec_5.2.2">5.2.2</a>) to
transform the controller list into instructions for the new machine and
installs these as the machine's instruction sequence. <code>Make-machine</code>
returns as its value the modified machine model.</p>
<pre><code class="language-scheme editable">(define (make-machine register-names ops controller-text)
  (let ((machine (make-new-machine)))
    (for-each (lambda (register-name)
                ((machine 'allocate-register) register-name))
              register-names)
    ((machine 'install-operations) ops)    
    ((machine 'install-instruction-sequence)
     (assemble controller-text machine))
    machine))
</code></pre>
<h4 id="registers"><a class="header" href="#registers"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_724">Registers</a></a></h4>
<p>We will represent a register as a procedure with local
state, as in chapter 3. The procedure <code>make-register</code> creates a register
that holds a value that can be accessed or changed:</p>
<pre><code class="language-scheme editable">(define (make-register name)
  (let ((contents '*unassigned*))
    (define (dispatch message)
      (cond ((eq? message 'get) contents)
            ((eq? message 'set)
             (lambda (value) (set! contents value)))
            (else
             (error "Unknown request -- REGISTER" message))))
    dispatch))
</code></pre>
<p>The following procedures are used to access registers:</p>
<pre><code class="language-scheme editable">(define (get-contents register)
  (register 'get))
</code></pre>
<pre><code class="language-scheme editable">(define (set-contents! register value)
  ((register 'set) value))
</code></pre>
<h4 id="the-stack"><a class="header" href="#the-stack"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_725">The stack</a></a></h4>
<p>We can also represent a stack as a procedure with local
state. The procedure <code>make-stack</code> creates a stack whose local state
consists of a list of the items on the stack. A stack accepts requests
to <code>push</code> an item onto the stack, to <code>pop</code> the top item off the stack
and return it, and to <code>initialize</code> the stack to empty.</p>
<pre><code class="language-scheme editable">(define (make-stack)
  (let ((s '()))
    (define (push x)
      (set! s (cons x s)))
    (define (pop)
      (if (null? s)
          (error "Empty stack -- POP")
          (let ((top (car s)))
            (set! s (cdr s))
            top)))
    (define (initialize)
      (set! s '())
      'done)
    (define (dispatch message)
      (cond ((eq? message 'push) push)
            ((eq? message 'pop) (pop))
            ((eq? message 'initialize) (initialize))
            (else (error "Unknown request -- STACK"
                         message))))
    dispatch))
</code></pre>
<p>The following procedures are used to access stacks:</p>
<pre><code class="language-scheme editable">(define (pop stack)
  (stack 'pop))
</code></pre>
<pre><code class="language-scheme editable">(define (push stack value)
  ((stack 'push) value))
</code></pre>
<h4 id="the-basic-machine"><a class="header" href="#the-basic-machine"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_726">The basic machine</a></a></h4>
<p>The <code>make-new-machine</code> procedure, shown in
figure <a href="book-Z-H-32.html#%_fig_5.13">5.13</a>, constructs an object whose
local state consists of a stack, an initially empty instruction
sequence, a list of operations that initially contains an operation to
initialize the stack, and a <em>register
table</em> that initially contains two
registers, named <code>flag</code> and <code>pc</code>
(for ``program counter''). The internal procedure
<code>allocate-register</code> adds new entries to the register table, and the
internal procedure <code>lookup-register</code> looks up registers in the table.</p>
<p>The <code>flag</code> register is used to control branching in the simulated
machine. <code>Test</code> instructions set the contents of <code>flag</code> to the result of
the test (true or false). <code>Branch</code> instructions decide whether or not to
branch by examining the contents of <code>flag</code>.</p>
<p>The <code>pc</code> register determines the sequencing of instructions as the
machine runs. This sequencing is implemented by the internal procedure
<code>execute</code>. In the simulation model, each machine instruction is a data
structure that includes a procedure of no arguments, called the
<em>instruction execution procedure</em>, such
that calling this procedure simulates executing the instruction. As the
simulation runs, <code>pc</code> points to the place in the instruction sequence
beginning with the next instruction to be executed.
<code>Execute</code> gets that instruction, executes it by calling
the instruction execution procedure, and repeats this cycle until there
are no more instructions to execute (i.e., until <code>pc</code> points to the end
of the instruction sequence).</p>
<pre><code class="language-scheme editable">(define (make-new-machine)
  (let ((pc (make-register 'pc))
        (flag (make-register 'flag))
        (stack (make-stack))
        (the-instruction-sequence '()))
    (let ((the-ops
           (list (list 'initialize-stack
                       (lambda () (stack 'initialize)))))
          (register-table
           (list (list 'pc pc) (list 'flag flag))))
      (define (allocate-register name)
        (if (assoc name register-table)
            (error "Multiply defined register: " name)
            (set! register-table
                  (cons (list name (make-register name))
                        register-table))))
        'register-allocated)
      (define (lookup-register name)
        (let ((val (assoc name register-table)))
          (if val
              (cadr val)
              (error "Unknown register:" name))))
      (define (execute)
        (let ((insts (get-contents pc)))
          (if (null? insts)
              'done
              (begin
                ((instruction-execution-proc (car insts)))
                (execute)))))
      (define (dispatch message)
        (cond ((eq? message 'start)
               (set-contents! pc the-instruction-sequence)
               (execute))
              ((eq? message 'install-instruction-sequence)
               (lambda (seq) (set! the-instruction-sequence seq)))
              ((eq? message 'allocate-register) allocate-register)
              ((eq? message 'get-register) lookup-register)
              ((eq? message 'install-operations)
               (lambda (ops) (set! the-ops (append the-ops ops))))
              ((eq? message 'stack) stack)
              ((eq? message 'operations) the-ops)
              (else (error "Unknown request -- MACHINE" message))))
      dispatch)))
</code></pre>
<p><strong>Figure 5.13:</strong>  The <code>make-new-machine</code> procedure, which implements the
basic machine model.</p>
<p>As part of its operation, each instruction execution procedure modifies
<code>pc</code> to indicate the next instruction to be executed. <code>Branch</code> and
<code>goto</code> instructions change <code>pc</code> to point to the new destination. All
other instructions simply advance <code>pc</code>, making it point to the next
instruction in the sequence. Observe that each call to <code>execute</code> calls
<code>execute</code> again, but this does not produce an infinite loop because
running the instruction execution procedure changes the contents of
<code>pc</code>.</p>
<p><code>Make-new-machine</code> returns a <code>dispatch</code> procedure that implements
message-passing access to the internal state. Notice that starting the
machine is accomplished by setting <code>pc</code> to the beginning of the
instruction sequence and calling <code>execute</code>.</p>
<p>For convenience, we provide an alternate procedural interface to a
machine's <code>start</code> operation, as well as procedures to set and examine
register contents, as specified at the beginning of
section <a href="book-Z-H-32.html#%_sec_5.2">5.2</a>:</p>
<pre><code class="language-scheme editable">(define (start machine)
  (machine 'start))
</code></pre>
<pre><code class="language-scheme editable">(define (get-register-contents machine register-name)
  (get-contents (get-register machine register-name)))
</code></pre>
<pre><code class="language-scheme editable">(define (set-register-contents! machine register-name value)
  (set-contents! (get-register machine register-name) value)
  'done)
</code></pre>
<p>These procedures (and many procedures in
sections <a href="book-Z-H-32.html#%_sec_5.2.2">5.2.2</a> and
<a href="book-Z-H-32.html#%_sec_5.2.3">5.2.3</a>) use the following to look up the
register with a given name in a given machine:</p>
<pre><code class="language-scheme editable">(define (get-register machine reg-name)
  ((machine 'get-register) reg-name))
</code></pre>
<h3 id="522--the-assembler"><a class="header" href="#522--the-assembler"><a href="book-Z-H-4.html#%_toc_%_sec_5.2.2">5.2.2  The Assembler</a></a></h3>
<p>The assembler transforms the sequence of controller
expressions for a machine into a corresponding list of machine
instructions, each with its execution procedure. Overall, the assembler
is much like the evaluators we studied in chapter 4 -- there is an
input language (in this case, the register-machine language) and we must
perform an appropriate action for each type of expression in the
language.</p>
<p>The technique of producing an execution procedure for
each instruction is just what we used in
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a> to speed up the evaluator
by separating analysis from runtime execution. As we saw in chapter 4,
much useful analysis of Scheme expressions could be performed without
knowing the actual values of variables. Here, analogously, much useful
analysis of register-machine-language expressions can be performed
without knowing the actual contents of machine registers. For example,
we can replace references to registers by pointers to the register
objects, and we can replace references to labels by pointers to the
place in the instruction sequence that the label designates.</p>
<p>Before it can generate the instruction execution procedures, the
assembler must know what all the labels refer to, so it begins by
scanning the controller text to separate the labels from the
instructions. As it scans the text, it constructs both a list of
instructions and a table that associates each label with a pointer into
that list. Then the assembler augments the instruction list by inserting
the execution procedure for each instruction.</p>
<p>The <code>assemble</code> procedure is the main entry to the assembler. It takes
the controller text and the machine model as arguments and returns the
instruction sequence to be stored in the model. <code>Assemble</code> calls
<code>extract-labels</code> to build the initial instruction list and label table
from the supplied controller text. The second argument to
<code>extract-labels</code> is a procedure to be called to process these results:
This procedure uses <code>update-insts!</code> to generate the instruction
execution procedures and insert them into the instruction list, and
returns the modified list.</p>
<pre><code class="language-scheme editable">(define (assemble controller-text machine)
  (extract-labels controller-text
    (lambda (insts labels)
      (update-insts! insts labels machine)
      insts)))
</code></pre>
<p><code>Extract-labels</code> takes as arguments a list <code>text</code> (the sequence of
controller instruction expressions) and a <code>receive</code> procedure. <code>Receive</code>
will be called with two values: (1) a list <code>insts</code> of instruction data
structures, each containing an instruction from <code>text</code>; and (2) a table
called <code>labels</code>, which associates each label from <code>text</code> with the
position in the list <code>insts</code> that the label designates.</p>
<pre><code class="language-scheme editable">(define (extract-labels text receive)
  (if (null? text)
      (receive '() '())
      (extract-labels (cdr text)
        (lambda (insts labels)
          (let ((next-inst (car text)))
            (if (symbol? next-inst)
                (receive insts
                         (cons (make-label-entry next-inst
                                                 insts)
                               labels))
                (receive (cons (make-instruction next-inst)
                               insts)
                         labels))))))
</code></pre>
<p><code>Extract-labels</code> works by sequentially scanning the elements of the
<code>text</code> and accumulating the <code>insts</code> and the <code>labels</code>. If an element is a
symbol (and thus a label) an appropriate entry is added to the <code>labels</code>
table. Otherwise the element is accumulated onto the <code>insts</code>
list.<a href="book-Z-H-32.html#footnote_Temp_727">^[4]{.small}^</a></p>
<p><code>Update-insts!</code> modifies the instruction list, which initially contains
only the text of the instructions, to include the corresponding
execution procedures:</p>
<pre><code class="language-scheme editable">(define (update-insts! insts labels machine)
  (let ((pc (get-register machine 'pc))
        (flag (get-register machine 'flag))
        (stack (machine 'stack))
        (ops (machine 'operations)))
    (for-each
     (lambda (inst)
       (set-instruction-execution-proc! 
        inst
        (make-execution-procedure
         (instruction-text inst) labels machine
         pc flag stack ops)))
     insts)))
</code></pre>
<p>The machine instruction data structure simply pairs the instruction text
with the corresponding execution procedure. The execution procedure is
not yet available when <code>extract-labels</code> constructs the instruction, and
is inserted later by <code>update-insts!</code>.</p>
<pre><code class="language-scheme editable">(define (make-instruction text)
  (cons text '()))
</code></pre>
<pre><code class="language-scheme editable">(define (instruction-text inst)
  (car inst))
</code></pre>
<pre><code class="language-scheme editable">(define (instruction-execution-proc inst)
  (cdr inst))
</code></pre>
<pre><code class="language-scheme editable">(define (set-instruction-execution-proc! inst proc)
  (set-cdr! inst proc))
</code></pre>
<p>The instruction text is not used by our simulator, but it is handy to
keep around for debugging (see
exercise <a href="book-Z-H-32.html#%_thm_5.16">5.16</a>).</p>
<p>Elements of the label table are pairs:</p>
<pre><code class="language-scheme editable">(define (make-label-entry label-name insts)
  (cons label-name insts))
</code></pre>
<p>Entries will be looked up in the table with</p>
<pre><code class="language-scheme editable">(define (lookup-label labels label-name)
  (let ((val (assoc label-name labels)))
    (if val
        (cdr val)
        (error "Undefined label -- ASSEMBLE" label-name))))
</code></pre>
<p><strong>Exercise 5.8.</strong>  The following register-machine code is
ambiguous, because the label <code>here</code> is defined more than once:</p>
<pre><code class="language-scheme editable">start
  (goto (label here))
here
  (assign a (const 3))
  (goto (label there))
here
  (assign a (const 4))
  (goto (label there))
there
</code></pre>
<p>With the simulator as written, what will the contents of register <code>a</code> be
when control reaches <code>there</code>? Modify the <code>extract-labels</code> procedure so
that the assembler will signal an error if the same label name is used
to indicate two different locations.</p>
<h3 id="523--generating-execution-procedures-for-instructions"><a class="header" href="#523--generating-execution-procedures-for-instructions"><a href="book-Z-H-4.html#%_toc_%_sec_5.2.3">5.2.3  Generating Execution Procedures for Instructions</a></a></h3>
<p>The assembler calls <code>make-execution-procedure</code> to
generate the execution procedure for an instruction. Like the <code>analyze</code>
procedure in the evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>, this dispatches on the
type of instruction to generate the appropriate execution procedure.</p>
<pre><code class="language-scheme editable">(define (make-execution-procedure inst labels machine
                                  pc flag stack ops)
  (cond ((eq? (car inst) 'assign)
         (make-assign inst machine labels ops pc))
        ((eq? (car inst) 'test)
         (make-test inst machine labels ops flag pc))
        ((eq? (car inst) 'branch)
         (make-branch inst machine labels flag pc))
        ((eq? (car inst) 'goto)
         (make-goto inst machine labels pc))
        ((eq? (car inst) 'save)
         (make-save inst machine stack pc))
        ((eq? (car inst) 'restore)
         (make-restore inst machine stack pc))
        ((eq? (car inst) 'perform)
         (make-perform inst machine labels ops pc))
        (else (error "Unknown instruction type -- ASSEMBLE"
                     inst))))
</code></pre>
<p>For each type of instruction in the register-machine language, there is
a generator that builds an appropriate execution procedure. The details
of these procedures determine both the syntax and meaning of the
individual instructions in the register-machine language. We use data
abstraction to isolate the detailed syntax of register-machine
expressions from the general execution mechanism, as we did for
evaluators in section <a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a>, by using
syntax procedures to extract and classify the parts of an instruction.</p>
<h4 id="assign-instructions"><a class="header" href="#assign-instructions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_729"><code>Assign</code> instructions</a></a></h4>
<p>The <code>make-assign</code> procedure handles <code>assign</code>
instructions:</p>
<pre><code class="language-scheme editable">(define (make-assign inst machine labels operations pc)
  (let ((target
         (get-register machine (assign-reg-name inst)))
        (value-exp (assign-value-exp inst)))
    (let ((value-proc
           (if (operation-exp? value-exp)
               (make-operation-exp
                value-exp machine labels operations)
               (make-primitive-exp
                (car value-exp) machine labels))))
      (lambda ()         ; execution procedure for ``assign`
        (set-contents! target (value-proc))
        (advance-pc pc)))))
</code></pre>
<p><code>Make-assign</code> extracts the target register name (the second element of
the instruction) and the value expression (the rest of the list that
forms the instruction) from the <code>assign</code> instruction using the selectors</p>
<pre><code class="language-scheme editable">(define (assign-reg-name assign-instruction)
  (cadr assign-instruction))
</code></pre>
<pre><code class="language-scheme editable">(define (assign-value-exp assign-instruction)
  (cddr assign-instruction))
</code></pre>
<p>The register name is looked up with <code>get-register</code> to produce the target
register object. The value expression is passed to <code>make-operation-exp</code>
if the value is the result of an operation, and to <code>make-primitive-exp</code>
otherwise. These procedures (shown below) parse the value expression and
produce an execution procedure for the value. This is a procedure of no
arguments, called <code>value-proc</code>, which will be evaluated
during the simulation to produce the actual value to be assigned to the
register. Notice that the work of looking up the register name and
parsing the value expression is performed just once, at assembly time,
not every time the instruction is simulated. This saving of work is the
reason we use execution procedures, and corresponds
directly to the saving in work we obtained by separating program
analysis from execution in the evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>.</p>
<p>The result returned by <code>make-assign</code> is the execution procedure for the
<code>assign</code> instruction. When this procedure is called (by the machine
model's <code>execute</code> procedure), it sets the contents of the target
register to the result obtained by executing <code>value-proc</code>. Then it
advances the <code>pc</code> to the next instruction by running the procedure</p>
<pre><code class="language-scheme editable">(define (advance-pc pc)
  (set-contents! pc (cdr (get-contents pc))))
</code></pre>
<p><code>Advance-pc</code> is the normal termination for all instructions except
<code>branch</code> and <code>goto</code>.</p>
<h4 id="test-branch-and-goto-instructions"><a class="header" href="#test-branch-and-goto-instructions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_730"><code>Test</code>, <code>branch</code>, and <code>goto</code> instructions</a></a></h4>
<p><code>Make-test</code> handles <code>test</code> instructions in a similar way.
It extracts the expression that specifies the condition to be tested and
generates an execution procedure for it. At simulation time, the
procedure for the condition is called, the result is assigned to the
<code>flag</code> register, and the <code>pc</code> is advanced:</p>
<pre><code class="language-scheme editable">(define (make-test inst machine labels operations flag pc)
  (let ((condition (test-condition inst)))
    (if (operation-exp? condition)
        (let ((condition-proc
               (make-operation-exp
                condition machine labels operations)))
          (lambda ()
            (set-contents! flag (condition-proc))
            (advance-pc pc)))
        (error "Bad TEST instruction -- ASSEMBLE" inst))))
</code></pre>
<pre><code class="language-scheme editable">(define (test-condition test-instruction)
  (cdr test-instruction))
</code></pre>
<p>The execution procedure for a <code>branch</code> instruction checks
the contents of the <code>flag</code> register and either sets the contents of the
<code>pc</code> to the branch destination (if the branch is taken) or else just
advances the <code>pc</code> (if the branch is not taken). Notice that the
indicated destination in a <code>branch</code> instruction must be a label, and the
<code>make-branch</code> procedure enforces this. Notice also that the label is
looked up at assembly time, not each time the <code>branch</code> instruction is
simulated.</p>
<pre><code class="language-scheme editable">(define (make-branch inst machine labels flag pc)
  (let ((dest (branch-dest inst)))
    (if (label-exp? dest)
        (let ((insts
               (lookup-label labels (label-exp-label dest))))
          (lambda ()
            (if (get-contents flag)
                (set-contents! pc insts)
                (advance-pc pc))))
        (error "Bad BRANCH instruction -- ASSEMBLE" inst))))
</code></pre>
<pre><code class="language-scheme editable">(define (branch-dest branch-instruction)
  (cadr branch-instruction))
</code></pre>
<p>A <code>goto</code> instruction is similar to a branch, except that
the destination may be specified either as a label or as a register, and
there is no condition to check -- the <code>pc</code> is always set to the new
destination.</p>
<pre><code class="language-scheme editable">(define (make-goto inst machine labels pc)
  (let ((dest (goto-dest inst)))
    (cond ((label-exp? dest)
           (let ((insts
                  (lookup-label labels
                                (label-exp-label dest))))
             (lambda () (set-contents! pc insts))))
          ((register-exp? dest)
           (let ((reg
                  (get-register machine
                                (register-exp-reg dest))))
             (lambda ()
               (set-contents! pc (get-contents reg)))))
          (else (error "Bad GOTO instruction -- ASSEMBLE"
                       inst)))))
</code></pre>
<pre><code class="language-scheme editable">(define (goto-dest goto-instruction)
  (cadr goto-instruction))
</code></pre>
<h4 id="other-instructions"><a class="header" href="#other-instructions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_731">Other instructions</a></a></h4>
<p>The stack instructions <code>save</code> and <code>restore</code> simply use the stack with
the designated register and advance the <code>pc</code>:</p>
<pre><code class="language-scheme editable">(define (make-save inst machine stack pc)
  (let ((reg (get-register machine
                         (stack-inst-reg-name inst))))
    (lambda ()
      (push stack (get-contents reg))
      (advance-pc pc))))
</code></pre>
<pre><code class="language-scheme editable">(define (make-restore inst machine stack pc)
  (let ((reg (get-register machine
                         (stack-inst-reg-name inst))))
    (lambda ()
      (set-contents! reg (pop stack))    
      (advance-pc pc))))
</code></pre>
<pre><code class="language-scheme editable">(define (stack-inst-reg-name stack-instruction)
  (cadr stack-instruction))
</code></pre>
<p>The final instruction type, handled by <code>make-perform</code>,
generates an execution procedure for the action to be performed. At
simulation time, the action procedure is executed and the <code>pc</code> advanced.</p>
<pre><code class="language-scheme editable">(define (make-perform inst machine labels operations pc)
  (let ((action (perform-action inst)))
    (if (operation-exp? action)
        (let ((action-proc
               (make-operation-exp
                action machine labels operations)))
          (lambda ()
            (action-proc)
            (advance-pc pc)))
        (error "Bad PERFORM instruction -- ASSEMBLE" inst))))
</code></pre>
<pre><code class="language-scheme editable">(define (perform-action inst) (cdr inst))
</code></pre>
<h4 id="execution-procedures-for-subexpressions"><a class="header" href="#execution-procedures-for-subexpressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_732">Execution procedures for subexpressions</a></a></h4>
<p>The value of a <code>reg</code>,
<code>label</code>, or <code>const</code> expression may be needed for assignment to a
register (<code>make-assign</code>) or for input to an operation
(<code>make-operation-exp</code>, below). The following procedure generates
execution procedures to produce values for these expressions during the
simulation:</p>
<pre><code class="language-scheme editable">(define (make-primitive-exp exp machine labels)
  (cond ((constant-exp? exp)
         (let ((c (constant-exp-value exp)))
           (lambda () c)))
        ((label-exp? exp)
         (let ((insts
                (lookup-label labels
                              (label-exp-label exp))))
           (lambda () insts)))
        ((register-exp? exp)
         (let ((r (get-register machine
                              (register-exp-reg exp))))
           (lambda () (get-contents r))))
        (else
         (error "Unknown expression type -- ASSEMBLE" exp))))
</code></pre>
<p>The syntax of <code>reg</code>, <code>label</code>, and <code>const</code> expressions is determined by</p>
<pre><code class="language-scheme editable">(define (register-exp? exp) (tagged-list? exp 'reg))
</code></pre>
<pre><code class="language-scheme editable">(define (register-exp-reg exp) (cadr exp))
</code></pre>
<pre><code class="language-scheme editable">(define (constant-exp? exp) (tagged-list? exp 'const))
</code></pre>
<pre><code class="language-scheme editable">(define (constant-exp-value exp) (cadr exp))
</code></pre>
<pre><code class="language-scheme editable">(define (label-exp? exp) (tagged-list? exp 'label))
</code></pre>
<pre><code class="language-scheme editable">(define (label-exp-label exp) (cadr exp))
</code></pre>
<p><code>Assign</code>, <code>perform</code>, and <code>test</code> instructions may include
the application of a machine operation (specified by an <code>op</code> expression)
to some operands (specified by <code>reg</code> and <code>const</code> expressions). The
following procedure produces an execution procedure for an ``operation
expression'' -- a list containing the operation and operand
expressions from the instruction:</p>
<pre><code class="language-scheme editable">(define (make-operation-exp exp machine labels operations)
  (let ((op (lookup-prim (operation-exp-op exp) operations))
        (aprocs
         (map (lambda (e)
                (make-primitive-exp e machine labels))
              (operation-exp-operands exp))))
    (lambda ()
      (apply op (map (lambda (p) (p)) aprocs)))))
</code></pre>
<p>The syntax of operation expressions is determined by</p>
<pre><code class="language-scheme editable">(define (operation-exp? exp)
  (and (pair? exp) (tagged-list? (car exp) 'op)))
</code></pre>
<pre><code class="language-scheme editable">(define (operation-exp-op operation-exp)
  (cadr (car operation-exp)))
</code></pre>
<pre><code class="language-scheme editable">(define (operation-exp-operands operation-exp)
  (cdr operation-exp))
</code></pre>
<p>Observe that the treatment of operation expressions is very much like
the treatment of procedure applications by the <code>analyze-application</code>
procedure in the evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a> in that we generate an
execution procedure for each operand. At simulation time, we call the
operand procedures and apply the Scheme procedure that simulates the
operation to the resulting values. The simulation procedure is found by
looking up the operation name in the operation table for the machine:</p>
<pre><code class="language-scheme editable">(define (lookup-prim symbol operations)
  (let ((val (assoc symbol operations)))
    (if val
        (cadr val)
        (error "Unknown operation -- ASSEMBLE" symbol))))
</code></pre>
<p><strong>Exercise 5.9.</strong>  The treatment of machine operations
above permits them to operate on labels as well as on constants and the
contents of registers. Modify the expression-processing procedures to
enforce the condition that operations can be used only with registers
and constants.</p>
<p><strong>Exercise 5.10.</strong>  Design a new syntax for
register-machine instructions and modify the simulator to use your new
syntax. Can you implement your new syntax without changing any part of
the simulator except the syntax procedures in this section?</p>
<p><strong>Exercise 5.11.</strong>  When
we introduced <code>save</code> and <code>restore</code> in
section <a href="book-Z-H-31.html#%_sec_5.1.4">5.1.4</a>, we didn't specify what
would happen if you tried to restore a register that was not the last
one saved, as in the sequence</p>
<pre><code class="language-scheme editable">(save y)
(save x)
(restore y)
</code></pre>
<p>There are several reasonable possibilities for the meaning of <code>restore</code>:</p>
<p>a.  <code>(restore y)</code> puts into <code>y</code> the last value saved on the stack,
regardless of what register that value came from. This is the way our
simulator behaves. Show how to take advantage of this behavior to
eliminate one instruction from the Fibonacci machine of
section <a href="book-Z-H-31.html#%_sec_5.1.4">5.1.4</a>
(figure <a href="book-Z-H-31.html#%_fig_5.12">5.12</a>).</p>
<p>b.  <code>(restore y)</code> puts into <code>y</code> the last value saved on the stack, but
only if that value was saved from <code>y</code>; otherwise, it signals an error.
Modify the simulator to behave this way. You will have to change <code>save</code>
to put the register name on the stack along with the value.</p>
<p>c.  <code>(restore y)</code> puts into <code>y</code> the last value saved from <code>y</code> regardless
of what other registers were saved after <code>y</code> and not restored. Modify
the simulator to behave this way. You will have to associate a separate
stack with each register. You should make the <code>initialize-stack</code>
operation initialize all the register stacks.</p>
<p><strong>Exercise 5.12.</strong>  The simulator can be used to help
determine the data paths required for implementing a machine with a
given controller. Extend the assembler to store the following
information in the machine model:</p>
<ul>
<li>a list of all instructions, with duplicates removed, sorted by
instruction type (<code>assign</code>, <code>goto</code>, and so on);</li>
<li>a list (without duplicates) of the registers used to hold entry points
(these are the registers referenced by <code>goto</code> instructions);</li>
<li>a list (without duplicates) of the registers that are <code>save</code>d or
<code>restore</code>d;</li>
<li>for each register, a list (without duplicates) of the sources from
which it is assigned (for example, the sources for register <code>val</code> in
the factorial machine of figure <a href="book-Z-H-31.html#%_fig_5.11">5.11</a>
are <code>(const 1)</code> and <code>((op *) (reg n) (reg val))</code>).</li>
</ul>
<p>Extend the message-passing interface to the machine to provide access to
this new information. To test your analyzer, define the Fibonacci
machine from figure <a href="book-Z-H-31.html#%_fig_5.12">5.12</a> and examine the
lists you constructed.</p>
<p><strong>Exercise 5.13.</strong>  Modify the simulator so that it uses
the controller sequence to determine what registers the machine has
rather than requiring a list of registers as an argument to
<code>make-machine</code>. Instead of pre-allocating the registers in
<code>make-machine</code>, you can allocate them one at a time when they are first
seen during assembly of the instructions.</p>
<h3 id="524--monitoring-machine-performance"><a class="header" href="#524--monitoring-machine-performance"><a href="book-Z-H-4.html#%_toc_%_sec_5.2.4">5.2.4  Monitoring Machine Performance</a></a></h3>
<p>Simulation is useful not only for
verifying the correctness of a proposed machine design but also for
measuring the machine's performance. For example, we can install in our
simulation program a ``meter'' that measures the number of stack
operations used in a computation. To do this, we modify our simulated
stack to keep track of the number of times registers are saved on the
stack and the maximum depth reached by the stack, and add a message to
the stack's interface that prints the statistics, as shown below. We
also add an operation to the basic machine model to print the stack
statistics, by initializing <code>the-ops</code> in <code>make-new-machine</code> to</p>
<pre><code class="language-scheme editable">(list (list 'initialize-stack
            (lambda () (stack 'initialize)))
      (list 'print-stack-statistics
            (lambda () (stack 'print-statistics))))
</code></pre>
<p>Here is the new version of <code>make-stack</code>:</p>
<pre><code class="language-scheme editable">(define (make-stack)
  (let ((s '())
        (number-pushes 0)
        (max-depth 0)
        (current-depth 0))
    (define (push x)
      (set! s (cons x s))
      (set! number-pushes (+ 1 number-pushes))
      (set! current-depth (+ 1 current-depth))
      (set! max-depth (max current-depth max-depth)))
    (define (pop)
      (if (null? s)
          (error "Empty stack -- POP")
          (let ((top (car s)))
            (set! s (cdr s))
            (set! current-depth (- current-depth 1))
            top)))    
    (define (initialize)
      (set! s '())
      (set! number-pushes 0)
      (set! max-depth 0)
      (set! current-depth 0)
      'done)
    (define (print-statistics)
      (newline)
      (display (list 'total-pushes  '= number-pushes
                     'maximum-depth '= max-depth)))
    (define (dispatch message)
      (cond ((eq? message 'push) push)
            ((eq? message 'pop) (pop))
            ((eq? message 'initialize) (initialize))
            ((eq? message 'print-statistics)
             (print-statistics))
            (else
             (error "Unknown request -- STACK" message))))
    dispatch))
</code></pre>
<p>Exercises <a href="book-Z-H-32.html#%_thm_5.15">5.15</a>
through <a href="book-Z-H-32.html#%_thm_5.19">5.19</a> describe other useful
monitoring and debugging features that can be added to the
register-machine simulator.</p>
<p><strong>Exercise 5.14.</strong>  Measure the number of
pushes and the maximum stack depth required to compute <em>n</em>! for various
small values of <em>n</em> using the factorial machine shown in
figure <a href="book-Z-H-31.html#%_fig_5.11">5.11</a>. From your data determine
formulas in terms of <em>n</em> for the total number of push operations and the
maximum stack depth used in computing <em>n</em>! for any <em>n</em> &gt; 1. Note that
each of these is a linear function of <em>n</em> and is thus determined by two
constants. In order to get the statistics printed, you will have to
augment the factorial machine with instructions to initialize the stack
and print the statistics. You may want to also modify the machine so
that it repeatedly reads a value for <em>n</em>, computes the factorial, and
prints the result (as we did for the GCD machine in
figure <a href="book-Z-H-31.html#%_fig_5.4">5.4</a>), so that you will not have to
repeatedly invoke <code>get-register-contents</code>, <code>set-register-contents!</code>, and
<code>start</code>.</p>
<p><strong>Exercise 5.15.</strong>  Add <em>instruction
counting</em> to the register machine simulation. That is, have the machine
model keep track of the number of instructions executed. Extend the
machine model's interface to accept a new message that prints the value
of the instruction count and resets the count to zero.</p>
<p><strong>Exercise 5.16.</strong>  Augment the simulator to provide for
<em>instruction tracing</em>. That is, before
each instruction is executed, the simulator should print the text of the
instruction. Make the machine model accept <code>trace-on</code> and <code>trace-off</code>
messages to turn tracing on and off.</p>
<p><strong>Exercise 5.17.</strong>  Extend the instruction tracing of
exercise <a href="book-Z-H-32.html#%_thm_5.16">5.16</a> so that before printing an
instruction, the simulator prints any labels that immediately precede
that instruction in the controller sequence. Be careful to do this in a
way that does not interfere with instruction counting
(exercise <a href="book-Z-H-32.html#%_thm_5.15">5.15</a>). You will have to make
the simulator retain the necessary label information.</p>
<p><strong>Exercise 5.18.</strong>  Modify
the <code>make-register</code> procedure of
section <a href="book-Z-H-32.html#%_sec_5.2.1">5.2.1</a> so that registers can be
traced. Registers should accept messages that turn tracing on and off.
When a register is traced, assigning a value to the register should
print the name of the register, the old contents of the register, and
the new contents being assigned. Extend the interface to the machine
model to permit you to turn tracing on and off for designated machine
registers.</p>
<p><strong>Exercise 5.19.</strong>  Alyssa P. Hacker wants a
<em>breakpoint</em> feature in the simulator to help her debug
her machine designs. You have been hired to install this feature for
her. She wants to be able to specify a place in the controller sequence
where the simulator will stop and allow her to examine the state of the
machine. You are to implement a procedure</p>
<pre><code class="language-scheme editable">(set-breakpoint &lt;`*`machine`*`&gt; &lt;`*`label`*`&gt; &lt;`*`n`*`&gt;)
</code></pre>
<p>that sets a breakpoint just before the <em>n</em>th instruction after the given
label. For example,</p>
<pre><code class="language-scheme editable">(set-breakpoint gcd-machine 'test-b 4)
</code></pre>
<p>installs a breakpoint in <code>gcd-machine</code> just before the assignment to
register <code>a</code>. When the simulator reaches the breakpoint it should print
the label and the offset of the breakpoint and stop executing
instructions. Alyssa can then use <code>get-register-contents</code> and
<code>set-register-contents!</code> to manipulate the state of the simulated
machine. She should then be able to continue execution by saying</p>
<pre><code class="language-scheme editable">(proceed-machine &lt;`*`machine`*`&gt;)
</code></pre>
<p>She should also be able to remove a specific breakpoint by means of</p>
<pre><code class="language-scheme editable">(cancel-breakpoint &lt;`*`machine`*`&gt; &lt;`*`label`*`&gt; &lt;`*`n`*`&gt;)
</code></pre>
<p>or to remove all breakpoints by means of</p>
<pre><code class="language-scheme editable">(cancel-all-breakpoints &lt;`*`machine`*`&gt;)
</code></pre>
<hr />
<p>^[4]{.small}^](book-Z-H-32.html#call_footnote_Temp_727)
Using the <code>receive</code> procedure here is a way to get
<code>extract-labels</code> to effectively return two values -- <code>labels</code> and
<code>insts</code> -- without explicitly making a compound data structure to hold
them. An alternative implementation, which returns an explicit pair of
values, is</p>
<pre><code class="language-scheme editable">(define (extract-labels text)
  (if (null? text)
      (cons '() '())
      (let ((result (extract-labels (cdr text))))
        (let ((insts (car result)) (labels (cdr result)))
          (let ((next-inst (car text)))
            (if (symbol? next-inst)
                (cons insts
                      (cons (make-label-entry next-inst insts) labels))
                (cons (cons (make-instruction next-inst) insts)
                      labels))))))
</code></pre>
<p>which would be called by <code>assemble</code> as follows:</p>
<pre><code class="language-scheme editable">(define (assemble controller-text machine)
  (let ((result (extract-labels controller-text)))
    (let ((insts (car result)) (labels (cdr result)))
      (update-insts! insts labels machine)
      insts)))
</code></pre>
<p>You can consider our use of
<code>receive</code> as demonstrating an elegant way to return multiple values, or
simply an excuse to show off a programming trick. An argument like
<code>receive</code> that is the next procedure to be invoked is called a
``continuation.'' Recall that we also used continuations to
implement the backtracking control structure in the <code>amb</code> evaluator in
section <a href="book-Z-H-28.html#%_sec_4.3.3">4.3.3</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="53--storage-allocation-and-garbage-collection"><a class="header" href="#53--storage-allocation-and-garbage-collection"><a href="book-Z-H-4.html#%_toc_%_sec_5.3">5.3  Storage Allocation and Garbage Collection</a></a></h2>
<p>In
section <a href="book-Z-H-34.html#%_sec_5.4">5.4</a>, we will show how to implement
a Scheme evaluator as a register machine. In order to simplify the
discussion, we will assume that our register machines can be equipped
with a <em>list-structured memory</em>, in which the basic operations for
manipulating list-structured data are primitive. Postulating the
existence of such a memory is a useful abstraction when one is focusing
on the mechanisms of control in a Scheme interpreter, but this does not
reflect a realistic view of the actual primitive data operations of
contemporary computers. To obtain a more complete picture of how a Lisp
system operates, we must investigate how list structure can be
represented in a way that is compatible with conventional computer
memories.</p>
<p>There are two considerations in implementing list structure. The first
is purely an issue of representation: how to represent the
'box-and-pointer' structure of Lisp pairs, using only the storage
and addressing capabilities of typical computer memories. The second
issue concerns the management of memory as a computation proceeds. The
operation of a Lisp system depends crucially on the ability to
continually create new data objects. These include objects that are
explicitly created by the Lisp procedures being interpreted as well as
structures created by the interpreter itself, such as environments and
argument lists. Although the constant creation of new data objects would
pose no problem on a computer with an infinite amount of rapidly
addressable memory, computer memories are available only in finite sizes
(more's the pity). Lisp systems thus provide an
<em>automatic storage allocation</em> facility to support the
illusion of an infinite memory. When a data object is no longer needed,
the memory allocated to it is automatically recycled and used to
construct new data objects. There are various techniques for providing
such automatic storage allocation. The method we shall discuss in this
section is called <em>garbage collection</em>.</p>
<h3 id="531--memory-as-vectors"><a class="header" href="#531--memory-as-vectors"><a href="book-Z-H-4.html#%_toc_%_sec_5.3.1">5.3.1  Memory as Vectors</a></a></h3>
<p>A conventional computer memory can be thought of as an array of
cubbyholes, each of which can contain a piece of information. Each
cubbyhole has a unique name, called its <em>address</em> or
<em>location</em>. Typical memory systems provide two primitive
operations: one that fetches the data stored in a specified location and
one that assigns new data to a specified location. Memory addresses can
be incremented to support sequential access to some set of the
cubbyholes. More generally, many important data operations require that
memory addresses be treated as data, which can be stored in memory
locations and manipulated in machine registers. The representation of
list structure is one application of such
<em>address arithmetic</em>.</p>
<p>To model computer memory, we use a new kind of data structure called a
<em>vector</em>. Abstractly, a vector is a compound data object
whose individual elements can be accessed by means of an integer index
in an amount of time that is independent of the
index.<a href="book-Z-H-33.html#footnote_Temp_744">^[5]{.small}^</a>
In order to describe memory operations, we use two primitive Scheme
procedures for manipulating vectors:</p>
<ul>
<li></li>
<li>
<p><code>(vector-ref &lt;</code><em><code>vector</code></em><code>&gt; &lt;</code><em><code>n</code></em><code>&gt;)</code> returns the <em>n</em>th element of
the vector.</p>
</li>
<li>
<p><code>(vector-set! &lt;</code><em><code>vector</code></em><code>&gt; &lt;</code><em><code>n</code></em><code>&gt; &lt;</code><em><code>value</code></em><code>&gt;)</code> sets the <em>n</em>th
element of the vector to the designated value.</p>
</li>
</ul>
<p>For example, if <code>v</code> is a vector, then <code>(vector-ref v 5)</code> gets the fifth
entry in the vector <code>v</code> and <code>(vector-set! v 5 7)</code> changes the value of
the fifth entry of the vector <code>v</code> to
7.<a href="book-Z-H-33.html#footnote_Temp_745">^[6]{.small}^</a>
For computer memory, this access can be implemented through the use of
address arithmetic to combine a <em>base address</em> that specifies the
beginning location of a vector in memory with an <em>index</em> that specifies
the offset of a particular element of the vector.</p>
<h4 id="representing-lisp-data"><a class="header" href="#representing-lisp-data"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_746">Representing Lisp data</a></a></h4>
<p>We can use vectors to implement the basic
pair structures required for a list-structured memory. Let us imagine
that computer memory is divided into two vectors:
<code>the-cars</code> and <code>the-cdrs</code>. We will
represent list structure as follows: A pointer to a pair is an index
into the two vectors. The <code>car</code> of the pair is the entry in <code>the-cars</code>
with the designated index, and the <code>cdr</code> of the pair is the entry in
<code>the-cdrs</code> with the designated index. We also need a representation for
objects other than pairs (such as numbers and symbols) and a way to
distinguish one kind of data from another. There are many methods of
accomplishing this, but they all reduce to using
<em>typed pointers</em>, that is, to extending
the notion of 'pointer' to include information on data
type.<a href="book-Z-H-33.html#footnote_Temp_747">^[7]{.small}^</a>
The data type enables the system to distinguish a pointer to a pair
(which consists of the 'pair' data type and an index into the
memory vectors) from pointers to other kinds of data (which consist of
some other data type and whatever is being used to represent data of
that type). Two data objects are considered to be the
same (<code>eq?</code>) if their pointers are
identical.<a href="book-Z-H-33.html#footnote_Temp_748">^[8]{.small}^</a>
Figure <a href="book-Z-H-33.html#%_fig_5.14">5.14</a> illustrates the use of this
method to represent the list <code>((1 2) 3 4)</code>, whose box-and-pointer
diagram is also shown. We use letter prefixes to denote the data-type
information. Thus, a pointer to the pair with index 5 is denoted <code>p5</code>,
the empty list is denoted by the pointer <code>e0</code>, and a pointer to the
number 4 is denoted <code>n4</code>. In the box-and-pointer diagram, we have
indicated at the lower left of each pair the vector index that specifies
where the <code>car</code> and <code>cdr</code> of the pair are stored. The blank locations in
<code>the-cars</code> and <code>the-cdrs</code> may contain parts of other list structures
(not of interest here).</p>
<p><img src="ch5-Z-G-7.gif" alt="" /></p>
<p><strong>Figure 5.14:</strong>  Box-and-pointer and memory-vector representations of
the list <code>((1 2) 3 4)</code>.</p>
<p>A pointer to a number, such as <code>n4</code>, might consist of a type indicating
numeric data together with the actual representation of the number
4.<a href="book-Z-H-33.html#footnote_Temp_749">^[9]{.small}^</a>
To deal with numbers that are too large to be represented in the fixed
amount of space allocated for a single pointer, we could use a distinct
<em>bignum</em> data type, for which the pointer designates a
list in which the parts of the number are
stored.<a href="book-Z-H-33.html#footnote_Temp_750">^[10]{.small}^</a></p>
<p>A symbol might be represented as a typed pointer that
designates a sequence of the characters that form the symbol's printed
representation. This sequence is constructed by the Lisp reader when the
character string is initially encountered in input. Since we want two
instances of a symbol to be recognized as the 'same' symbol by
<code>eq?</code> and we want <code>eq?</code> to be a simple test for equality
of pointers, we must ensure that if the reader sees the same character
string twice, it will use the same pointer (to the same sequence of
characters) to represent both occurrences. To accomplish this, the
reader maintains a table, traditionally called the
<em>obarray</em>, of all the symbols it has ever encountered.
When the reader encounters a character string and is about to construct
a symbol, it checks the obarray to see if it has ever before seen the
same character string. If it has not, it uses the characters to
construct a new symbol (a typed pointer to a new character sequence) and
enters this pointer in the obarray. If the reader has seen the string
before, it returns the symbol pointer stored in the obarray. This
process of replacing character strings by unique pointers is called
<em>interning</em> symbols.</p>
<h4 id="implementing-the-primitive-list-operations"><a class="header" href="#implementing-the-primitive-list-operations"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_751">Implementing the primitive list operations</a></a></h4>
<p>Given the above representation scheme, we
can replace each 'primitive' list operation of a register machine
with one or more primitive vector operations. We will use two registers,
<code>the-cars</code> and <code>the-cdrs</code>, to identify the memory vectors, and will
assume that <code>vector-ref</code> and <code>vector-set!</code> are available as primitive
operations. We also assume that numeric operations on pointers (such as
incrementing a pointer, using a pair pointer to index a vector, or
adding two numbers) use only the index portion of the typed pointer.</p>
<p>For example, we can make a register machine support the instructions</p>
<pre><code class="language-scheme editable">(assign &lt;*reg~1~*&gt; (op car) (reg &lt;*reg~2~*&gt;))

(assign &lt;*reg~1~*&gt; (op cdr) (reg &lt;*reg~2~*&gt;))
</code></pre>
<p>if we implement these, respectively, as</p>
<pre><code class="language-scheme editable">(assign &lt;*reg~1~*&gt; (op vector-ref) (reg the-cars) (reg &lt;*reg~2~*&gt;))

(assign &lt;*reg~1~*&gt; (op vector-ref) (reg the-cdrs) (reg &lt;*reg~2~*&gt;))
</code></pre>
<p>The instructions</p>
<pre><code class="language-scheme editable">(perform (op set-car!) (reg &lt;*reg~1~*&gt;) (reg &lt;*reg~2~*&gt;))

(perform (op set-cdr!) (reg &lt;*reg~1~*&gt;) (reg &lt;*reg~2~*&gt;))
</code></pre>
<p>are implemented as</p>
<pre><code class="language-scheme editable">(perform
 (op vector-set!) (reg the-cars) (reg &lt;*reg~1~*&gt;) (reg &lt;*reg~2~*&gt;))

(perform
 (op vector-set!) (reg the-cdrs) (reg &lt;*reg~1~*&gt;) (reg &lt;*reg~2~*&gt;))
</code></pre>
<p><code>Cons</code> is performed by allocating an unused index and
storing the arguments to <code>cons</code> in <code>the-cars</code> and <code>the-cdrs</code> at that
indexed vector position. We presume that there is a special register,
<code>free</code>, that always holds a pair pointer containing the
next available index, and that we can increment the index part of that
pointer to find the next free
location.<a href="book-Z-H-33.html#footnote_Temp_752">^[11]{.small}^</a>
For example, the instruction</p>
<pre><code class="language-scheme editable">(assign &lt;*reg~1~*&gt; (op cons) (reg &lt;*reg~2~*&gt;) (reg &lt;*reg~3~*&gt;))
</code></pre>
<p>is implemented as the following sequence of vector
operations:<a href="book-Z-H-33.html#footnote_Temp_753">^[12]{.small}^</a></p>
<pre><code class="language-scheme editable">(perform
 (op vector-set!) (reg the-cars) (reg free) (reg &lt;*reg~2~*&gt;))
(perform
 (op vector-set!) (reg the-cdrs) (reg free) (reg &lt;*reg~3~*&gt;))
(assign &lt;*reg~1~*&gt; (reg free))
(assign free (op +) (reg free) (const 1))
</code></pre>
<p>The <code>eq?</code> operation</p>
<pre><code class="language-scheme editable">(op eq?) (reg &lt;*reg~1~*&gt;) (reg &lt;*reg~2~*&gt;)
</code></pre>
<p>simply tests the equality of all fields in the registers, and
predicates
such as <code>pair?</code>, <code>null?</code>, <code>symbol?</code>, and <code>number?</code> need only check the
type field.</p>
<h4 id="implementing-stacks"><a class="header" href="#implementing-stacks"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_754">Implementing stacks</a></a></h4>
<p>Although our register machines use stacks, we need do
nothing special here, since stacks can be modeled in terms of lists. The
stack can be a list of the saved values, pointed to by a special
register <code>the-stack</code>. Thus, <code>(save &lt;</code><em><code>reg</code></em><code>&gt;)</code> can be implemented as</p>
<pre><code class="language-scheme editable">(assign the-stack (op cons) (reg &lt;*reg*&gt;) (reg the-stack))
</code></pre>
<p>Similarly, <code>(restore &lt;</code><em><code>reg</code></em><code>&gt;)</code> can be implemented as</p>
<pre><code class="language-scheme editable">(assign &lt;*reg*&gt; (op car) (reg the-stack))
(assign the-stack (op cdr) (reg the-stack))
</code></pre>
<p>and <code>(perform (op initialize-stack))</code> can be implemented as</p>
<pre><code class="language-scheme editable">(assign the-stack (const ()))
</code></pre>
<p>These operations can be further expanded in terms of the vector
operations given above. In conventional computer architectures, however,
it is usually advantageous to allocate the stack as a separate vector.
Then pushing and popping the stack can be accomplished by incrementing
or decrementing an index into that vector.</p>
<p><strong>Exercise 5.20.</strong>  Draw the box-and-pointer
representation and the memory-vector representation (as in
figure <a href="book-Z-H-33.html#%_fig_5.14">5.14</a>) of the list structure
produced by</p>
<pre><code class="language-scheme editable">(define x (cons 1 2))
(define y (list x x))
</code></pre>
<p>with the <code>free</code> pointer initially <code>p1</code>. What is the final value of
<code>free</code> ? What pointers represent the values of <code>x</code> and <code>y</code> ?</p>
<p><strong>Exercise 5.21.</strong>  Implement register
machines for the following procedures. Assume that the list-structure
memory operations are available as machine primitives.</p>
<p>a. Recursive <code>count-leaves</code>:</p>
<pre><code class="language-scheme editable">(define (count-leaves tree)
  (cond ((null? tree) 0)
        ((not (pair? tree)) 1)
        (else (+ (count-leaves (car tree))
                 (count-leaves (cdr tree))))))
</code></pre>
<p>b. Recursive <code>count-leaves</code> with explicit counter:</p>
<pre><code class="language-scheme editable">(define (count-leaves tree)
  (define (count-iter tree n)
    (cond ((null? tree) n)
          ((not (pair? tree)) (+ n 1))
          (else (count-iter (cdr tree)
                            (count-iter (car tree) n)))))
  (count-iter tree 0))
</code></pre>
<p><strong>Exercise
5.22.</strong>  Exercise <a href="book-Z-H-22.html#%_thm_3.12">3.12</a>
of section <a href="book-Z-H-22.html#%_sec_3.3.1">3.3.1</a> presented an <code>append</code>
procedure that appends two lists to form a new list and an <code>append!</code>
procedure that splices two lists together. Design a register machine to
implement each of these procedures. Assume that the list-structure
memory operations are available as primitive operations.</p>
<h3 id="532--maintaining-the-illusion-of-infinite-memory"><a class="header" href="#532--maintaining-the-illusion-of-infinite-memory"><a href="book-Z-H-4.html#%_toc_%_sec_5.3.2">5.3.2  Maintaining the Illusion of Infinite Memory</a></a></h3>
<p>The representation method outlined in
section <a href="book-Z-H-33.html#%_sec_5.3.1">5.3.1</a> solves the problem of
implementing list structure, provided that we have an infinite amount of
memory. With a real computer we will eventually run out of free space in
which to construct new
pairs.<a href="book-Z-H-33.html#footnote_Temp_758">^[13]{.small}^</a>
However, most of the pairs generated in a typical computation are used
only to hold intermediate results. After these results are accessed, the
pairs are no longer needed -- they are <em>garbage</em>. For instance, the
computation</p>
<pre><code class="language-scheme editable">(accumulate + 0 (filter odd? (enumerate-interval 0 n)))
</code></pre>
<p>constructs two lists: the enumeration and the result of filtering the
enumeration. When the accumulation is complete, these lists are no
longer needed, and the allocated memory can be reclaimed. If we can
arrange to collect all the garbage periodically, and if this turns out
to recycle memory at about the same rate at which we construct new
pairs, we will have preserved the illusion that there is an infinite
amount of memory.</p>
<p>In order to recycle pairs, we must have a way to determine which
allocated pairs are not needed (in the sense that their contents can no
longer influence the future of the computation). The method we shall
examine for accomplishing this is known as <em>garbage collection</em>. Garbage
collection is based on the observation that, at any moment in a Lisp
interpretation, the only objects that can affect the future of the
computation are those that can be reached by some succession of <code>car</code>
and <code>cdr</code> operations starting from the pointers that are currently in
the machine
registers.<a href="book-Z-H-33.html#footnote_Temp_759">^[14]{.small}^</a>
Any memory cell that is not so accessible may be recycled.</p>
<p>There are many ways to perform garbage collection. The method we shall
examine here is called <em>stop-and-copy</em>.
The basic idea is to divide memory into two halves: 'working
memory' and 'free memory.' When <code>cons</code> constructs pairs, it
allocates these in working memory. When working memory is full, we
perform garbage collection by locating all the useful pairs in working
memory and copying these into consecutive locations in free memory. (The
useful pairs are located by tracing all the <code>car</code> and <code>cdr</code> pointers,
starting with the machine registers.) Since we do not copy the garbage,
there will presumably be additional free memory that we can use to
allocate new pairs. In addition, nothing in the working memory is
needed, since all the useful pairs in it have been copied. Thus, if we
interchange the roles of working memory and free memory, we can continue
processing; new pairs will be allocated in the new working memory (which
was the old free memory). When this is full, we can copy the useful
pairs into the new free memory (which was the old working
memory).^[15]{.small}^](book-Z-H-33.html#footnote_Temp_760)</p>
<h4 id="implementation-of-a-stop-and-copy-garbage-collector"><a class="header" href="#implementation-of-a-stop-and-copy-garbage-collector"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_761">Implementation of a stop-and-copy garbage collector</a></a></h4>
<p>We now use our register-machine language to describe the stop-and-copy
algorithm in more detail. We will assume that there is a register called
<code>root</code> that contains a pointer to a structure that
eventually points at all accessible data. This can be arranged by
storing the contents of all the machine registers in a pre-allocated
list pointed at by <code>root</code> just before starting garbage
collection.<a href="book-Z-H-33.html#footnote_Temp_762">^[16]{.small}^</a>
We also assume that, in addition to the current working memory, there is
free memory available into which we can copy the useful data. The
current working memory consists of vectors whose base addresses are in
registers called <code>the-cars</code> and
<code>the-cdrs</code>, and the free memory is in registers called
<code>new-cars</code> and <code>new-cdrs</code>.</p>
<p>Garbage collection is triggered when we exhaust the free cells in the
current working memory, that is, when a <code>cons</code> operation attempts to
increment the <code>free</code> pointer beyond the end of the memory vector. When
the garbage-collection process is complete, the <code>root</code> pointer will
point into the new memory, all objects accessible from the <code>root</code> will
have been moved to the new memory, and the <code>free</code> pointer will indicate
the next place in the new memory where a new pair can be allocated. In
addition, the roles of working memory and new memory will have been
interchanged -- new pairs will be constructed in the new memory,
beginning at the place indicated by <code>free</code>, and the (previous) working
memory will be available as the new memory for the next garbage
collection. Figure <a href="book-Z-H-33.html#%_fig_5.15">5.15</a> shows the
arrangement of memory just before and just after garbage collection.</p>
<p><img src="ch5-Z-G-8.gif" alt="" /></p>
<p><strong>Figure 5.15:</strong>  Reconfiguration of memory by the garbage-collection
process.</p>
<p>The state of the garbage-collection
process is controlled by maintaining two pointers: <code>free</code> and <code>scan</code>.
These are initialized to point to the beginning of the new memory. The
algorithm begins by relocating the pair pointed at by <code>root</code> to the
beginning of the new memory. The pair is copied, the <code>root</code> pointer is
adjusted to point to the new location, and the <code>free</code> pointer is
incremented. In addition, the old location of the pair is marked to show
that its contents have been moved. This marking is done as follows: In
the <code>car</code> position, we place a special tag that signals that this is an
already-moved object. (Such an object is traditionally called a
<em>broken
heart</em>.)^[17]{.small}^](book-Z-H-33.html#footnote_Temp_763)
In the <code>cdr</code> position we place a <em>forwarding address</em>
that points at the location to which the object has been moved.</p>
<p>After relocating the root, the garbage collector enters its basic cycle.
At each step in the algorithm, the <code>scan</code> pointer (initially pointing at
the relocated root) points at a pair that has been moved to the new
memory but whose <code>car</code> and <code>cdr</code> pointers still refer to objects in the
old memory. These objects are each relocated, and the <code>scan</code> pointer is
incremented. To relocate an object (for example, the object indicated by
the <code>car</code> pointer of the pair we are scanning) we check to see if the
object has already been moved (as indicated by the presence of a
broken-heart tag in the <code>car</code> position of the object). If the object
has not already been moved, we copy it to the place indicated by <code>free</code>,
update <code>free</code>, set up a broken heart at the object's old location, and
update the pointer to the object (in this example, the <code>car</code> pointer of
the pair we are scanning) to point to the new location. If the object
has already been moved, its forwarding address (found in the <code>cdr</code>
position of the broken heart) is substituted for the pointer in the pair
being scanned. Eventually, all accessible objects will have been moved
and scanned, at which point the <code>scan</code> pointer will overtake the <code>free</code>
pointer and the process will terminate.</p>
<p>We can specify the stop-and-copy algorithm as a sequence of instructions
for a register machine. The basic step of relocating an object is
accomplished by a subroutine called <code>relocate-old-result-in-new</code>. This
subroutine gets its argument, a pointer to the object to be relocated,
from a register named <code>old</code>. It relocates the designated
object (incrementing <code>free</code> in the process), puts a pointer to the
relocated object into a register called <code>new</code>, and
returns by branching to the entry point stored in the register
<code>relocate-continue</code>. To begin garbage collection, we invoke this
subroutine to relocate the <code>root</code> pointer, after initializing <code>free</code> and
<code>scan</code>. When the relocation of <code>root</code> has been accomplished, we install
the new pointer as the new <code>root</code> and enter the main loop of the garbage
collector.</p>
<pre><code class="language-scheme editable">begin-garbage-collection
  (assign free (const 0))
  (assign scan (const 0))
  (assign old (reg root))
  (assign relocate-continue (label reassign-root))
  (goto (label relocate-old-result-in-new))
reassign-root
  (assign root (reg new))
  (goto (label gc-loop))
</code></pre>
<p>In the main loop of the garbage collector we must determine whether
there are any more objects to be scanned. We do this by testing whether
the <code>scan</code> pointer is coincident with the <code>free</code> pointer. If the
pointers are equal, then all accessible objects have been relocated, and
we branch to <code>gc-flip</code>, which cleans things up so that we can continue
the interrupted computation. If there are still pairs to be scanned, we
call the relocate subroutine to relocate the <code>car</code> of the next pair (by
placing the <code>car</code> pointer in <code>old</code>). The <code>relocate-continue</code> register is
set up so that the subroutine will return to update the <code>car</code> pointer.</p>
<pre><code class="language-scheme editable">gc-loop
  (test (op =) (reg scan) (reg free))
  (branch (label gc-flip))
  (assign old (op vector-ref) (reg new-cars) (reg scan))
  (assign relocate-continue (label update-car))
  (goto (label relocate-old-result-in-new))
</code></pre>
<p>At <code>update-car</code>, we modify the <code>car</code> pointer of the pair being scanned,
then proceed to relocate the <code>cdr</code> of the pair. We return to
<code>update-cdr</code> when that relocation has been accomplished. After
relocating and updating the <code>cdr</code>, we are finished scanning that pair,
so we continue with the main loop.</p>
<pre><code class="language-scheme editable">update-car
  (perform
   (op vector-set!) (reg new-cars) (reg scan) (reg new))
  (assign old (op vector-ref) (reg new-cdrs) (reg scan))
  (assign relocate-continue (label update-cdr))
  (goto (label relocate-old-result-in-new))

update-cdr
  (perform
   (op vector-set!) (reg new-cdrs) (reg scan) (reg new))
  (assign scan (op +) (reg scan) (const 1))
  (goto (label gc-loop))
</code></pre>
<p>The subroutine <code>relocate-old-result-in-new</code> relocates objects as
follows: If the object to be relocated (pointed at by <code>old</code>) is not a
pair, then we return the same pointer to the object unchanged (in
<code>new</code>). (For example, we may be scanning a pair whose <code>car</code> is the
number 4. If we represent the <code>car</code> by <code>n4</code>, as described in
section <a href="book-Z-H-33.html#%_sec_5.3.1">5.3.1</a>, then we want the
'relocated' <code>car</code> pointer to still be <code>n4</code>.) Otherwise, we must
perform the relocation. If the <code>car</code> position of the pair to be
relocated contains a broken-heart tag, then the pair has in fact already
been moved, so we retrieve the forwarding address (from the <code>cdr</code>
position of the broken heart) and return this in <code>new</code>. If the pointer
in <code>old</code> points at a yet-unmoved pair, then we move the pair to the
first free cell in new memory (pointed at by <code>free</code>) and set up the
broken heart by storing a broken-heart tag and forwarding address at the
old location. <code>Relocate-old-result-in-new</code> uses a register
<code>oldcr</code> to hold the <code>car</code> or the <code>cdr</code> of the object
pointed at by
<code>old</code>.<a href="book-Z-H-33.html#footnote_Temp_764">^[18]{.small}^</a></p>
<pre><code class="language-scheme editable">relocate-old-result-in-new
  (test (op pointer-to-pair?) (reg old))
  (branch (label pair))
  (assign new (reg old))
  (goto (reg relocate-continue))
pair
  (assign oldcr (op vector-ref) (reg the-cars) (reg old))
  (test (op broken-heart?) (reg oldcr))
  (branch (label already-moved))
  (assign new (reg free)) ; new location for pair
  ;; Update "free" pointer.
  (assign free (op +) (reg free) (const 1))
  ;; Copy the "car" and "cdr" to new memory.
  (perform (op vector-set!)
           (reg new-cars) (reg new) (reg oldcr))
  (assign oldcr (op vector-ref) (reg the-cdrs) (reg old))
  (perform (op vector-set!)
           (reg new-cdrs) (reg new) (reg oldcr))
  ;; Construct the broken heart.
  (perform (op vector-set!)
           (reg the-cars) (reg old) (const broken-heart))
  (perform
   (op vector-set!) (reg the-cdrs) (reg old) (reg new))
  (goto (reg relocate-continue))
already-moved
  (assign new (op vector-ref) (reg the-cdrs) (reg old))
  (goto (reg relocate-continue))
</code></pre>
<p>At the very end of the garbage-collection process, we interchange the
role of old and new memories by interchanging pointers: interchanging
<code>the-cars</code> with <code>new-cars</code>, and <code>the-cdrs</code> with <code>new-cdrs</code>. We will then
be ready to perform another garbage collection the next time memory runs
out.</p>
<pre><code class="language-scheme editable">gc-flip
  (assign temp (reg the-cdrs))
  (assign the-cdrs (reg new-cdrs))
  (assign new-cdrs (reg temp))
  (assign temp (reg the-cars))
  (assign the-cars (reg new-cars))
  (assign new-cars (reg temp))
</code></pre>
<hr />
<p>^[5]{.small}^](book-Z-H-33.html#call_footnote_Temp_744)
We could represent memory as lists of items. However, the access time
would then not be independent of the index, since accessing the <em>n</em>th
element of a list requires <em>n</em> - 1 <code>cdr</code> operations.</p>
<p>^[6]{.small}^](book-Z-H-33.html#call_footnote_Temp_745)
For completeness, we should specify a <code>make-vector</code> operation that
constructs vectors. However, in the present application we will use
vectors only to model fixed divisions of the computer memory.</p>
<p>^[7]{.small}^](book-Z-H-33.html#call_footnote_Temp_747)
This is precisely the same 'tagged
data' idea we introduced in chapter 2 for dealing with generic
operations. Here, however, the data types are included at the primitive
machine level rather than constructed through the use of lists.</p>
<p>^[8]{.small}^](book-Z-H-33.html#footnote_Temp_748)
Type information may be encoded in a variety of ways, depending on the
details of the machine on which the Lisp system is to be implemented.
The execution efficiency of Lisp programs will be strongly dependent on
how cleverly this choice is made, but it is difficult to formulate
general design rules for good choices. The most straightforward way to
implement typed pointers is to allocate a fixed set of bits in each
pointer to be a <em>type field</em> that encodes the data type.
Important questions to be addressed in designing such a representation
include the following: How many type bits are required? How large must
the vector indices be? How efficiently can the primitive machine
instructions be used to manipulate the type fields of pointers? Machines
that include special hardware for the efficient handling of type fields
are said to have <em>tagged architectures</em>.</p>
<p>^[9]{.small}^](book-Z-H-33.html#footnote_Temp_749)
This decision on the
representation of numbers
determines whether <code>eq?</code>, which tests equality of pointers, can be used
to test for equality of numbers. If the pointer contains the number
itself, then equal numbers will have the same pointer. But if the
pointer contains the index of a location where the number is stored,
equal numbers will be guaranteed to have equal pointers only if we are
careful never to store the same number in more than one location.</p>
<p>^[10]{.small}^](book-Z-H-33.html#footnote_Temp_750)
This is just like writing a number as a sequence of digits, except that
each 'digit' is a number between 0 and the largest number that can
be stored in a single pointer.</p>
<p>^[11]{.small}^](book-Z-H-33.html#call_footnote_Temp_752)
There are other ways of finding free storage. For example, we could link
together all the unused pairs into a <em>free list</em>. Our
free locations are consecutive (and hence can be accessed by
incrementing a pointer) because we are using a compacting garbage
collector, as we will see in
section <a href="book-Z-H-33.html#%_sec_5.3.2">5.3.2</a>.</p>
<p>^[12]{.small}^](book-Z-H-33.html#call_footnote_Temp_753)
This is essentially the implementation of <code>cons</code> in terms of <code>set-car!</code>
and <code>set-cdr!</code>, as described in
section <a href="book-Z-H-22.html#%_sec_3.3.1">3.3.1</a>. The operation
<code>get-new-pair</code> used in that implementation is realized here by the
<code>free</code> pointer.</p>
<p>^[13]{.small}^](book-Z-H-33.html#footnote_Temp_758)
This may not be true eventually, because memories may get large enough
so that it would be impossible to run out of free memory in the lifetime
of the computer. For example, there are about 3× 10^13^, microseconds in
a year, so if we were to <code>cons</code> once per microsecond we would need about
10^15^ cells of memory to build a machine that could operate for 30
years without running out of memory. That much memory seems absurdly
large by today's standards, but it is not physically impossible. On the
other hand, processors are getting faster and a future computer may have
large numbers of processors operating in parallel on a single memory, so
it may be possible to use up memory much faster than we have postulated.</p>
<p>^[14]{.small}^](book-Z-H-33.html#footnote_Temp_759)
We assume here that the stack is represented as a list as described in
section <a href="book-Z-H-33.html#%_sec_5.3.1">5.3.1</a>, so that items on the
stack are accessible via the pointer in the stack register.</p>
<p>^[15]{.small}^](book-Z-H-33.html#footnote_Temp_760)
This idea was invented and first implemented by Minsky,
as part of the implementation of Lisp for the PDP-1 at
the MIT Research Laboratory of Electronics. It was
further developed by Fenichel and
Yochelson (1969) for use in the Lisp implementation for
the Multics time-sharing system. Later,
Baker (1978) developed a 'real-time' version of the
method, which does not require the computation to stop during garbage
collection. Baker's idea was extended by
Hewitt, Lieberman, and Moon
(see Lieberman and Hewitt 1983) to take advantage of the fact that some
structure is more volatile and other structure is more permanent.</p>
<p>An alternative commonly used garbage-collection technique is the
<em>mark-sweep</em> method. This consists of
tracing all the structure accessible from the machine registers and
marking each pair we reach. We then scan all of memory, and any location
that is unmarked is 'swept up' as garbage and made available for
reuse. A full discussion of the mark-sweep method can be
found in Allen 1978.</p>
<p>The Minsky-Fenichel-Yochelson algorithm is the dominant algorithm in use
for large-memory systems because it examines only the useful part of
memory. This is in contrast to mark-sweep, in which the sweep phase must
check all of memory. A second advantage of stop-and-copy is that it is a
<em>compacting</em> garbage collector. That is,
at the end of the garbage-collection phase the useful data will have
been moved to consecutive memory locations, with all garbage pairs
compressed out. This can be an extremely important performance
consideration in machines with virtual memory, in which accesses to
widely separated memory addresses may require extra paging operations.</p>
<p>^[16]{.small}^](book-Z-H-33.html#footnote_Temp_762)
This list of registers does not include the registers used by the
storage-allocation system -- <code>root</code>, <code>the-cars</code>, <code>the-cdrs</code>, and the
other registers that will be introduced in this section.</p>
<p>^[17]{.small}^](book-Z-H-33.html#footnote_Temp_763)
The term <em>broken heart</em> was coined by David Cressey, who
wrote a garbage collector for MDL, a
dialect of Lisp developed at MIT during the early 1970s.</p>
<p>^[18]{.small}^](book-Z-H-33.html#footnote_Temp_764)
The garbage collector uses the low-level predicate <code>pointer-to-pair?</code>
instead of the list-structure <code>pair?</code> operation because in a real system
there might be various things that are treated as pairs for
garbage-collection purposes. For example, in a Scheme system that
conforms to the IEEE standard a procedure object may be implemented as a
special kind of 'pair' that doesn't satisfy the <code>pair?</code>
predicate. For simulation purposes, <code>pointer-to-pair?</code> can be
implemented as <code>pair?</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="54--the-explicit-control-evaluator"><a class="header" href="#54--the-explicit-control-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_5.4">5.4  The Explicit-Control Evaluator</a></a></h2>
<p>In section <a href="book-Z-H-31.html#%_sec_5.1">5.1</a> we saw how
to transform simple Scheme programs into descriptions of register
machines. We will now perform this transformation on a more complex
program, the metacircular evaluator of sections
<a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>-<a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>,
which shows how the behavior of a Scheme interpreter can be described in
terms of the procedures <code>eval</code> and <code>apply</code>. The <em>explicit-control
evaluator</em> that we develop in this section shows how the underlying
procedure-calling and argument-passing mechanisms used in the evaluation
process can be described in terms of operations on registers and stacks.
In addition, the explicit-control evaluator can serve as an
implementation of a Scheme interpreter, written in a language that is
very similar to the native machine language of conventional computers.
The evaluator can be executed by the register-machine simulator of
section <a href="book-Z-H-32.html#%_sec_5.2">5.2</a>. Alternatively, it can be used
as a starting point for building a machine-language implementation of a
Scheme evaluator, or even a
special-purpose machine for
evaluating Scheme expressions.
Figure <a href="book-Z-H-34.html#%_fig_5.16">5.16</a> shows such a hardware
implementation: a silicon chip that acts as an evaluator for Scheme. The
chip designers started with the data-path and controller specifications
for a register machine similar to the evaluator described in this
section and used design automation programs to construct the
integrated-circuit
layout.<a href="book-Z-H-34.html#footnote_Temp_765">^[19]{.small}^</a></p>
<h4 id="registers-and-operations"><a class="header" href="#registers-and-operations"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_766">Registers and operations</a></a></h4>
<p>In designing the explicit-control
evaluator, we must specify the operations to be used in our register
machine. We described the metacircular evaluator in terms of abstract
syntax, using procedures such as <code>quoted?</code> and <code>make-procedure</code>. In
implementing the register machine, we could expand these procedures into
sequences of elementary list-structure memory operations, and implement
these operations on our register machine. However, this would make our
evaluator very long, obscuring the basic structure with details. To
clarify the presentation, we will include as primitive operations of the
register machine the syntax procedures given in
section <a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a> and the procedures for
representing environments and other run-time data given in
sections <a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a>
and <a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>. In order to completely
specify an evaluator that could be programmed in a low-level machine
language or implemented in hardware, we would replace these operations
by more elementary operations, using the list-structure implementation
we described in section <a href="book-Z-H-33.html#%_sec_5.3">5.3</a>.</p>
<p><img src="chip.jpg" alt="" /></p>
<p><strong>Figure 5.16:</strong>  A silicon-chip implementation of an evaluator for
Scheme.</p>
<p>Our
Scheme evaluator register machine includes a stack and seven registers:
<code>exp</code>, <code>env</code>, <code>val</code>, <code>continue</code>, <code>proc</code>, <code>argl</code>, and <code>unev</code>. <code>Exp</code> is
used to hold the expression to be evaluated, and <code>env</code> contains the
environment in which the evaluation is to be performed. At the end of an
evaluation, <code>val</code> contains the value obtained by evaluating the
expression in the designated environment. The <code>continue</code> register is
used to implement recursion, as explained in
section <a href="book-Z-H-31.html#%_sec_5.1.4">5.1.4</a>. (The evaluator needs to
call itself recursively, since evaluating an expression requires
evaluating its subexpressions.) The registers <code>proc</code>, <code>argl</code>, and <code>unev</code>
are used in evaluating combinations.</p>
<p>We will not provide a data-path diagram to show how the registers and
operations of the evaluator are connected, nor will we give the complete
list of machine operations. These are implicit in the evaluator's
controller, which will be presented in detail.</p>
<h3 id="541--the-core-of-the-explicit-control-evaluator"><a class="header" href="#541--the-core-of-the-explicit-control-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_5.4.1">5.4.1  The Core of the Explicit-Control Evaluator</a></a></h3>
<p>The central element in the evaluator is the sequence of
instructions beginning at <code>eval-dispatch</code>. This corresponds to the
<code>eval</code> procedure of the metacircular evaluator described in
section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>. When the controller
starts at <code>eval-dispatch</code>, it evaluates the expression specified by
<code>exp</code> in the environment specified by <code>env</code>. When evaluation is
complete, the controller will go to the entry point stored in
<code>continue</code>, and the <code>val</code> register will hold the value of the
expression. As with the metacircular <code>eval</code>, the structure of
<code>eval-dispatch</code> is a case analysis on the syntactic type of the
expression to be
evaluated.<a href="book-Z-H-34.html#footnote_Temp_767">^[20]{.small}^</a></p>
<pre><code class="language-scheme editable">eval-dispatch
  (test (op self-evaluating?) (reg exp))
  (branch (label ev-self-eval))
  (test (op variable?) (reg exp))
  (branch (label ev-variable))
  (test (op quoted?) (reg exp))
  (branch (label ev-quoted))
  (test (op assignment?) (reg exp))
  (branch (label ev-assignment))
  (test (op definition?) (reg exp))
  (branch (label ev-definition))
  (test (op if?) (reg exp))
  (branch (label ev-if))
  (test (op lambda?) (reg exp))
  (branch (label ev-lambda))
  (test (op begin?) (reg exp))
  (branch (label ev-begin))
  (test (op application?) (reg exp))
  (branch (label ev-application))
  (goto (label unknown-expression-type))
</code></pre>
<h4 id="evaluating-simple-expressions"><a class="header" href="#evaluating-simple-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_768">Evaluating simple expressions</a></a></h4>
<p>Numbers and strings (which are self-evaluating),
variables, quotations, and <code>lambda</code> expressions have no subexpressions
to be evaluated. For these, the evaluator simply places the correct
value in the <code>val</code> register and continues execution at the entry point
specified by <code>continue</code>. Evaluation of simple expressions is performed
by the following controller code:</p>
<pre><code class="language-scheme editable">ev-self-eval
  (assign val (reg exp))
  (goto (reg continue))
</code></pre>
<pre><code class="language-scheme editable">ev-variable
  (assign val (op lookup-variable-value) (reg exp) (reg env))
  (goto (reg continue))
</code></pre>
<pre><code class="language-scheme editable">ev-quoted
  (assign val (op text-of-quotation) (reg exp))
  (goto (reg continue))
</code></pre>
<pre><code class="language-scheme editable">ev-lambda
  (assign unev (op lambda-parameters) (reg exp))
  (assign exp (op lambda-body) (reg exp))
  (assign val (op make-procedure)
              (reg unev) (reg exp) (reg env))
  (goto (reg continue))
</code></pre>
<p>Observe how <code>ev-lambda</code> uses the <code>unev</code> and <code>exp</code> registers to hold the
parameters and body of the lambda expression so that they can be passed
to the <code>make-procedure</code> operation, along with the environment in <code>env</code>.</p>
<h4 id="evaluating-procedure-applications"><a class="header" href="#evaluating-procedure-applications"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_769">Evaluating procedure applications</a></a></h4>
<p>A procedure application is specified by a
combination containing an operator and operands. The operator is a
subexpression whose value is a procedure, and the operands are
subexpressions whose values are the arguments to which the procedure
should be applied. The metacircular <code>eval</code> handles applications by
calling itself recursively to evaluate each element of the combination,
and then passing the results to <code>apply</code>, which performs the actual
procedure application. The explicit-control evaluator does the same
thing; these recursive calls are implemented by <code>goto</code> instructions,
together with use of the stack to save registers that
will be restored after the recursive call returns. Before each call we
will be careful to identify which registers must be saved (because their
values will be needed
later).<a href="book-Z-H-34.html#footnote_Temp_770">^[21]{.small}^</a></p>
<p>We begin the evaluation of an application by evaluating the operator to
produce a procedure, which will later be applied to the evaluated
operands. To evaluate the operator, we move it to the <code>exp</code> register and
go to <code>eval-dispatch</code>. The environment in the <code>env</code> register is already
the correct one in which to evaluate the operator. However, we save
<code>env</code> because we will need it later to evaluate the operands. We also
extract the operands into <code>unev</code> and save this on the stack. We set up
<code>continue</code> so that <code>eval-dispatch</code> will resume at <code>ev-appl-did-operator</code>
after the operator has been evaluated. First, however, we save the old
value of <code>continue</code>, which tells the controller where to continue after
the application.</p>
<pre><code class="language-scheme editable">ev-application
  (save continue)
  (save env)
  (assign unev (op operands) (reg exp))
  (save unev)
  (assign exp (op operator) (reg exp))
  (assign continue (label ev-appl-did-operator))
  (goto (label eval-dispatch))
</code></pre>
<p>Upon returning from evaluating the operator
subexpression, we proceed to evaluate the operands of the combination
and to accumulate the resulting arguments in a list, held in <code>argl</code>.
First we restore the unevaluated operands and the environment. We
initialize <code>argl</code> to an empty list. Then we assign to the <code>proc</code>
register the procedure that was produced by evaluating the operator. If
there are no operands, we go directly to <code>apply-dispatch</code>. Otherwise we
save <code>proc</code> on the stack and start the argument-evaluation
loop:<a href="book-Z-H-34.html#footnote_Temp_771">^[22]{.small}^</a></p>
<pre><code class="language-scheme editable">ev-appl-did-operator
  (restore unev)                  ; the operands
  (restore env)
  (assign argl (op empty-arglist))
  (assign proc (reg val))         ; the operator
  (test (op no-operands?) (reg unev))
  (branch (label apply-dispatch))
  (save proc)
</code></pre>
<p>Each cycle of the argument-evaluation loop evaluates an operand from the
list in <code>unev</code> and accumulates the result into <code>argl</code>. To evaluate an
operand, we place it in the <code>exp</code> register and go to <code>eval-dispatch</code>,
after setting <code>continue</code> so that execution will resume with the
argument-accumulation phase. But first we save the arguments accumulated
so far (held in <code>argl</code>), the environment (held in <code>env</code>), and the
remaining operands to be evaluated (held in <code>unev</code>). A special case is
made for the evaluation of the last operand, which is handled at
<code>ev-appl-last-arg</code>.</p>
<pre><code class="language-scheme editable">ev-appl-operand-loop
  (save argl)
  (assign exp (op first-operand) (reg unev))
  (test (op last-operand?) (reg unev))
  (branch (label ev-appl-last-arg))
  (save env)
  (save unev)
  (assign continue (label ev-appl-accumulate-arg))
  (goto (label eval-dispatch))
</code></pre>
<p>When an operand has been evaluated, the value is accumulated into the
list held in <code>argl</code>. The operand is then removed from the list of
unevaluated operands in <code>unev</code>, and the argument-evaluation continues.</p>
<pre><code class="language-scheme editable">ev-appl-accumulate-arg
  (restore unev)
  (restore env)
  (restore argl)
  (assign argl (op adjoin-arg) (reg val) (reg argl))
  (assign unev (op rest-operands) (reg unev))
  (goto (label ev-appl-operand-loop))
</code></pre>
<p>Evaluation of the last argument is handled differently. There is no need
to save the environment or the list of unevaluated operands before going
to <code>eval-dispatch</code>, since they will not be required after the last
operand is evaluated. Thus, we return from the evaluation to a special
entry point <code>ev-appl-accum-last-arg</code>, which restores the argument list,
accumulates the new argument, restores the saved procedure, and goes off
to perform the
application.<a href="book-Z-H-34.html#footnote_Temp_772">^[23]{.small}^</a></p>
<pre><code class="language-scheme editable">ev-appl-last-arg
  (assign continue (label ev-appl-accum-last-arg))
  (goto (label eval-dispatch))
eveval-appl-accum-last-arg
  (restore argl)
  (assign argl (op adjoin-arg) (reg val) (reg argl))
  (restore proc)
  (goto (label apply-dispatch))
</code></pre>
<p>The details of the argument-evaluation loop determine the
order in which the interpreter evaluates the operands of a combination
(e.g., left to right or right to left -- see
exercise <a href="book-Z-H-20.html#%_thm_3.8">3.8</a>). This order is not
determined by the metacircular evaluator, which inherits its control
structure from the underlying Scheme in which it is
implemented.<a href="book-Z-H-34.html#footnote_Temp_773">^[24]{.small}^</a>
Because the <code>first-operand</code> selector (used in <code>ev-appl-operand-loop</code> to
extract successive operands from <code>unev</code>) is implemented as <code>car</code> and the
<code>rest-operands</code> selector is implemented as <code>cdr</code>, the explicit-control
evaluator will evaluate the operands of a combination in left-to-right
order.</p>
<h4 id="procedure-application"><a class="header" href="#procedure-application"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_774">Procedure application</a></a></h4>
<p>The entry point <code>apply-dispatch</code> corresponds to the <code>apply</code> procedure of
the metacircular evaluator. By the time we get to <code>apply-dispatch</code>, the
<code>proc</code> register contains the procedure to apply and <code>argl</code> contains the
list of evaluated arguments to which it must be applied. The saved value
of <code>continue</code> (originally passed to <code>eval-dispatch</code> and saved at
<code>ev-application</code>), which tells where to return with the result of the
procedure application, is on the stack. When the application is
complete, the controller transfers to the entry point specified by the
saved <code>continue</code>, with the result of the application in <code>val</code>. As with
the metacircular <code>apply</code>, there are two cases to consider. Either the
procedure to be applied is a primitive or it is a compound procedure.</p>
<pre><code class="language-scheme editable">apply-dispatch
  (test (op primitive-procedure?) (reg proc))
  (branch (label primitive-apply))
  (test (op compound-procedure?) (reg proc))  
  (branch (label compound-apply))
  (goto (label unknown-procedure-type))
</code></pre>
<p>We assume that each primitive is implemented so as to
obtain its arguments from <code>argl</code> and place its result in <code>val</code>. To
specify how the machine handles primitives, we would have to provide a
sequence of controller instructions to implement each primitive and
arrange for <code>primitive-apply</code> to dispatch to the instructions for the
primitive identified by the contents of <code>proc</code>. Since we are interested
in the structure of the evaluation process rather than the details of
the primitives, we will instead just use an <code>apply-primitive-procedure</code>
operation that applies the procedure in <code>proc</code> to the arguments in
<code>argl</code>. For the purpose of simulating the evaluator with the simulator
of section <a href="book-Z-H-32.html#%_sec_5.2">5.2</a> we use the procedure
<code>apply-primitive-procedure</code>, which calls on the underlying Scheme system
to perform the application, just as we did for the metacircular
evaluator in section <a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>. After
computing the value of the primitive application, we restore <code>continue</code>
and go to the designated entry point.</p>
<pre><code class="language-scheme editable">primitive-apply
  (assign val (op apply-primitive-procedure)
              (reg proc)
              (reg argl))
  (restore continue)
  (goto (reg continue))
</code></pre>
<p>To apply a compound procedure, we proceed just as with
the metacircular evaluator. We construct a frame that binds the
procedure's parameters to the arguments, use this frame to extend the
environment carried by the procedure, and evaluate in this extended
environment the sequence of expressions that forms the body of the
procedure. <code>Ev-sequence</code>, described below in
section <a href="book-Z-H-34.html#%_sec_5.4.2">5.4.2</a>, handles the evaluation of
the sequence.</p>
<pre><code class="language-scheme editable">compound-apply
  (assign unev (op procedure-parameters) (reg proc))
  (assign env (op procedure-environment) (reg proc))
  (assign env (op extend-environment)
              (reg unev) (reg argl) (reg env))
  (assign unev (op procedure-body) (reg proc))
  (goto (label ev-sequence))
</code></pre>
<p><code>Compound-apply</code> is the only place in the interpreter where the <code>env</code>
register is ever assigned a new value. Just as in the metacircular
evaluator, the new environment is constructed from the environment
carried by the procedure, together with the argument list and the
corresponding list of variables to be bound.</p>
<h3 id="542--sequence-evaluation-and-tail-recursion"><a class="header" href="#542--sequence-evaluation-and-tail-recursion"><a href="book-Z-H-4.html#%_toc_%_sec_5.4.2">5.4.2  Sequence Evaluation and Tail Recursion</a></a></h3>
<p>The portion of the explicit-control evaluator at
<code>ev-sequence</code> is analogous to the metacircular evaluator's
<code>eval-sequence</code> procedure. It handles sequences of expressions in
procedure bodies or in explicit <code>begin</code> expressions.</p>
<p>Explicit <code>begin</code> expressions are evaluated by placing the sequence of
expressions to be evaluated in <code>unev</code>, saving <code>continue</code> on the stack,
and jumping to <code>ev-sequence</code>.</p>
<pre><code class="language-scheme editable">ev-begin
  (assign unev (op begin-actions) (reg exp))
  (save continue)
  (goto (label ev-sequence))
</code></pre>
<p>The implicit sequences in procedure bodies are handled by jumping to
<code>ev-sequence</code> from <code>compound-apply</code>, at which point <code>continue</code> is
already on the stack, having been saved at <code>ev-application</code>.</p>
<p>The entries at <code>ev-sequence</code> and <code>ev-sequence-continue</code> form a loop that
successively evaluates each expression in a sequence. The list of
unevaluated expressions is kept in <code>unev</code>. Before evaluating each
expression, we check to see if there are additional expressions to be
evaluated in the sequence. If so, we save the rest of the unevaluated
expressions (held in <code>unev</code>) and the environment in which these must be
evaluated (held in <code>env</code>) and call <code>eval-dispatch</code> to evaluate the
expression. The two saved registers are restored upon the return from
this evaluation, at <code>ev-sequence-continue</code>.</p>
<p>The final expression in the sequence is handled differently, at the
entry point <code>ev-sequence-last-exp</code>. Since there are no more expressions
to be evaluated after this one, we need not save <code>unev</code> or <code>env</code> before
going to <code>eval-dispatch</code>. The value of the whole sequence is the value
of the last expression, so after the evaluation of the last expression
there is nothing left to do except continue at the entry point currently
held on the stack (which was saved by <code>ev-application</code> or <code>ev-begin</code>.)
Rather than setting up <code>continue</code> to arrange for <code>eval-dispatch</code> to
return here and then restoring <code>continue</code> from the stack and continuing
at that entry point, we restore <code>continue</code> from the stack before going
to <code>eval-dispatch</code>, so that <code>eval-dispatch</code> will continue at that entry
point after evaluating the expression.</p>
<pre><code class="language-scheme editable">ev-sequence
  (assign exp (op first-exp) (reg unev))
  (test (op last-exp?) (reg unev))
  (branch (label ev-sequence-last-exp))
  (save unev)
  (save env)
  (assign continue (label ev-sequence-continue))
  (goto (label eval-dispatch))
eveval-sequence-continue
  (restore env)
  (restore unev)
  (assign unev (op rest-exps) (reg unev))
  (goto (label ev-sequence))
eveval-sequence-last-exp
  (restore continue)
  (goto (label eval-dispatch))
</code></pre>
<h4 id="tail-recursion"><a class="header" href="#tail-recursion"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_775">Tail recursion</a></a></h4>
<p>In chapter 1 we said that the process
described by a procedure such as</p>
<pre><code class="language-scheme editable">(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x)
                 x)))
</code></pre>
<p>is an iterative process. Even though the procedure is syntactically
recursive (defined in terms of itself), it is not logically necessary
for an evaluator to save information in passing from one call to
<code>sqrt-iter</code> to the
next.<a href="book-Z-H-34.html#footnote_Temp_776">^[25]{.small}^</a>
An evaluator that can execute a procedure such as <code>sqrt-iter</code> without
requiring increasing storage as the procedure continues to call itself
is called a <em>tail-recursive</em> evaluator.
The metacircular implementation of the
evaluator in chapter 4 does not specify whether the evaluator is
tail-recursive, because that evaluator inherits its mechanism for saving
state from the underlying Scheme. With the explicit-control evaluator,
however, we can trace through the evaluation process to see when
procedure calls cause a net accumulation of information on the stack.</p>
<p>Our evaluator is tail-recursive, because in order to evaluate the final
expression of a sequence we transfer directly to <code>eval-dispatch</code> without
saving any information on the stack. Hence, evaluating the final
expression in a sequence -- even if it is a procedure call (as in
<code>sqrt-iter</code>, where the <code>if</code> expression, which is the last expression in
the procedure body, reduces to a call to <code>sqrt-iter</code>) -- will not cause
any information to be accumulated on the
stack.<a href="book-Z-H-34.html#footnote_Temp_777">^[26]{.small}^</a></p>
<p>If we did not think to take advantage of the fact that it was
unnecessary to save information in this case, we might have implemented
<code>eval-sequence</code> by treating all the expressions in a sequence in the
same way -- saving the registers, evaluating the expression, returning
to restore the registers, and repeating this until all the expressions
have been
evaluated:<a href="book-Z-H-34.html#footnote_Temp_778">^[27]{.small}^</a></p>
<pre><code class="language-scheme editable">ev-sequence
  (test (op no-more-exps?) (reg unev))
  (branch (label ev-sequence-end))
  (assign exp (op first-exp) (reg unev))
  (save unev)
  (save env)
  (assign continue (label ev-sequence-continue))
  (goto (label eval-dispatch))
eveval-sequence-continue
  (restore env)
  (restore unev)
  (assign unev (op rest-exps) (reg unev))
  (goto (label ev-sequence))
eveval-sequence-end
  (restore continue)
  (goto (reg continue))
</code></pre>
<p>This may seem like a minor change to our previous code for evaluation of
a sequence: The only difference is that we go through the save-restore
cycle for the last expression in a sequence as well as for the others.
The interpreter will still give the same value for any expression. But
this change is fatal to the tail-recursive implementation, because we
must now return after evaluating the final expression in a sequence in
order to undo the (useless) register saves. These extra saves will
accumulate during a nest of procedure calls. Consequently, processes
such as <code>sqrt-iter</code> will require space proportional to the number of
iterations rather than requiring constant space. This difference can be
significant. For example, with tail recursion, an
infinite loop can be expressed using only the procedure-call mechanism:</p>
<pre><code class="language-scheme editable">(define (count n)
  (newline)
  (display n)
  (count (+ n 1)))
</code></pre>
<p>Without tail recursion, such a procedure would eventually run out of
stack space, and expressing a true iteration would require some control
mechanism other than procedure call.</p>
<h3 id="543--conditionals-assignments-and-definitions"><a class="header" href="#543--conditionals-assignments-and-definitions"><a href="book-Z-H-4.html#%_toc_%_sec_5.4.3">5.4.3  Conditionals, Assignments, and Definitions</a></a></h3>
<p>As with the metacircular evaluator, special forms are
handled by selectively evaluating fragments of the expression. For an
<code>if</code> expression, we must evaluate the predicate and decide, based on the
value of predicate, whether to evaluate the consequent or the
alternative.</p>
<p>Before evaluating the predicate, we save the <code>if</code> expression itself so
that we can later extract the consequent or alternative. We also save
the environment, which we will need later in order to evaluate the
consequent or the alternative, and we save <code>continue</code>, which we will
need later in order to return to the evaluation of the expression that
is waiting for the value of the <code>if</code>.</p>
<pre><code class="language-scheme editable">ev-if
  (save exp)                    ; save expression for later
  (save env)
  (save continue)
  (assign continue (label ev-if-decide))
  (assign exp (op if-predicate) (reg exp))
  (goto (label eval-dispatch))  ; evaluate the predicate
</code></pre>
<p>When we return from evaluating the predicate, we test whether it was
true or false and, depending on the result, place either the consequent
or the alternative in <code>exp</code> before going to <code>eval-dispatch</code>. Notice that
restoring <code>env</code> and <code>continue</code> here sets up <code>eval-dispatch</code> to have the
correct environment and to continue at the right place to receive the
value of the <code>if</code> expression.</p>
<pre><code class="language-scheme editable">ev-if-decide
  (restore continue)
  (restore env)
  (restore exp)
  (test (op true?) (reg val))
  (branch (label ev-if-consequent))

ev-if-alternative
  (assign exp (op if-alternative) (reg exp))
  (goto (label eval-dispatch))
ev-if-consequent
  (assign exp (op if-consequent) (reg exp))
  (goto (label eval-dispatch))
</code></pre>
<h4 id="assignments-and-definitions-1"><a class="header" href="#assignments-and-definitions-1"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_779">Assignments and definitions</a></a></h4>
<p>Assignments are handled by <code>ev-assignment</code>, which is
reached from <code>eval-dispatch</code> with the assignment expression in <code>exp</code>.
The code at <code>ev-assignment</code> first evaluates the value part of the
expression and then installs the new value in the environment.
<code>Set-variable-value!</code> is assumed to be available as a machine operation.</p>
<pre><code class="language-scheme editable">ev-assignment
  (assign unev (op assignment-variable) (reg exp))
  (save unev)                   ; save variable for later
  (assign exp (op assignment-value) (reg exp))
  (save env)
  (save continue)
  (assign continue (label ev-assignment-1))
  (goto (label eval-dispatch))  ; evaluate the assignment value
ev-assignment-1
  (restore continue)
  (restore env)
  (restore unev)
  (perform
   (op set-variable-value!) (reg unev) (reg val) (reg env))
  (assign val (const ok))
  (goto (reg continue))
</code></pre>
<p>Definitions are handled in a similar way:</p>
<pre><code class="language-scheme editable">ev-definition
  (assign unev (op definition-variable) (reg exp))
  (save unev)                   ; save variable for later
  (assign exp (op definition-value) (reg exp))
  (save env)
  (save continue)
  (assign continue (label ev-definition-1))
  (goto (label eval-dispatch))  ; evaluate the definition value
ev-definition-1
  (restore continue)
  (restore env)
  (restore unev)
  (perform
   (op define-variable!) (reg unev) (reg val) (reg env))
  (assign val (const ok))
  (goto (reg continue))
</code></pre>
<p><strong>Exercise
5.23.</strong>  Extend the
evaluator to handle derived expressions such as <code>cond</code>, <code>let</code>, and so on
(section <a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a>). You may ''cheat''
and assume that the syntax transformers such as <code>cond-&gt;if</code> are available
as machine
operations.<a href="book-Z-H-34.html#footnote_Temp_781">^[28]{.small}^</a></p>
<p><strong>Exercise 5.24.</strong>  Implement <code>cond</code> as a
new basic special form without reducing it to <code>if</code>. You will have to
construct a loop that tests the predicates of successive <code>cond</code> clauses
until you find one that is true, and then use <code>ev-sequence</code> to evaluate
the actions of the clause.</p>
<p><strong>Exercise 5.25.</strong>  Modify
the evaluator so that it uses normal-order evaluation, based on the lazy
evaluator of section <a href="book-Z-H-27.html#%_sec_4.2">4.2</a>.</p>
<h3 id="544--running-the-evaluator"><a class="header" href="#544--running-the-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_5.4.4">5.4.4  Running the Evaluator</a></a></h3>
<p>With the implementation of
the explicit-control evaluator we come to the end of a development,
begun in chapter 1, in which we have explored successively more precise
models of the evaluation process. We started with the relatively
informal substitution model, then extended this in chapter 3 to the
environment model, which enabled us to deal with state and change. In
the metacircular evaluator of chapter 4, we used Scheme itself as a
language for making more explicit the environment structure constructed
during evaluation of an expression. Now, with register machines, we have
taken a close look at the evaluator's mechanisms for storage
management, argument passing, and control. At each new level of
description, we have had to raise issues and resolve ambiguities that
were not apparent at the previous, less precise treatment of evaluation.
To understand the behavior of the explicit-control evaluator, we can
simulate it and monitor its performance.</p>
<p>We will install a driver loop in our
evaluator machine. This plays the role of the <code>driver-loop</code> procedure of
section <a href="book-Z-H-26.html#%_sec_4.1.4">4.1.4</a>. The evaluator will
repeatedly print a prompt, read an expression, evaluate the expression
by going to <code>eval-dispatch</code>, and print the result. The following
instructions form the beginning of the explicit-control evaluator's
controller
sequence:<a href="book-Z-H-34.html#footnote_Temp_784">^[29]{.small}^</a></p>
<pre><code class="language-scheme editable">read-eval-print-loop
  (perform (op initialize-stack))
  (perform
   (op prompt-for-input) (const ";;; EC-Eval input:"))
  (assign exp (op read))
  (assign env (op get-global-environment))
  (assign continue (label print-result))
  (goto (label eval-dispatch))
</code></pre>
<pre><code class="language-scheme editable">print-result
  (perform
   (op announce-output) (const ";;; EC-Eval value:"))
  (perform (op user-print) (reg val))
  (goto (label read-eval-print-loop))
</code></pre>
<p>When we encounter an error in a procedure
(such as the ''unknown procedure type error'' indicated at
<code>apply-dispatch</code>), we print an error message and return to the driver
loop.<a href="book-Z-H-34.html#footnote_Temp_785">^[30]{.small}^</a></p>
<pre><code class="language-scheme editable">unknown-expression-type
  (assign val (const unknown-expression-type-error))
  (goto (label signal-error))
</code></pre>
<pre><code class="language-scheme editable">unknown-procedure-type
  (restore continue)    ; clean up stack (from ``apply-dispatch``)
  (assign val (const unknown-procedure-type-error))
  (goto (label signal-error))
</code></pre>
<pre><code class="language-scheme editable">signal-error
  (perform (op user-print) (reg val))
  (goto (label read-eval-print-loop))
</code></pre>
<p>For the purposes of the simulation, we initialize the stack each time
through the driver loop, since it might not be empty after an error
(such as an undefined variable) interrupts an
evaluation.<a href="book-Z-H-34.html#footnote_Temp_786">^[31]{.small}^</a></p>
<p>If we combine all the code fragments presented in
sections
<a href="book-Z-H-34.html#%_sec_5.4.1">5.4.1</a>-<a href="book-Z-H-34.html#%_sec_5.4.4">5.4.4</a>,
we can create an evaluator machine model that we can run using the
register-machine simulator of section <a href="book-Z-H-32.html#%_sec_5.2">5.2</a>.</p>
<pre><code class="language-scheme editable">(define eceval
  (make-machine
   '(exp env val proc argl continue unev)
   eceval-operations
  '(
    read-eval-print-loop
      &lt;*entire machine controller as given above*&gt;
   )))
</code></pre>
<p>We must define Scheme procedures to simulate the operations used as
primitives by the evaluator. These are the same procedures we used for
the metacircular evaluator in section <a href="book-Z-H-26.html#%_sec_4.1">4.1</a>,
together with the few additional ones defined in footnotes throughout
section <a href="book-Z-H-34.html#%_sec_5.4">5.4</a>.</p>
<pre><code class="language-scheme editable">(define eceval-operations
  (list (list 'self-evaluating? self-evaluating)
        &lt;*complete list of operations for eceval machine*&gt;))
</code></pre>
<p>Finally, we can initialize the global environment and run the evaluator:</p>
<pre><code class="language-scheme editable">(define the-global-environment (setup-environment))

(start eceval)
</code></pre>
<p><em>;;; EC-Eval input:</em></p>
<pre><code class="language-scheme editable">(define (append x y)
  (if (null? x)
      y
      (cons (car x)
            (append (cdr x) y))))
</code></pre>
<p><em>;;; EC-Eval value:</em>
<em><code>ok</code></em>
<em>;;; EC-Eval input:</em></p>
<pre><code class="language-scheme editable">(append '(a b c) '(d e f))
</code></pre>
<p><em>;;; EC-Eval value:</em>
<em><code>(a b c d e f)</code></em></p>
<p>Of course, evaluating expressions in this way will take much longer than
if we had directly typed them into Scheme, because of the multiple
levels of simulation involved. Our expressions are evaluated by the
explicit-control-evaluator machine, which is being simulated by a Scheme
program, which is itself being evaluated by the Scheme interpreter.</p>
<h4 id="monitoring-the-performance-of-the-evaluator"><a class="header" href="#monitoring-the-performance-of-the-evaluator"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_787">Monitoring the performance of the evaluator</a></a></h4>
<p>Simulation can be a powerful tool to
guide the implementation of evaluators. Simulations make it easy not
only to explore variations of the register-machine design but also to
monitor the performance of the simulated evaluator. For example, one
important factor in performance is how efficiently the evaluator uses
the stack. We can observe the number of stack operations required to
evaluate various expressions by defining the evaluator register machine
with the version of the simulator that collects statistics on stack use
(section <a href="book-Z-H-32.html#%_sec_5.2.4">5.2.4</a>), and adding an
instruction at the evaluator's <code>print-result</code> entry point to print the
statistics:</p>
<pre><code class="language-scheme editable">print-result
  (perform (op print-stack-statistics)); added instruction
  (perform
   (op announce-output) (const ";;; EC-Eval value:"))
  ... ; same as before
</code></pre>
<p>Interactions with the evaluator now look like this:</p>
<p><em>;;; EC-Eval input:</em></p>
<pre><code class="language-scheme editable">(define (factorial n)
  (if (= n 1)
      1
      (* (factorial (- n 1)) n)))
</code></pre>
<p><em><code>(total-pushes = 3 maximum-depth = 3)</code></em>
<em>;;; EC-Eval value:</em>
<em><code>ok</code></em>
<em>;;; EC-Eval input:</em></p>
<pre><code class="language-scheme editable">(factorial 5)
</code></pre>
<p><em><code>(total-pushes = 144 maximum-depth = 28)</code></em>
<em>;;; EC-Eval value:</em>
<em><code>120</code></em></p>
<p>Note that the driver loop of the evaluator reinitializes the stack at
the start of each interaction, so that the statistics printed will refer
only to stack operations used to evaluate the previous expression.</p>
<p><strong>Exercise
5.26.</strong>  Use the monitored
stack to explore the tail-recursive property of the evaluator
(section <a href="book-Z-H-34.html#%_sec_5.4.2">5.4.2</a>). Start the evaluator and
define the iterative <code>factorial</code> procedure from
section <a href="book-Z-H-11.html#%_sec_1.2.1">1.2.1</a>:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (define (iter product counter)
    (if (&gt; counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
</code></pre>
<p>Run the procedure with some small values of <em>n</em>. Record the maximum
stack depth and the number of pushes required to compute <em>n</em>! for each
of these values.</p>
<p>a. You will find that the maximum depth required to evaluate <em>n</em>! is
independent of <em>n</em>. What is that depth?</p>
<p>b. Determine from your data a formula in terms of <em>n</em> for the total
number of push operations used in evaluating <em>n</em>! for any <em>n</em>
[&gt;]{.underline} 1. Note that the number of operations used is a linear
function of <em>n</em> and is thus determined by two constants.</p>
<p><strong>Exercise 5.27.</strong>  For comparison with
exercise <a href="book-Z-H-34.html#%_thm_5.26">5.26</a>, explore the behavior of
the following procedure for computing factorials recursively:</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (if (= n 1)
      1
      (* (factorial (- n 1)) n)))
</code></pre>
<p>By running this procedure with the monitored stack, determine, as a
function of <em>n</em>, the maximum depth of the stack and the total number of
pushes used in evaluating <em>n</em>! for <em>n</em> [&gt;]{.underline} 1. (Again, these
functions will be linear.) Summarize your experiments by filling in the
following table with the appropriate expressions in terms of <em>n</em>:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: left"></th><th style="text-align: left">Maximum depth</th><th style="text-align: left">Number of pushes</th></tr></thead><tbody>
<tr><td style="text-align: left">Recursive factorial</td><td style="text-align: left"></td><td style="text-align: left"></td></tr>
<tr><td style="text-align: left">Iterative factorial</td><td style="text-align: left"></td><td style="text-align: left"></td></tr>
</tbody></table>
</div>
<p>The maximum depth is a measure of the amount of space used by the
evaluator in carrying out the computation, and the number of pushes
correlates well with the time required.</p>
<p><strong>Exercise 5.28.</strong>  Modify
the definition of the evaluator by changing <code>eval-sequence</code> as described
in section <a href="book-Z-H-34.html#%_sec_5.4.2">5.4.2</a> so that the evaluator
is no longer tail-recursive. Rerun your experiments from
exercises <a href="book-Z-H-34.html#%_sec_5.26">5.26</a>
and <a href="book-Z-H-34.html#%_sec_5.27">5.27</a> to demonstrate that both
versions of the <code>factorial</code> procedure now require space that grows
linearly with their input.</p>
<p><strong>Exercise 5.29.</strong>  Monitor the stack
operations in the tree-recursive Fibonacci computation:</p>
<pre><code class="language-scheme editable">(define (fib n)
  (if (&lt; n 2)
      n
      (+ (fib (- n 1)) (fib (- n 2)))))
</code></pre>
<p>a. Give a formula in terms of <em>n</em> for the maximum depth of the stack
required to compute <em>Fib</em>(<em>n</em>) for <em>n</em> [&gt;]{.underline} 2. Hint: In
section <a href="book-Z-H-11.html#%_sec_1.2.2">1.2.2</a> we argued that the space
used by this process grows linearly with <em>n</em>.</p>
<p>b. Give a formula for the total number of pushes used to compute
<em>Fib</em>(<em>n</em>) for <em>n</em> [&gt;]{.underline} 2. You should find that the number
of pushes (which correlates well with the time used) grows exponentially
with <em>n</em>. Hint: Let <em>S</em>(<em>n</em>) be the number of pushes used in computing
<em>Fib</em>(<em>n</em>). You should be able to argue that there is a formula that
expresses <em>S</em>(<em>n</em>) in terms of <em>S</em>(<em>n</em> - 1), <em>S</em>(<em>n</em> - 2), and some
fixed ''overhead'' constant <em>k</em> that is independent of <em>n</em>. Give the
formula, and say what <em>k</em> is. Then show that <em>S</em>(<em>n</em>) can be expressed
as <em>a</em> <em>Fib</em>(<em>n</em> + 1) + <em>b</em> and give the values of <em>a</em> and <em>b</em>.</p>
<p><strong>Exercise 5.30.</strong>  Our
evaluator currently catches and signals only two kinds of errors --
unknown expression types and unknown procedure types. Other errors will
take us out of the evaluator read-eval-print loop. When we run the
evaluator using the register-machine simulator, these errors are caught
by the underlying Scheme system. This is analogous to the computer
crashing when a user program makes an
error.<a href="book-Z-H-34.html#footnote_Temp_793">^[32]{.small}^</a>
It is a large project to make a real error system work, but it is well
worth the effort to understand what is involved here.</p>
<p>a. Errors that occur in the evaluation process, such as an attempt to
access an unbound variable, could be caught by changing the lookup
operation to make it return a distinguished condition code, which cannot
be a possible value of any user variable. The evaluator can test for
this condition code and then do what is necessary to go to
<code>signal-error</code>. Find all of the places in the evaluator where such a
change is necessary and fix them. This is lots of work.</p>
<p>b. Much worse is the problem of handling errors that are signaled by
applying primitive procedures, such as an attempt to divide by zero or
an attempt to extract the <code>car</code> of a symbol. In a professionally written
high-quality system, each primitive application is checked for safety as
part of the primitive. For example, every call to <code>car</code> could first
check that the argument is a pair. If the argument is not a pair, the
application would return a distinguished condition code to the
evaluator, which would then report the failure. We could arrange for
this in our register-machine simulator by making each primitive
procedure check for applicability and returning an appropriate
distinguished condition code on failure. Then the <code>primitive-apply</code> code
in the evaluator can check for the condition code and go to
<code>signal-error</code> if necessary. Build this structure and make it work. This
is a major project.</p>
<hr />
<p>^[19]{.small}^](book-Z-H-34.html#call_footnote_Temp_765)
See Batali et al. 1982 for more information on the chip
and the method by which it was designed.</p>
<p>^[20]{.small}^](book-Z-H-34.html#call_footnote_Temp_767)
In our controller, the dispatch is written as a sequence of <code>test</code> and
<code>branch</code> instructions. Alternatively, it could have been written in a
data-directed style (and in a real system it probably would have been)
to avoid the need to perform sequential tests and to facilitate the
definition of new expression types. A machine designed to run Lisp would
probably include a <code>dispatch-on-type</code> instruction that would efficiently
execute such data-directed dispatches.</p>
<p>^[21]{.small}^](book-Z-H-34.html#call_footnote_Temp_770)
This is an important but subtle point in translating algorithms from a
procedural language, such as Lisp, to a register-machine language. As an
alternative to saving only what is needed, we could save all the
registers (except <code>val</code>) before each recursive call. This is called a
<em>framed-stack</em> discipline. This would work
but might save more registers than necessary; this could be an important
consideration in a system where stack operations are expensive. Saving
registers whose contents will not be needed later may also hold onto
useless data that could otherwise be garbage-collected, freeing space to
be reused.</p>
<p>^[22]{.small}^](book-Z-H-34.html#call_footnote_Temp_771)
We add to the evaluator data-structure procedures in
section <a href="book-Z-H-26.html#%_sec_4.1.3">4.1.3</a> the following two
procedures for manipulating argument lists:</p>
<pre><code class="language-scheme editable">(define (empty-arglist) '())
</code></pre>
<pre><code class="language-scheme editable">(define (adjoin-arg arg arglist)
  (append arglist (list arg)))
</code></pre>
<p>We also use an additional syntax procedure to test for the last operand
in a combination:</p>
<pre><code class="language-scheme editable">(define (last-operand? ops)
  (null? (cdr ops)))
</code></pre>
<p>^[23]{.small}^](book-Z-H-34.html#call_footnote_Temp_772)
The optimization of treating the last operand specially
is known as <em>evlis tail recursion</em> (see Wand 1980). We
could be somewhat more efficient in the argument evaluation loop if we
made evaluation of the first operand a special case too. This would
permit us to postpone initializing <code>argl</code> until after evaluating the
first operand, so as to avoid saving <code>argl</code> in this case. The compiler
in section <a href="book-Z-H-35.html#%_sec_5.5">5.5</a> performs this optimization.
(Compare the <code>construct-arglist</code> procedure of
section <a href="book-Z-H-35.html#%_sec_5.5.3">5.5.3</a>.)</p>
<p>^[24]{.small}^](book-Z-H-34.html#call_footnote_Temp_773)
The order of operand evaluation in the metacircular evaluator is
determined by the order of evaluation of the arguments to <code>cons</code> in the
procedure <code>list-of-values</code> of
section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a> (see
exercise <a href="book-Z-H-26.html#%_thm_4.1">4.1</a>).</p>
<p>^[25]{.small}^](book-Z-H-34.html#call_footnote_Temp_776)
We saw in section <a href="book-Z-H-31.html#%_sec_5.1">5.1</a> how to implement
such a process with a register machine that had no stack; the state of
the process was stored in a fixed set of registers.</p>
<p>^[26]{.small}^](book-Z-H-34.html#call_footnote_Temp_777)
This implementation of tail recursion in <code>ev-sequence</code> is one variety of
a well-known optimization technique used by many compilers. In compiling
a procedure that ends with a procedure call, one can replace the call by
a jump to the called procedure's entry point. Building this strategy
into the interpreter, as we have done in this section, provides the
optimization uniformly throughout the language.</p>
<p>^[27]{.small}^](book-Z-H-34.html#call_footnote_Temp_778)
We can define <code>no-more-exps?</code> as follows:</p>
<pre><code class="language-scheme editable">(define (no-more-exps? seq) (null? seq))
</code></pre>
<p>^[28]{.small}^](book-Z-H-34.html#call_footnote_Temp_781)
This isn't really cheating. In an actual implementation built from
scratch, we would use our explicit-control evaluator to interpret a
Scheme program that performs source-level transformations like
<code>cond-&gt;if</code> in a syntax phase that runs before execution.</p>
<p>^[29]{.small}^](book-Z-H-34.html#call_footnote_Temp_784)
We assume here that <code>read</code> and the various printing operations are
available as primitive machine operations, which is useful for our
simulation, but completely unrealistic in practice. These are actually
extremely complex operations. In practice, they would be implemented
using low-level input-output operations such as transferring single
characters to and from a device.</p>
<p>To support the <code>get-global-environment</code> operation we define</p>
<pre><code class="language-scheme editable">(define the-global-environment (setup-environment))
</code></pre>
<pre><code class="language-scheme editable">(define (get-global-environment)
  the-global-environment)
</code></pre>
<p>^[30]{.small}^](book-Z-H-34.html#call_footnote_Temp_785)
There are other errors that we would like the interpreter to handle, but
these are not so simple. See
exercise <a href="book-Z-H-34.html#%_thm_5.30">5.30</a>.</p>
<p>^[31]{.small}^](book-Z-H-34.html#call_footnote_Temp_786)
We could perform the stack initialization only after errors, but doing
it in the driver loop will be convenient for monitoring the evaluator's
performance, as described below.</p>
<p>^[32]{.small}^](book-Z-H-34.html#call_footnote_Temp_793)
Regrettably, this is the normal state of affairs in
conventional compiler-based language systems such as C.
In UNIX ^<em>TM</em>^ the system
''dumps core,'' and in DOS/Windows ^<em>TM</em>^ it becomes catatonic. The
Macintosh ^<em>TM</em>^ displays a picture of an exploding bomb and offers you
the opportunity to reboot the computer -- if you're lucky.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="55--compilation"><a class="header" href="#55--compilation"><a href="book-Z-H-4.html#%_toc_%_sec_5.5">5.5  Compilation</a></a></h2>
<p>The explicit-control evaluator of
section <a href="book-Z-H-34.html#%_sec_5.4">5.4</a> is a register machine whose
controller interprets Scheme programs. In this section we will see how
to run Scheme programs on a register machine whose controller is not a
Scheme interpreter.</p>
<p>The explicit-control evaluator machine is
universal -- it can carry out any computational process that can be
described in Scheme. The evaluator's controller orchestrates the use of
its data paths to perform the desired computation. Thus, the
evaluator's data paths are universal: They are sufficient to perform
any computation we desire, given an appropriate
controller.<a href="book-Z-H-35.html#footnote_Temp_794">^[33]{.small}^</a></p>
<p>Commercial general-purpose computers are
register machines organized around a collection of registers and
operations that constitute an efficient and convenient universal set of
data paths. The controller for a general-purpose machine is an
interpreter for a register-machine language like the one we have been
using. This language is called the <em>native language</em> of
the machine, or simply <em>machine language</em>. Programs
written in machine language are sequences of instructions that use the
machine's data paths. For example, the explicit-control
evaluator's instruction sequence can be thought of as a
machine-language program for a general-purpose computer rather than as
the controller for a specialized interpreter machine.</p>
<p>There are two common strategies for
bridging the gap between higher-level languages and register-machine
languages. The explicit-control evaluator illustrates the strategy of
interpretation. An interpreter written in the native language of a
machine configures the machine to execute programs written in a language
(called the <em>source language</em>) that may differ from the
native language of the machine performing the evaluation. The primitive
procedures of the source language are implemented as a library of
subroutines written in the native language of the given machine. A
program to be interpreted (called the <em>source program</em>)
is represented as a data structure. The interpreter traverses this data
structure, analyzing the source program. As it does so, it simulates the
intended behavior of the source program by calling appropriate primitive
subroutines from the library.</p>
<p>In this section, we explore the alternative strategy of <em>compilation</em>. A
compiler for a given source language and machine translates a source
program into an equivalent program (called the <em>object
program</em>) written in the machine's native language. The compiler that
we implement in this section translates programs written in Scheme into
sequences of instructions to be executed using the explicit-control
evaluator machine's data
paths.<a href="book-Z-H-35.html#footnote_Temp_795">^[34]{.small}^</a></p>
<p>Compared with interpretation, compilation can provide a great increase
in the efficiency of program execution, as we will explain below in the
overview of the compiler. On the other hand, an interpreter provides a
more powerful environment for interactive program development and
debugging, because the source program being executed is available at run
time to be examined and modified. In addition, because the entire
library of primitives is present, new programs can be constructed and
added to the system during debugging.</p>
<p>In view of the complementary advantages of compilation and
interpretation, modern program-development environments pursue a mixed
strategy. Lisp interpreters are generally organized so that interpreted
procedures and compiled procedures can call each other. This enables a
programmer to compile those parts of a program that are assumed to be
debugged, thus gaining the efficiency advantage of compilation, while
retaining the interpretive mode of execution for those parts of the
program that are in the flux of interactive development and debugging.
In section <a href="book-Z-H-35.html#%_sec_5.5.7">5.5.7</a>, after we have
implemented the compiler, we will show how to interface it with our
interpreter to produce an integrated interpreter-compiler development
system.</p>
<h4 id="an-overview-of-the-compiler"><a class="header" href="#an-overview-of-the-compiler"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_796">An overview of the compiler</a></a></h4>
<p>Our compiler is much like our
interpreter, both in its structure and in the function it performs.
Accordingly, the mechanisms used by the compiler for analyzing
expressions will be similar to those used by the interpreter. Moreover,
to make it easy to interface compiled and interpreted code, we will
design the compiler to generate code that obeys the same conventions of
register usage as the interpreter: The environment will
be kept in the <code>env</code> register, argument lists will be accumulated in
<code>argl</code>, a procedure to be applied will be in <code>proc</code>, procedures will
return their answers in <code>val</code>, and the location to which a procedure
should return will be kept in <code>continue</code>. In general, the compiler
translates a source program into an object program that performs
essentially the same register operations as would the interpreter in
evaluating the same source program.</p>
<p>This description suggests a strategy for implementing a rudimentary
compiler: We traverse the expression in the same way the interpreter
does. When we encounter a register instruction that the interpreter
would perform in evaluating the expression, we do not execute the
instruction but instead accumulate it into a sequence. The resulting
sequence of instructions will be the object code. Observe the
efficiency advantage of compilation over
interpretation. Each time the interpreter evaluates an expression --
for example, <code>(f 84 96)</code> -- it performs the work of classifying the
expression (discovering that this is a procedure application) and
testing for the end of the operand list (discovering that there are two
operands). With a compiler, the expression is analyzed only once, when
the instruction sequence is generated at compile time. The object code
produced by the compiler contains only the instructions that evaluate
the operator and the two operands, assemble the argument list, and apply
the procedure (in <code>proc</code>) to the arguments (in <code>argl</code>).</p>
<p>This is the same kind of optimization we implemented in
the analyzing evaluator of
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>. But there are further
opportunities to gain efficiency in compiled code. As the interpreter
runs, it follows a process that must be applicable to any expression in
the language. In contrast, a given segment of compiled code is meant to
execute some particular expression. This can make a big difference, for
example in the use of the stack to save registers. When the interpreter
evaluates an expression, it must be prepared for any contingency. Before
evaluating a subexpression, the interpreter saves all registers that
will be needed later, because the subexpression might require an
arbitrary evaluation. A compiler, on the other hand, can exploit the
structure of the particular expression it is processing to generate code
that avoids unnecessary stack operations.</p>
<p>As a case in point, consider the combination <code>(f 84 96)</code>. Before the
interpreter evaluates the operator of the combination, it prepares for
this evaluation by saving the registers containing the operands and the
environment, whose values will be needed later. The interpreter then
evaluates the operator to obtain the result in <code>val</code>, restores the saved
registers, and finally moves the result from <code>val</code> to <code>proc</code>. However,
in the particular expression we are dealing with, the operator is the
symbol <code>f</code>, whose evaluation is accomplished by the machine operation
<code>lookup-variable-value</code>, which does not alter any registers. The
compiler that we implement in this section will take advantage of this
fact and generate code that evaluates the operator using the instruction</p>
<pre><code class="language-scheme editable">(assign proc (op lookup-variable-value) (const f) (reg env))
</code></pre>
<p>This code not only avoids the unnecessary saves and restores but also
assigns the value of the lookup directly to <code>proc</code>, whereas the
interpreter would obtain the result in <code>val</code> and then move this to
<code>proc</code>.</p>
<p>A compiler can also optimize access to the environment. Having analyzed
the code, the compiler can in many cases know in which frame a
particular variable will be located and access that frame directly,
rather than performing the <code>lookup-variable-value</code> search. We will
discuss how to implement such variable access in
section <a href="book-Z-H-35.html#%_sec_5.5.6">5.5.6</a>. Until then, however, we
will focus on the kind of register and stack optimizations described
above. There are many other optimizations that can be performed by a
compiler, such as coding primitive operations ''in line'' instead of
using a general <code>apply</code> mechanism (see
exercise <a href="book-Z-H-35.html#%_thm_5.38">5.38</a>); but we will not emphasize
these here. Our main goal in this section is to illustrate the
compilation process in a simplified (but still interesting) context.</p>
<h3 id="551--structure-of-the-compiler"><a class="header" href="#551--structure-of-the-compiler"><a href="book-Z-H-4.html#%_toc_%_sec_5.5.1">5.5.1  Structure of the Compiler</a></a></h3>
<p>In
section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a> we modified our original
metacircular interpreter to separate analysis from execution. We
analyzed each expression to produce an execution procedure that took an
environment as argument and performed the required operations. In our
compiler, we will do essentially the same analysis. Instead of producing
execution procedures, however, we will generate sequences of
instructions to be run by our register machine.</p>
<p>The procedure <code>compile</code> is the top-level dispatch in the compiler. It
corresponds to the <code>eval</code> procedure of
section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>, the <code>analyze</code> procedure
of section <a href="book-Z-H-26.html#%_sec_4.1.7">4.1.7</a>, and the
<code>eval-dispatch</code> entry point of the explicit-control-evaluator in
section <a href="book-Z-H-34.html#%_sec_5.4.1">5.4.1</a>. The compiler, like the
interpreters, uses the expression-syntax procedures
defined in
section <a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a>.<a href="book-Z-H-35.html#footnote_Temp_797">^[35]{.small}^</a>
<code>Compile</code> performs a case analysis on the syntactic type of the
expression to be compiled. For each type of expression, it dispatches to
a specialized <em>code generator</em>:</p>
<pre><code class="language-scheme editable">(define (compile exp target linkage)
  (cond ((self-evaluating? exp)
         (compile-self-evaluating exp target linkage))
        ((quoted? exp) (compile-quoted exp target linkage))
        ((variable? exp)
         (compile-variable exp target linkage))
        ((assignment? exp)
         (compile-assignment exp target linkage))
        ((definition? exp)
         (compile-definition exp target linkage))
        ((if? exp) (compile-if exp target linkage))
        ((lambda? exp) (compile-lambda exp target linkage))
        ((begin? exp)
         (compile-sequence (begin-actions exp)
                           target
                           linkage))
        ((cond? exp) (compile (cond-&gt;if exp) target linkage))
        ((application? exp)
         (compile-application exp target linkage))
        (else
         (error "Unknown expression type -- COMPILE" exp))))
</code></pre>
<h4 id="targets-and-linkages"><a class="header" href="#targets-and-linkages"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_798">Targets and linkages</a></a></h4>
<p><code>Compile</code> and the code generators that it calls take two
arguments in addition to the expression to compile. There is a
<em>target</em>, which specifies the register in which the
compiled code is to return the value of the expression. There is also a
<em>linkage descriptor</em>, which describes how the code
resulting from the compilation of the expression should proceed when it
has finished its execution. The linkage descriptor can require that the
code do one of the following three things:</p>
<ul>
<li>continue at the next instruction in sequence (this is
specified by the linkage descriptor <code>next</code>),</li>
<li>return from the procedure being compiled (this is specified
by the linkage descriptor <code>return</code>), or</li>
<li>jump to a named entry point (this is specified by using the designated
label as the linkage descriptor).</li>
</ul>
<p>For example, compiling the expression <code>5</code> (which is self-evaluating)
with a target of the <code>val</code> register and a linkage of <code>next</code> should
produce the instruction</p>
<pre><code class="language-scheme editable">(assign val (const 5))
</code></pre>
<p>Compiling the same expression with a linkage of <code>return</code> should produce
the instructions</p>
<pre><code class="language-scheme editable">(assign val (const 5))
(goto (reg continue))
</code></pre>
<p>In the first case, execution will continue with the next instruction in
the sequence. In the second case, we will return from a procedure call.
In both cases, the value of the expression will be placed into the
target <code>val</code> register.</p>
<h4 id="instruction-sequences-and-stack-usage"><a class="header" href="#instruction-sequences-and-stack-usage"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_799">Instruction sequences and stack usage</a></a></h4>
<p>Each code generator returns an
<em>instruction sequence</em> containing the object code it has generated for
the expression. Code generation for a compound expression is
accomplished by combining the output from simpler code generators for
component expressions, just as evaluation of a compound expression is
accomplished by evaluating the component expressions.</p>
<p>The simplest method for combining instruction sequences is a procedure
called <code>append-instruction-sequences</code>. It takes as
arguments any number of instruction sequences that are to be executed
sequentially; it appends them and returns the combined sequence. That
is, if &lt;*<em>seq</em><del>1</del><em>&gt; and &lt;*<em>seq</em><del>2</del></em>&gt; are sequences of instructions,
then evaluating</p>
<p><code>(append-instruction-sequences &lt;</code><strong><code>seq</code><em><del><code>1</code></del></em><code>&gt; &lt;</code></strong><code>seq</code><em><del><code>2</code></del></em><code>&gt;)</code></p>
<p>produces the sequence</p>
<p><code>\&lt;</code><strong><code>seq</code><em><del><code>1</code></del></em><code>&gt;\</code>
<code>\&lt;</code></strong><code>seq</code><em><del><code>2</code></del></em><code>&gt;\</code></p>
<p>Whenever registers might need to be saved, the
compiler's code generators use <code>preserving</code>, which is a
more subtle method for combining instruction sequences. <code>Preserving</code>
takes three arguments: a set of registers and two instruction sequences
that are to be executed sequentially. It appends the sequences in such a
way that the contents of each register in the set is preserved over the
execution of the first sequence, if this is needed for the execution of
the second sequence. That is, if the first sequence modifies the
register and the second sequence actually needs the register's original
contents, then <code>preserving</code> wraps a <code>save</code> and a <code>restore</code> of the
register around the first sequence before appending the sequences.
Otherwise, <code>preserving</code> simply returns the appended instruction
sequences. Thus, for example,</p>
<p><code>(preserving (list &lt;</code><strong><code>reg</code><em><del><code>1</code></del></em><code>&gt; &lt;</code></strong><code>reg</code><em><del><code>2</code></del></em><code>&gt;) &lt;</code><strong><code>seq</code><em><del><code>1</code></del></em><code>&gt; &lt;</code></strong><code>seq</code><em><del><code>2</code></del></em><code>&gt;)</code></p>
<p>produces one of the following four sequences of instructions, depending
on how &lt;*<em>seq</em><del>1</del><em>&gt; and &lt;*<em>seq</em><del>2</del></em>&gt; use &lt;*<em>reg</em><del>1</del><em>&gt; and
&lt;*<em>reg</em><del>2</del></em>&gt;:</p>
<p><img src="ch5-Z-G-9.gif" alt="" /></p>
<p>By using <code>preserving</code> to combine instruction sequences the compiler
avoids unnecessary stack operations. This also isolates the details of
whether or not to generate <code>save</code> and <code>restore</code> instructions within the
<code>preserving</code> procedure, separating them from the concerns that arise in
writing each of the individual code generators. In fact no <code>save</code> or
<code>restore</code> instructions are explicitly produced by the code generators.</p>
<p>In principle, we could represent an instruction sequence simply as a
list of instructions. <code>Append-instruction-sequences</code> could then combine
instruction sequences by performing an ordinary list <code>append</code>. However,
<code>preserving</code> would then be a complex operation, because it would have to
analyze each instruction sequence to determine how the sequence uses its
registers. <code>Preserving</code> would be inefficient as well as complex, because
it would have to analyze each of its instruction sequence arguments,
even though these sequences might themselves have been constructed by
calls to <code>preserving</code>, in which case their parts would have already been
analyzed. To avoid such repetitious analysis we will associate with each
instruction sequence some information about its register use. When we
construct a basic instruction sequence we will provide this information
explicitly, and the procedures that combine instruction sequences will
derive register-use information for the combined sequence from the
information associated with the component sequences.</p>
<p>An instruction sequence will contain three pieces of information:</p>
<ul>
<li>the set of registers that must be initialized before the instructions
in the sequence are executed (these registers are said to be <em>needed</em>
by the sequence),</li>
<li>the set of registers whose values are modified by the instructions in
the sequence, and</li>
<li>the actual instructions (also called <em>statements</em>) in the sequence.</li>
</ul>
<p>We will represent an instruction sequence as a list of its three parts.
The constructor for instruction sequences is thus</p>
<pre><code class="language-scheme editable">(define (make-instruction-sequence needs modifies statements)
  (list needs modifies statements))
</code></pre>
<p>For example, the two-instruction sequence that looks up the value of the
variable <code>x</code> in the current environment, assigns the result to <code>val</code>,
and then returns, requires registers <code>env</code> and <code>continue</code> to have been
initialized, and modifies register <code>val</code>. This sequence would therefore
be constructed as</p>
<pre><code class="language-scheme editable">(make-instruction-sequence '(env continue) '(val)
 '((assign val
         (op lookup-variable-value) (const x) (reg env))
   (goto (reg continue))))
</code></pre>
<p>We sometimes need to construct an instruction sequence with no
statements:</p>
<pre><code class="language-scheme editable">(define (empty-instruction-sequence)
  (make-instruction-sequence '() '() '()))
</code></pre>
<p>The procedures for combining instruction sequences are shown in
section <a href="book-Z-H-35.html#%_sec_5.5.4">5.5.4</a>.</p>
<p><strong>Exercise 5.31.</strong>  In
evaluating a procedure application, the explicit-control evaluator
always saves and restores the <code>env</code> register around the evaluation of
the operator, saves and restores <code>env</code> around the evaluation of each
operand (except the final one), saves and restores <code>argl</code> around the
evaluation of each operand, and saves and restores <code>proc</code> around the
evaluation of the operand sequence. For each of the following
combinations, say which of these <code>save</code> and <code>restore</code> operations are
superfluous and thus could be eliminated by the compiler's <code>preserving</code>
mechanism:</p>
<pre><code class="language-scheme editable">(f 'x 'y)

((f) 'x 'y)

(f (g 'x) y)

(f (g 'x) 'y)
</code></pre>
<p><strong>Exercise 5.32.</strong>  Using
the <code>preserving</code> mechanism, the compiler will avoid saving and restoring
<code>env</code> around the evaluation of the operator of a combination in the case
where the operator is a symbol. We could also build such optimizations
into the evaluator. Indeed, the explicit-control evaluator of
section <a href="book-Z-H-34.html#%_sec_5.4">5.4</a> already performs a similar
optimization, by treating combinations with no operands as a special
case.</p>
<p>a. Extend the explicit-control evaluator to recognize as a separate
class of expressions combinations whose operator is a symbol, and to
take advantage of this fact in evaluating such expressions.</p>
<p>b. Alyssa P. Hacker suggests that by extending the evaluator to
recognize more and more special cases we could incorporate all the
compiler's optimizations, and that this would eliminate the advantage
of compilation altogether. What do you think of this idea?</p>
<h3 id="552--compiling-expressions"><a class="header" href="#552--compiling-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_5.5.2">5.5.2  Compiling Expressions</a></a></h3>
<p>In this section and the next we implement the code generators to which
the <code>compile</code> procedure dispatches.</p>
<h4 id="compiling-linkage-code"><a class="header" href="#compiling-linkage-code"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_802">Compiling linkage code</a></a></h4>
<p>In general, the output of each code generator will end
with instructions -- generated by the procedure <code>compile-linkage</code> --
that implement the required linkage. If the linkage is <code>return</code> then we
must generate the instruction <code>(goto (reg continue))</code>. This needs the
<code>continue</code> register and does not modify any registers. If the linkage is
<code>next</code>, then we needn't include any additional instructions. Otherwise,
the linkage is a label, and we generate a <code>goto</code> to that label, an
instruction that does not need or modify any
registers.<a href="book-Z-H-35.html#footnote_Temp_803">^[36]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (compile-linkage linkage)
  (cond ((eq? linkage 'return)
         (make-instruction-sequence '(continue) '()
          '((goto (reg continue)))))
        ((eq? linkage 'next)
         (empty-instruction-sequence))
        (else
         (make-instruction-sequence '() '()
          `((goto (label ,linkage)))))))
</code></pre>
<p>The linkage code is appended to an instruction sequence by <code>preserving</code>
the <code>continue</code> register, since a <code>return</code> linkage will require the
<code>continue</code> register: If the given instruction sequence modifies
<code>continue</code> and the linkage code needs it, <code>continue</code> will be saved and
restored.</p>
<pre><code class="language-scheme editable">(define (end-with-linkage linkage instruction-sequence)
  (preserving '(continue)
    instruction-sequence
    (compile-linkage linkage)))
</code></pre>
<h4 id="compiling-simple-expressions"><a class="header" href="#compiling-simple-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_804">Compiling simple expressions</a></a></h4>
<p>The code generators for
self-evaluating expressions, quotations, and variables construct
instruction sequences that assign the required value to the target
register and then proceed as specified by the linkage descriptor.</p>
<pre><code class="language-scheme editable">(define (compile-self-evaluating exp target linkage)
  (end-with-linkage linkage
   (make-instruction-sequence '() (list target)
    `((assign ,target (const ,exp))))))
(define (compile-quoted exp target linkage)
  (end-with-linkage linkage
   (make-instruction-sequence '() (list target)
    `((assign ,target (const ,(text-of-quotation exp)))))))
(define (compile-variable exp target linkage)
  (end-with-linkage linkage
   (make-instruction-sequence '(env) (list target)
    `((assign ,target 
             (op lookup-variable-value)
             (const ,exp)
             (reg env))))))
</code></pre>
<p>All these assignment instructions modify the target register, and the
one that looks up a variable needs the <code>env</code> register.</p>
<p>Assignments and definitions are handled
much as they are in the interpreter. We recursively generate code that
computes the value to be assigned to the variable, and append to it a
two-instruction sequence that actually sets or defines the variable and
assigns the value of the whole expression (the symbol <code>ok</code>) to the
target register. The recursive compilation has target <code>val</code> and linkage
<code>next</code> so that the code will put its result into <code>val</code> and continue with
the code that is appended after it. The appending is done preserving
<code>env</code>, since the environment is needed for setting or defining the
variable and the code for the variable value could be the compilation of
a complex expression that might modify the registers in arbitrary ways.</p>
<pre><code class="language-scheme editable">(define (compile-assignment exp target linkage)
  (let ((var (assignment-variable exp))
        (get-value-code
         (compile (assignment-value exp) 'val 'next)))
    (end-with-linkage linkage
     (preserving '(env)
       get-value-code
       (make-instruction-sequence '(env val) (list target)
        `((perform (op set-variable-value!) 
                   (const ,var)
                   (reg val)
                   (reg env))
          (assign ,target (const ok))))))))
(define (compile-definition exp target linkage)
  (let ((var (definition-variable exp))
        (get-value-code
         (compile (definition-value exp) 'val 'next)))
    (end-with-linkage linkage
     (preserving '(env)
       get-value-code
       (make-instruction-sequence '(env val) (list target)
        `((perform (op define-variable!) 
                   (const ,var)
                   (reg val)
                   (reg env))
          (assign ,target (const ok))))))))
</code></pre>
<p>The appended two-instruction sequence requires <code>env</code> and <code>val</code> and
modifies the target. Note that although we preserve <code>env</code> for this
sequence, we do not preserve <code>val</code>, because the <code>get-value-code</code> is
designed to explicitly place its result in <code>val</code> for use by this
sequence. (In fact, if we did preserve <code>val</code>, we would have a bug,
because this would cause the previous contents of <code>val</code> to be restored
right after the <code>get-value-code</code> is run.)</p>
<h4 id="compiling-conditional-expressions"><a class="header" href="#compiling-conditional-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_805">Compiling conditional expressions</a></a></h4>
<p>The code for an <code>if</code> expression compiled with a given
target and linkage has the form</p>
<p><code> &lt;</code><em><code>compilation of predicate, target ``val``, linkage ``next</code></em><code>&gt;</code>
<code> (test (op false?) (reg val))</code>
<code> (branch (label false-branch))</code>
<code>true-branch</code>
<code> &lt;</code><em><code>compilation of consequent with given target and given linkage or ``after-if</code></em><code>&gt;</code>
<code>false-branch</code>
<code> &lt;</code><em><code>compilation of alternative with given target and linkage</code></em><code>&gt;</code>
<code>after-if</code></p>
<p>To generate this code, we compile the predicate, consequent, and
alternative, and combine the resulting code with instructions to test
the predicate result and with newly generated labels to mark the true
and false branches and the end of the
conditional.<a href="book-Z-H-35.html#footnote_Temp_806">^[37]{.small}^</a>
In this arrangement of code, we must branch around the true branch if
the test is false. The only slight complication is in how the linkage
for the true branch should be handled. If the linkage for the
conditional is <code>return</code> or a label, then the true and false branches
will both use this same linkage. If the linkage is <code>next</code>, the true
branch ends with a jump around the code for the false branch to the
label at the end of the conditional.</p>
<pre><code class="language-scheme editable">(define (compile-if exp target linkage)
  (let ((t-branch (make-label 'true-branch))
        (f-branch (make-label 'false-branch))              
        (after-if (make-label 'after-if)))
    (let ((consequent-linkage
           (if (eq? linkage 'next) after-if linkage)))
      (let ((p-code (compile (if-predicate exp) 'val 'next))
            (c-code
             (compile
              (if-consequent exp) target consequent-linkage))
            (a-code
             (compile (if-alternative exp) target linkage)))
        (preserving '(env continue)
          p-code
          (append-instruction-sequences
           (make-instruction-sequence '(val) '()
            `((test (op false?) (reg val)) 
              (branch (label ,f-branch))))
           (parallel-instruction-sequences
            (append-instruction-sequences t-branch c-code)
            (append-instruction-sequences f-branch a-code))
           after-if)))))
</code></pre>
<p><code>Env</code> is preserved around the predicate code because it could be needed
by the true and false branches, and <code>continue</code> is preserved because it
could be needed by the linkage code in those branches. The code for the
true and false branches (which are not executed sequentially) is
appended using a special combiner <code>parallel-instruction-sequences</code>
described in section <a href="book-Z-H-35.html#%_sec_5.5.4">5.5.4</a>.</p>
<p>Note that <code>cond</code> is a derived expression, so all that the compiler needs
to do handle it is to apply the <code>cond-&gt;if</code> transformer (from
section <a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a>) and compile the resulting
<code>if</code> expression.</p>
<h4 id="compiling-sequences"><a class="header" href="#compiling-sequences"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_807">Compiling sequences</a></a></h4>
<p>The compilation of sequences (from procedure bodies or
explicit <code>begin</code> expressions) parallels their evaluation. Each
expression of the sequence is compiled -- the last expression with the
linkage specified for the sequence, and the other expressions with
linkage <code>next</code> (to execute the rest of the sequence). The instruction
sequences for the individual expressions are appended to form a single
instruction sequence, such that <code>env</code> (needed for the rest of the
sequence) and <code>continue</code> (possibly needed for the linkage at the end of
the sequence) are preserved.</p>
<pre><code class="language-scheme editable">(define (compile-sequence seq target linkage)
  (if (last-exp? seq)
      (compile (first-exp seq) target linkage)
      (preserving '(env continue)
        (compile (first-exp seq) target 'next)
        (compile-sequence (rest-exps seq) target linkage))))
</code></pre>
<h4 id="compiling-lambda-expressions"><a class="header" href="#compiling-lambda-expressions"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_808">Compiling <code>lambda</code> expressions</a></a></h4>
<p><code>Lambda</code> expressions construct procedures. The object
code for a <code>lambda</code> expression must have the form</p>
<p><code>&lt;{*construct procedure object and assign it to target register*}&gt;</code>
<code>&lt;{*linkage*}&gt;</code></p>
<p>When we compile the <code>lambda</code> expression, we also generate the code for
the procedure body. Although the body won't be executed at the time of
procedure construction, it is convenient to insert it into the object
code right after the code for the <code>lambda</code>. If the linkage for the
<code>lambda</code> expression is a label or <code>return</code>, this is fine. But if the
linkage is <code>next</code>, we will need to skip around the code for the
procedure body by using a linkage that jumps to a label that is inserted
after the body. The object code thus has the form</p>
<p><code> &lt;{*construct procedure object and assign it to target register*}&gt;</code>
<code> &lt;{*code for given linkage*}&gt;</code><em><code>or</code></em><code> (goto (label after-lambda))</code>
<code> &lt;{*compilation of procedure body*}&gt;</code>
<code>after-lambda</code></p>
<p><code>Compile-lambda</code> generates the code for constructing the procedure
object followed by the code for the procedure body. The procedure object
will be constructed at run time by combining the current environment
(the environment at the point of definition) with the entry point to the
compiled procedure body (a newly generated
label).<a href="book-Z-H-35.html#footnote_Temp_809">^[38]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (compile-lambda exp target linkage)
  (let ((proc-entry (make-label 'entry))
        (after-lambda (make-label 'after-lambda)))
    (let ((lambda-linkage
           (if (eq? linkage 'next) after-lambda linkage)))
      (append-instruction-sequences
       (tack-on-instruction-sequence
        (end-with-linkage lambda-linkage
         (make-instruction-sequence '(env) (list target)
          `((assign ,target 
                   (op make-compiled-procedure)
                   (label ,proc-entry)
                   (reg env)))))
        (compile-lambda-body exp proc-entry))
       after-lambda))))
</code></pre>
<p><code>Compile-lambda</code> uses the special combiner
<code>tack-on-instruction-sequence</code>
(section <a href="book-Z-H-35.html#%_sec_5.5.4">5.5.4</a>) rather than
<code>append-instruction-sequences</code> to append the procedure body to the
<code>lambda</code> expression code, because the body is not part of the sequence
of instructions that will be executed when the combined sequence is
entered; rather, it is in the sequence only because that was a
convenient place to put it.</p>
<p><code>Compile-lambda-body</code> constructs the code for the body of the procedure.
This code begins with a label for the entry point. Next come
instructions that will cause the run-time evaluation environment to
switch to the correct environment for evaluating the procedure body --
namely, the definition environment of the procedure, extended to include
the bindings of the formal parameters to the arguments with which the
procedure is called. After this comes the code for the sequence of
expressions that makes up the procedure body. The sequence is compiled
with linkage <code>return</code> and target <code>val</code> so that it will end by returning
from the procedure with the procedure result in <code>val</code>.</p>
<pre><code class="language-scheme editable">(define (compile-lambda-body exp proc-entry)
  (let ((formals (lambda-parameters exp)))
    (append-instruction-sequences
     (make-instruction-sequence '(env proc argl) '(env)
      `(,proc-entry 
        (assign env (op compiled-procedure-env) (reg proc))
        (assign env
                (op extend-environment)
                (const ,formals)
                (reg argl)
                (reg env))))
     (compile-sequence (lambda-body exp) 'val 'return))))
</code></pre>
<h3 id="553--compiling-combinations"><a class="header" href="#553--compiling-combinations"><a href="book-Z-H-4.html#%_toc_%_sec_5.5.3">5.5.3  Compiling Combinations</a></a></h3>
<p>The essence of the compilation process is
the compilation of procedure applications. The code for a combination
compiled with a given target and linkage has the form</p>
<p><code>&lt;{*compilation of operator, target proc, linkage next*}&gt;</code>
<code>&lt;{*evaluate operands and construct argument list in argl*}&gt;</code>
<code>&lt;{*compilation of procedure call with given target and linkage*}&gt;</code></p>
<p>The registers <code>env</code>, <code>proc</code>, and <code>argl</code> may have to be saved and
restored during evaluation of the operator and operands. Note that this
is the only place in the compiler where a target other than <code>val</code> is
specified.</p>
<p>The required code is generated by <code>compile-application</code>. This
recursively compiles the operator, to produce code that puts the
procedure to be applied into <code>proc</code>, and compiles the operands, to
produce code that evaluates the individual operands of the application.
The instruction sequences for the operands are combined (by
<code>construct-arglist</code>) with code that constructs the list of arguments in
<code>argl</code>, and the resulting argument-list code is combined with the
procedure code and the code that performs the procedure call (produced
by <code>compile-procedure-call</code>). In appending the code sequences, the <code>env</code>
register must be preserved around the evaluation of the operator (since
evaluating the operator might modify <code>env</code>, which will be needed to
evaluate the operands), and the <code>proc</code> register must be preserved around
the construction of the argument list (since evaluating the operands
might modify <code>proc</code>, which will be needed for the actual procedure
application). <code>Continue</code> must also be preserved throughout, since it is
needed for the linkage in the procedure call.</p>
<pre><code class="language-scheme editable">(define (compile-application exp target linkage)
  (let ((proc-code (compile (operator exp) 'proc 'next))
        (operand-codes
         (map (lambda (operand) (compile operand 'val 'next))
              (operands exp))))
    (preserving '(env continue)
      proc-code
      (preserving '(proc continue)
        (construct-arglist operand-codes)
        (compile-procedure-call target linkage)))))
</code></pre>
<p>The code to construct the argument list will evaluate each operand into
<code>val</code> and then <code>cons</code> that value onto the argument list being
accumulated in <code>argl</code>. Since we <code>cons</code> the arguments onto <code>argl</code> in
sequence, we must start with the last argument and end with the first,
so that the arguments will appear in order from first to last in the
resulting list. Rather than waste an instruction by initializing <code>argl</code>
to the empty list to set up for this sequence of evaluations, we make
the first code sequence construct the initial <code>argl</code>. The general form
of the argument-list construction is thus as follows:</p>
<p><code>&lt;{*compilation of last operand, targeted to val*}&gt;</code>
<code>(assign argl (op list) (reg val))</code>
<code>&lt;{*compilation of next operand, targeted to val*}&gt;</code>
<code>(assign argl (op cons) (reg val) (reg argl))</code>
<code>...</code>
<code>&lt;{*compilation of first operand, targeted to val*}&gt;</code>
<code>(assign argl (op cons) (reg val) (reg argl))</code></p>
<p><code>Argl</code> must be preserved around each operand evaluation except the first
(so that arguments accumulated so far won't be lost), and <code>env</code> must be
preserved around each operand evaluation except the last (for use by
subsequent operand evaluations).</p>
<p>Compiling this argument code is a bit tricky, because of the special
treatment of the first operand to be evaluated and the need to preserve
<code>argl</code> and <code>env</code> in different places. The <code>construct-arglist</code> procedure
takes as arguments the code that evaluates the individual operands. If
there are no operands at all, it simply emits the instruction</p>
<pre><code class="language-scheme editable">(assign argl (const ()))
</code></pre>
<p>Otherwise, <code>construct-arglist</code> creates code that initializes <code>argl</code> with
the last argument, and appends code that evaluates the rest of the
arguments and adjoins them to <code>argl</code> in succession. In order to process
the arguments from last to first, we must reverse the list of operand
code sequences from the order supplied by <code>compile-application</code>.</p>
<pre><code class="language-scheme editable">(define (construct-arglist operand-codes)
  (let ((operand-codes (reverse operand-codes)))
    (if (null? operand-codes)
        (make-instruction-sequence '() '(argl)
         '((assign argl (const ())))))
        (let ((code-to-get-last-arg
               (append-instruction-sequences
                (car operand-codes)
                (make-instruction-sequence '(val) '(argl)
                 '((assign argl (op list) (reg val)))))))
          (if (null? (cdr operand-codes))
              code-to-get-last-arg
              (preserving '(env)
                code-to-get-last-arg
                (code-to-get-rest-args
                 (cdr operand-codes))))))))
(define (code-to-get-rest-args operand-codes)
  (let ((code-for-next-arg
         (preserving '(argl)
           (car operand-codes)
           (make-instruction-sequence '(val argl) '(argl)
            '((assign argl
                    (op cons) (reg val) (reg argl)))))))
    (if (null? (cdr operand-codes))
        code-for-next-arg
        (preserving '(env)
          code-for-next-arg
          (code-to-get-rest-args (cdr operand-codes))))))
</code></pre>
<h4 id="applying-procedures"><a class="header" href="#applying-procedures"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_810">Applying procedures</a></a></h4>
<p>After evaluating the elements of a combination, the compiled code must
apply the procedure in <code>proc</code> to the arguments in <code>argl</code>. The code
performs essentially the same dispatch as the <code>apply</code> procedure in the
metacircular evaluator of section <a href="book-Z-H-26.html#%_sec_4.1.1">4.1.1</a>
or the <code>apply-dispatch</code> entry point in the explicit-control evaluator of
section <a href="book-Z-H-34.html#%_sec_5.4.1">5.4.1</a>. It checks whether the
procedure to be applied is a primitive procedure or a compiled
procedure. For a primitive procedure, it uses
<code>apply-primitive-procedure</code>; we will see shortly how it handles compiled
procedures. The procedure-application code has the following form:</p>
<p><code> (test (op primitive-procedure?) (reg proc))</code>
<code> (branch (label primitive-branch))</code>
<code>compiled-branch</code>
<code> &lt;{*code to apply compiled procedure with given target and appropriate linkage*}&gt;</code>
<code>primitive-branch</code>
<code> (assign &lt;{*target*}&gt;</code>
<code>         (op apply-primitive-procedure)</code>
<code>         (reg proc)</code>
<code>         (reg argl))</code>
<code> &lt;{*linkage*}&gt;</code>
<code>after-call</code></p>
<p>Observe that the compiled branch must skip around the primitive branch.
Therefore, if the linkage for the original procedure call was <code>next</code>,
the compound branch must use a linkage that jumps to a label that is
inserted after the primitive branch. (This is similar to the linkage
used for the true branch in <code>compile-if</code>.)</p>
<pre><code class="language-scheme editable">(define (compile-procedure-call target linkage)
  (let ((primitive-branch (make-label 'primitive-branch))
        (compiled-branch (make-label 'compiled-branch))
        (after-call (make-label 'after-call)))
    (let ((compiled-linkage
           (if (eq? linkage 'next) after-call linkage)))
      (append-instruction-sequences
       (make-instruction-sequence '(proc) '()
        `((test (op primitive-procedure?) (reg proc)) 
          (branch (label ,primitive-branch))))
       (parallel-instruction-sequences
        (append-instruction-sequences
         compiled-branch
         (compile-proc-appl target compiled-linkage))
        (append-instruction-sequences
         primitive-branch
         (end-with-linkage linkage
          (make-instruction-sequence '(proc argl)
                                     (list target)
           `((assign ,target 
                    (op apply-primitive-procedure)
                    (reg proc)
                    (reg argl)))))))
       after-call))))
</code></pre>
<p>The primitive and compound branches, like the true and false branches in
<code>compile-if</code>, are appended using <code>parallel-instruction-sequences</code> rather
than the ordinary <code>append-instruction-sequences</code>, because they will not
be executed sequentially.</p>
<h4 id="applying-compiled-procedures"><a class="header" href="#applying-compiled-procedures"><a href="book-Z-H-4.html#%_toc_%_sec_Temp_811">Applying compiled procedures</a></a></h4>
<p>The code that handles procedure application is the most subtle part of
the compiler, even though the instruction sequences it generates are
very short. A compiled procedure (as constructed by <code>compile-lambda</code>)
has an entry point, which is a label that designates where the code for
the procedure starts. The code at this entry point computes a result in
<code>val</code> and returns by executing the instruction <code>(goto (reg continue))</code>.
Thus, we might expect the code for a compiled-procedure application (to
be generated by <code>compile-proc-appl</code>) with a given target and linkage to
look like this if the linkage is a label</p>
<p><code> (assign continue (label proc-return))</code>
<code> (assign val (op compiled-procedure-entry) (reg proc))</code>
<code> (goto (reg val))</code>
<code>proc-return</code>
<code>(assign &lt;{*target*}&gt; (reg val))  </code><em><code>; included if target is not val</code></em><code> </code> (goto (label &lt;{<em>linkage</em>}&gt;))   <code>*</code>; linkage code<code>*</code></p>
<p>or like this if the linkage is <code>return</code>.</p>
<p><code> (save continue)</code>
<code> (assign continue (label proc-return))</code>
<code> (assign val (op compiled-procedure-entry) (reg proc))</code>
<code> (goto (reg val))</code>
<code>proc-return</code>
<code>(assign &lt;{*target*}&gt; (reg val))  </code><em><code>; included if target is not val</code></em><code> </code> (restore continue)<code> </code> (goto (reg continue))   <code>*</code>; linkage code<code>*</code></p>
<p>This code sets up <code>continue</code> so that the procedure will return to a
label <code>proc-return</code> and jumps to the procedure's entry point. The code
at <code>proc-return</code> transfers the procedure's result from <code>val</code> to the
target register (if necessary) and then jumps to the location specified
by the linkage. (The linkage is always <code>return</code> or a label, because
<code>compile-procedure-call</code> replaces a <code>next</code> linkage for the
compound-procedure branch by an <code>after-call</code> label.)</p>
<p>In fact, if the target is not <code>val</code>, that is exactly the code our
compiler will
generate.<a href="book-Z-H-35.html#footnote_Temp_812">^[39]{.small}^</a>
Usually, however, the target is <code>val</code> (the only time the compiler
specifies a different register is when targeting the evaluation of an
operator to <code>proc</code>), so the procedure result is put directly into the
target register and there is no need to return to a special location
that copies it. Instead, we simplify the code by setting up <code>continue</code>
so that the procedure will ''return'' directly to the place
specified by the caller's linkage:</p>
<p><code>&lt;{*set up continue for linkage*}&gt;</code>
<code>(assign val (op compiled-procedure-entry) (reg proc))</code>
<code>(goto (reg val))</code></p>
<p>If the linkage is a label, we set up <code>continue</code> so that the procedure
will return to that label. (That is, the <code>(goto (reg continue))</code> the
procedure ends with becomes equivalent to the
<code>(goto (label &lt;</code><em><code>linkage</code></em><code>&gt;))</code> at <code>proc-return</code> above.)</p>
<p><code>(assign continue (label &lt;{*linkage*}&gt;))</code>
<code>(assign val (op compiled-procedure-entry) (reg proc))</code>
<code>(goto (reg val))</code></p>
<p>If the linkage is <code>return</code>, we don't need to set up <code>continue</code> at all:
It already holds the desired location. (That is, the
<code>(goto (reg continue))</code> the procedure ends with goes directly to the
place where the <code>(goto (reg continue))</code> at <code>proc-return</code> would have
gone.)</p>
<p><code>(assign val (op compiled-procedure-entry) (reg proc))</code>
<code>(goto (reg val))</code></p>
<p>With this implementation of the <code>return</code>
linkage, the compiler generates tail-recursive code. Calling a procedure
as the final step in a procedure body does a direct transfer, without
saving any information on the stack.</p>
<p>Suppose instead that we had handled the case of a procedure call with a
linkage of <code>return</code> and a target of <code>val</code> as shown above for a non-<code>val</code>
target. This would destroy tail recursion. Our system would still give
the same value for any expression. But each time we called a procedure,
we would save <code>continue</code> and return after the call to undo the (useless)
save. These extra saves would accumulate during a nest of procedure
calls.<a href="book-Z-H-35.html#footnote_Temp_813">^[40]{.small}^</a></p>
<p><code>Compile-proc-appl</code> generates the above procedure-application code by
considering four cases, depending on whether the target for the call is
<code>val</code> and whether the linkage is <code>return</code>. Observe that the instruction
sequences are declared to modify all the registers, since executing the
procedure body can change the registers in arbitrary
ways.<a href="book-Z-H-35.html#footnote_Temp_814">^[41]{.small}^</a>
Also note that the code sequence for the case with target <code>val</code> and
linkage <code>return</code> is declared to need <code>continue</code>: Even though <code>continue</code>
is not explicitly used in the two-instruction sequence, we must be sure
that <code>continue</code> will have the correct value when we enter the compiled
procedure.</p>
<pre><code class="language-scheme editable">(define (compile-proc-appl target linkage)
  (cond ((and (eq? target 'val) (not (eq? linkage 'return)))
         (make-instruction-sequence '(proc) all-regs
          `((assign continue (label ,linkage)) 
            (assign val (op compiled-procedure-entry)
                        (reg proc))
            (goto (reg val)))))
        ((and (not (eq? target 'val))
              (not (eq? linkage 'return)))
         (let ((proc-return (make-label 'proc-return)))
           (make-instruction-sequence '(proc) all-regs
            `((assign continue (label ,proc-return)) 
              (assign val (op compiled-procedure-entry)
                          (reg proc))
              (goto (reg val))
              ,proc-return
              (assign ,target (reg val))
              (goto (label ,linkage))))))
        ((and (eq? target 'val) (eq? linkage 'return))
         (make-instruction-sequence '(proc continue) all-regs
          '((assign val (op compiled-procedure-entry)
                        (reg proc))
            (goto (reg val)))))
        ((and (not (eq? target 'val)) (eq? linkage 'return))
         (error "return linkage, target not val -- COMPILE"
                target))))
</code></pre>
<h3 id="554--combining-instruction-sequences"><a class="header" href="#554--combining-instruction-sequences"><a href="book-Z-H-4.html#%_toc_%_sec_5.5.4">5.5.4  Combining Instruction Sequences</a></a></h3>
<p>This section describes the details on how instruction
sequences are represented and combined. Recall from
section <a href="book-Z-H-35.html#%_sec_5.5.1">5.5.1</a> that an instruction
sequence is represented as a list of the registers needed, the registers
modified, and the actual instructions. We will also consider a label
(symbol) to be a degenerate case of an instruction sequence, which
doesn't need or modify any registers. So to determine the registers
needed and modified by instruction sequences we use the selectors</p>
<pre><code class="language-scheme editable">(define (registers-needed s)
  (if (symbol? s) '() (car s)))
(define (registers-modified s)
  (if (symbol? s) '() (cadr s)))
(define (statements s)
  (if (symbol? s) (list s) (caddr s)))
</code></pre>
<p>and to determine whether a given sequence needs or modifies a given
register we use the predicates</p>
<pre><code class="language-scheme editable">(define (needs-register? seq reg)
  (memq reg (registers-needed seq)))
(define (modifies-register? seq reg)
  (memq reg (registers-modified seq)))
</code></pre>
<p>In terms of these predicates and selectors, we can implement the various
instruction sequence combiners used throughout the compiler.</p>
<p>The basic combiner is <code>append-instruction-sequences</code>. This takes as
arguments an arbitrary number of instruction sequences that are to be
executed sequentially and returns an instruction sequence whose
statements are the statements of all the sequences appended together.
The subtle point is to determine the registers that are needed and
modified by the resulting sequence. It modifies those registers that are
modified by any of the sequences; it needs those registers that must be
initialized before the first sequence can be run (the registers needed
by the first sequence), together with those registers needed by any of
the other sequences that are not initialized (modified) by sequences
preceding it.</p>
<p>The sequences are appended two at a time by <code>append-2-sequences</code>. This
takes two instruction sequences <code>seq1</code> and <code>seq2</code> and returns the
instruction sequence whose statements are the statements of <code>seq1</code>
followed by the statements of <code>seq2</code>, whose modified registers are those
registers that are modified by either <code>seq1</code> or <code>seq2</code>, and whose needed
registers are the registers needed by <code>seq1</code> together with those
registers needed by <code>seq2</code> that are not modified by <code>seq1</code>. (In terms of
set operations, the new set of needed registers is the union of the set
of registers needed by <code>seq1</code> with the set difference of the registers
needed by <code>seq2</code> and the registers modified by <code>seq1</code>.) Thus,
<code>append-instruction-sequences</code> is implemented as follows:</p>
<pre><code class="language-scheme editable">(define (append-instruction-sequences . seqs)
  (define (append-2-sequences seq1 seq2)
    (make-instruction-sequence
     (list-union (registers-needed seq1)
                 (list-difference (registers-needed seq2)
                                  (registers-modified seq1)))
     (list-union (registers-modified seq1)
                 (registers-modified seq2))
     (append (statements seq1) (statements seq2))))
  (define (append-seq-list seqs)
    (if (null? seqs)
        (empty-instruction-sequence)
        (append-2-sequences (car seqs)
                            (append-seq-list (cdr seqs)))))
  (append-seq-list seqs))
</code></pre>
<p>This procedure uses some simple operations for manipulating sets
represented as lists, similar to the (unordered) set representation
described in section <a href="book-Z-H-16.html#%_sec_2.3.3">2.3.3</a>:</p>
<pre><code class="language-scheme editable">(define (list-union s1 s2)
  (cond ((null? s1) s2)
        ((memq (car s1) s2) (list-union (cdr s1) s2))
        (else (cons (car s1) (list-union (cdr s1) s2)))))
(define (list-difference s1 s2)
  (cond ((null? s1) '())
        ((memq (car s1) s2) (list-difference (cdr s1) s2))
        (else (cons (car s1)
                    (list-difference (cdr s1) s2)))))
</code></pre>
<p><code>Preserving</code>, the second major instruction sequence combiner, takes a
list of registers <code>regs</code> and two instruction sequences <code>seq1</code> and <code>seq2</code>
that are to be executed sequentially. It returns an instruction sequence
whose statements are the statements of <code>seq1</code> followed by the statements
of <code>seq2</code>, with appropriate <code>save</code> and <code>restore</code> instructions around
<code>seq1</code> to protect the registers in <code>regs</code> that are modified by <code>seq1</code>
but needed by <code>seq2</code>. To accomplish this, <code>preserving</code> first creates a
sequence that has the required <code>save</code>s followed by the statements of
<code>seq1</code> followed by the required <code>restore</code>s. This sequence needs the
registers being saved and restored in addition to the registers needed
by <code>seq1</code>, and modifies the registers modified by <code>seq1</code> except for the
ones being saved and restored. This augmented sequence and <code>seq2</code> are
then appended in the usual way. The following procedure implements this
strategy recursively, walking down the list of registers to be
preserved:<a href="book-Z-H-35.html#footnote_Temp_815">^[42]{.small}^</a></p>
<pre><code class="language-scheme editable">(define (preserving regs seq1 seq2)
  (if (null? regs)
      (append-instruction-sequences seq1 seq2)
      (let ((first-reg (car regs)))
        (if (and (needs-register? seq2 first-reg)
                 (modifies-register? seq1 first-reg))
            (preserving (cdr regs)
             (make-instruction-sequence
              (list-union (list first-reg)
                          (registers-needed seq1))
              (list-difference (registers-modified seq1)
                               (list first-reg))
              (append `((save ,first-reg)) 
                      (statements seq1)
                      `((restore ,first-reg)))) 
             seq2)
            (preserving (cdr regs) seq1 seq2)))))
</code></pre>
<p>Another sequence combiner, <code>tack-on-instruction-sequence</code>, is used by
<code>compile-lambda</code> to append a procedure body to another sequence. Because
the procedure body is not ''in line'' to be executed as part of the
combined sequence, its register use has no impact on the register use of
the sequence in which it is embedded. We thus ignore the procedure
body's sets of needed and modified registers when we tack it onto the
other sequence.</p>
<pre><code class="language-scheme editable">(define (tack-on-instruction-sequence seq body-seq)
  (make-instruction-sequence
   (registers-needed seq)
   (registers-modified seq)
   (append (statements seq) (statements body-seq))))
</code></pre>
<p><code>Compile-if</code> and <code>compile-procedure-call</code> use a special combiner called
<code>parallel-instruction-sequences</code> to append the two alternative branches
that follow a test. The two branches will never be executed
sequentially; for any particular evaluation of the test, one branch or
the other will be entered. Because of this, the registers needed by the
second branch are still needed by the combined sequence, even if these
are modified by the first branch.</p>
<pre><code class="language-scheme editable">(define (parallel-instruction-sequences seq1 seq2)
  (make-instruction-sequence
   (list-union (registers-needed seq1)
               (registers-needed seq2))
   (list-union (registers-modified seq1)
               (registers-modified seq2))
   (append (statements seq1) (statements seq2))))
</code></pre>
<h3 id="555--an-example-of-compiled-code"><a class="header" href="#555--an-example-of-compiled-code"><a href="book-Z-H-4.html#%_toc_%_sec_5.5.5">5.5.5  An Example of Compiled Code</a></a></h3>
<p>Now that we have seen all the elements of
the compiler, let us examine an example of compiled code to see how
things fit together. We will compile the definition of a recursive
<code>factorial</code> procedure by calling <code>compile</code>:</p>
<pre><code class="language-scheme editable">(compile
 '(define (factorial n)
    (if (= n 1)
        1
        (* (factorial (- n 1)) n)))
 'val
 'next)
</code></pre>
<p>We have specified that the value of the <code>define</code> expression should be
placed in the <code>val</code> register. We don't care what the compiled code does
after executing the <code>define</code>, so our choice of <code>next</code> as the linkage
descriptor is arbitrary.</p>
<p><code>Compile</code> determines that the expression is a definition, so it calls
<code>compile-definition</code> to compile code to compute the value to be assigned
(targeted to <code>val</code>), followed by code to install the definition,
followed by code to put the value of the <code>define</code> (which is the symbol
<code>ok</code>) into the target register, followed finally by the linkage code.
<code>Env</code> is preserved around the computation of the value, because it is
needed in order to install the definition. Because the linkage is
<code>next</code>, there is no linkage code in this case. The skeleton of the
compiled code is thus</p>
<p><code>  &lt;</code><em><code>save env if modified by code to compute value</code></em><code>&gt;</code>
<code>  &lt;</code><em><code>compilation of definition value, target val, linkage next</code></em><code>&gt;</code>
<code>  &lt;</code><em><code>restore env if saved above</code></em><code>&gt;</code>
<code>  (perform (op define-variable!))</code>
<code>           (const factorial)</code>
<code>           (reg val)</code>
<code>           (reg env))</code>
<code>  (assign val (const ok))</code></p>
<p>The expression that is to be compiled to produce the value for the
variable <code>factorial</code> is a <code>lambda</code> expression whose value is the
procedure that computes factorials. <code>Compile</code> handles this by calling
<code>compile-lambda</code>, which compiles the procedure body, labels it as a new
entry point, and generates the instruction that will combine the
procedure body at the new entry point with the run-time environment and
assign the result to <code>val</code>. The sequence then skips around the compiled
procedure code, which is inserted at this point. The procedure code
itself begins by extending the procedure's definition environment by a
frame that binds the formal parameter <code>n</code> to the procedure argument.
Then comes the actual procedure body. Since this code for the value of
the variable doesn't modify the <code>env</code> register, the optional <code>save</code> and
<code>restore</code> shown above aren't generated. (The procedure code at <code>entry2</code>
isn't executed at this point, so its use of <code>env</code> is irrelevant.)
Therefore, the skeleton for the compiled code becomes</p>
<p><code>  (assign val (op make-compiled-procedure))</code>
<code>              (label entry2)</code>
<code>              (reg env))</code>
<code>  (goto (label after-lambda1))</code>
<code>entry2</code>
<code>  (assign env (op compiled-procedure-env) (reg proc))</code>
<code>  (assign env (op extend-environment))</code>
<code>              (const (n))</code>
<code>              (reg argl)</code>
<code>              (reg env))</code>
<code>  &lt;</code><em><code>compilation of procedure body</code></em><code>&gt;</code>
<code>after-lambda1</code>
<code>  (perform (op define-variable!))</code>
<code>           (const factorial)</code>
<code>           (reg val)</code>
<code>           (reg env))</code>
<code>  (assign val (const ok))</code></p>
<p>A procedure body is always compiled (by <code>compile-lambda-body</code>) as a
sequence with target <code>val</code> and linkage <code>return</code>. The sequence in this
case consists of a single <code>if</code> expression:</p>
<pre><code class="language-scheme editable">(if (= n 1)
    1
    (* (factorial (- n 1)) n))
</code></pre>
<p><code>Compile-if</code> generates code that first computes the predicate (targeted
to <code>val</code>), then checks the result and branches around the true branch if
the predicate is false. <code>Env</code> and <code>continue</code> are preserved around the
predicate code, since they may be needed for the rest of the <code>if</code>
expression. Since the <code>if</code> expression is the final expression (and only
expression) in the sequence making up the procedure body, its target is
<code>val</code> and its linkage is <code>return</code>, so the true and false branches are
both compiled with target <code>val</code> and linkage <code>return</code>. (That is, the
value of the conditional, which is the value computed by either of its
branches, is the value of the procedure.)</p>
<p><code>  &lt;</code><em><code>save continue, env if modified by predicate and needed by branches</code></em><code>&gt;</code>
<code>  &lt;</code><em><code>compilation of predicate, target val, linkage next</code></em><code>&gt;</code>
<code>  &lt;</code><em><code>restore continue, env if saved above</code></em><code>&gt;</code>
<code>  (test (op false?) (reg val))</code>
<code>  (branch (label false-branch4))</code>
<code>true-branch5</code>
<code>  &lt;</code><em><code>compilation of true branch, target val, linkage return</code></em><code>&gt;</code>
<code>false-branch4</code>
<code>  &lt;</code><em><code>compilation of false branch, target val, linkage return</code></em><code>&gt;</code>
<code>after-if3</code></p>
<p>The predicate <code>(= n 1)</code> is a procedure call. This looks up the operator
(the symbol <code>=</code>) and places this value in <code>proc</code>. It then assembles the
arguments <code>1</code> and the value of <code>n</code> into <code>argl</code>. Then it tests whether
<code>proc</code> contains a primitive or a compound procedure, and dispatches to a
primitive branch or a compound branch accordingly. Both branches resume
at the <code>after-call</code> label. The requirements to preserve registers around
the evaluation of the operator and operands don't result in any saving
of registers, because in this case those evaluations don't modify the
registers in question.</p>
<p><code>  (assign proc)</code>
<code>          (op lookup-variable-value) (const =) (reg env))</code>
<code>  (assign val (const 1))</code>
<code>  (assign argl (op list) (reg val))</code>
<code>  (assign val (op lookup-variable-value) (const n) (reg env))</code>
<code>  (assign argl (op cons) (reg val) (reg argl))</code>
<code>  (test (op primitive-procedure?) (reg proc))</code>
<code>  (branch (label primitive-branch17))</code>
<code>compiled-branch16</code>
<code>  (assign continue (label after-call15))</code>
<code>  (assign val (op compiled-procedure-entry) (reg proc))</code>
<code>  (goto (reg val))</code>
<code>primitive-branch17</code>
<code>  (assign val (op apply-primitive-procedure)</code>
<code>              (reg proc)</code>
<code>              (reg argl))</code>
<code>after-call15</code></p>
<p>The true branch, which is the constant 1, compiles (with target <code>val</code>
and linkage <code>return</code>) to</p>
<p><code>  (assign val (const 1))</code>
<code>  (goto (reg continue))</code></p>
<p>The code for the false branch is another a procedure call, where the
procedure is the value of the symbol <code>*</code>, and the arguments are <code>n</code> and
the result of another procedure call (a call to <code>factorial</code>). Each of
these calls sets up <code>proc</code> and <code>argl</code> and its own primitive and compound
branches. Figure <a href="book-Z-H-35.html#%_fig_5.17">5.17</a> shows the complete
compilation of the definition of the <code>factorial</code> procedure. Notice that
the possible <code>save</code> and <code>restore</code> of <code>continue</code> and <code>env</code> around the
predicate, shown above, are in fact generated, because these registers
are modified by the procedure call in the predicate and needed for the
procedure call and the <code>return</code> linkage in the branches.</p>
<p><strong>Exercise 5.33.</strong>  Consider the following definition of
a factorial procedure, which is slightly different from the one given
above:</p>
<pre><code class="language-scheme editable">(define (factorial-alt n)
  (if (= n 1)
      1
      (* n (factorial-alt (- n 1)))))
</code></pre>
<p>Compile this procedure and compare the resulting code with that produced
for <code>factorial</code>. Explain any differences you find. Does either program
execute more efficiently than the other?</p>
<p><strong>Exercise
5.34.</strong>  Compile the iterative factorial
procedure</p>
<pre><code class="language-scheme editable">(define (factorial n)
  (define (iter product counter)
    (if (&gt; counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
</code></pre>
<p>Annotate the resulting code, showing the essential difference between
the code for iterative and recursive versions of <code>factorial</code> that makes
one process build up stack space and the other run in constant stack
space.</p>
<p><em><code>;; construct the procedure and skip over code for the procedure body</code></em><code> </code>  (assign val)<code> </code>          (op make-compiled-procedure) (label entry2) (reg env))<code> </code>  (goto (label after-lambda1))`</p>
<p><code>entry2     </code><em><code>; calls to factorial will enter here</code></em><code> </code>  (assign env (op compiled-procedure-env) (reg proc))<code> </code>  (assign env)<code> </code>          (op extend-environment) (const (n)) (reg argl) (reg env))<code> *</code>;; begin actual procedure body<code>*</code>
<code>  (save continue))</code>
<code>  (save env))</code></p>
<p><em><code>;; compute (= n 1)</code></em><code> </code>  (assign proc (op lookup-variable-value) (const =) (reg env))<code> </code>  (assign val (const 1))<code> </code>  (assign argl (op list) (reg val))<code> </code>  (assign val (op lookup-variable-value) (const n) (reg env))<code> </code>  (assign argl (op cons) (reg val) (reg argl))<code> </code>  (test (op primitive-procedure?) (reg proc))<code> </code>  (branch (label primitive-branch17))<code> </code>compiled-branch16<code> </code>  (assign continue (label after-call15))<code> </code>  (assign val (op compiled-procedure-entry) (reg proc))<code> </code>  (goto (reg val))<code> </code>primitive-branch17<code> </code>  (assign val (op apply-primitive-procedure) (reg proc) (reg argl))`</p>
<p><code>after-call15   </code><em><code>; val now contains result of (= n 1)</code></em><code> </code>  (restore env))<code> </code>  (restore continue))<code> </code>  (test (op false?) (reg val))<code> </code>  (branch (label false-branch4))<code> </code>true-branch5  <code>*</code>; return 1<code>*</code>
<code>  (assign val (const 1))</code>
<code>  (goto (reg continue))</code></p>
<p><code>false-branch4</code>
<em><code>;; compute and return (* (factorial (- n 1)) n)</code></em><code> </code>  (assign proc (op lookup-variable-value) (const <em>) (reg env))<code> </code>  (save continue))<code> </code>  (save proc)   <code>*</code>; save * procedure<code>*</code>
<code>  (assign val (op lookup-variable-value) (const n) (reg env))</code>
<code>  (assign argl (op list) (reg val))</code>
<code> (save argl)  </code></em><code>; save partial argument list for *</code>*`</p>
<p><em><code>;; compute (factorial (- n 1)), which is the other argument for *</code></em><code> </code>  (assign proc)<code> </code>          (op lookup-variable-value) (const factorial) (reg env))<code> </code>  (save proc)  <code>*</code>; save factorial procedure<code>*</code></p>
<p><strong>Figure 5.17:</strong>  Compilation of the definition of the <code>factorial</code>
procedure (continued on next page).</p>
<p><em><code>;; compute (- n 1), which is the argument for factorial</code></em><code> </code>  (assign proc (op lookup-variable-value) (const -) (reg env))<code> </code>  (assign val (const 1))<code> </code>  (assign argl (op list) (reg val))<code> </code>  (assign val (op lookup-variable-value) (const n) (reg env))<code> </code>  (assign argl (op cons) (reg val) (reg argl))<code> </code>  (test (op primitive-procedure?) (reg proc))<code> </code>  (branch (label primitive-branch8))<code> </code>compiled-branch7<code> </code>  (assign continue (label after-call6))<code> </code>  (assign val (op compiled-procedure-entry) (reg proc))<code> </code>  (goto (reg val))<code> </code>primitive-branch8<code> </code>  (assign val (op apply-primitive-procedure) (reg proc) (reg argl))`</p>
<p><code>after-call6   </code><em><code>; val now contains result of (- n 1)</code></em><code> </code>  (assign argl (op list) (reg val))<code> </code>  (restore proc) <code>*</code>; restore factorial<code>*</code>
<em><code>;; apply factorial</code></em><code> </code>  (test (op primitive-procedure?) (reg proc))<code> </code>  (branch (label primitive-branch11))<code> </code>compiled-branch10<code> </code>  (assign continue (label after-call9))<code> </code>  (assign val (op compiled-procedure-entry) (reg proc))<code> </code>  (goto (reg val))<code> </code>primitive-branch11<code> </code>  (assign val (op apply-primitive-procedure) (reg proc) (reg argl))`</p>
<p><code>after-call9      </code><em><code>; val now contains result of (factorial (- n 1))</code></em><code> </code>  (restore argl) <code>*</code>; restore partial argument list for <em><code>*</code>
<code>  (assign argl (op cons) (reg val) (reg argl))</code>
<code> (restore proc)</code></em><code>; restore *</code>*<code> </code>  (restore continue))<code> *</code>;; apply * and return its value<code> </code>  (test (op primitive-procedure?) (reg proc))<code> </code>  (branch (label primitive-branch14))<code> </code>compiled-branch13<code> *</code>;; note that a compound procedure here is called tail-recursively<code>*</code>
<code>  (assign val (op compiled-procedure-entry) (reg proc))</code>
<code>  (goto (reg val))</code>
<code>primitive-branch14</code>
<code>  (assign val (op apply-primitive-procedure) (reg proc) (reg argl))</code>
<code>  (goto (reg continue))</code>
<code>after-call12</code>
<code>after-if3</code>
<code>after-lambda1</code>
<em><code>;; assign the procedure to the variable factorial</code></em><code> </code>  (perform)<code> </code>   (op define-variable!) (const factorial) (reg val) (reg env))<code> </code>  (assign val (const ok))`</p>
<p><strong>Figure 5.17:</strong>  (continued)</p>
<p><strong>Exercise 5.35.</strong>  What expression was compiled to
produce the code shown in figure <a href="book-Z-H-35.html#%_fig_5.18">5.18</a>?</p>
<p><code>  (assign val (op make-compiled-procedure) (label entry16))</code>
<code>                                           (reg env))</code>
<code>  (goto (label after-lambda15))</code>
<code>entry16</code>
<code>  (assign env (op compiled-procedure-env) (reg proc))</code>
<code>  (assign env)</code>
<code>          (op extend-environment) (const (x)) (reg argl) (reg env))</code>
<code>  (assign proc (op lookup-variable-value) (const +) (reg env))</code>
<code>  (save continue))</code>
<code>  (save proc))</code>
<code>  (save env))</code>
<code>  (assign proc (op lookup-variable-value) (const g) (reg env))</code>
<code>  (save proc))</code>
<code>  (assign proc (op lookup-variable-value) (const +) (reg env))</code>
<code>  (assign val (const 2))</code>
<code>  (assign argl (op list) (reg val))</code>
<code>  (assign val (op lookup-variable-value) (const x) (reg env))</code>
<code>  (assign argl (op cons) (reg val) (reg argl))</code>
<code>  (test (op primitive-procedure?) (reg proc))</code>
<code>  (branch (label primitive-branch19))</code>
<code>compiled-branch18</code>
<code>  (assign continue (label after-call17))</code>
<code>  (assign val (op compiled-procedure-entry) (reg proc))</code>
<code>  (goto (reg val))</code>
<code>primitive-branch19</code>
<code>  (assign val (op apply-primitive-procedure) (reg proc) (reg argl))</code>
<code>after-call17</code>
<code>  (assign argl (op list) (reg val))</code>
<code>  (restore proc))</code>
<code>  (test (op primitive-procedure?) (reg proc))</code>
<code>  (branch (label primitive-branch22))</code>
<code>compiled-branch21</code>
<code>  (assign continue (label after-call20))</code>
<code>  (assign val (op compiled-procedure-entry) (reg proc))</code>
<code>  (goto (reg val))</code>
<code>primitive-branch22</code>
<code>  (assign val (op apply-primitive-procedure) (reg proc) (reg argl))</code></p>
<p><strong>Figure 5.18:</strong>  An example of compiler output (continued on next
page). See exercise <a href="book-Z-H-35.html#%_thm_5.35">5.35</a>.</p>
<p><code>after-call20</code>
<code>  (assign argl (op list) (reg val))</code>
<code>  (restore env))</code>
<code>  (assign val (op lookup-variable-value) (const x) (reg env))</code>
<code>  (assign argl (op cons) (reg val) (reg argl))</code>
<code>  (restore proc))</code>
<code>  (restore continue))</code>
<code>  (test (op primitive-procedure?) (reg proc))</code>
<code>  (branch (label primitive-branch25))</code>
<code>compiled-branch24</code>
<code>  (assign val (op compiled-procedure-entry) (reg proc))</code>
<code>  (goto (reg val))</code>
<code>primitive-branch25</code>
<code>  (assign val (op apply-primitive-procedure) (reg proc) (reg argl))</code>
<code>  (goto (reg continue))</code>
<code>after-call23</code>
<code>after-lambda15</code>
<code>  (perform (op define-variable!) (const f) (reg val) (reg env))</code>
<code>  (assign val (const ok))</code></p>
<p><strong>Figure 5.18:</strong>  (continued)</p>
<p><strong>Exercise 5.36.</strong>  What
order of evaluation does our compiler produce for operands of a
combination? Is it left-to-right, right-to-left, or some other order?
Where in the compiler is this order determined? Modify the compiler so
that it produces some other order of evaluation. (See the discussion of
order of evaluation for the explicit-control evaluator in
section <a href="book-Z-H-34.html#%_sec_5.4.1">5.4.1</a>.) How does changing the
order of operand evaluation affect the efficiency of the code that
constructs the argument list?</p>
<p><strong>Exercise 5.37.</strong>  One
way to understand the compiler's <code>preserving</code> mechanism for optimizing
stack usage is to see what extra operations would be generated if we did
not use this idea. Modify <code>preserving</code> so that it always generates the
<code>save</code> and <code>restore</code> operations. Compile some simple expressions and
identify the unnecessary stack operations that are generated. Compare
the code to that generated with the <code>preserving</code> mechanism intact.</p>
<p><strong>Exercise 5.38.</strong>  Our
compiler is not very clever. For example, it does not understand that
<code>(f 3)</code> is a call to the procedure <code>f</code> with argument 3, but rather treats
it as a general application. The general <code>compile-application</code> code sets
up <code>argl</code> and <code>proc</code> and then determines that the procedure is compound,
at which point it pushes <code>continue</code>, sets <code>continue</code> to a new value, and
goes to the procedure's entry point. A better strategy for <code>(f 3)</code> would
be to compile it as</p>
<p><code>(assign argl (const (3)))</code>
<code>(assign proc (op lookup-variable-value) (const f) (reg env))</code>
<code>(assign continue (label &lt;</code><em><code>linkage</code></em><code>&gt;))</code>
<code>(assign val (op compiled-procedure-entry) (reg proc))</code>
<code>(goto (reg val))</code></p>
<p>if the linkage is a label, or as</p>
<p><code>(assign argl (const (3)))</code>
<code>(assign proc (op lookup-variable-value) (const f) (reg env))</code>
<code>(assign val (op compiled-procedure-entry) (reg proc))</code>
<code>(goto (reg val))</code></p>
<p>if the linkage is <code>return</code>. This strategy doesn't require a <code>test</code> for
primitive versus compound procedures, and it doesn't require saving
<code>continue</code>. Modify the compiler to incorporate this optimization. To do
this you will have to modify <code>compile-application</code> to recognize the case
where the operator is a symbol and to dispatch to a special code
generator for this case. Also, this optimization cannot be used for any
procedure, because some procedures must be called by the general
<code>apply</code> mechanism of the interpreter. For example, <code>(apply f '(1 2))</code>
must be handled by the interpreter's <code>apply</code> procedure, not by jumping
directly to the entry point of the procedure <code>f</code>. To handle this, we
will stipulate that only procedures with a fixed number of arguments can
be called in this way. The <code>lambda</code> syntax we have been using specifies
procedures with a fixed number of arguments, so we can identify the
procedures to which the optimization is applicable by looking at the
<code>lambda</code> expression.</p>
<p><strong>Exercise 5.48.</strong>  The optimization of
exercise <a href="book-Z-H-35.html#%_thm_5.47">5.47</a> is effective because we can
determine at compile time that the operator is a symbol, and therefore
we know that its value will be a procedure. We can extend this optimization
by noticing that if the operator is a <code>lambda</code> expression, then we have
the procedure itself at compile time. A clever compiler can produce code
that completely avoids the overhead of constructing the procedure object
at run time and applying it. Instead, the compiler can generate code for
the procedure body directly, with the arguments substituted for the
parameters. For example, compiling</p>
<pre><code class="language-scheme editable">((lambda (x y) (+ x y)) 3 4)
</code></pre>
<p>could generate the same code as compiling <code>(+ 3 4)</code>. This is a version
of the optimization called <em>in-line expansion</em>.</p>
<p>a. Extend the compiler to incorporate in-line expansion. To do this,
modify <code>compile-application</code> to check if the operator of a combination
is a <code>lambda</code> expression. If so, it should compile the combination as
follows: First compile the operands of the combination. Then compile the
procedure body with the linkage of the original combination, in a new
compile-time environment where the procedure parameters are bound to
<em>temporary storage</em>. The values of the operands should be loaded into
the temporary storage before the procedure body is executed. You will
have to invent a mechanism for allocating and managing temporary
storage.</p>
<p>b. The implementation in part a is still not as good as it could be,
because the values of the operands are still computed and stored in
temporary storage, only to be immediately fetched as the values of the
parameters. A better implementation would substitute the code for the
operands directly into the body of the procedure in place of references
to the parameters. For example, the code for</p>
<pre><code class="language-scheme editable">((lambda (x y) (+ x y)) 3 4)
</code></pre>
<p>would be the same as for <code>(+ 3 4)</code>. And the code for</p>
<pre><code class="language-scheme editable">((lambda (x) (* x x)) (+ y 1))
</code></pre>
<p>would be the same as for <code>(* (+ y 1) (+ y 1))</code>. Implement this version of
in-line expansion. You will have to be careful about how you handle
substitutions for variables that appear more than once in the procedure
body.</p>
<p><strong>Exercise 5.49.</strong>  The compiler can also
be made to operate on programs that use the explicit-control evaluator's
data structures. This will allow us to compile the evaluator of
section <a href="book-Z-H-34.html#%_sec_5.4">5.4</a> to produce an object-code
version of the evaluator that can be run on the evaluator machine. Set
up a system that can do this. You will have to supply the compiler with
a library of primitive procedures for manipulating lists and vectors.
You will also have to arrange for the machine to be able to <code>get</code> and
<code>set!</code> the contents of the machine registers. One way to do this is to
represent the machine registers as a vector, as we did for the stack in
section <a href="book-Z-H-32.html#%_sec_5.2.3">5.2.3</a>.</p>
<hr />
<p>^[33]{.small}^](book-Z-H-35.html#call_footnote_Temp_794)
This is a deep idea. The fact that a single machine can be programmed to
carry out any computation that can be carried out by any other machine
is the basis for the great flexibility of the general-purpose computer.
The idea of a universal computational machine was first clearly
formulated by Alan Turing in 1936. In his seminal paper, Turing presented
a simple computational model -- now called a Turing machine -- and
argued that any ''effective process'' can be formulated as a program
for such a machine. He then implemented a universal machine, i.e., a
Turing machine that behaves as an evaluator for Turing-machine programs.
(See footnote <a href="book-Z-H-26.html#footnote_Temp_553">19</a> in
chapter 4.)</p>
<p>^[34]{.small}^](book-Z-H-35.html#call_footnote_Temp_795)
The explicit-control evaluator machine is itself a register machine,
described in a register-machine language. We can thus think of the
compiler as a program that translates Scheme programs into programs in
the register-machine language.</p>
<p>^[35]{.small}^](book-Z-H-35.html#call_footnote_Temp_797)
We will assume that the syntax procedures have been augmented to support
any new special forms that our compiler will handle, such as <code>let</code>
(exercise <a href="book-Z-H-26.html#%_thm_4.6">4.6</a>).</p>
<p>^[36]{.small}^](book-Z-H-35.html#call_footnote_Temp_803)
The <code>compile-linkage</code> procedure uses the <code>quasiquote</code> syntax described
in section <a href="book-Z-H-17.html#%_sec_2.4.1">2.4.1</a>. For example,
<code>((goto (label ,linkage)))</code> is our way of writing
<code>(list '(goto (label 'try-again)))</code> if the value of <code>linkage</code> is the
symbol <code>try-again</code>.</p>
<p>^[37]{.small}^](book-Z-H-35.html#call_footnote_Temp_806)
The labels are created using <code>make-label</code> from the register-machine
simulator (section <a href="book-Z-H-32.html#%_sec_5.2.2">5.2.2</a>).</p>
<p>^[38]{.small}^](book-Z-H-35.html#call_footnote_Temp_809)
The compiler needs to be able to mention the run-time environment in the
code it emits. It does this by means of the <code>make-compiled-procedure</code>
operation. This is an operation that will be executed by the evaluator
machine. We can implement it as a new primitive procedure for the
evaluator machine. <code>Make-compiled-procedure</code> takes a label and an
environment and returns a procedure object that contains the label and
the environment. We also need corresponding selectors
<code>compiled-procedure-entry</code> and <code>compiled-procedure-env</code> and a predicate
<code>compiled-procedure?</code> (to be used in the evaluator's <code>apply-dispatch</code>).
The implementation of these procedure-representation operations is given
in section <a href="book-Z-H-35.html#%_sec_5.5.7">5.5.7</a>.</p>
<p>^[39]{.small}^](book-Z-H-35.html#call_footnote_Temp_812)
The compiler uses <code>all-regs</code> to indicate that all registers are modified
by a procedure call. <code>All-regs</code> is a list of all the registers used by
the evaluator machine: <code>(env proc val continue argl)</code>.</p>
<p>^[40]{.small}^](book-Z-H-35.html#call_footnote_Temp_813)
This is a subtle but important point about tail recursion. See
exercise <a href="book-Z-H-34.html#%_thm_5.26">5.26</a>.</p>
<p>^[41]{.small}^](book-Z-H-35.html#call_footnote_Temp_814)
This is not quite true. A procedure does not modify the <code>continue</code>
register. But the compiler must act as if any register might be modified,
unless it has specific knowledge about the procedure being called.
Exercises <a href="book-Z-H-35.html#%_thm_5.47">5.47</a>
and <a href="book-Z-H-35.html#%_thm_5.48">5.48</a> explore this issue.</p>
<p>^[42]{.small}^](book-Z-H-35.html#call_footnote_Temp_815)
The implementation of <code>preserving</code> shown here is inefficient because it
walks down the list of registers to be preserved and generates a separate
<code>save</code>/<code>restore</code> pair for each register. A more realistic implementation
would generate a single instruction to save all the registers on the
stack and a single instruction to restore them. We have not provided
such instructions in our register-machine language in order to keep the
language simple.</p>
<p>^[43]{.small}^](book-Z-H-35.html#call_footnote_Temp_822)
We assume here that the primitive operations of the machine can take
constants as arguments.</p>
<p>^[44]{.small}^](book-Z-H-35.html#call_footnote_Temp_823)
This is not the best way to design a compiler. With this approach, the
list of reserved words will be different for the compiler and the
interpreter, and the languages they accept will therefore be different.
This will make it difficult to debug the compiler, since programs that
run on the interpreter may not run on the compiled-code machine. A better
approach is to have the compiler determine which names are names of
primitives by looking them up in the compile-time environment. If the
compiler finds that a name is bound to a primitive procedure object, it
can generate open code for that primitive. This is another example of
the advantages of using compile-time environments, as discussed in
section <a href="book-Z-H-35.html#%_sec_5.5.6">5.5.6</a>.</p>
<p>^[45]{.small}^](book-Z-H-35.html#call_footnote_Temp_824)
This is true if we consider only <code>lambda</code> and application. Special forms
such as <code>let</code> can be handled by viewing them as syntactic sugar for
<code>lambda</code> and application, as in
section <a href="book-Z-H-26.html#%_sec_4.1.2">4.1.2</a>. <code>Define</code> is more
problematic. See exercise <a href="book-Z-H-35.html#%_thm_5.43">5.43</a>.</p>
<p>^[46]{.small}^](book-Z-H-35.html#call_footnote_Temp_826)
We need to check for <code>*unassigned*</code> because the <code>letrec</code> implementation
in exercise <a href="book-Z-H-26.html#%_thm_4.20">4.20</a> uses this to ensure that
variables are not used before they are assigned values.</p>
<p>^[47]{.small}^](book-Z-H-35.html#call_footnote_Temp_830)
The global environment is the one part of the run-time environment that
is shared by all parts of a program. In a typical Lisp system, the
global environment is used to hold bindings for the library of primitive
procedures. We do not want to have to recompile all of these procedures
each time we compile a user's program. Instead, we can require that
global variables be looked up in the ordinary way, so that primitive
names can be bound in the global environment and these bindings can be
shared by all compiled and interpreted code.</p>
<p>^[48]{.small}^](book-Z-H-35.html#call_footnote_Temp_833)
We assume that the machine operations <code>compiled-procedure?</code>,
<code>compiled-procedure-entry</code>, and <code>compiled-procedure-env</code> have been added
to the explicit-control evaluator.</p>
<p>^[49]{.small}^](book-Z-H-35.html#call_footnote_Temp_834)
We assume that the <code>branch</code> instruction has been modified to check the
<code>flag</code> register rather than the result of a <code>test</code> instruction.</p>
<p>^[50]{.small}^](book-Z-H-35.html#call_footnote_Temp_835)
The <code>print-result</code> entry point is the same as the one at the end of
<code>read-eval-print-loop</code> in
section <a href="book-Z-H-34.html#%_sec_5.4.4">5.4.4</a>.</p>
<p>^[51]{.small}^](book-Z-H-35.html#call_footnote_Temp_837)
The compiler we have implemented here is, like our interpreters, written
in Lisp. This is not a necessary feature of a compiler. There is no
reason why a compiler for a language L~1~ cannot be written in a language
L~2~ that is different from L~1~. For example, the first Lisp compiler was
an assembly-language program that ran on the IBM 704.</p>
<p>^[52]{.small}^](book-Z-H-35.html#call_footnote_Temp_838)
This is not to say that a compiler must produce code that is less
intelligible than an interpretation. Good compilers for use in
interactive development environments are designed to make the object code
as intelligible as possible. For example, the variables in the object
code may be the same as the source-code variables, and the instruction-level
procedure calls may be organized to parallel the source-code procedure
calls. This permits the user to examine and modify the object code and
to trace its execution in terms of the source language.</p>
<p>Compilers for popular languages, such as C and C++, put
hardly any error-checking operations into running code, so as to make
things run as fast as possible. As a result, it falls to programmers to
explicitly provide error checking. Unfortunately, people often neglect
to do this, even in critical applications where speed is not a
constraint. Their programs lead fast and dangerous lives. For example,
the notorious ''Worm'' that paralyzed the Internet in
1988 exploited the UNIX ^<em>TM</em>^ operating system's
failure to check whether the input buffer has overflowed
in the finger daemon. (See Spafford 1989.)</p>
<p>^[53]{.small}^](book-Z-H-35.html#call_footnote_Temp_839)
Of course, with either the interpretation or the compilation strategy we
must also implement for the new machine storage allocation, input and
output, and all the various operations that we took as ''primitive''
in our discussion of the evaluator and compiler. One strategy for
minimizing work here is to write as many of these operations as possible
in Lisp and then compile them for the new machine. Ultimately,
everything reduces to a small kernel (such as garbage collection and the
mechanism for applying actual machine primitives) that is hand-coded for
the new machine.</p>
<p>^[54]{.small}^](book-Z-H-35.html#call_footnote_Temp_840)
This is an instance of the process of <em>bootstrapping</em> a language. See
exercise <a href="book-Z-H-26.html#%_thm_4.1">4.1</a> in chapter 4.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="./highlight.js"></script>
        <script src="./src/languages/scheme.min.js"></script>
        <script src="./biwascheme.min.js"></script>
        <script src="./biwascheme_run_logic.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
